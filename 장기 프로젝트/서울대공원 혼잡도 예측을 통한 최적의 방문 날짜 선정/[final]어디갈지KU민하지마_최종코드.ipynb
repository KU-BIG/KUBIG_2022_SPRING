{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[최종 코드]",
      "provenance": [],
      "collapsed_sections": [
        "oCBtV1-icF1Q",
        "L1r4wcDGinzN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 라이브러리 불러오기"
      ],
      "metadata": {
        "id": "0adlVdOdZfgs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdNLB3vkZSsR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 불러오기"
      ],
      "metadata": {
        "id": "jsJfDl-FZe57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train= pd.read_csv(\"/content/drive/Shareddrives/22-1 KUBIG 장기프로젝트/최종프로젝트/train_서울대공원_혼잡도예측_프로젝트.csv\")\n",
        "test=pd.read_csv(\"/content/drive/Shareddrives/22-1 KUBIG 장기프로젝트/최종프로젝트/test_서울대공원_혼잡도예측_프로젝트.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbCYY7YGZkeU",
        "outputId": "72ba57e2-58ba-433b-bf99-87589a79de61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# K-MEANS"
      ],
      "metadata": {
        "id": "i95JpMizvDD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이용자 수 분류 목적"
      ],
      "metadata": {
        "id": "O54CDL_zauIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_y=train[['입장객 수']]\n",
        "#임시휴원 있는 행 삭제\n",
        "spac=train_y[train_y['입장객 수']=='임시휴원'].index\n",
        "train_y.drop(spac,inplace=True)\n",
        "\n",
        "train_y = train_y.astype({'입장객 수':'float64'})      \n",
        "\n",
        "#변수명 영어로\n",
        "train_y=train_y.rename(columns={\"입장객 수\":\"Attendance\"})\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "#k-means#################################################\n",
        "k = 3\n",
        "\n",
        "# 그룹 수, random_state 설정\n",
        "model = KMeans(n_clusters = k, random_state = 10)\n",
        "\n",
        "# 정규화된 데이터에 학습\n",
        "model.fit(train_y)\n",
        "\n",
        "# 클러스터링 결과 각 데이터가 몇 번째 그룹에 속하는지 저장\n",
        "train_y['cluster'] = model.fit_predict(train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZB_KUoRvInL",
        "outputId": "3a1dbd7f-e12f-413c-86d2-dd1b35b53480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.loc[train_y['cluster'] == 0, 'cluster'] = 'slack' #여유\n",
        "train_y.loc[train_y['cluster'] == 1, 'cluster'] = 'normal' #보통\n",
        "train_y.loc[train_y['cluster'] == 2, 'cluster'] = 'crowded'  #혼잡\n",
        "\n",
        "cluster0=train_y[train_y['cluster']=='slack']['Attendance']\n",
        "cluster1=train_y[train_y['cluster']=='normal']['Attendance']\n",
        "cluster2=train_y[train_y['cluster']=='crowded']['Attendance']\n",
        "\n",
        "print(f'한산은 {cluster0.max()} 이하, 보통은 {cluster0.max()} 초과 {cluster1.max()} 이하, 혼잡은 {cluster1.max()} 초과')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYogt8eivKbH",
        "outputId": "bf6dec7a-c38a-4be0-b667-ae3da3895408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한산은 9312.0 이하, 보통은 9312.0 초과 23117.0 이하, 혼잡은 23117.0 초과\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x='Attendance',y=\"cluster\",hue=\"cluster\", data=train_y, palette=\"Set2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "MGMl7qFZvLtK",
        "outputId": "1d2adc3a-8301-44b2-a937-bfe5ee1ab6be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f115a21f510>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train+test 데이터 통합\n",
        "\n",
        "같이 전처리 후 분할 예정\n",
        "\n",
        "ntrain/ntest 저장을 위해 행 삭제하는 전처리 미리 진행"
      ],
      "metadata": {
        "id": "oCBtV1-icF1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#임시휴원 있는 행 삭제\n",
        "spac=train[train['입장객 수']=='임시휴원'].index\n",
        "train.drop(spac,inplace=True)\n",
        "\n",
        "#test data의 y값 '정보없음' 행 삭제\n",
        "test=test.drop([249])\n",
        "\n",
        "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
        "\n",
        "ntrain = train.shape[0]\n",
        "ntest = test.shape[0]\n"
      ],
      "metadata": {
        "id": "ms10sloPaCFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 정제"
      ],
      "metadata": {
        "id": "Gq_3CITKMGTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#날짜 분리하여 새로운 변수 만들기\n",
        "all_data[['년','월','일']] = all_data['날짜'].str.split('-', expand=True)\n",
        "all_data.drop(['날짜'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "#임시휴원 있는 행 삭제\n",
        "spac=all_data[all_data['입장객 수']=='임시휴원'].index\n",
        "all_data.drop(spac,inplace=True)\n",
        "\n",
        "\n",
        "#미세먼지 농도 - -> NAN값 처리\n",
        "all_data['미세먼지 농도']=all_data['미세먼지 농도'].replace('-', np.NaN)\n",
        "\n",
        "#공휴일 여부 -> 0,1로 변환\n",
        "all_data['공휴일여부']=all_data['공휴일여부'].replace(np.NaN, 0)\n",
        "all_data['공휴일여부']=all_data['공휴일여부'].replace('공휴일', 1)\n",
        "\n",
        "#'쉬는날여부' 제거, '주말여부' 파생변수 생성\n",
        "all_data.drop('쉬는날여부', axis = 1, inplace = True)\n",
        "all_data['주말여부'] = np.where((all_data['요일'] == '토') | (all_data['요일'] == '일'), 1, 0)"
      ],
      "metadata": {
        "id": "zi2HhEs9MUzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#변수 영어로 바꾸기\n",
        "all_data.columns = ['Day','Season','Pub_holiday','Vacation','Precipitation_accum','Humidity_avg','Attendance','Get_off_subway','Fine_dust_concentration',\n",
        "                 'L_Temperature','H_Temperature','A_Temperature','Year','Month','Date','Weekend']\n",
        "\n",
        "#변수 영어로 바꾸기2\n",
        "all_data = all_data.replace({'Day' : '월'},'Mon')\n",
        "all_data = all_data.replace({'Day' : '화'},'Tue')\n",
        "all_data = all_data.replace({'Day' : '수'},'Wed')\n",
        "all_data = all_data.replace({'Day' : '목'},'Thu')\n",
        "all_data = all_data.replace({'Day' : '금'},'Fri')\n",
        "all_data = all_data.replace({'Day' : '토'},'Sat')\n",
        "all_data = all_data.replace({'Day' : '일'},'Sun')\n",
        "\n",
        "all_data = all_data.replace({'Season' : '봄'},'Spring')\n",
        "all_data = all_data.replace({'Season' : '여름'},'Summer')\n",
        "all_data = all_data.replace({'Season' : '가을'},'fall')\n",
        "all_data = all_data.replace({'Season' : '겨울'},'Winter')   "
      ],
      "metadata": {
        "id": "XivWqF1YNXGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "L1r4wcDGinzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = all_data[:ntrain]\n",
        "#데이터 타입 바꾸기\n",
        "train = train.astype({'Year':'int'})\n",
        "train = train.astype({'Month':'int'})\n",
        "train = train.astype({'Date':'int'})\n",
        "train = train.astype({'Fine_dust_concentration':'float64'})\n",
        "train = train.astype({'Attendance':'float64'})    \n",
        "#변수정렬\n",
        "train=train[['Year','Month','Date','Day','Season','Pub_holiday','Vacation','Precipitation_accum','Humidity_avg','Attendance','Get_off_subway','Fine_dust_concentration',\n",
        "                 'L_Temperature','H_Temperature','A_Temperature','Weekend']]"
      ],
      "metadata": {
        "id": "2POECOXkOVCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape); print(test.shape) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oejoy2AGirK7",
        "outputId": "ecc7aae7-eadb-42d1-d948-b7325f899ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(994, 16)\n",
            "(364, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "입장객과 대공원역 하차자수의 분포 비교"
      ],
      "metadata": {
        "id": "lTZWcQUgLo51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots_adjust(left=0.125,\n",
        "                    bottom=0.1, \n",
        "                    right=2, \n",
        "                    top=0.9, \n",
        "                    wspace=0.2, \n",
        "                    hspace=0.35)\n",
        "plt.subplot(121)\n",
        "sns.distplot(train[\"Attendance\"], color=\"yellow\")\n",
        "plt.subplot(122)\n",
        "sns.distplot(train[\"Get_off_subway\"], color=\"green\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "RBz5p7MNLrUC",
        "outputId": "aa8b853f-4649-4180-f9e8-3e012e28197c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y의 요약통계량\n",
        "train['Attendance'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhZtY2VjOhHU",
        "outputId": "c7ae5ba2-cbd1-4dff-e1af-532ee7478499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count      994.000000\n",
              "mean      6948.727364\n",
              "std       8413.125054\n",
              "min        128.000000\n",
              "25%       1430.000000\n",
              "50%       3339.000000\n",
              "75%       8543.500000\n",
              "max      56576.000000\n",
              "Name: Attendance, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3~MAX 사이의 일부 입장객 수 정보"
      ],
      "metadata": {
        "id": "6C_A1G9pPX-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train[train['Attendance']>8543.5]\n",
        "#공휴일과 주말에 입장객이 엄청 많다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "U7mKfW94PNd8",
        "outputId": "be1c5b76-186b-494e-9399-695dc8583af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Year  Month  Date  Day  Season  Pub_holiday  Vacation  \\\n",
              "40   2016      2    10  Wed  Winter            1         0   \n",
              "65   2016      3     6  Sun  Spring            0         0   \n",
              "67   2016      3     8  Tue  Spring            0         0   \n",
              "78   2016      3    19  Sat  Spring            0         0   \n",
              "79   2016      3    20  Sun  Spring            0         0   \n",
              "..    ...    ...   ...  ...     ...          ...       ...   \n",
              "922  2018     10    21  Sun    fall            0         0   \n",
              "927  2018     10    26  Fri    fall            0         0   \n",
              "928  2018     10    27  Sat    fall            0         0   \n",
              "935  2018     11     3  Sat    fall            0         0   \n",
              "936  2018     11     4  Sun    fall            0         0   \n",
              "\n",
              "     Precipitation_accum  Humidity_avg  Attendance  Get_off_subway  \\\n",
              "40                   0.0     45.041667      9949.0          7664.0   \n",
              "65                   0.0     50.875000     11564.0          6197.0   \n",
              "67                   0.0     40.791667     11521.0          2997.0   \n",
              "78                   0.0     61.583333     33131.0         15698.0   \n",
              "79                   0.0     55.250000     34360.0         12699.0   \n",
              "..                   ...           ...         ...             ...   \n",
              "922                  0.0     63.750000     21054.0          9972.0   \n",
              "927                 11.0     65.000000     14283.0          9486.0   \n",
              "928                  4.0     57.208333     21256.0         13015.0   \n",
              "935                  0.0     66.875000     16625.0         11957.0   \n",
              "936                  0.0     62.416667     15903.0          9472.0   \n",
              "\n",
              "     Fine_dust_concentration  L_Temperature  H_Temperature  A_Temperature  \\\n",
              "40                      41.0           -1.5       9.100000       2.929167   \n",
              "65                      89.0            4.5      12.400000       7.741667   \n",
              "67                      76.0           -1.8       5.000000       1.691667   \n",
              "78                      76.0            3.0      16.200001       9.795833   \n",
              "79                      81.0            3.3      16.000000       9.591667   \n",
              "..                       ...            ...            ...            ...   \n",
              "922                     38.0            5.1      20.200001      11.070833   \n",
              "927                     32.0            7.8      14.300000      11.254167   \n",
              "928                     27.0            2.6      11.800000       7.579167   \n",
              "935                     52.0            2.0      19.299999       8.954167   \n",
              "936                     38.0            3.5      19.100000      10.025000   \n",
              "\n",
              "     Weekend  \n",
              "40         0  \n",
              "65         1  \n",
              "67         0  \n",
              "78         1  \n",
              "79         1  \n",
              "..       ...  \n",
              "922        1  \n",
              "927        0  \n",
              "928        1  \n",
              "935        1  \n",
              "936        1  \n",
              "\n",
              "[249 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-920fdbe8-5e40-4b6f-9e31-3d1bc8798eb7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Date</th>\n",
              "      <th>Day</th>\n",
              "      <th>Season</th>\n",
              "      <th>Pub_holiday</th>\n",
              "      <th>Vacation</th>\n",
              "      <th>Precipitation_accum</th>\n",
              "      <th>Humidity_avg</th>\n",
              "      <th>Attendance</th>\n",
              "      <th>Get_off_subway</th>\n",
              "      <th>Fine_dust_concentration</th>\n",
              "      <th>L_Temperature</th>\n",
              "      <th>H_Temperature</th>\n",
              "      <th>A_Temperature</th>\n",
              "      <th>Weekend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>Wed</td>\n",
              "      <td>Winter</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.041667</td>\n",
              "      <td>9949.0</td>\n",
              "      <td>7664.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>9.100000</td>\n",
              "      <td>2.929167</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>2016</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>Sun</td>\n",
              "      <td>Spring</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.875000</td>\n",
              "      <td>11564.0</td>\n",
              "      <td>6197.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>12.400000</td>\n",
              "      <td>7.741667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>2016</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>Tue</td>\n",
              "      <td>Spring</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.791667</td>\n",
              "      <td>11521.0</td>\n",
              "      <td>2997.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.691667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>2016</td>\n",
              "      <td>3</td>\n",
              "      <td>19</td>\n",
              "      <td>Sat</td>\n",
              "      <td>Spring</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>61.583333</td>\n",
              "      <td>33131.0</td>\n",
              "      <td>15698.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.200001</td>\n",
              "      <td>9.795833</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>2016</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>Sun</td>\n",
              "      <td>Spring</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55.250000</td>\n",
              "      <td>34360.0</td>\n",
              "      <td>12699.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>9.591667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>922</th>\n",
              "      <td>2018</td>\n",
              "      <td>10</td>\n",
              "      <td>21</td>\n",
              "      <td>Sun</td>\n",
              "      <td>fall</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>63.750000</td>\n",
              "      <td>21054.0</td>\n",
              "      <td>9972.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>20.200001</td>\n",
              "      <td>11.070833</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>2018</td>\n",
              "      <td>10</td>\n",
              "      <td>26</td>\n",
              "      <td>Fri</td>\n",
              "      <td>fall</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>14283.0</td>\n",
              "      <td>9486.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>14.300000</td>\n",
              "      <td>11.254167</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>2018</td>\n",
              "      <td>10</td>\n",
              "      <td>27</td>\n",
              "      <td>Sat</td>\n",
              "      <td>fall</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>57.208333</td>\n",
              "      <td>21256.0</td>\n",
              "      <td>13015.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>11.800000</td>\n",
              "      <td>7.579167</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>2018</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>Sat</td>\n",
              "      <td>fall</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.875000</td>\n",
              "      <td>16625.0</td>\n",
              "      <td>11957.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.299999</td>\n",
              "      <td>8.954167</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>2018</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>Sun</td>\n",
              "      <td>fall</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62.416667</td>\n",
              "      <td>15903.0</td>\n",
              "      <td>9472.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>19.100000</td>\n",
              "      <td>10.025000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>249 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-920fdbe8-5e40-4b6f-9e31-3d1bc8798eb7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-920fdbe8-5e40-4b6f-9e31-3d1bc8798eb7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-920fdbe8-5e40-4b6f-9e31-3d1bc8798eb7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "요일별 입장객수 비교"
      ],
      "metadata": {
        "id": "XE8-1pfZRIG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_groupby = train.groupby(by='Day')\n",
        "train_groupby_mean=train_groupby.mean().sort_values(by=['Attendance'],ascending=False)\n",
        "sns.barplot(x=train_groupby_mean.index ,y='Attendance',data=train_groupby_mean)\n",
        "\n",
        "#Q. 어떤 요일에 서울대공원을 방문하면 좋을까?\n",
        "#주말과 금요일에 사람들이 가장 많이 방문(나머지는 대동소이)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "2OdRaEpRREWf",
        "outputId": "23d2098c-a5c9-494c-801d-0b247fd01587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff80b594190>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "요일별 공휴일의 수 비교"
      ],
      "metadata": {
        "id": "u3awAUw9QFjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_public_holiday=train[train['Pub_holiday']==1]\n",
        "#공휴일에 방문자가 많을텐데, 요일의 관계를 알고싶으면 공휴일 역시 고려해야되지 않을까?-> 공휴일이 월화수목에 많다\n",
        "#Attendance의 평균이 6948임을 고려할때, 요일에 상관없이 모든 공휴일의 방문객 수의 평균이 이를 넘었다. 즉 공휴일(주말x)에 평소보다 사람이 더 많이 옴을 확인 \n",
        "#종합적으로 고려해보았을때 평상시에는 금토일에 더 많은 비율의 사람이 몰릴 것이라 예상(밑에서 알 수 있듯이 주말을 제외한 공휴일에 주말보다 많은 방문객을 확인\n",
        "#즉 공휴일이 아닌 평일에는 훨씬 더 적은 방문객임을 알 수 있다) \n",
        "print(train_public_holiday['Day'].value_counts())\n",
        "train_public_holiday.groupby(by='Day').mean().sort_values(by=['Attendance'],ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "0ZsQW1g7QDyl",
        "outputId": "69598570-456b-47f1-881e-4427e06b761d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue    9\n",
            "Mon    8\n",
            "Wed    7\n",
            "Thu    5\n",
            "Fri    4\n",
            "Sat    3\n",
            "Sun    2\n",
            "Name: Day, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Year     Month       Date  Pub_holiday  Vacation  \\\n",
              "Day                                                            \n",
              "Sat  2017.333333  4.000000  12.000000          1.0  0.000000   \n",
              "Thu  2017.000000  5.800000   8.200000          1.0  0.000000   \n",
              "Fri  2016.750000  4.250000   9.500000          1.0  0.250000   \n",
              "Wed  2017.142857  7.142857   7.857143          1.0  0.142857   \n",
              "Sun  2017.000000  9.500000  16.000000          1.0  0.000000   \n",
              "Tue  2017.222222  7.222222  12.777778          1.0  0.222222   \n",
              "Mon  2016.750000  7.250000  11.375000          1.0  0.375000   \n",
              "\n",
              "     Precipitation_accum  Humidity_avg    Attendance  Get_off_subway  \\\n",
              "Day                                                                    \n",
              "Sat             6.166667     46.194444  29298.333333    16958.000000   \n",
              "Thu             0.080000     54.725000  22122.400000    13415.600000   \n",
              "Fri             4.275000     57.708333  21094.250000    10860.250000   \n",
              "Wed             0.014286     60.136905  18081.000000    10960.428571   \n",
              "Sun             0.000000     54.395833  17262.000000     8141.500000   \n",
              "Tue            12.766667     67.611111  14953.777778     9163.777778   \n",
              "Mon             0.012500     63.609375  14364.375000     8269.125000   \n",
              "\n",
              "     Fine_dust_concentration  L_Temperature  H_Temperature  A_Temperature  \\\n",
              "Day                                                                         \n",
              "Sat                44.333333       7.566667      16.600000      11.669444   \n",
              "Thu                37.250000       7.260000      15.740000      11.182500   \n",
              "Fri                54.750000       4.900000      15.075000      10.586458   \n",
              "Wed                39.857143      13.000000      24.914286      18.418452   \n",
              "Sun                24.000000       9.050000      20.950000      14.983333   \n",
              "Tue                28.666667       7.955556      15.444444      11.221759   \n",
              "Mon                32.000000       8.600000      17.737500      12.948438   \n",
              "\n",
              "     Weekend  \n",
              "Day           \n",
              "Sat      1.0  \n",
              "Thu      0.0  \n",
              "Fri      0.0  \n",
              "Wed      0.0  \n",
              "Sun      1.0  \n",
              "Tue      0.0  \n",
              "Mon      0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18fc59ea-41f7-403d-aff2-71b208e5b81c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Date</th>\n",
              "      <th>Pub_holiday</th>\n",
              "      <th>Vacation</th>\n",
              "      <th>Precipitation_accum</th>\n",
              "      <th>Humidity_avg</th>\n",
              "      <th>Attendance</th>\n",
              "      <th>Get_off_subway</th>\n",
              "      <th>Fine_dust_concentration</th>\n",
              "      <th>L_Temperature</th>\n",
              "      <th>H_Temperature</th>\n",
              "      <th>A_Temperature</th>\n",
              "      <th>Weekend</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Day</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Sat</th>\n",
              "      <td>2017.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.166667</td>\n",
              "      <td>46.194444</td>\n",
              "      <td>29298.333333</td>\n",
              "      <td>16958.000000</td>\n",
              "      <td>44.333333</td>\n",
              "      <td>7.566667</td>\n",
              "      <td>16.600000</td>\n",
              "      <td>11.669444</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Thu</th>\n",
              "      <td>2017.000000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>8.200000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>54.725000</td>\n",
              "      <td>22122.400000</td>\n",
              "      <td>13415.600000</td>\n",
              "      <td>37.250000</td>\n",
              "      <td>7.260000</td>\n",
              "      <td>15.740000</td>\n",
              "      <td>11.182500</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fri</th>\n",
              "      <td>2016.750000</td>\n",
              "      <td>4.250000</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>4.275000</td>\n",
              "      <td>57.708333</td>\n",
              "      <td>21094.250000</td>\n",
              "      <td>10860.250000</td>\n",
              "      <td>54.750000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>15.075000</td>\n",
              "      <td>10.586458</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wed</th>\n",
              "      <td>2017.142857</td>\n",
              "      <td>7.142857</td>\n",
              "      <td>7.857143</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.014286</td>\n",
              "      <td>60.136905</td>\n",
              "      <td>18081.000000</td>\n",
              "      <td>10960.428571</td>\n",
              "      <td>39.857143</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>24.914286</td>\n",
              "      <td>18.418452</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sun</th>\n",
              "      <td>2017.000000</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.395833</td>\n",
              "      <td>17262.000000</td>\n",
              "      <td>8141.500000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>9.050000</td>\n",
              "      <td>20.950000</td>\n",
              "      <td>14.983333</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tue</th>\n",
              "      <td>2017.222222</td>\n",
              "      <td>7.222222</td>\n",
              "      <td>12.777778</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>12.766667</td>\n",
              "      <td>67.611111</td>\n",
              "      <td>14953.777778</td>\n",
              "      <td>9163.777778</td>\n",
              "      <td>28.666667</td>\n",
              "      <td>7.955556</td>\n",
              "      <td>15.444444</td>\n",
              "      <td>11.221759</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mon</th>\n",
              "      <td>2016.750000</td>\n",
              "      <td>7.250000</td>\n",
              "      <td>11.375000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>63.609375</td>\n",
              "      <td>14364.375000</td>\n",
              "      <td>8269.125000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>8.600000</td>\n",
              "      <td>17.737500</td>\n",
              "      <td>12.948438</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18fc59ea-41f7-403d-aff2-71b208e5b81c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18fc59ea-41f7-403d-aff2-71b208e5b81c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18fc59ea-41f7-403d-aff2-71b208e5b81c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds=pd.DataFrame(train_public_holiday['Day'].value_counts())\n",
        "sns.barplot(x=ds.index ,y=ds['Day'],data=ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "9DS1u0y1QQEU",
        "outputId": "ae94b5d1-be10-45b0-cdc1-08fbd4fd6ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff80ad07d10>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "입장객 수 비교: 공휴일(주말 제외) vs 주말 vs 평일(공휴일 제외)"
      ],
      "metadata": {
        "id": "FIrs3P2xQkNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#그렇다면 공휴일(주말 제외) vs 주말 vs 평일(공휴일 제외) 의 방문객수의 평균 중 어떤 때가 더 많을까?\n",
        "train_weekend= train.loc[(train['Day'] == 'Sat') | (train['Day'] == 'Sun'),['Attendance','Day']]\n",
        "print(train_weekend['Attendance'].mean()) #주말 평균 12489\n",
        "a=train_weekend['Attendance'].mean()\n",
        "#공휴일(주말제외)\n",
        "train_pubholi=train.loc[(train['Pub_holiday'] == 1) & (train['Day'] != 'Sat')& (train['Day'] != 'Sun'),['Attendance','Day']]\n",
        "print(train_pubholi['Attendance'].mean()) #17304 #예상외로 주말을 제외한 공휴일에 주말보다 방문객이 더 많았다(어린이날 등의 영향일듯)\n",
        "b=train_pubholi['Attendance'].mean()\n",
        "\n",
        "#평일(공휴일제외)\n",
        "train_day=train.loc[(train['Pub_holiday'] == 0) & (train['Day'] != 'Sat')& (train['Day'] != 'Sun'),['Attendance','Day']]\n",
        "print(train_day['Attendance'].mean())  #4107 예상대로 가장 적음\n",
        "c=train_day['Attendance'].mean()\n",
        "\n",
        "sns.barplot(x=['Holiday','Weekend','Weekday'] ,y=[b,a,c])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "oKNYfYJdQmPb",
        "outputId": "5429a450-1875-489b-be88-d6d89a2eed01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12489.982456140351\n",
            "17304.696969696968\n",
            "4107.004437869822\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff80b90a410>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "계절별/방학별 입장객 수는?"
      ],
      "metadata": {
        "id": "e2ChOVCMRbLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_groupby = train.groupby(by='Season')\n",
        "train_groupby_mean=train_groupby.mean().sort_values(by=['Attendance'],ascending=False)\n",
        "\n",
        "plt.subplots_adjust(left=0.125,\n",
        "                    bottom=0.1, \n",
        "                    right=2, \n",
        "                    top=0.9, \n",
        "                    wspace=0.2, \n",
        "                    hspace=0.35)\n",
        "plt.subplot(121)\n",
        "sns.barplot(x=train_groupby_mean.index ,y='Attendance',data=train_groupby_mean)\n",
        "#봄-가을-여름-겨울 순\n",
        "\n",
        "train_groupby1 = train.groupby(by='Vacation')\n",
        "train_groupby1_mean=train_groupby1.mean().sort_values(by=['Attendance'],ascending=False)\n",
        "\n",
        "plt.subplot(122)\n",
        "sns.barplot(x=train_groupby1_mean.index ,y='Attendance',data=train_groupby1_mean)\n",
        "#(여름/겨울)방학이 아닐때 오히려 더 많은 방문객 수\n",
        "\n",
        "## 학생들의 방학이 방문객 수에 큰 영향을 끼치지 않은 것으로 파악(중고등학생들의 방문이 적음을 유추)->실제 데이터에서 어린이/청소년의 방문이 예상외로 적다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "KGDfiBbORdVv",
        "outputId": "d8f0256b-a795-49b9-c16c-807bc50c36d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff80b4eb610>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "년별/달별 입장객 수"
      ],
      "metadata": {
        "id": "3wFo6rPqRkgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_groupby = train.groupby(by='Year')\n",
        "train_groupby_mean=train_groupby.mean().sort_values(by=['Attendance'],ascending=False)\n",
        "\n",
        "plt.subplots_adjust(left=0.125,\n",
        "                    bottom=0.1, \n",
        "                    right=2, \n",
        "                    top=0.9, \n",
        "                    wspace=0.2, \n",
        "                    hspace=0.35)\n",
        "plt.subplot(121)\n",
        "sns.barplot(x=train_groupby_mean.index ,y='Attendance',data=train_groupby_mean)\n",
        "#년도별 비교는 큰 의미 없을듯\n",
        "\n",
        "train_groupby1 = train.groupby(by='Month')\n",
        "train_groupby1_mean=train_groupby1.mean().sort_values(by=['Attendance'],ascending=False)\n",
        "\n",
        "plt.subplot(122)\n",
        "sns.barplot(x=train_groupby1_mean.index ,y='Attendance',data=train_groupby1_mean)\n",
        "\n",
        "#4,5,10월이 높음-> 봄,가을-> 선선한 날씨의 영향일듯\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "kZv4c9YKRpd5",
        "outputId": "65089b7b-aca0-4177-d2ee-1a8388b1b4e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff80ac5c590>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "절기별 운영시간의 차이 분석"
      ],
      "metadata": {
        "id": "KeCyRZY4RrFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_1=train.loc[(train['Month'] == 3) | (train['Month'] == 4)| (train['Month'] == 9)| (train['Month'] == 10),['Attendance','Day']]\n",
        "train_2=train.loc[(train['Month'] == 5) | (train['Month'] == 8)| (train['Month'] == 6)| (train['Month'] == 7),['Attendance','Day']]\n",
        "train_3=train.loc[(train['Month'] == 11) | (train['Month'] == 12)| (train['Month'] == 1)| (train['Month'] == 2),['Attendance','Day']]\n",
        " \n",
        "print(train_1['Attendance'].mean()) #간절기\n",
        "a=train_1['Attendance'].mean()\n",
        "print(train_2['Attendance'].mean()) #하절기\n",
        "b=train_2['Attendance'].mean()\n",
        "print(train_3['Attendance'].mean()) #동절기\n",
        "c= train_3['Attendance'].mean()\n",
        "\n",
        "sns.barplot(x=['3.4,9,10','5,6,7,8','11,12,1,2'] ,y=[a,b,c])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "E-zR_DJQRyQv",
        "outputId": "4a1febdb-70b2-44aa-d85d-dad74c61177f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10188.112759643916\n",
            "7526.723577235773\n",
            "2417.6388888888887\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff80b64d0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "수치형 변수 단변수 분포 확인"
      ],
      "metadata": {
        "id": "tvGEwa0MR90_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots_adjust(left=0.125,\n",
        "                    bottom=0.1, \n",
        "                    right=2, \n",
        "                    top=0.9, \n",
        "                    wspace=0.2, \n",
        "                    hspace=0.35)\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(331)\n",
        "sns.scatterplot(x='Precipitation_accum', y= 'Attendance', data= train,marker='+',ci=99)  #강수량이 늘어날수록 입장객 감소(강수량의 영향)\n",
        "plt.subplot(332)\n",
        "sns.scatterplot(x='Humidity_avg', y= 'Attendance', data= train,marker='+',ci=99) #습도가 높아질수록 입장객의 감소하나 그 영향이 미비함\n",
        "plt.subplot(333) \n",
        "sns.scatterplot(x='Fine_dust_concentration', y= 'Attendance', data= train,marker='+',ci=99) #미세먼지 31~80 정도가 보통인데 아무래도 미세먼지가 높으면 입장객 감소\n",
        "plt.subplot(334)\n",
        "sns.scatterplot(x='L_Temperature', y= 'Attendance', data= train, marker='+',ci=99) #\n",
        "plt.subplot(335)\n",
        "sns.scatterplot(x='H_Temperature', y= 'Attendance', data= train, marker='+',ci=99) #\n",
        "plt.subplot(336)\n",
        "sns.scatterplot(x='A_Temperature', y= 'Attendance', data= train, marker='+',ci=99) #최저,최고,평균 기온보다 볼록한 분포->일정 온도 이상 입장객 증가했다가 그 후 다시 감소\n",
        "plt.subplot(337)\n",
        "sns.scatterplot(x='Get_off_subway', y= 'Attendance', data= train, marker='+',ci=99) #대공원역 하차자 수와는 명확한 양의 상관"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "v6STk88OR_bR",
        "outputId": "71ea792a-da18-4461-bc08-7b3cc86bd8d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff80a801cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 7 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "히트맵 확인"
      ],
      "metadata": {
        "id": "gaVFFxn2SRyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(train.corr()))\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(train.corr(), mask=mask, cmap=cmap,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()\n",
        "\n",
        "#Attendance 쪽을 보면 모든 수치형변수들이 양의 관계를 가지지만 '하차자수'를 제외하면 그 영향이 그리 크지 않음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "yxZaSd1-STAY",
        "outputId": "45a921ef-e425-4b3f-fb57-6f28627e8447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "피어슨 상관분석(대공원역 하차자 수vs 입장객수)"
      ],
      "metadata": {
        "id": "66z6VB6bSaKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "rho, p_val = stats.pearsonr(train['Attendance'], train['Get_off_subway'])\n",
        "print(\"correlation coefficient : {}, p-value : {}\".format(rho,p_val))\n",
        "\n",
        "#귀무가설 기각(상관계수=0)-> 대공원역 하차자수와 입장객 사이의 높은 양의 상관을 검증할 수 있다. 즉 대공원역 하차자가 많을수록 입장객이 증가한다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrSe4EhTSgSZ",
        "outputId": "0929be3b-d05d-4e48-bc56-66be29caf6c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correlation coefficient : 0.868898425844079, p-value : 3.19515523031619e-305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Factor analysis"
      ],
      "metadata": {
        "id": "yF5jUKBMSWbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train=train.dropna(axis=0)"
      ],
      "metadata": {
        "id": "6Kn9yLOJSYJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_num=train[['Precipitation_accum','Humidity_avg','Get_off_subway','Fine_dust_concentration','L_Temperature','H_Temperature','A_Temperature']]\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "train_std = pd.DataFrame(scaler.fit_transform(train_num), columns=train_num.columns, index=train_num.index) "
      ],
      "metadata": {
        "id": "rvI-cyafS7BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca= PCA(n_components=5)\n",
        "pca_fit=pca.fit(train_std)\n",
        "\n",
        "#scree plot\n",
        "plt.title('Scree Plot')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.plot(pca.explained_variance_ratio_,'o-')\n",
        "pca.explained_variance_ratio_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "G5gpqFz7TOAm",
        "outputId": "64540d74-2e3f-4a78-984a-3987cced0001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.48897834, 0.2100101 , 0.119117  , 0.10686878, 0.06943051])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgcZbn+8e89k5lksq8s2RdISEC2DIiAbAcOSySggqKiggL+jkQFBIWDCyIux4gi4kEWV1ARkcMOYUcUwUxYAgmELCZkARJIJoEkJJnM8/ujqkNnmKUnmZ6e6b4/19XXdFdVVz1TSfcz71v1vo8iAjMzK11lhQ7AzMwKy4nAzKzEORGYmZU4JwIzsxLnRGBmVuKcCMzMSpwTgVkHIek0SX8vdBxWepwIrGhJOljSE5JWS1op6R+S9itwTJdI2iTpbUm1aXwf2Ib9PCrpjHzEaKXHicCKkqTewF3Az4H+wBDgO8CGVu6nS9tHx58joicwCPg7cKsk5eE4ZjlxIrBiNRYgIv4UEZsjYn1E3B8RMzMbSDpT0ouS3pI0W9K+6fKFkr4uaSawVlIXSQekf73XSnpO0mFZ++kj6VeSXpW0VNJlkspbCjAiNgG/A3YCBjRcL+lASdPTFs10SQemy78HfBC4Km1ZXLVdZ8pKnhOBFauXgc2SfifpWEn9sldKOhm4BPgM0BuYDLyZtckngElAX2BH4G7gMpLWxfnAXyUNSrf9LVAH7ALsA/wn0GK3jaSuwGnA4oh4o8G6/ukxryRJEj8B7pY0ICIuBh4HpkREz4iYksP5MGuSE4EVpYhYAxwMBHAdsELSHZJ2TDc5A/hRREyPxLyIWJS1iysjYnFErAdOBe6JiHsioj4iHgBqgOPS/R0HnBMRayNiOfBT4JRmwvuYpFpgMTAR+HAj20wC5kbEDRFRFxF/Al4Cjt/GU2LWpHz0f5p1CBHxIslf3EjaDbgRuILkr/1hwPxm3r446/kI4GRJ2V/CFcAj6boK4NWsbv6yBu9v6OaIOLWF8AcDixosW0RyrcOsTTkRWEmIiJck/Rb4QrpoMTCmubdkPV8M3BARZzbcSNLOJBegB0ZEXRuFC7CMJMlkGw7c10h8ZtvFXUNWlCTtJumrkoamr4eRtASeTDe5Hjhf0kQldpHU8Is340bgeElHSyqX1E3SYZKGRsSrwP3A5ZJ6SyqTNEbSodv5K9wDjJX0yfRi9ceBCSR3QgG8DozezmOYAU4EVrzeAt4PPCVpLUkCeAH4KkBE/AX4HvDHdNvbSC4Ev0dELAZOAP4bWEHSQriAdz8/nwEqgdnAKuAWYOftCT4i3gQ+lMb7JvA14ENZF5V/BpwkaZWkK7fnWGZyYRozs9LmFoGZWYlzIjAzK3FOBGZmJc6JwMysxHW6cQQDBw6MkSNHFjoMM7NOZcaMGW9ExKDG1nW6RDBy5EhqamoKHYaZWaciqeFI9S3y2jUk6RhJcyTNk3RhI+tPk7RC0rPpw/Orm5m1s7y1CNJpeH8BHAUsAaZLuiMiZjfY9M+ePdHMrHDy2SLYH5gXEQsiYiNwE8noTDMz60DymQiGsPUMjEtofObEj0qaKemWdD6Y95B0lqQaSTUrVqzIR6xmZiWr0LeP3gmMjIg9gQdIqjW9R0RcGxHVEVE9aFCjF73NzGwb5fOuoaUkc75nDE2XbZFOrJVxPfCjfARy2zNLmTptDstq1zO4bxUXHD2OE/fxtO5mZpDfFsF0YFdJoyRVklRsuiN7g3Qu94zJwIttHcRtzyzlolufZ2ntegJYWruei259ntueWdrie83MSkHeEkFapGMKMI3kC/7miJgl6VJJk9PNvixplqTngC+TVpNqS1OnzWH9ps1bLVu/aTNTp81p60OZmXVKeR1QFhH3kBTYyF72raznFwEX5TOGZbXrW7XczKzUFPpicd4N7lvVquVmZqWm6BPBBUePo6qifKtlXcrEBUePK1BEZmYdS6eba6i1MncHZe4a6tqljPoIDhwzoMCRmZl1DEWfCCBJBpmEsPCNtfznT//Gj6bN4ccn71XgyMzMCq/ou4YaGjmwB587eBS3zFjCc4trCx2OmVnBlVwiAJhyxC4M6tWVS+6cRX19FDocM7OCKslE0LNrF7529DieeaWW25/zwDIzK20lmQgAPrrvUPYa2ocf3vsSazfUFTocM7OCKdlEUFYmvnX87ry+ZgNXPzq/0OGYmRVMySYCgIkj+vHhfYZw7eMLWLxyXaHDMTMriJJOBABfP2Y3yiW+d3ebz3dnZtYplHwi2KlPN84+fAz3zXqNJ+a9UehwzMzaXcknAoAzPjiaof2quPSu2dRtri90OGZm7cqJAOhWUc43Jo3npdfe4k/TF7f8BjOzIuJEkDp69534wOgB/OT+OdSu21jocMzM2o0TQUoS3zp+AqvXb+KKB+cWOhwzs3bjRJBl/M69+eT7h3PDk4t4+fW3Ch2OmVm7cCJo4KtHjaNn1y58967ZRHgeIjMrfk4EDfTrUcm5R+7K43Pf4MEXlxc6HDOzvHMiaMSnDhjBrjv05LK7Z7OhbnPLbzAz68ScCBpRUV7Gt46fwKI31/Hrvy8sdDhmZnnlRNCED+46iCPH78hVD89l+Zp3Ch2OmVne5JQIJFVJKrlq79+YNJ5Nm4MfTZtT6FDMzPKmxUQg6XjgWeC+9PXeku7Id2AdgctamlkpyKVFcAmwP1ALEBHPAqPyGFOHkl3W0reTmlkxyiURbIqI1Q2Wlcw3YnZZy9uedVlLMys+uSSCWZI+CZRL2lXSz4En8hxXh+KylmZWzHJJBF8Cdgc2AH8EVgPn5DOojsZlLc2smLWYCCJiXURcHBH7pY9vRETJ3U/pspZmVqxyuWvoAUl9s173kzQtv2F1TJmylt+/x2Utzax45NI1NDAittw7GRGrgB3yF1LHlSlree8Lr/HEfJe1NLPikEsiqJc0PPNC0ghK6K6hhraUtbzTZS3NrDjkkgguBv4u6QZJNwJ/Ay7Kb1gdl8tamlmxyeVi8X3AvsCfgZuAiRFRktcIMlzW0syKSa6TznUFVgJrgAmSDslfSB2fy1qaWTHp0tIGkv4H+DgwC8h0igdJF1HJyi5r+cn3D2fsjr0KHZKZ2TbJpUVwIjAuIiZFxPHpY3K+A+sMzjtqHD0qy13W0sw6tVwSwQKgIt+BdEb9e1Ry3lFjXdbSzDq1XBLBOuBZSddIujLzyGXnko6RNEfSPEkXNrPdRyWFpOpcA+8oXNbSzDq7XBLBHcB3SSaam5H1aJakcuAXwLHABOATkiY0sl0v4CvAU7mH3XFkl7X8zT8WFjocM7NWa/FicUT8bhv3vT8wLyIWAEi6CTgBmN1gu+8C/wNcsI3HKbhMWcufPzSXj+wzhB16dyt0SGZmOctlrqFdJd0iabakBZlHDvseAmSPuFqSLsve977AsIi4u4UYzpJUI6lmxYoVORy6/X1j0ng2bq53WUsz63Ry6Rr6DXA1UAccDvweuHF7DyypDPgJ8NWWto2IayOiOiKqBw0atL2HzguXtTSzziqXRFAVEQ8BiohFEXEJMCmH9y0FhmW9Hpouy+gF7AE8KmkhcABwR2e8YJzxpSN2dVlLM+t0ckkEG9K/3udKmiLpw0DPHN43HdhV0ihJlcApJBeeAYiI1RExMCJGRsRI4ElgckTUtP7X6Biyy1re/uyyQodjZpaTXBLBV4DuwJeBicCngc+29KaIqAOmANOAF4GbI2KWpEslFe2AtI/uO5Q9h/bhB/e+6LKWZtYpqLN1YVRXV0dNTcduNMxYtIqPXv0EUw7fhfOPHlfocMzMkDQjIhrtem/y9lFJV0TEOZLupJH6A55momkTR/TjxL0Hc+3jC/j4fsMY1r97oUMyM2tSc+MIbkh//rg9Aik2Fx47nmmzXuf797zI1adOLHQ4ZmZNajIRRMSMdHTwWRHxqXaMqShkylr++P6XeWL+Gxw4ZmChQzIza1SzF4sjYjMwIr3rx1rJZS3NrDPIdfbRf0j6pqTzMo98B1YMulWUc/FxLmtpZh1bLolgPnBXum2vrIfl4Jg9duKA0f1d1tLMOqxcJp37TnsEUqwk8e3jd2fSlY9zxYNzuWTy7oUOycxsK7lMOjdI0lRJ90h6OPNoj+CKRXZZy7mvv1XocMzMtpJL19AfgJeAUcB3gIUk00dYK2TKWl7qspZm1sHkkggGRMSvgE0R8VhEfA44Is9xFZ3+PSo512UtzawDyiURbEp/vippkqR9gP55jKloneqylmbWATWZCCRlCtZfJqkPSd2A84HrgXPbIbai47KWZtYRNdciWCrpemA9sCYiXoiIwyNiYkTc0cz7rBnZZS2Xv/VOocMxM2s2EYwnuSj8DWCxpJ9JOqB9wipuW8pa3ueylmZWeE0mgoh4MyKuiYjDSQrRLwB+Kmm+pO+1W4RFyGUtzawjyeViMRGxDPgVSe3it4Az8hlUKZhy+C4M7OmylmZWeM0mAkndJJ0s6VZgHsltoxcCg9sjuGLWq1sFXz/GZS3NrPCau2voj8ArwMdIBpWNjIjTIuK+dFZS204ua2lmHUFzLYL7gDERcXJE/DUifItLGysrS+Yhen3NBq5+dH6hwzGzEtXcxeLfR4Qnxsmz7LKWi1euK3Q4ZlaCcrpYbPn19WN3o1zi+/e8WOhQzKwEORF0ADv3qeLsw8dw7wuv8cT8NwodjpmVmCbrEUj6SHNvjIhb2z6c0nXGB0dz0/TFXHrnbO760sF0KXeONrP20dy3zfHp4/MkYwg+lT6uBz6X/9BKi8tamlmhNHex+PSIOB2oACZExEcj4qPA7ukya2Mua2lmhZBL/8OwiHg16/XrwPA8xVPSMmUtV6/fxBUPzi10OGZWInJJBA9JmibpNEmnAXcDD+Y3rNLlspZm1t5aTAQRMQX4JbBX+rg2Ir6U78BKmctamll7yvXWlKeBuyPiXGCapF55jKnkuaylmbWnFhOBpDOBW4Br0kVDgNvyGZQlZS13cVlLM2sHubQIzgYOAtYARMRcYId8BmVpWcsPuaylmeVfLolgQ0RsuZdRUhfAHdft4JCxLmtpZvmXSyJ4TNJ/A1WSjgL+AtyZ37AsI1PWcqrLWppZnuSSCC4EVgDPA18A7iGpY2ztIFPW8i8ua2lmeZLL7aP1EXFdWpfgpPS5u4bakctamlk+5XLX0EGSHpD0sqQFkv4taUF7BGeJXt0q+JrLWppZnuTSNfQr4CfAwcB+QHX609rRSS5raWZ5kksiWB0R90bE8oh4M/PIe2S2leyylr98zGUtzazt5JIIHpE0VdIHJO2beeSyc0nHSJojaZ6kCxtZ//8kPS/pWUl/lzSh1b9BCcmUtbzmby5raWZtJ5dE8H6S7qDvA5enjx+39CZJ5cAvgGOBCcAnGvmi/2NEvC8i9gZ+RNIFZc1wWUsza2tNVijLiIjDt3Hf+wPzImIBgKSbgBOA2Vn7XpO1fQ88UK1FO/ep4ouHjeHyB17miflvcOCYgYUOycw6ueZKVZ4aETdKOq+x9RHR0l/vQ4DsUltLSFoXDY9zNnAeUAkc0UQsZwFnAQwf7lIIZx4ymj/XuKylmbWN5r5BeqQ/ezXxaBMR8YuIGAN8nSYGqkXEtRFRHRHVgwYNaqtDd1rZZS1vcllLM9tOTbYIIuKa9Od3tnHfS4FhWa+HpsuachNw9TYeq+Rkylpefv8cjt9zMH26u3qomW2bXAaUdZN0tqT/lfTrzCOHfU8HdpU0SlIlcApwR4N975r1chLg+ow5ksS3PpSUtfzpgy8XOhwz68Ry6Vy+AdgJOBp4jOQv+xZrKEZEHTAFmAa8CNwcEbMkXSppcrrZFEmzJD1Lcp3gs9vwO5SsCYN784n9XdbSzLaPWpq7RtIzEbGPpJkRsaekCuDxiDigfULcWnV1ddTU1BTi0B3SyrUbOWzqI+w1rC+//9z+SCp0SGbWAUmaERHVja3LpUWwKf1ZK2kPoA8uTNNhZJe1fMhlLc1sG+SSCK6V1A/4Jkkf/2ySwV/WQWTKWn7XZS3NbBvkMg319RGxKiIei4jREbFDRPyyPYKz3FSUl/FNl7U0s23U3ICyRgeSZeQwoMza0aFjB3Hk+B34+UNz+ci+Q9ihV7dCh2RmnURzLYKmBpK16YAyazsXT5rgspZm1mrNDSjb1oFkViCj0rKW1zy2gFMPGMFew/oWOiQz6wRyGVA2WtKdklZIWi7pdkmj2yM4a71MWcvvuKylmeUol7uG/gjcDOwMDAb+Avwpn0HZtsuUtXzaZS3NLEe5JILuEXFDRNSljxsBX4nswE7adyjvG+KylmaWm1wSwb2SLpQ0UtIISV8D7pHUX1L/fAdorVdWJi6ZPMFlLc0sJy0WpgE+lv78QoPlp5AUkvH1gg5o4oj+W8pafqx6GMP6dy90SGbWQeUyoGxUMw8ngQ7MZS3NLBe53DX03bT+cOZ1b0m/yW9Y1hYyZS3vfeE1npj/RqHDMbMOKpdrBF2Af0naU9JRJHUGZuQ3LGsrZx4ymiF9q7j0ztnUba4vdDhm1gHl0jV0EfA14Cngd8CkiLgq34FZ2+hWUc7Fk1zW0syalkvX0CHAlcClwKPAzyUNznNc1oaOzSpruXrdppbfYGYlJZeuoR8DJ0fEDyLik8B1wMP5DcvakstamllzckkEH4iI2ZkXEXErcFD+QrJ8cFlLM2tKk4lA0hUAEbFZ0lcarL48r1FZXpx31Fh6VJZz6V2zPQ+RmW3RXIvgkKznDYvK75mHWCzPBvTsyjlHuqylmW2tuUSgJp5bJ/bpDyRlLS9zWUszSzWXCMok9ZM0IOt5Zn6h8mbeZx1YpqzlQpe1NLNUc3MN9SEZOJZpDTydtc4dzJ2Yy1qaWbYmWwQRMTItVu85hoqQy1qaWUYut49aERo1sAefO2gUf5mxhOcW1xY6HDMrICeCEjblCJe1NDMngpLmspZmBjkmAkkHSzo9fT5I0qj8hmXtxWUtzSyXSee+DXwduChdVAHcmM+grP24rKWZ5dIi+DAwGVgLEBHLgF75DMra18QR/TkhLWu5eOW6QodjZu0sl0SwMZIriQEgqUd+Q7JCuDAta/mDe13W0qzU5JIIbpZ0DdBX0pnAgyRTUVsRyZS1vOd5l7U0KzW5VCj7MXAL8FdgHPCtiPh5vgOz9ueylmalKZeLxecBsyPigog4PyIeaIe4rABc1tKsNOXSNdQLuF/S45KmSNox30FZ4Ry7x06MGdiDb93+AqMuvJuDfvgwtz2ztNBhmVke5dI19J2I2B04G9gZeEzSg3mPzAri9meXsaR2PfWR3B2wtHY9F936vJOBWRFrzcji5cBrwJvADvkJxwpt6rQ5bKjb+vrA+k2bmTrNk9OZFatcrhF8UdKjwEPAAODMiHCFsiK1rHZ9o8uX1q5nky8gmxWlXFoEw4BzImL3iLgku5B9SyQdI2mOpHmSLmxk/XmSZkuaKekhSSNaE7y1vcF9q5pcd/RP/8aDs1/3BHVmRaa54vW906dTgVcy1cmyqpQ1S1I58AvgWGAC8AlJExps9gxQnbYwbgF+tC2/hLWdC44eR1XF1gXoqirKOOODo0Bwxu9r+NT1TzFr2eoCRWhmba25FsEf058zgJr054ys1y3ZH5gXEQsiYiNwE3BC9gYR8UhEZOY0eBIY2orYLQ9O3GcIP/jI+xjStwoBQ/pW8YOP7Mk3Jk1g2jmH8J3JuzP71TV86Od/5+u3zGT5mncKHbKZbSflq5kv6STgmIg4I339aeD9ETGlie2vAl6LiMsaWXcWcBbA8OHDJy5atCgvMVtuVq/bxFWPzOW3TyykoryM/zp0DGd8cDRVlS5lbdZRSZoREdWNrcvlYvFDuSzbHpJOBapJuqHeIyKujYjqiKgeNGhQWx7atkGf7hVcPGkCD553KIeOHcTlD7zMEZc/yv89s4T6el8/MOtsmrtG0C29FjBQUr+s6wMjgSE57HspyYXmjKHpsobHORK4GJgcERtaE7wV1ogBPbj61Inc/IUPMKhXV87983Oc+L//4F//Xlno0MysFZprEXyB5HrAbmx9feB24Koc9j0d2FXSKEmVwCnAHdkbSNoHuIYkCSxvffjWEew/qj+3ffEgfvrxvVjx1gY+ds0/+a8bZ7DozbWFDs3MctDiNQJJX9rWSeYkHQdcAZQDv46I70m6FKiJiDvSEcrvA15N3/JKRExubp/V1dVRU5PLtWorhPUbN3Pd4wu4+tH51NXXc9qBI5lyxK70qaoodGhmJa25awQ5XSyWtAfJLaDdMssi4vdtFmErOBF0Dq+veYfL75/DX2YsoW9VBeccOZZPvn84FeUuk21WCNuVCNJSlYeRJIJ7SMYF/D0iTmrjOHPiRNC5zFq2msvuepF/LniT0YN6cPFx4zlitx2QVOjQzErKdt01BJwE/AfJrZ2nA3sBfdowPitiuw/uwx/PfD/Xf6YaAj7/uxpO/dVTzF62ptChmVkql0SwPiLqgbp0tPFytr4byKxZkjhywo5MO/cQLjl+ArOWrWHSzx/nwr/OZPlbHpBmVmi5JIIaSX1JylPOAJ4G/pnXqKwoVZSXcdpBo3js/MP5/EGj+OvTSzhs6qNc9fBc3tm0udDhmZWsVo0sTscQ9I6ImfkKqCW+RlA8Fr6xlh/e+xL3zXqNwX268bVjdmPyXoMpK/P1A7O2tk0XiyXt29xOI+LpNoit1ZwIis+TC97ksrtn88LSNew1tA/f+NAE9hvZ4ryGZtYK25oIHmlmnxERR7RFcK3lRFCc6uuD/3tmKT+a9hKvr9nAce/biQuPGc/wAd0LHZpZUdjucQQdiRNBcVu3sY7r/vZvfvnYfDbXB6cdNJKzD9/FA9LMttP2jiP4TGPLPaDM8un1Ne/w42lzuOXpZEDauUeN5RP7e0Ca2bba3kSQPb1EN5IxBU97QJm1hxeWruayu2fz5IKVjBnUg4snjefwcR6QZtZabdo1lN5KelNEHNMWwbWWE0HpiQgefHE537/nRf79xloO3mUgF08az/ide7f8ZjMDtn9kcUNrgVHbF5JZ7iRx1IQdmXbOIXz7+Ak8v3Q1k670gDSzttKlpQ0k3Qlkmg1lJHMO3ZzPoMwaU9mljNMPGsWH9xnClQ/N4/f/XMidzy3ji4fvwucPHkW3CldIM9sWuVwjODTrZR2wKCKW5DWqZrhryDIWrHibH977EvfPfp3Bfbrx9WN34/g9PSDNrDFtco0gnWdoSwsiIgpShsqJwBr65/xkQNqsZWvYa1hfvjlpPNUekGa2le2tWXyWpNeAmUANyXxD/ia2DuMDYwZw55SD+fHJe/Ha6vWc9Mt/cvYfnuaVN9cVOjSzTiGXrqG5wAci4o32Cal5bhFYc9ZtrOPavy3gmscWsLk+OP2gkZx9xC707uYBaVbatveuofmA/7SyTqF7ZRfOOXIsj5x/GJP3Hsy1jy/gsKmPcsM/F1K3ub7Q4Zl1SLm0CPYBfgM8BWzILI+IL+c3tMa5RWCt8cLS1Xz3rtk89e+V7LJDTy4+bjyHjRvkAWlWcra3RXAN8DDwJMn1gczDrMPbY0gfbjrrAK759ETqNtdz+m+n85lf/4uXXnOFNLOMXFoEz0TEPu0UT4vcIrBttbGunhueXMTPHnyZtzfU8fH9hnPeUWMZ1KtroUMzy7vtbRHcm945tLOk/plHG8dolneVXcr4/MGjeOyCw/nsgSP5S81iDpv6CL94ZJ4rpFlJy6VF8O9GFkdEjM5PSM1zi8DayoIVb/ODe1/igdmvM6RvFV87ZhyT9xrs6wdWlFyPwKwZT8x/g8vuepHZr65h72F9+eaHxjNxhBu9Vlxcj8CsBZvrg1ufXsLUaXNY/tYGJu25MxcesxvD+rtCmhWH5hJBi5POAftlPd9SjwAoSCIwy4fyMnFy9TCOe9/OyYC0v83ngVmvc/rBSYU0D0izYuZ6BGaNeHX1eqZOm8OtTy+lf4/KpELafsPo4gpp1km5HoFZK+3cp4qffGxv7phyELvs0JNv3vYCx/7scR6Zs7zQoZm1OdcjMGvGnkP78uezDmDarNf5wb0vcvpvpnPI2EFcfNx4xu3Uq9DhmbUJ1yMwy9HGunp+/8+FXPnQXN7eUMcp+w/n3CM9IM06h226a0jSLsCOEfGPBssPAl6LiPltHmkOnAis0Fat3cjPHprLjU8uoltFOYeNG8jTi2p5dfU7DO5bxQVHj+PEfYYUOkyzrWzrNYIrgMYmZFmTrjMrSf16VHLJ5N2Zdu4hjBjQnbtmvsay1e8QwNLa9Vz415ncUrO40GGa5ay5awQ7RsTzDRdGxPOSRuYtIrNOYsygntSu2/Se5e/U1XP+LTO55M7Z9O1eQf8elfTtXkn/7hXJzx6V9Mt6ntmmX/dK1122gmguEfRtZl1VWwdi1hktq13f5LqTq4dSu24TK9dupHbdRv79xtvUrt3EWxvqmnxPt4oy+nev3CpJ9OteSb80ebybVNJ1PSrpUVnuaTFsuzSXCGoknRkR12UvlHQGnobaDIDBfatY2kgyGNK3im8fv3uj79lYV0/t+o1bJYmVazexat27z2vXbWTluo0srV3PyrUbWb3+vS2PjMrysqyWx9aJo1/3pKXRcF3vbl2cPGyL5hLBOcD/SfoU737xVwOVwIfzHZhZZ3DB0eO46NbnWZ81e2lVRTkXHD2uyfdUdiljh17d2KFXt5yPs7k+WL0+O3EkiWRVmjBq125Kfq7byNzlb7Nq7UZq129ic33jN4OUl2lL91R2wtiSQNKuquznfaoqKC9rm+Rx2zNLmTptDstq1/sCewfQZCKIiNeBAyUdDuyRLr47Ih5ul8jMOoHMl1e+v9TKy0T/Hslf9rmqrw/eeqfu3WSxbiOr0pbHqqyWx6p1G1n05jqeXVzLqnUb2bS5qTsJoU9VxbsJoqnEsWV50gqpaDAa+7Znlm6VPJfWrueiW5PLkU4GheHZR81si4hg7cbNrFq7MU0Ym959vjZ9vS7z+t3n72xquh50r65dtkoYTy1YuVULKmNI3yr+ceER+fz1Str2Tjq3PQc+BvgZUA5cHxE/bLD+EJJbUfcETomIW/IZj5k1TxI9u3ahZ9curZp5dUdk8AUAAA06SURBVP3Gze9JENnXPjJJZeXajY0mAUhaBrc/u5Tqkf0Z0tf3o7SnvCUCSeXAL4CjgCXAdEl3RMTsrM1eAU4Dzs9XHGaWf1WV5VRVVjE4hy/wg374cKMX2AV85aZnAdi5TzcmjuhH9Yh+VI/sz2479fKEf3mUzxbB/sC8iFgAIOkm4ARgSyKIiIXpuqbblWZWVJq6wP69E3dn7E69mbFoFTWLVlGzcCV3zXwVgB6V5ewzvB/VI/tRPaI/+wzvS4+uee3QKCn5PJNDgOzhlUuA9+fxeGbWCbR0gX2PIX347IEjgaS7qGbhSmoWJsnhZw/NJSK5eD5+515Uj+i/JTns1Cf3u7Bsa50ipUo6CzgLYPjw4QWOxsy214n7DMnpDqEhfasYsvcQTtg72XbNO5t45pVaZixcSc2iVfx5+mJ++8TCLdvuN7IfE0f2p3pEP8bu2KvNbnctdvlMBEuBYVmvh6bLWi0irgWuheSuoe0Pzcw6o97dKjh07CAOHTsIgE2b63nx1TVpi2ElT8x/k9ueXQZAr25d2Hf4u9cZ9h7Wl6pKT+HRmHwmgunArpJGkSSAU4BP5vF4ZlZiKsrL2HNoX/Yc2pfPHTyKiGDJqvVMT1sMNQtXcvkDKwDoUiZ2H9yb6rTFMHFkv1YN6itmeR1HIOk4kttDy4FfR8T3JF0K1ETEHZL2A/4P6Ae8QzK9dePj8lMeR2BmrbF63SaefmXVluTw3OJaNtQl96eMGNA9vTupP/uN7MeYQT0pK9LupG2qR9BRORGY2fbYWFfPrGWrt3Qn1SxcxZtrNwLJyOmJI969O2nPoX2KZkbYgg0oMzPraCq7lLHP8H7sM7wfZzKaiGDhm+uy7k5aycMvJbWpK8rF+4b0ebc7aUQ/BvQsvop0bhGYmTWwcu3GdDzDSmYsXMXMJavZuDnpTho9sMeWFsPEkf0YPbBHp5jJ1V1DZmbb4Z1Nm3lh6eotF6BnLFrFqrQoUf8elVuNgt5jSG+6dul43UnuGjIz2w7dKsqT7qGR/eHQMUQE81esTbqTFq1ixqJVPDD7dSDpetpr6NbdSX275z5rbCG4RWBm1gZWvLUh6U5Kk8MLS1dTl9aD2HWHnlSP7MfE9O6k4f27t3t3kruGzMza2fqNm3luSe1WyeGtd5IypQN7dk27kpLupN0H935P3Ya25q4hM7N2VlVZzgGjB3DA6AFAUiho7vK3t9yyWrNoJffNeg1IalXvPazvlgvQ+w7vR5+qii37yndFN7cIzMwK5PU172xJCjMWrWLWsjVsrg8kGLdjLyaO6IcEf6lZsmUQHCSztf7gI+9rVTJw15CZWSewdkMdzy2uZXqaHJ55pZa3N9Q1um1rK7q5a8jMrBPo0bULB+4ykAN3GQjA5vpgl/++h8b+XF/WSHGfbeWSP2ZmHVR5mZqs+pZLNbhcORGYmXVgFxw9jqoG8x1VVZRzwdHj2uwY7hoyM+vAWqro1hacCMzMOrhcK7ptK3cNmZmVOCcCM7MS50RgZlbinAjMzEqcE4GZWYnrdFNMSFoBLNrGtw8E3mjDcNqK42odx9V6HTU2x9U62xPXiIgY1NiKTpcItoekmqbm2igkx9U6jqv1Ompsjqt18hWXu4bMzEqcE4GZWYkrtURwbaEDaILjah3H1XodNTbH1Tp5iaukrhGYmdl7lVqLwMzMGnAiMDMrcUWZCCQdI2mOpHmSLmxkfVdJf07XPyVpZAeJ6zRJKyQ9mz7OaKe4fi1puaQXmlgvSVemcc+UtG8HieswSauzzte32iGmYZIekTRb0ixJX2lkm3Y/XznGVYjz1U3SvyQ9l8b1nUa2affPY45xFeTzmB67XNIzku5qZF3bn6+IKKoHUA7MB0YDlcBzwIQG23wR+GX6/BTgzx0krtOAqwpwzg4B9gVeaGL9ccC9gIADgKc6SFyHAXe187naGdg3fd4LeLmRf8d2P185xlWI8yWgZ/q8AngKOKDBNoX4POYSV0E+j+mxzwP+2Ni/Vz7OVzG2CPYH5kXEgojYCNwEnNBgmxOA36XPbwH+Q5I6QFwFERF/A1Y2s8kJwO8j8STQV9LOHSCudhcRr0bE0+nzt4AXgYYTxbf7+coxrnaXnoO305cV6aPhHSrt/nnMMa6CkDQUmARc38QmbX6+ijERDAEWZ71ewns/EFu2iYg6YDUwoAPEBfDRtDvhFknD8hxTrnKNvRA+kDbv75W0e3seOG2S70Py12S2gp6vZuKCApyvtJvjWWA58EBENHm+2vHzmEtcUJjP4xXA14D6Jta3+fkqxkTQmd0JjIyIPYEHeDfrW+OeJpk/ZS/g58Bt7XVgST2BvwLnRMSa9jpuS1qIqyDnKyI2R8TewFBgf0l7tMdxW5JDXO3+eZT0IWB5RMzI97GyFWMiWApkZ+6h6bJGt5HUBegDvFnouCLizYjYkL68HpiY55hylcs5bXcRsSbTvI+Ie4AKSQPzfVxJFSRftn+IiFsb2aQg56uluAp1vrKOXws8AhzTYFUhPo8txlWgz+NBwGRJC0m6j4+QdGODbdr8fBVjIpgO7CpplKRKkospdzTY5g7gs+nzk4CHI73yUsi4GvQjTybp5+0I7gA+k94NcwCwOiJeLXRQknbK9I1K2p/k/3Nev0DS4/0KeDEiftLEZu1+vnKJq0Dna5CkvunzKuAo4KUGm7X75zGXuArxeYyIiyJiaESMJPmOeDgiTm2wWZufr6IrXh8RdZKmANNI7tT5dUTMknQpUBMRd5B8YG6QNI/kYuQpHSSuL0uaDNSlcZ2W77gAJP2J5I6SgZKWAN8muXhGRPwSuIfkTph5wDrg9A4S10nAf0mqA9YDp7RDQj8I+DTwfNq/DPDfwPCsuApxvnKJqxDna2fgd5LKSRLPzRFxV6E/jznGVZDPY2Pyfb48xYSZWYkrxq4hMzNrBScCM7MS50RgZlbinAjMzEqcE4GZWYlzIrC8kxSSLs96fb6kS9po37+VdFJb7KuF45ws6UVJjzSybqykeyTNlfS0pJsl7ZjvmPJJ0omSJhQ6DmsfTgTWHjYAH2nPUay5SEdl5urzwJkRcXiDfXQD7gaujohdI2Jf4H+BQW0XaUGcCDgRlAgnAmsPdSS1Vs9tuKLhX/SS3k5/HibpMUm3S1og6YeSPqVkDvnnJY3J2s2RkmokvZzO1ZKZUGyqpOnppGFfyNrv45LuAGY3Es8n0v2/IOl/0mXfAg4GfiVpaoO3fBL4Z0TcmVkQEY9GxAtK5rz/Tbq/ZyQdnu7vNEm3SXpA0kJJUySdl27zpKT+6XaPSvqZkrnwX0hHAyOpf/r+men2e6bLL1FSw+HR9Jx9Oev3OjU9d89KuiYdSIWktyV9T8lEdE9K2lHSgSQjaaem24+R9GUltQ5mSropl39060S2dx5rP/xo6QG8DfQGFpLMi3I+cEm67rfASdnbpj8PA2pJRoB2JZlf5Tvpuq8AV2S9/z6SP2p2JZnpsxtwFvCNdJuuQA0wKt3vWmBUI3EOBl4h+Wu+C/AwcGK67lGgupH3/AT4ShO/91dJRpAD7JbuuxvJCNV5JHUDBpHMHvn/0u1+SjJhXOaY16XPDyGty0AyYdy30+dHAM+mzy8Bnkh/34Ek00dUAONJJlCrSLf7X+Az6fMAjk+f/yjrnDX8d1kGdE2f9y30/yk/2vbhFoG1i0hmwvw98OWWts0yPZJ59jeQFPW5P13+PDAya7ubI6I+IuYCC0i+dP+TZL6fZ0mmYx5AkigA/hUR/27kePsBj0bEikim9/0DyRfwtjoYuBEgIl4CFgFj03WPRMRbEbGCJBFkWhQNf7c/pe//G9A7nR/nYOCGdPnDwABJvdPt746IDRHxBsn0yjsC/0EyYdr09Hz8B0mBJICNQKYK1owGx842E/iDpFNJWnhWRIpuriHr0K4gmQr5N1nL6ki7KCWVkVRvy9iQ9bw+63U9W//fbThPSpBUoPpSREzLXiHpMJIWQVuZBRy6De/bnt8t1/1uTvcl4HcRcVEj22+KiGiwfWMmkSTF44GLJb0vTZZWBNwisHYTESuBm0kuvGYs5N3pfSeTTirXSidLKkuvG4wG5pBM7vdfSqZmztzZ06OF/fwLOFTSwLQP/RPAYy2854/AgZImZRZIOkTJ3PaPA5/KHJ9kArg5rfzdPp6+/2CSWUxXN9jvYcAb0XxNhIeAkyTtkL6nv6QRLRz3LZKuq0yCHhYRjwBfJ+ne69nK38M6MLcIrL1dDkzJen0dcLuk50j6+rflr/VXSL7Ee5P0tb8j6XqSbo6nJQlYQXInTJMi4lVJF5LMTS+SbpbbW3jP+vQC9RWSrgA2kXSjfIWkL/5qSc+TtHxOi4gNal1VwXckPUOSID+XLrsE+LWkmSSzm362ifdmYpwt6RvA/emX+ibgbJKuqqbcBFyXXnA+heRCeR+S83JlJHP4W5Hw7KNmHZSkR4HzI6Km0LFYcXPXkJlZiXOLwMysxLlFYGZW4pwIzMxKnBOBmVmJcyIwMytxTgRmZiXu/wMG/3QbjPUqWAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install factor_analyzer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3IUyzGmTRnF",
        "outputId": "d4e5a1fb-d5ab-4b4d-f8bb-dded75e17707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting factor_analyzer\n",
            "  Downloading factor_analyzer-0.4.0.tar.gz (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 507 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from factor_analyzer) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from factor_analyzer) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from factor_analyzer) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from factor_analyzer) (1.0.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->factor_analyzer) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->factor_analyzer) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->factor_analyzer) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->factor_analyzer) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->factor_analyzer) (3.1.0)\n",
            "Building wheels for collected packages: factor-analyzer\n",
            "  Building wheel for factor-analyzer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for factor-analyzer: filename=factor_analyzer-0.4.0-py3-none-any.whl size=41455 sha256=64486c9b54cec635c6e22c7ba26e7bc528eb3fa90319c3b9cc4bf95e3b0a7fb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/00/37/1f0e8a5039f9e9f207c4405bbce0796f07701eb377bfc6cc76\n",
            "Successfully built factor-analyzer\n",
            "Installing collected packages: factor-analyzer\n",
            "Successfully installed factor-analyzer-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from factor_analyzer import FactorAnalyzer\n",
        "fa = FactorAnalyzer(n_factors=3, method=\"ml\", rotation=\"promax\")\n",
        "fa.fit(train_std)\n",
        "print(pd.DataFrame(fa.loadings_, index=train_std.columns))\n",
        "result=pd.DataFrame(fa.loadings_, index=train_std.columns)\n",
        "\n",
        "plt.figure(figsize=(6,10))\n",
        "sns.heatmap(result, cmap=\"Blues\", annot=True, fmt='.2f')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "id": "x-aG7z_ATT1p",
        "outputId": "10604747-29ad-4624-b20a-122ce51caeda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                0         1         2\n",
            "Precipitation_accum     -0.010060  0.519560  0.076297\n",
            "Humidity_avg             0.386386  0.341589  0.327462\n",
            "Get_off_subway           0.278444 -0.225989 -0.199574\n",
            "Fine_dust_concentration -0.041465 -0.374370  0.013678\n",
            "L_Temperature            1.005071 -0.039572  0.197967\n",
            "H_Temperature            0.946579  0.113656 -0.169869\n",
            "A_Temperature            0.979081  0.057578 -0.015865\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff80291d610>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "\n",
        "fig = plt.figure(figsize=(50, 40))\n",
        "fig.set_size_inches(30, 30)\n",
        "ax3d = plt.figure().gca(projection='3d')\n",
        "\n",
        "arrayx = result[0].values\n",
        "arrayy = result[1].values\n",
        "arrayz = result[2].values\n",
        "\n",
        "labels = ['Precipitation_accum', 'Humidity_avg', 'Get_off_subway',\n",
        "       'Fine_dust_concentration','Temperature_lowest','Temperature_higest','Temperature_avg']\n",
        "\n",
        "arrayx = arrayx.flatten()\n",
        "arrayy = arrayy.flatten()\n",
        "arrayz = arrayz.flatten()\n",
        "\n",
        "ax3d.scatter(arrayx, arrayy, arrayz)\n",
        "\n",
        "#give the labels to each point\n",
        "for x_label, y_label, z_label, label in zip(arrayx, arrayy, arrayz, labels):\n",
        "    ax3d.text(x_label, y_label, z_label, label)\n",
        "\n",
        "plt.title(\"coordinate of fa\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "nu3WX7roTWSA",
        "outputId": "65aa984f-d102-4097-a79e-742010242de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x2160 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리1"
      ],
      "metadata": {
        "id": "K_MYXxCIhrur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#'강우여부' 파생변수 생성, 누적강수량 제거\n",
        "all_data['Precipitation_accum'] = np.where(all_data['Precipitation_accum'] == 0, 0, 1)\n",
        "\n",
        "#'평균기온', '최저기온','최고기온'을 '기온'으로 통일\n",
        "all_data['Temperature'] = np.where(all_data['Season'] == 'Winter', all_data['L_Temperature'], np.where(all_data['Season'] == 'Summer', all_data['H_Temperature'], all_data['A_Temperature']))\n",
        "all_data.drop(['L_Temperature', 'A_Temperature', 'H_Temperature'], axis = 1, inplace = True)\n",
        "\n",
        "#데이터 타입 바꾸기\n",
        "all_data = all_data.astype({'Year':'int'})\n",
        "all_data = all_data.astype({'Month':'int'})\n",
        "all_data = all_data.astype({'Date':'int'})\n",
        "all_data = all_data.astype({'Fine_dust_concentration':'float64'})\n",
        "all_data = all_data.astype({'Attendance':'float64'})         \n",
        "\n",
        "#변수 정렬\n",
        "all_data=all_data[ ['Year','Month','Date','Day','Season','Pub_holiday', 'Weekend','Vacation','Precipitation_accum','Humidity_avg','Attendance','Get_off_subway','Fine_dust_concentration',\n",
        "                 'Temperature']]\n",
        "\n",
        "#변수 영어로 바꾸기2\n",
        "all_data = all_data.replace({'Day' : '월'},'Mon')\n",
        "all_data = all_data.replace({'Day' : '화'},'Tue')\n",
        "all_data = all_data.replace({'Day' : '수'},'Wed')\n",
        "all_data = all_data.replace({'Day' : '목'},'Thu')\n",
        "all_data = all_data.replace({'Day' : '금'},'Fri')\n",
        "all_data = all_data.replace({'Day' : '토'},'Sat')\n",
        "all_data = all_data.replace({'Day' : '일'},'Sun')\n",
        "\n",
        "all_data = all_data.replace({'Season' : '봄'},'Spring')\n",
        "all_data = all_data.replace({'Season' : '여름'},'Summer')\n",
        "all_data = all_data.replace({'Season' : '가을'},'fall')\n",
        "all_data = all_data.replace({'Season' : '겨울'},'Winter')     "
      ],
      "metadata": {
        "id": "0JGqm02YdLEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 미세먼지 결측값-> 하차자수와 미세먼지 변수의 단일선형회귀로 얻은 예측값으로 대체\n",
        "\n",
        "(이유: factor analysis 결과, 미세먼지와 하차자수 사이에 밀접한 관련이 있음을 확인)"
      ],
      "metadata": {
        "id": "dSut9brWkI6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "X= all_data.dropna(axis=0)['Get_off_subway']\n",
        "y= all_data.dropna(axis=0)['Fine_dust_concentration']\n",
        "\n",
        "\n",
        "X=pd.DataFrame(X,index=X.index)\n",
        "y=pd.DataFrame(y,index=y.index)\n",
        "\n",
        "lin_reg_model = lin_reg.fit(X, y)\n",
        "y_pred = lin_reg_model.predict(all_data.loc[:, ['Get_off_subway']])\n",
        "\n",
        "\n",
        "all_data['Fine_dust_concentration'] = np.where(all_data['Fine_dust_concentration'].isnull(), \n",
        "                              pd.Series(y_pred.flatten()), \n",
        "                              all_data['Fine_dust_concentration'])"
      ],
      "metadata": {
        "id": "2JHnkKg0j1Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 원핫인코딩"
      ],
      "metadata": {
        "id": "e-i871mdltDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data_final=pd.get_dummies(all_data)"
      ],
      "metadata": {
        "id": "TRVd703fluvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 분석에 필요없는 변수 지우기"
      ],
      "metadata": {
        "id": "yxDvSxLBl3DS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data_final.drop(columns=[\"Year\", \"Month\",\"Date\"],inplace=True)"
      ],
      "metadata": {
        "id": "lN7V_30sl45K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. y값 로그변환"
      ],
      "metadata": {
        "id": "lt7tsYJgqcXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data_final['Attendance']=np.log1p(all_data_final['Attendance'])"
      ],
      "metadata": {
        "id": "i3R5qHwBqfhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "시각화"
      ],
      "metadata": {
        "id": "5_EFusl4iVxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax1 = plt.subplots(ncols=2, nrows=2, figsize=(15,15))\n",
        "\n",
        "ax=sns.distplot(all_data_final['Attendance'], hist=True, kde=True, bins=10, color='green', hist_kws={'edgecolor': 'gray'}, kde_kws={'linewidth': 2},ax=ax1[0,0])\n",
        "ax.set_title('Befor transformation')\n",
        "\n",
        "ax=sns.distplot(np.log1p(all_data_final['Attendance']), hist=True, kde=True, bins=10, color='blue', hist_kws={'edgecolor': 'gray'}, kde_kws={'linewidth': 2},ax=ax1[0,1])\n",
        "ax.set_title('After Logtransformation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "L3JZQQM3iVGn",
        "outputId": "332f0600-fbdf-4605-abbb-1a12d3005bc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'After Logtransformation')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train+test 다시 split"
      ],
      "metadata": {
        "id": "X6oW0d8Il-8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = all_data_final[:ntrain]\n",
        "test = all_data_final[ntrain:]\n",
        "\n",
        "test.reset_index(drop= True, inplace = True)"
      ],
      "metadata": {
        "id": "d34Pwu6hmHU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리2\n",
        "\n",
        "표준화"
      ],
      "metadata": {
        "id": "RgIuyna2pSWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train data 처리\n",
        "train_num=train[['Humidity_avg','Get_off_subway','Fine_dust_concentration','Temperature']]\n",
        "train_obj=train.drop(['Humidity_avg','Get_off_subway','Attendance','Fine_dust_concentration','Temperature'],axis=1)\n",
        "\n",
        "#표준화\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(train_num)\n",
        "train_std = pd.DataFrame(scaler.transform(train_num), columns=train_num.columns, index=train_num.index) \n",
        "\n",
        "#최종 train_x와 train_y\n",
        "train_final_x=pd.concat([train_std,train_obj],axis=1)\n",
        "train_final_y=train['Attendance']\n",
        "\n",
        "###########################################################################################################\n",
        "\n",
        "#test data 처리\n",
        "test_num=test[['Humidity_avg','Get_off_subway','Fine_dust_concentration','Temperature']]\n",
        "test_obj=test.drop(['Humidity_avg','Get_off_subway','Attendance','Fine_dust_concentration','Temperature'],axis=1)\n",
        "\n",
        "#표준화(test data에는 transform만 적용)\n",
        "test_std = pd.DataFrame(scaler.transform(test_num), columns=test_num.columns, index=test_num.index) \n",
        "\n",
        "#최종 test_x와 test_y\n",
        "test_final_x=pd.concat([test_std,test_obj],axis=1)\n",
        "test_final_y=test['Attendance']"
      ],
      "metadata": {
        "id": "wYeHF20CkllB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_final_x.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjbYhs0HnBdf",
        "outputId": "718bb484-6a24-424a-ddaa-cd3b476e3776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Humidity_avg', 'Get_off_subway', 'Fine_dust_concentration',\n",
              "       'Temperature', 'Pub_holiday', 'Weekend', 'Vacation',\n",
              "       'Precipitation_accum', 'Day_Fri', 'Day_Mon', 'Day_Sat', 'Day_Sun',\n",
              "       'Day_Thu', 'Day_Tue', 'Day_Wed', 'Season_Spring', 'Season_Summer',\n",
              "       'Season_Winter', 'Season_fall'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#선형회귀 돌려보기"
      ],
      "metadata": {
        "id": "J_ObIAg5mwbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.concat([train_final_x,train_final_y],axis=1)\n",
        "from statsmodels.formula.api import ols\n",
        "res=ols('Attendance ~Humidity_avg+ Get_off_subway+Fine_dust_concentration+Temperature+Pub_holiday+Weekend+Vacation+Precipitation_accum+Day_Fri+Day_Mon+Day_Sat+Day_Sun+Day_Thu+Day_Tue+Day_Wed+Season_Spring+Season_Summer+Season_Winter+Season_fall',data=train).fit()\n",
        "res.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "id": "r5QDYIzEmyfR",
        "outputId": "2eb7bcb6-df09-45fd-df17-e66b13054bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:             Attendance   R-squared:                       0.765\n",
              "Model:                            OLS   Adj. R-squared:                  0.761\n",
              "Method:                 Least Squares   F-statistic:                     198.9\n",
              "Date:                Thu, 07 Jul 2022   Prob (F-statistic):          1.08e-293\n",
              "Time:                        06:31:13   Log-Likelihood:                -858.42\n",
              "No. Observations:                 994   AIC:                             1751.\n",
              "Df Residuals:                     977   BIC:                             1834.\n",
              "Df Model:                          16                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "===========================================================================================\n",
              "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
              "-------------------------------------------------------------------------------------------\n",
              "Intercept                   5.7309      0.019    300.598      0.000       5.693       5.768\n",
              "Humidity_avg               -0.0632      0.025     -2.525      0.012      -0.112      -0.014\n",
              "Get_off_subway              0.6401      0.026     24.313      0.000       0.588       0.692\n",
              "Fine_dust_concentration     0.0046      0.021      0.223      0.824      -0.036       0.045\n",
              "Temperature                 0.3117      0.047      6.568      0.000       0.219       0.405\n",
              "Pub_holiday                 0.5233      0.102      5.105      0.000       0.322       0.724\n",
              "Weekend                     0.9877      0.027     36.820      0.000       0.935       1.040\n",
              "Vacation                   -0.3774      0.057     -6.611      0.000      -0.489      -0.265\n",
              "Precipitation_accum        -0.1703      0.046     -3.672      0.000      -0.261      -0.079\n",
              "Day_Fri                     0.8465      0.044     19.062      0.000       0.759       0.934\n",
              "Day_Mon                     1.0281      0.045     22.697      0.000       0.939       1.117\n",
              "Day_Sat                     0.3386      0.039      8.753      0.000       0.263       0.415\n",
              "Day_Sun                     0.6491      0.036     17.873      0.000       0.578       0.720\n",
              "Day_Thu                     0.9834      0.044     22.281      0.000       0.897       1.070\n",
              "Day_Tue                     0.9677      0.045     21.741      0.000       0.880       1.055\n",
              "Day_Wed                     0.9174      0.044     20.745      0.000       0.831       1.004\n",
              "Season_Spring               1.6926      0.039     43.738      0.000       1.617       1.769\n",
              "Season_Summer               1.1650      0.066     17.655      0.000       1.036       1.295\n",
              "Season_Winter               1.1513      0.073     15.823      0.000       1.008       1.294\n",
              "Season_fall                 1.7220      0.033     51.658      0.000       1.657       1.787\n",
              "==============================================================================\n",
              "Omnibus:                       91.930   Durbin-Watson:                   1.330\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              307.992\n",
              "Skew:                           0.414   Prob(JB):                     1.32e-67\n",
              "Kurtosis:                       5.598   Cond. No.                     2.10e+16\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The smallest eigenvalue is 4.08e-30. This might indicate that there are\n",
              "strong multicollinearity problems or that the design matrix is singular.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>       <td>Attendance</td>    <th>  R-squared:         </th> <td>   0.765</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.761</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   198.9</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Thu, 07 Jul 2022</td> <th>  Prob (F-statistic):</th> <td>1.08e-293</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>06:31:13</td>     <th>  Log-Likelihood:    </th> <td> -858.42</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   994</td>      <th>  AIC:               </th> <td>   1751.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   977</td>      <th>  BIC:               </th> <td>   1834.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    16</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "             <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th>               <td>    5.7309</td> <td>    0.019</td> <td>  300.598</td> <td> 0.000</td> <td>    5.693</td> <td>    5.768</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Humidity_avg</th>            <td>   -0.0632</td> <td>    0.025</td> <td>   -2.525</td> <td> 0.012</td> <td>   -0.112</td> <td>   -0.014</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Get_off_subway</th>          <td>    0.6401</td> <td>    0.026</td> <td>   24.313</td> <td> 0.000</td> <td>    0.588</td> <td>    0.692</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fine_dust_concentration</th> <td>    0.0046</td> <td>    0.021</td> <td>    0.223</td> <td> 0.824</td> <td>   -0.036</td> <td>    0.045</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Temperature</th>             <td>    0.3117</td> <td>    0.047</td> <td>    6.568</td> <td> 0.000</td> <td>    0.219</td> <td>    0.405</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Pub_holiday</th>             <td>    0.5233</td> <td>    0.102</td> <td>    5.105</td> <td> 0.000</td> <td>    0.322</td> <td>    0.724</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Weekend</th>                 <td>    0.9877</td> <td>    0.027</td> <td>   36.820</td> <td> 0.000</td> <td>    0.935</td> <td>    1.040</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Vacation</th>                <td>   -0.3774</td> <td>    0.057</td> <td>   -6.611</td> <td> 0.000</td> <td>   -0.489</td> <td>   -0.265</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Precipitation_accum</th>     <td>   -0.1703</td> <td>    0.046</td> <td>   -3.672</td> <td> 0.000</td> <td>   -0.261</td> <td>   -0.079</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Day_Fri</th>                 <td>    0.8465</td> <td>    0.044</td> <td>   19.062</td> <td> 0.000</td> <td>    0.759</td> <td>    0.934</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Day_Mon</th>                 <td>    1.0281</td> <td>    0.045</td> <td>   22.697</td> <td> 0.000</td> <td>    0.939</td> <td>    1.117</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Day_Sat</th>                 <td>    0.3386</td> <td>    0.039</td> <td>    8.753</td> <td> 0.000</td> <td>    0.263</td> <td>    0.415</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Day_Sun</th>                 <td>    0.6491</td> <td>    0.036</td> <td>   17.873</td> <td> 0.000</td> <td>    0.578</td> <td>    0.720</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Day_Thu</th>                 <td>    0.9834</td> <td>    0.044</td> <td>   22.281</td> <td> 0.000</td> <td>    0.897</td> <td>    1.070</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Day_Tue</th>                 <td>    0.9677</td> <td>    0.045</td> <td>   21.741</td> <td> 0.000</td> <td>    0.880</td> <td>    1.055</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Day_Wed</th>                 <td>    0.9174</td> <td>    0.044</td> <td>   20.745</td> <td> 0.000</td> <td>    0.831</td> <td>    1.004</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Season_Spring</th>           <td>    1.6926</td> <td>    0.039</td> <td>   43.738</td> <td> 0.000</td> <td>    1.617</td> <td>    1.769</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Season_Summer</th>           <td>    1.1650</td> <td>    0.066</td> <td>   17.655</td> <td> 0.000</td> <td>    1.036</td> <td>    1.295</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Season_Winter</th>           <td>    1.1513</td> <td>    0.073</td> <td>   15.823</td> <td> 0.000</td> <td>    1.008</td> <td>    1.294</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Season_fall</th>             <td>    1.7220</td> <td>    0.033</td> <td>   51.658</td> <td> 0.000</td> <td>    1.657</td> <td>    1.787</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>91.930</td> <th>  Durbin-Watson:     </th> <td>   1.330</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 307.992</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.414</td> <th>  Prob(JB):          </th> <td>1.32e-67</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 5.598</td> <th>  Cond. No.          </th> <td>2.10e+16</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.08e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델링"
      ],
      "metadata": {
        "id": "Ojmuq7y2sBdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import ElasticNet,  BayesianRidge, LassoLarsIC\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
        "!pip install catboost\n",
        "import catboost as cb\n",
        "\n",
        "\n",
        "def rmse_cv(model):\n",
        "    rmse = -cross_val_score(model, train_final_x,train_final_y, scoring=\"neg_root_mean_squared_error\", cv=5).mean()\n",
        "    return rmse\n",
        "def evaluation(y, predictions):\n",
        "    rmse = np.sqrt(mean_squared_error(y, predictions))\n",
        "    return rmse    "
      ],
      "metadata": {
        "id": "FUde48kur2nQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7fb71e-a910-4442-93d1-6b39ba4c6b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.0.6)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CB"
      ],
      "metadata": {
        "id": "hkuacWNx21VA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CB = cb.CatBoostRegressor()\n",
        "parameters = {'depth' : [6,8,10],\n",
        "              'learning_rate' : [0.01, 0.05, 0.1],\n",
        "              'iterations'    : [30, 50, 100]\n",
        "              }\n",
        "grid_search = GridSearchCV(CB,parameters, cv=5, scoring='neg_root_mean_squared_error')\n",
        "grid_search.fit(train_final_x,train_final_y)\n",
        "print('최적의 하이퍼파라미터',grid_search.best_params_)\n",
        "print('최적 모델의 cv score', -grid_search.best_score_)\n",
        "print('최적 모델',grid_search.best_estimator_ )\n",
        "\n",
        "models=pd.DataFrame(columns=[\"Model\",\"최적 모델의 cv_RMSE\"])\n",
        "new_row = {\"Model\": \"CB\",\"최적 모델의 cv_RMSE\": -grid_search.best_score_}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RoGyw44X22cN",
        "outputId": "1b50b418-b488-4cc1-ad02-10aefec2482a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "3:\tlearn: 1.1711221\ttotal: 49.7ms\tremaining: 572ms\n",
            "4:\tlearn: 1.1642144\ttotal: 53.4ms\tremaining: 480ms\n",
            "5:\tlearn: 1.1565381\ttotal: 62.2ms\tremaining: 456ms\n",
            "6:\tlearn: 1.1486746\ttotal: 83.2ms\tremaining: 511ms\n",
            "7:\tlearn: 1.1409993\ttotal: 92ms\tremaining: 483ms\n",
            "8:\tlearn: 1.1335541\ttotal: 103ms\tremaining: 468ms\n",
            "9:\tlearn: 1.1261032\ttotal: 111ms\tremaining: 443ms\n",
            "10:\tlearn: 1.1191365\ttotal: 115ms\tremaining: 408ms\n",
            "11:\tlearn: 1.1121681\ttotal: 121ms\tremaining: 382ms\n",
            "12:\tlearn: 1.1053784\ttotal: 124ms\tremaining: 353ms\n",
            "13:\tlearn: 1.0987585\ttotal: 129ms\tremaining: 331ms\n",
            "14:\tlearn: 1.0916959\ttotal: 138ms\tremaining: 323ms\n",
            "15:\tlearn: 1.0845434\ttotal: 142ms\tremaining: 302ms\n",
            "16:\tlearn: 1.0773326\ttotal: 150ms\tremaining: 292ms\n",
            "17:\tlearn: 1.0708203\ttotal: 157ms\tremaining: 279ms\n",
            "18:\tlearn: 1.0640323\ttotal: 178ms\tremaining: 290ms\n",
            "19:\tlearn: 1.0571240\ttotal: 190ms\tremaining: 285ms\n",
            "20:\tlearn: 1.0508071\ttotal: 218ms\tremaining: 301ms\n",
            "21:\tlearn: 1.0443540\ttotal: 221ms\tremaining: 281ms\n",
            "22:\tlearn: 1.0379073\ttotal: 248ms\tremaining: 291ms\n",
            "23:\tlearn: 1.0322213\ttotal: 264ms\tremaining: 286ms\n",
            "24:\tlearn: 1.0256041\ttotal: 271ms\tremaining: 271ms\n",
            "25:\tlearn: 1.0193364\ttotal: 281ms\tremaining: 259ms\n",
            "26:\tlearn: 1.0130042\ttotal: 293ms\tremaining: 250ms\n",
            "27:\tlearn: 1.0066394\ttotal: 306ms\tremaining: 240ms\n",
            "28:\tlearn: 1.0002395\ttotal: 314ms\tremaining: 227ms\n",
            "29:\tlearn: 0.9942054\ttotal: 324ms\tremaining: 216ms\n",
            "30:\tlearn: 0.9880574\ttotal: 330ms\tremaining: 202ms\n",
            "31:\tlearn: 0.9820847\ttotal: 348ms\tremaining: 196ms\n",
            "32:\tlearn: 0.9763213\ttotal: 356ms\tremaining: 183ms\n",
            "33:\tlearn: 0.9705706\ttotal: 365ms\tremaining: 172ms\n",
            "34:\tlearn: 0.9649609\ttotal: 375ms\tremaining: 161ms\n",
            "35:\tlearn: 0.9591670\ttotal: 381ms\tremaining: 148ms\n",
            "36:\tlearn: 0.9535965\ttotal: 390ms\tremaining: 137ms\n",
            "37:\tlearn: 0.9476858\ttotal: 397ms\tremaining: 125ms\n",
            "38:\tlearn: 0.9419056\ttotal: 414ms\tremaining: 117ms\n",
            "39:\tlearn: 0.9365906\ttotal: 430ms\tremaining: 107ms\n",
            "40:\tlearn: 0.9313213\ttotal: 458ms\tremaining: 101ms\n",
            "41:\tlearn: 0.9260838\ttotal: 479ms\tremaining: 91.3ms\n",
            "42:\tlearn: 0.9206054\ttotal: 493ms\tremaining: 80.2ms\n",
            "43:\tlearn: 0.9151004\ttotal: 514ms\tremaining: 70.1ms\n",
            "44:\tlearn: 0.9103112\ttotal: 519ms\tremaining: 57.6ms\n",
            "45:\tlearn: 0.9048578\ttotal: 530ms\tremaining: 46.1ms\n",
            "46:\tlearn: 0.9001707\ttotal: 540ms\tremaining: 34.4ms\n",
            "47:\tlearn: 0.8956511\ttotal: 548ms\tremaining: 22.8ms\n",
            "48:\tlearn: 0.8907327\ttotal: 553ms\tremaining: 11.3ms\n",
            "49:\tlearn: 0.8859428\ttotal: 563ms\tremaining: 0us\n",
            "0:\tlearn: 1.2021182\ttotal: 13ms\tremaining: 636ms\n",
            "1:\tlearn: 1.1938555\ttotal: 20.7ms\tremaining: 496ms\n",
            "2:\tlearn: 1.1859689\ttotal: 33.7ms\tremaining: 527ms\n",
            "3:\tlearn: 1.1777824\ttotal: 37.8ms\tremaining: 434ms\n",
            "4:\tlearn: 1.1704444\ttotal: 46.9ms\tremaining: 422ms\n",
            "5:\tlearn: 1.1631228\ttotal: 60.9ms\tremaining: 447ms\n",
            "6:\tlearn: 1.1555988\ttotal: 67.7ms\tremaining: 416ms\n",
            "7:\tlearn: 1.1476531\ttotal: 79.4ms\tremaining: 417ms\n",
            "8:\tlearn: 1.1405305\ttotal: 81.2ms\tremaining: 370ms\n",
            "9:\tlearn: 1.1334035\ttotal: 92.7ms\tremaining: 371ms\n",
            "10:\tlearn: 1.1260166\ttotal: 117ms\tremaining: 413ms\n",
            "11:\tlearn: 1.1188022\ttotal: 132ms\tremaining: 417ms\n",
            "12:\tlearn: 1.1112787\ttotal: 141ms\tremaining: 401ms\n",
            "13:\tlearn: 1.1042604\ttotal: 145ms\tremaining: 372ms\n",
            "14:\tlearn: 1.0968172\ttotal: 153ms\tremaining: 358ms\n",
            "15:\tlearn: 1.0898048\ttotal: 164ms\tremaining: 348ms\n",
            "16:\tlearn: 1.0833869\ttotal: 167ms\tremaining: 325ms\n",
            "17:\tlearn: 1.0761682\ttotal: 176ms\tremaining: 312ms\n",
            "18:\tlearn: 1.0691355\ttotal: 197ms\tremaining: 321ms\n",
            "19:\tlearn: 1.0627954\ttotal: 221ms\tremaining: 332ms\n",
            "20:\tlearn: 1.0562888\ttotal: 232ms\tremaining: 320ms\n",
            "21:\tlearn: 1.0499731\ttotal: 246ms\tremaining: 314ms\n",
            "22:\tlearn: 1.0432530\ttotal: 258ms\tremaining: 303ms\n",
            "23:\tlearn: 1.0365435\ttotal: 289ms\tremaining: 313ms\n",
            "24:\tlearn: 1.0305677\ttotal: 309ms\tremaining: 309ms\n",
            "25:\tlearn: 1.0237389\ttotal: 328ms\tremaining: 303ms\n",
            "26:\tlearn: 1.0172034\ttotal: 344ms\tremaining: 293ms\n",
            "27:\tlearn: 1.0109815\ttotal: 360ms\tremaining: 283ms\n",
            "28:\tlearn: 1.0049400\ttotal: 374ms\tremaining: 271ms\n",
            "29:\tlearn: 0.9989020\ttotal: 388ms\tremaining: 259ms\n",
            "30:\tlearn: 0.9929950\ttotal: 407ms\tremaining: 249ms\n",
            "31:\tlearn: 0.9868785\ttotal: 427ms\tremaining: 240ms\n",
            "32:\tlearn: 0.9805111\ttotal: 439ms\tremaining: 226ms\n",
            "33:\tlearn: 0.9745530\ttotal: 464ms\tremaining: 218ms\n",
            "34:\tlearn: 0.9691502\ttotal: 474ms\tremaining: 203ms\n",
            "35:\tlearn: 0.9637073\ttotal: 502ms\tremaining: 195ms\n",
            "36:\tlearn: 0.9580423\ttotal: 515ms\tremaining: 181ms\n",
            "37:\tlearn: 0.9519723\ttotal: 539ms\tremaining: 170ms\n",
            "38:\tlearn: 0.9464684\ttotal: 562ms\tremaining: 158ms\n",
            "39:\tlearn: 0.9407873\ttotal: 567ms\tremaining: 142ms\n",
            "40:\tlearn: 0.9355922\ttotal: 587ms\tremaining: 129ms\n",
            "41:\tlearn: 0.9304304\ttotal: 597ms\tremaining: 114ms\n",
            "42:\tlearn: 0.9251111\ttotal: 602ms\tremaining: 98.1ms\n",
            "43:\tlearn: 0.9199165\ttotal: 607ms\tremaining: 82.8ms\n",
            "44:\tlearn: 0.9147306\ttotal: 608ms\tremaining: 67.6ms\n",
            "45:\tlearn: 0.9092890\ttotal: 611ms\tremaining: 53.1ms\n",
            "46:\tlearn: 0.9040876\ttotal: 616ms\tremaining: 39.3ms\n",
            "47:\tlearn: 0.8990719\ttotal: 618ms\tremaining: 25.8ms\n",
            "48:\tlearn: 0.8944792\ttotal: 622ms\tremaining: 12.7ms\n",
            "49:\tlearn: 0.8900029\ttotal: 637ms\tremaining: 0us\n",
            "0:\tlearn: 1.1154270\ttotal: 11.7ms\tremaining: 576ms\n",
            "1:\tlearn: 1.1081992\ttotal: 25.8ms\tremaining: 619ms\n",
            "2:\tlearn: 1.1005579\ttotal: 39.6ms\tremaining: 621ms\n",
            "3:\tlearn: 1.0933088\ttotal: 48.6ms\tremaining: 559ms\n",
            "4:\tlearn: 1.0867963\ttotal: 53.2ms\tremaining: 479ms\n",
            "5:\tlearn: 1.0803676\ttotal: 55.5ms\tremaining: 407ms\n",
            "6:\tlearn: 1.0733330\ttotal: 57.2ms\tremaining: 351ms\n",
            "7:\tlearn: 1.0662091\ttotal: 62.1ms\tremaining: 326ms\n",
            "8:\tlearn: 1.0593072\ttotal: 65.9ms\tremaining: 300ms\n",
            "9:\tlearn: 1.0525912\ttotal: 70.6ms\tremaining: 282ms\n",
            "10:\tlearn: 1.0460696\ttotal: 74.5ms\tremaining: 264ms\n",
            "11:\tlearn: 1.0395222\ttotal: 75.5ms\tremaining: 239ms\n",
            "12:\tlearn: 1.0329659\ttotal: 80.2ms\tremaining: 228ms\n",
            "13:\tlearn: 1.0262868\ttotal: 84.3ms\tremaining: 217ms\n",
            "14:\tlearn: 1.0200686\ttotal: 87.6ms\tremaining: 204ms\n",
            "15:\tlearn: 1.0134447\ttotal: 93.1ms\tremaining: 198ms\n",
            "16:\tlearn: 1.0070533\ttotal: 96.5ms\tremaining: 187ms\n",
            "17:\tlearn: 1.0002182\ttotal: 111ms\tremaining: 198ms\n",
            "18:\tlearn: 0.9941103\ttotal: 126ms\tremaining: 205ms\n",
            "19:\tlearn: 0.9881533\ttotal: 131ms\tremaining: 196ms\n",
            "20:\tlearn: 0.9819406\ttotal: 133ms\tremaining: 183ms\n",
            "21:\tlearn: 0.9764819\ttotal: 136ms\tremaining: 173ms\n",
            "22:\tlearn: 0.9707462\ttotal: 141ms\tremaining: 166ms\n",
            "23:\tlearn: 0.9649453\ttotal: 145ms\tremaining: 157ms\n",
            "24:\tlearn: 0.9590697\ttotal: 149ms\tremaining: 149ms\n",
            "25:\tlearn: 0.9537789\ttotal: 153ms\tremaining: 142ms\n",
            "26:\tlearn: 0.9476648\ttotal: 157ms\tremaining: 134ms\n",
            "27:\tlearn: 0.9421209\ttotal: 163ms\tremaining: 128ms\n",
            "28:\tlearn: 0.9365554\ttotal: 166ms\tremaining: 120ms\n",
            "29:\tlearn: 0.9309459\ttotal: 176ms\tremaining: 118ms\n",
            "30:\tlearn: 0.9255205\ttotal: 194ms\tremaining: 119ms\n",
            "31:\tlearn: 0.9202569\ttotal: 199ms\tremaining: 112ms\n",
            "32:\tlearn: 0.9152051\ttotal: 203ms\tremaining: 105ms\n",
            "33:\tlearn: 0.9098925\ttotal: 207ms\tremaining: 97.3ms\n",
            "34:\tlearn: 0.9048139\ttotal: 212ms\tremaining: 90.9ms\n",
            "35:\tlearn: 0.8997409\ttotal: 216ms\tremaining: 84.1ms\n",
            "36:\tlearn: 0.8947655\ttotal: 220ms\tremaining: 77.2ms\n",
            "37:\tlearn: 0.8897268\ttotal: 260ms\tremaining: 82.2ms\n",
            "38:\tlearn: 0.8844258\ttotal: 271ms\tremaining: 76.5ms\n",
            "39:\tlearn: 0.8795428\ttotal: 283ms\tremaining: 70.6ms\n",
            "40:\tlearn: 0.8746564\ttotal: 298ms\tremaining: 65.3ms\n",
            "41:\tlearn: 0.8700432\ttotal: 309ms\tremaining: 58.9ms\n",
            "42:\tlearn: 0.8651963\ttotal: 327ms\tremaining: 53.2ms\n",
            "43:\tlearn: 0.8601983\ttotal: 345ms\tremaining: 47ms\n",
            "44:\tlearn: 0.8558090\ttotal: 347ms\tremaining: 38.5ms\n",
            "45:\tlearn: 0.8508197\ttotal: 357ms\tremaining: 31ms\n",
            "46:\tlearn: 0.8461796\ttotal: 360ms\tremaining: 23ms\n",
            "47:\tlearn: 0.8420661\ttotal: 366ms\tremaining: 15.2ms\n",
            "48:\tlearn: 0.8376900\ttotal: 375ms\tremaining: 7.65ms\n",
            "49:\tlearn: 0.8333064\ttotal: 395ms\tremaining: 0us\n",
            "0:\tlearn: 1.1771981\ttotal: 4.42ms\tremaining: 216ms\n",
            "1:\tlearn: 1.1687422\ttotal: 5.84ms\tremaining: 140ms\n",
            "2:\tlearn: 1.1611901\ttotal: 9.54ms\tremaining: 149ms\n",
            "3:\tlearn: 1.1534411\ttotal: 13.9ms\tremaining: 160ms\n",
            "4:\tlearn: 1.1454339\ttotal: 32.6ms\tremaining: 293ms\n",
            "5:\tlearn: 1.1387039\ttotal: 44.3ms\tremaining: 325ms\n",
            "6:\tlearn: 1.1314737\ttotal: 55.3ms\tremaining: 340ms\n",
            "7:\tlearn: 1.1235532\ttotal: 66.6ms\tremaining: 349ms\n",
            "8:\tlearn: 1.1164578\ttotal: 82.4ms\tremaining: 375ms\n",
            "9:\tlearn: 1.1092208\ttotal: 86.2ms\tremaining: 345ms\n",
            "10:\tlearn: 1.1020870\ttotal: 89.7ms\tremaining: 318ms\n",
            "11:\tlearn: 1.0955784\ttotal: 101ms\tremaining: 321ms\n",
            "12:\tlearn: 1.0884854\ttotal: 112ms\tremaining: 318ms\n",
            "13:\tlearn: 1.0817795\ttotal: 121ms\tremaining: 311ms\n",
            "14:\tlearn: 1.0747243\ttotal: 131ms\tremaining: 305ms\n",
            "15:\tlearn: 1.0676128\ttotal: 141ms\tremaining: 300ms\n",
            "16:\tlearn: 1.0615284\ttotal: 151ms\tremaining: 294ms\n",
            "17:\tlearn: 1.0550795\ttotal: 162ms\tremaining: 288ms\n",
            "18:\tlearn: 1.0484345\ttotal: 179ms\tremaining: 292ms\n",
            "19:\tlearn: 1.0418251\ttotal: 183ms\tremaining: 274ms\n",
            "20:\tlearn: 1.0353824\ttotal: 185ms\tremaining: 256ms\n",
            "21:\tlearn: 1.0290087\ttotal: 196ms\tremaining: 249ms\n",
            "22:\tlearn: 1.0227209\ttotal: 202ms\tremaining: 237ms\n",
            "23:\tlearn: 1.0162496\ttotal: 213ms\tremaining: 230ms\n",
            "24:\tlearn: 1.0101533\ttotal: 225ms\tremaining: 225ms\n",
            "25:\tlearn: 1.0039470\ttotal: 234ms\tremaining: 216ms\n",
            "26:\tlearn: 0.9977154\ttotal: 238ms\tremaining: 203ms\n",
            "27:\tlearn: 0.9919390\ttotal: 244ms\tremaining: 191ms\n",
            "28:\tlearn: 0.9861830\ttotal: 247ms\tremaining: 179ms\n",
            "29:\tlearn: 0.9806262\ttotal: 258ms\tremaining: 172ms\n",
            "30:\tlearn: 0.9745779\ttotal: 261ms\tremaining: 160ms\n",
            "31:\tlearn: 0.9687549\ttotal: 271ms\tremaining: 153ms\n",
            "32:\tlearn: 0.9629793\ttotal: 285ms\tremaining: 147ms\n",
            "33:\tlearn: 0.9571566\ttotal: 290ms\tremaining: 136ms\n",
            "34:\tlearn: 0.9514242\ttotal: 295ms\tremaining: 126ms\n",
            "35:\tlearn: 0.9454967\ttotal: 298ms\tremaining: 116ms\n",
            "36:\tlearn: 0.9397082\ttotal: 304ms\tremaining: 107ms\n",
            "37:\tlearn: 0.9342836\ttotal: 308ms\tremaining: 97.2ms\n",
            "38:\tlearn: 0.9293068\ttotal: 313ms\tremaining: 88.3ms\n",
            "39:\tlearn: 0.9240071\ttotal: 317ms\tremaining: 79.1ms\n",
            "40:\tlearn: 0.9188088\ttotal: 322ms\tremaining: 70.6ms\n",
            "41:\tlearn: 0.9132206\ttotal: 323ms\tremaining: 61.5ms\n",
            "42:\tlearn: 0.9080545\ttotal: 327ms\tremaining: 53.2ms\n",
            "43:\tlearn: 0.9027865\ttotal: 332ms\tremaining: 45.2ms\n",
            "44:\tlearn: 0.8974117\ttotal: 335ms\tremaining: 37.2ms\n",
            "45:\tlearn: 0.8925288\ttotal: 352ms\tremaining: 30.7ms\n",
            "46:\tlearn: 0.8874177\ttotal: 363ms\tremaining: 23.2ms\n",
            "47:\tlearn: 0.8822644\ttotal: 370ms\tremaining: 15.4ms\n",
            "48:\tlearn: 0.8773759\ttotal: 374ms\tremaining: 7.63ms\n",
            "49:\tlearn: 0.8725960\ttotal: 384ms\tremaining: 0us\n",
            "0:\tlearn: 1.1534314\ttotal: 3.74ms\tremaining: 183ms\n",
            "1:\tlearn: 1.1145823\ttotal: 21.6ms\tremaining: 518ms\n",
            "2:\tlearn: 1.0781290\ttotal: 26.9ms\tremaining: 422ms\n",
            "3:\tlearn: 1.0482640\ttotal: 36.4ms\tremaining: 418ms\n",
            "4:\tlearn: 1.0188022\ttotal: 41.7ms\tremaining: 376ms\n",
            "5:\tlearn: 0.9877129\ttotal: 51.5ms\tremaining: 378ms\n",
            "6:\tlearn: 0.9598303\ttotal: 63.6ms\tremaining: 391ms\n",
            "7:\tlearn: 0.9316988\ttotal: 68.9ms\tremaining: 362ms\n",
            "8:\tlearn: 0.9045311\ttotal: 83.1ms\tremaining: 379ms\n",
            "9:\tlearn: 0.8807412\ttotal: 99.6ms\tremaining: 398ms\n",
            "10:\tlearn: 0.8575307\ttotal: 110ms\tremaining: 390ms\n",
            "11:\tlearn: 0.8346986\ttotal: 121ms\tremaining: 382ms\n",
            "12:\tlearn: 0.8131474\ttotal: 133ms\tremaining: 377ms\n",
            "13:\tlearn: 0.7936631\ttotal: 136ms\tremaining: 351ms\n",
            "14:\tlearn: 0.7741517\ttotal: 146ms\tremaining: 340ms\n",
            "15:\tlearn: 0.7546885\ttotal: 157ms\tremaining: 333ms\n",
            "16:\tlearn: 0.7353991\ttotal: 174ms\tremaining: 337ms\n",
            "17:\tlearn: 0.7196336\ttotal: 212ms\tremaining: 376ms\n",
            "18:\tlearn: 0.7032100\ttotal: 232ms\tremaining: 379ms\n",
            "19:\tlearn: 0.6866780\ttotal: 249ms\tremaining: 374ms\n",
            "20:\tlearn: 0.6725578\ttotal: 258ms\tremaining: 356ms\n",
            "21:\tlearn: 0.6609522\ttotal: 261ms\tremaining: 332ms\n",
            "22:\tlearn: 0.6483524\ttotal: 271ms\tremaining: 318ms\n",
            "23:\tlearn: 0.6375724\ttotal: 287ms\tremaining: 311ms\n",
            "24:\tlearn: 0.6270418\ttotal: 295ms\tremaining: 295ms\n",
            "25:\tlearn: 0.6144221\ttotal: 305ms\tremaining: 281ms\n",
            "26:\tlearn: 0.6040061\ttotal: 314ms\tremaining: 267ms\n",
            "27:\tlearn: 0.5943454\ttotal: 335ms\tremaining: 263ms\n",
            "28:\tlearn: 0.5845191\ttotal: 364ms\tremaining: 263ms\n",
            "29:\tlearn: 0.5745851\ttotal: 376ms\tremaining: 251ms\n",
            "30:\tlearn: 0.5654018\ttotal: 388ms\tremaining: 238ms\n",
            "31:\tlearn: 0.5579366\ttotal: 399ms\tremaining: 224ms\n",
            "32:\tlearn: 0.5499287\ttotal: 410ms\tremaining: 211ms\n",
            "33:\tlearn: 0.5414641\ttotal: 419ms\tremaining: 197ms\n",
            "34:\tlearn: 0.5345986\ttotal: 431ms\tremaining: 185ms\n",
            "35:\tlearn: 0.5271691\ttotal: 444ms\tremaining: 173ms\n",
            "36:\tlearn: 0.5202381\ttotal: 474ms\tremaining: 166ms\n",
            "37:\tlearn: 0.5137004\ttotal: 488ms\tremaining: 154ms\n",
            "38:\tlearn: 0.5078296\ttotal: 498ms\tremaining: 140ms\n",
            "39:\tlearn: 0.5029494\ttotal: 512ms\tremaining: 128ms\n",
            "40:\tlearn: 0.4974271\ttotal: 521ms\tremaining: 114ms\n",
            "41:\tlearn: 0.4927351\ttotal: 532ms\tremaining: 101ms\n",
            "42:\tlearn: 0.4875585\ttotal: 552ms\tremaining: 89.9ms\n",
            "43:\tlearn: 0.4825414\ttotal: 560ms\tremaining: 76.4ms\n",
            "44:\tlearn: 0.4781661\ttotal: 568ms\tremaining: 63.1ms\n",
            "45:\tlearn: 0.4741839\ttotal: 581ms\tremaining: 50.5ms\n",
            "46:\tlearn: 0.4706366\ttotal: 591ms\tremaining: 37.7ms\n",
            "47:\tlearn: 0.4674920\ttotal: 601ms\tremaining: 25.1ms\n",
            "48:\tlearn: 0.4637628\ttotal: 607ms\tremaining: 12.4ms\n",
            "49:\tlearn: 0.4600448\ttotal: 608ms\tremaining: 0us\n",
            "0:\tlearn: 1.1656690\ttotal: 3.7ms\tremaining: 181ms\n",
            "1:\tlearn: 1.1276511\ttotal: 8.53ms\tremaining: 205ms\n",
            "2:\tlearn: 1.0926105\ttotal: 13.7ms\tremaining: 214ms\n",
            "3:\tlearn: 1.0583985\ttotal: 17.2ms\tremaining: 198ms\n",
            "4:\tlearn: 1.0293827\ttotal: 22.3ms\tremaining: 201ms\n",
            "5:\tlearn: 0.9979422\ttotal: 26.7ms\tremaining: 196ms\n",
            "6:\tlearn: 0.9670341\ttotal: 30.2ms\tremaining: 185ms\n",
            "7:\tlearn: 0.9379754\ttotal: 35.9ms\tremaining: 189ms\n",
            "8:\tlearn: 0.9094968\ttotal: 41.1ms\tremaining: 187ms\n",
            "9:\tlearn: 0.8856354\ttotal: 47.4ms\tremaining: 189ms\n",
            "10:\tlearn: 0.8631469\ttotal: 54.9ms\tremaining: 195ms\n",
            "11:\tlearn: 0.8398534\ttotal: 58.5ms\tremaining: 185ms\n",
            "12:\tlearn: 0.8170228\ttotal: 63.7ms\tremaining: 181ms\n",
            "13:\tlearn: 0.7966822\ttotal: 67.3ms\tremaining: 173ms\n",
            "14:\tlearn: 0.7764747\ttotal: 71.9ms\tremaining: 168ms\n",
            "15:\tlearn: 0.7564327\ttotal: 96ms\tremaining: 204ms\n",
            "16:\tlearn: 0.7380844\ttotal: 98.3ms\tremaining: 191ms\n",
            "17:\tlearn: 0.7206338\ttotal: 104ms\tremaining: 185ms\n",
            "18:\tlearn: 0.7052867\ttotal: 109ms\tremaining: 178ms\n",
            "19:\tlearn: 0.6915988\ttotal: 114ms\tremaining: 171ms\n",
            "20:\tlearn: 0.6763551\ttotal: 119ms\tremaining: 164ms\n",
            "21:\tlearn: 0.6634213\ttotal: 123ms\tremaining: 157ms\n",
            "22:\tlearn: 0.6498204\ttotal: 128ms\tremaining: 150ms\n",
            "23:\tlearn: 0.6376361\ttotal: 134ms\tremaining: 145ms\n",
            "24:\tlearn: 0.6262502\ttotal: 139ms\tremaining: 139ms\n",
            "25:\tlearn: 0.6155611\ttotal: 149ms\tremaining: 137ms\n",
            "26:\tlearn: 0.6042354\ttotal: 153ms\tremaining: 130ms\n",
            "27:\tlearn: 0.5931156\ttotal: 161ms\tremaining: 127ms\n",
            "28:\tlearn: 0.5828729\ttotal: 182ms\tremaining: 132ms\n",
            "29:\tlearn: 0.5726640\ttotal: 195ms\tremaining: 130ms\n",
            "30:\tlearn: 0.5637674\ttotal: 199ms\tremaining: 122ms\n",
            "31:\tlearn: 0.5551177\ttotal: 208ms\tremaining: 117ms\n",
            "32:\tlearn: 0.5481044\ttotal: 219ms\tremaining: 113ms\n",
            "33:\tlearn: 0.5413189\ttotal: 244ms\tremaining: 115ms\n",
            "34:\tlearn: 0.5345150\ttotal: 275ms\tremaining: 118ms\n",
            "35:\tlearn: 0.5282372\ttotal: 304ms\tremaining: 118ms\n",
            "36:\tlearn: 0.5208710\ttotal: 322ms\tremaining: 113ms\n",
            "37:\tlearn: 0.5165041\ttotal: 328ms\tremaining: 104ms\n",
            "38:\tlearn: 0.5108896\ttotal: 338ms\tremaining: 95.3ms\n",
            "39:\tlearn: 0.5050265\ttotal: 354ms\tremaining: 88.4ms\n",
            "40:\tlearn: 0.4998265\ttotal: 376ms\tremaining: 82.5ms\n",
            "41:\tlearn: 0.4941985\ttotal: 395ms\tremaining: 75.2ms\n",
            "42:\tlearn: 0.4891088\ttotal: 424ms\tremaining: 69ms\n",
            "43:\tlearn: 0.4845069\ttotal: 445ms\tremaining: 60.6ms\n",
            "44:\tlearn: 0.4808632\ttotal: 454ms\tremaining: 50.5ms\n",
            "45:\tlearn: 0.4766018\ttotal: 475ms\tremaining: 41.3ms\n",
            "46:\tlearn: 0.4726377\ttotal: 497ms\tremaining: 31.7ms\n",
            "47:\tlearn: 0.4686540\ttotal: 515ms\tremaining: 21.4ms\n",
            "48:\tlearn: 0.4652481\ttotal: 528ms\tremaining: 10.8ms\n",
            "49:\tlearn: 0.4608992\ttotal: 544ms\tremaining: 0us\n",
            "0:\tlearn: 1.1710704\ttotal: 10.2ms\tremaining: 501ms\n",
            "1:\tlearn: 1.1315399\ttotal: 15.7ms\tremaining: 376ms\n",
            "2:\tlearn: 1.0946485\ttotal: 20ms\tremaining: 314ms\n",
            "3:\tlearn: 1.0587466\ttotal: 34.1ms\tremaining: 392ms\n",
            "4:\tlearn: 1.0273996\ttotal: 38.4ms\tremaining: 346ms\n",
            "5:\tlearn: 0.9998088\ttotal: 50ms\tremaining: 366ms\n",
            "6:\tlearn: 0.9702939\ttotal: 54.2ms\tremaining: 333ms\n",
            "7:\tlearn: 0.9421793\ttotal: 61.8ms\tremaining: 325ms\n",
            "8:\tlearn: 0.9178181\ttotal: 63.3ms\tremaining: 288ms\n",
            "9:\tlearn: 0.8928162\ttotal: 78.5ms\tremaining: 314ms\n",
            "10:\tlearn: 0.8681893\ttotal: 95.4ms\tremaining: 338ms\n",
            "11:\tlearn: 0.8458786\ttotal: 109ms\tremaining: 346ms\n",
            "12:\tlearn: 0.8222738\ttotal: 120ms\tremaining: 340ms\n",
            "13:\tlearn: 0.8016325\ttotal: 126ms\tremaining: 324ms\n",
            "14:\tlearn: 0.7804708\ttotal: 137ms\tremaining: 320ms\n",
            "15:\tlearn: 0.7622997\ttotal: 146ms\tremaining: 311ms\n",
            "16:\tlearn: 0.7453074\ttotal: 154ms\tremaining: 299ms\n",
            "17:\tlearn: 0.7273317\ttotal: 175ms\tremaining: 312ms\n",
            "18:\tlearn: 0.7112283\ttotal: 191ms\tremaining: 312ms\n",
            "19:\tlearn: 0.6946089\ttotal: 211ms\tremaining: 317ms\n",
            "20:\tlearn: 0.6805346\ttotal: 226ms\tremaining: 312ms\n",
            "21:\tlearn: 0.6671457\ttotal: 239ms\tremaining: 305ms\n",
            "22:\tlearn: 0.6550144\ttotal: 249ms\tremaining: 293ms\n",
            "23:\tlearn: 0.6421296\ttotal: 262ms\tremaining: 284ms\n",
            "24:\tlearn: 0.6309314\ttotal: 272ms\tremaining: 272ms\n",
            "25:\tlearn: 0.6195933\ttotal: 280ms\tremaining: 258ms\n",
            "26:\tlearn: 0.6091088\ttotal: 300ms\tremaining: 256ms\n",
            "27:\tlearn: 0.5995625\ttotal: 311ms\tremaining: 244ms\n",
            "28:\tlearn: 0.5913021\ttotal: 314ms\tremaining: 227ms\n",
            "29:\tlearn: 0.5824665\ttotal: 322ms\tremaining: 215ms\n",
            "30:\tlearn: 0.5736071\ttotal: 340ms\tremaining: 209ms\n",
            "31:\tlearn: 0.5651632\ttotal: 353ms\tremaining: 199ms\n",
            "32:\tlearn: 0.5562673\ttotal: 370ms\tremaining: 190ms\n",
            "33:\tlearn: 0.5494378\ttotal: 380ms\tremaining: 179ms\n",
            "34:\tlearn: 0.5426000\ttotal: 392ms\tremaining: 168ms\n",
            "35:\tlearn: 0.5359120\ttotal: 409ms\tremaining: 159ms\n",
            "36:\tlearn: 0.5294388\ttotal: 430ms\tremaining: 151ms\n",
            "37:\tlearn: 0.5245982\ttotal: 434ms\tremaining: 137ms\n",
            "38:\tlearn: 0.5182286\ttotal: 446ms\tremaining: 126ms\n",
            "39:\tlearn: 0.5120181\ttotal: 463ms\tremaining: 116ms\n",
            "40:\tlearn: 0.5060659\ttotal: 491ms\tremaining: 108ms\n",
            "41:\tlearn: 0.5008026\ttotal: 502ms\tremaining: 95.7ms\n",
            "42:\tlearn: 0.4958118\ttotal: 513ms\tremaining: 83.5ms\n",
            "43:\tlearn: 0.4916341\ttotal: 525ms\tremaining: 71.6ms\n",
            "44:\tlearn: 0.4859885\ttotal: 536ms\tremaining: 59.5ms\n",
            "45:\tlearn: 0.4815404\ttotal: 544ms\tremaining: 47.3ms\n",
            "46:\tlearn: 0.4768490\ttotal: 559ms\tremaining: 35.7ms\n",
            "47:\tlearn: 0.4729325\ttotal: 576ms\tremaining: 24ms\n",
            "48:\tlearn: 0.4690039\ttotal: 591ms\tremaining: 12.1ms\n",
            "49:\tlearn: 0.4651035\ttotal: 601ms\tremaining: 0us\n",
            "0:\tlearn: 1.0870978\ttotal: 12.4ms\tremaining: 609ms\n",
            "1:\tlearn: 1.0524191\ttotal: 50.1ms\tremaining: 1.2s\n",
            "2:\tlearn: 1.0174762\ttotal: 54ms\tremaining: 846ms\n",
            "3:\tlearn: 0.9869325\ttotal: 60.5ms\tremaining: 696ms\n",
            "4:\tlearn: 0.9594547\ttotal: 64.6ms\tremaining: 581ms\n",
            "5:\tlearn: 0.9335256\ttotal: 66.7ms\tremaining: 489ms\n",
            "6:\tlearn: 0.9065748\ttotal: 73.1ms\tremaining: 449ms\n",
            "7:\tlearn: 0.8802653\ttotal: 74.5ms\tremaining: 391ms\n",
            "8:\tlearn: 0.8542242\ttotal: 78ms\tremaining: 355ms\n",
            "9:\tlearn: 0.8307849\ttotal: 83.2ms\tremaining: 333ms\n",
            "10:\tlearn: 0.8083665\ttotal: 86.6ms\tremaining: 307ms\n",
            "11:\tlearn: 0.7871859\ttotal: 91.1ms\tremaining: 289ms\n",
            "12:\tlearn: 0.7681722\ttotal: 95.5ms\tremaining: 272ms\n",
            "13:\tlearn: 0.7488394\ttotal: 97.4ms\tremaining: 250ms\n",
            "14:\tlearn: 0.7314901\ttotal: 102ms\tremaining: 238ms\n",
            "15:\tlearn: 0.7138861\ttotal: 106ms\tremaining: 225ms\n",
            "16:\tlearn: 0.6985504\ttotal: 107ms\tremaining: 209ms\n",
            "17:\tlearn: 0.6838198\ttotal: 112ms\tremaining: 199ms\n",
            "18:\tlearn: 0.6696629\ttotal: 116ms\tremaining: 189ms\n",
            "19:\tlearn: 0.6554800\ttotal: 120ms\tremaining: 181ms\n",
            "20:\tlearn: 0.6419311\ttotal: 125ms\tremaining: 172ms\n",
            "21:\tlearn: 0.6304241\ttotal: 128ms\tremaining: 163ms\n",
            "22:\tlearn: 0.6190455\ttotal: 134ms\tremaining: 157ms\n",
            "23:\tlearn: 0.6064188\ttotal: 137ms\tremaining: 149ms\n",
            "24:\tlearn: 0.5959541\ttotal: 142ms\tremaining: 142ms\n",
            "25:\tlearn: 0.5859470\ttotal: 177ms\tremaining: 163ms\n",
            "26:\tlearn: 0.5770758\ttotal: 188ms\tremaining: 160ms\n",
            "27:\tlearn: 0.5679741\ttotal: 194ms\tremaining: 152ms\n",
            "28:\tlearn: 0.5602439\ttotal: 199ms\tremaining: 144ms\n",
            "29:\tlearn: 0.5517218\ttotal: 203ms\tremaining: 135ms\n",
            "30:\tlearn: 0.5444009\ttotal: 212ms\tremaining: 130ms\n",
            "31:\tlearn: 0.5374556\ttotal: 216ms\tremaining: 121ms\n",
            "32:\tlearn: 0.5312318\ttotal: 221ms\tremaining: 114ms\n",
            "33:\tlearn: 0.5243361\ttotal: 235ms\tremaining: 111ms\n",
            "34:\tlearn: 0.5185190\ttotal: 237ms\tremaining: 102ms\n",
            "35:\tlearn: 0.5122459\ttotal: 244ms\tremaining: 95ms\n",
            "36:\tlearn: 0.5067290\ttotal: 250ms\tremaining: 87.8ms\n",
            "37:\tlearn: 0.5014560\ttotal: 264ms\tremaining: 83.5ms\n",
            "38:\tlearn: 0.4959263\ttotal: 272ms\tremaining: 76.6ms\n",
            "39:\tlearn: 0.4907444\ttotal: 286ms\tremaining: 71.6ms\n",
            "40:\tlearn: 0.4873721\ttotal: 289ms\tremaining: 63.5ms\n",
            "41:\tlearn: 0.4833506\ttotal: 301ms\tremaining: 57.3ms\n",
            "42:\tlearn: 0.4795298\ttotal: 307ms\tremaining: 50ms\n",
            "43:\tlearn: 0.4751245\ttotal: 311ms\tremaining: 42.5ms\n",
            "44:\tlearn: 0.4718227\ttotal: 315ms\tremaining: 35ms\n",
            "45:\tlearn: 0.4678815\ttotal: 320ms\tremaining: 27.9ms\n",
            "46:\tlearn: 0.4639624\ttotal: 322ms\tremaining: 20.5ms\n",
            "47:\tlearn: 0.4607048\ttotal: 325ms\tremaining: 13.5ms\n",
            "48:\tlearn: 0.4563041\ttotal: 331ms\tremaining: 6.75ms\n",
            "49:\tlearn: 0.4526734\ttotal: 334ms\tremaining: 0us\n",
            "0:\tlearn: 1.1467325\ttotal: 11.1ms\tremaining: 545ms\n",
            "1:\tlearn: 1.1069980\ttotal: 27.1ms\tremaining: 649ms\n",
            "2:\tlearn: 1.0725172\ttotal: 47ms\tremaining: 737ms\n",
            "3:\tlearn: 1.0416726\ttotal: 59.4ms\tremaining: 683ms\n",
            "4:\tlearn: 1.0114719\ttotal: 70.4ms\tremaining: 633ms\n",
            "5:\tlearn: 0.9802444\ttotal: 82.4ms\tremaining: 604ms\n",
            "6:\tlearn: 0.9517405\ttotal: 89.3ms\tremaining: 549ms\n",
            "7:\tlearn: 0.9231660\ttotal: 94.6ms\tremaining: 497ms\n",
            "8:\tlearn: 0.8967369\ttotal: 98.1ms\tremaining: 447ms\n",
            "9:\tlearn: 0.8715663\ttotal: 103ms\tremaining: 410ms\n",
            "10:\tlearn: 0.8472455\ttotal: 107ms\tremaining: 379ms\n",
            "11:\tlearn: 0.8235901\ttotal: 110ms\tremaining: 350ms\n",
            "12:\tlearn: 0.8026618\ttotal: 116ms\tremaining: 330ms\n",
            "13:\tlearn: 0.7814355\ttotal: 119ms\tremaining: 307ms\n",
            "14:\tlearn: 0.7613954\ttotal: 123ms\tremaining: 286ms\n",
            "15:\tlearn: 0.7412477\ttotal: 126ms\tremaining: 268ms\n",
            "16:\tlearn: 0.7228067\ttotal: 137ms\tremaining: 266ms\n",
            "17:\tlearn: 0.7065938\ttotal: 148ms\tremaining: 263ms\n",
            "18:\tlearn: 0.6885506\ttotal: 157ms\tremaining: 257ms\n",
            "19:\tlearn: 0.6722277\ttotal: 167ms\tremaining: 251ms\n",
            "20:\tlearn: 0.6578178\ttotal: 177ms\tremaining: 245ms\n",
            "21:\tlearn: 0.6445848\ttotal: 180ms\tremaining: 229ms\n",
            "22:\tlearn: 0.6327737\ttotal: 190ms\tremaining: 223ms\n",
            "23:\tlearn: 0.6206895\ttotal: 201ms\tremaining: 217ms\n",
            "24:\tlearn: 0.6094432\ttotal: 210ms\tremaining: 210ms\n",
            "25:\tlearn: 0.5979820\ttotal: 221ms\tremaining: 204ms\n",
            "26:\tlearn: 0.5869580\ttotal: 231ms\tremaining: 197ms\n",
            "27:\tlearn: 0.5770295\ttotal: 242ms\tremaining: 190ms\n",
            "28:\tlearn: 0.5680652\ttotal: 251ms\tremaining: 182ms\n",
            "29:\tlearn: 0.5575249\ttotal: 260ms\tremaining: 173ms\n",
            "30:\tlearn: 0.5492181\ttotal: 267ms\tremaining: 164ms\n",
            "31:\tlearn: 0.5415319\ttotal: 275ms\tremaining: 155ms\n",
            "32:\tlearn: 0.5333275\ttotal: 287ms\tremaining: 148ms\n",
            "33:\tlearn: 0.5254848\ttotal: 297ms\tremaining: 140ms\n",
            "34:\tlearn: 0.5184911\ttotal: 305ms\tremaining: 131ms\n",
            "35:\tlearn: 0.5114919\ttotal: 323ms\tremaining: 125ms\n",
            "36:\tlearn: 0.5039887\ttotal: 332ms\tremaining: 117ms\n",
            "37:\tlearn: 0.4977607\ttotal: 341ms\tremaining: 108ms\n",
            "38:\tlearn: 0.4918202\ttotal: 350ms\tremaining: 98.7ms\n",
            "39:\tlearn: 0.4865158\ttotal: 361ms\tremaining: 90.1ms\n",
            "40:\tlearn: 0.4810396\ttotal: 370ms\tremaining: 81.3ms\n",
            "41:\tlearn: 0.4758150\ttotal: 381ms\tremaining: 72.6ms\n",
            "42:\tlearn: 0.4706897\ttotal: 394ms\tremaining: 64.1ms\n",
            "43:\tlearn: 0.4663241\ttotal: 402ms\tremaining: 54.8ms\n",
            "44:\tlearn: 0.4616647\ttotal: 416ms\tremaining: 46.2ms\n",
            "45:\tlearn: 0.4567720\ttotal: 428ms\tremaining: 37.2ms\n",
            "46:\tlearn: 0.4530486\ttotal: 445ms\tremaining: 28.4ms\n",
            "47:\tlearn: 0.4492675\ttotal: 457ms\tremaining: 19ms\n",
            "48:\tlearn: 0.4453970\ttotal: 470ms\tremaining: 9.6ms\n",
            "49:\tlearn: 0.4416312\ttotal: 479ms\tremaining: 0us\n",
            "0:\tlearn: 1.1191846\ttotal: 11.4ms\tremaining: 558ms\n",
            "1:\tlearn: 1.0452029\ttotal: 21.6ms\tremaining: 518ms\n",
            "2:\tlearn: 0.9845394\ttotal: 32.5ms\tremaining: 509ms\n",
            "3:\tlearn: 0.9317197\ttotal: 43.9ms\tremaining: 505ms\n",
            "4:\tlearn: 0.8849220\ttotal: 56ms\tremaining: 504ms\n",
            "5:\tlearn: 0.8379313\ttotal: 65.5ms\tremaining: 480ms\n",
            "6:\tlearn: 0.7972742\ttotal: 75.5ms\tremaining: 464ms\n",
            "7:\tlearn: 0.7569038\ttotal: 91ms\tremaining: 478ms\n",
            "8:\tlearn: 0.7184576\ttotal: 112ms\tremaining: 508ms\n",
            "9:\tlearn: 0.6889329\ttotal: 120ms\tremaining: 482ms\n",
            "10:\tlearn: 0.6602859\ttotal: 137ms\tremaining: 485ms\n",
            "11:\tlearn: 0.6353305\ttotal: 155ms\tremaining: 491ms\n",
            "12:\tlearn: 0.6123527\ttotal: 166ms\tremaining: 474ms\n",
            "13:\tlearn: 0.5908512\ttotal: 180ms\tremaining: 462ms\n",
            "14:\tlearn: 0.5718959\ttotal: 189ms\tremaining: 440ms\n",
            "15:\tlearn: 0.5543632\ttotal: 200ms\tremaining: 424ms\n",
            "16:\tlearn: 0.5385055\ttotal: 211ms\tremaining: 409ms\n",
            "17:\tlearn: 0.5253771\ttotal: 221ms\tremaining: 393ms\n",
            "18:\tlearn: 0.5110949\ttotal: 229ms\tremaining: 374ms\n",
            "19:\tlearn: 0.4984792\ttotal: 243ms\tremaining: 364ms\n",
            "20:\tlearn: 0.4874620\ttotal: 253ms\tremaining: 350ms\n",
            "21:\tlearn: 0.4796183\ttotal: 255ms\tremaining: 325ms\n",
            "22:\tlearn: 0.4719566\ttotal: 273ms\tremaining: 321ms\n",
            "23:\tlearn: 0.4640156\ttotal: 284ms\tremaining: 308ms\n",
            "24:\tlearn: 0.4573047\ttotal: 295ms\tremaining: 295ms\n",
            "25:\tlearn: 0.4498544\ttotal: 312ms\tremaining: 288ms\n",
            "26:\tlearn: 0.4429272\ttotal: 320ms\tremaining: 273ms\n",
            "27:\tlearn: 0.4356733\ttotal: 334ms\tremaining: 262ms\n",
            "28:\tlearn: 0.4311015\ttotal: 345ms\tremaining: 250ms\n",
            "29:\tlearn: 0.4247462\ttotal: 356ms\tremaining: 238ms\n",
            "30:\tlearn: 0.4190468\ttotal: 366ms\tremaining: 225ms\n",
            "31:\tlearn: 0.4154056\ttotal: 377ms\tremaining: 212ms\n",
            "32:\tlearn: 0.4105526\ttotal: 384ms\tremaining: 198ms\n",
            "33:\tlearn: 0.4063557\ttotal: 389ms\tremaining: 183ms\n",
            "34:\tlearn: 0.4023261\ttotal: 394ms\tremaining: 169ms\n",
            "35:\tlearn: 0.3994098\ttotal: 398ms\tremaining: 155ms\n",
            "36:\tlearn: 0.3952323\ttotal: 404ms\tremaining: 142ms\n",
            "37:\tlearn: 0.3919421\ttotal: 408ms\tremaining: 129ms\n",
            "38:\tlearn: 0.3885386\ttotal: 413ms\tremaining: 116ms\n",
            "39:\tlearn: 0.3849884\ttotal: 418ms\tremaining: 104ms\n",
            "40:\tlearn: 0.3811318\ttotal: 429ms\tremaining: 94.1ms\n",
            "41:\tlearn: 0.3785658\ttotal: 442ms\tremaining: 84.1ms\n",
            "42:\tlearn: 0.3761936\ttotal: 447ms\tremaining: 72.8ms\n",
            "43:\tlearn: 0.3740997\ttotal: 459ms\tremaining: 62.6ms\n",
            "44:\tlearn: 0.3714154\ttotal: 476ms\tremaining: 52.9ms\n",
            "45:\tlearn: 0.3692956\ttotal: 487ms\tremaining: 42.4ms\n",
            "46:\tlearn: 0.3666561\ttotal: 494ms\tremaining: 31.5ms\n",
            "47:\tlearn: 0.3642574\ttotal: 497ms\tremaining: 20.7ms\n",
            "48:\tlearn: 0.3624645\ttotal: 502ms\tremaining: 10.2ms\n",
            "49:\tlearn: 0.3600117\ttotal: 506ms\tremaining: 0us\n",
            "0:\tlearn: 1.1297785\ttotal: 17.5ms\tremaining: 857ms\n",
            "1:\tlearn: 1.0577669\ttotal: 32ms\tremaining: 769ms\n",
            "2:\tlearn: 0.9879120\ttotal: 46.9ms\tremaining: 735ms\n",
            "3:\tlearn: 0.9309446\ttotal: 54.6ms\tremaining: 628ms\n",
            "4:\tlearn: 0.8841054\ttotal: 81.5ms\tremaining: 734ms\n",
            "5:\tlearn: 0.8348276\ttotal: 88.4ms\tremaining: 648ms\n",
            "6:\tlearn: 0.7937721\ttotal: 92ms\tremaining: 565ms\n",
            "7:\tlearn: 0.7572887\ttotal: 97.7ms\tremaining: 513ms\n",
            "8:\tlearn: 0.7227732\ttotal: 101ms\tremaining: 461ms\n",
            "9:\tlearn: 0.6934628\ttotal: 114ms\tremaining: 457ms\n",
            "10:\tlearn: 0.6664908\ttotal: 119ms\tremaining: 422ms\n",
            "11:\tlearn: 0.6421962\ttotal: 122ms\tremaining: 387ms\n",
            "12:\tlearn: 0.6185392\ttotal: 134ms\tremaining: 381ms\n",
            "13:\tlearn: 0.5959976\ttotal: 145ms\tremaining: 372ms\n",
            "14:\tlearn: 0.5780382\ttotal: 156ms\tremaining: 363ms\n",
            "15:\tlearn: 0.5589460\ttotal: 166ms\tremaining: 353ms\n",
            "16:\tlearn: 0.5433016\ttotal: 178ms\tremaining: 345ms\n",
            "17:\tlearn: 0.5291896\ttotal: 181ms\tremaining: 321ms\n",
            "18:\tlearn: 0.5159404\ttotal: 194ms\tremaining: 316ms\n",
            "19:\tlearn: 0.5036997\ttotal: 204ms\tremaining: 306ms\n",
            "20:\tlearn: 0.4930402\ttotal: 215ms\tremaining: 296ms\n",
            "21:\tlearn: 0.4844112\ttotal: 224ms\tremaining: 285ms\n",
            "22:\tlearn: 0.4763229\ttotal: 235ms\tremaining: 276ms\n",
            "23:\tlearn: 0.4677193\ttotal: 246ms\tremaining: 266ms\n",
            "24:\tlearn: 0.4601491\ttotal: 255ms\tremaining: 255ms\n",
            "25:\tlearn: 0.4535819\ttotal: 263ms\tremaining: 243ms\n",
            "26:\tlearn: 0.4466291\ttotal: 275ms\tremaining: 234ms\n",
            "27:\tlearn: 0.4407926\ttotal: 282ms\tremaining: 221ms\n",
            "28:\tlearn: 0.4341417\ttotal: 291ms\tremaining: 211ms\n",
            "29:\tlearn: 0.4299260\ttotal: 303ms\tremaining: 202ms\n",
            "30:\tlearn: 0.4263395\ttotal: 307ms\tremaining: 188ms\n",
            "31:\tlearn: 0.4229027\ttotal: 330ms\tremaining: 186ms\n",
            "32:\tlearn: 0.4180782\ttotal: 348ms\tremaining: 179ms\n",
            "33:\tlearn: 0.4143342\ttotal: 371ms\tremaining: 175ms\n",
            "34:\tlearn: 0.4108291\ttotal: 385ms\tremaining: 165ms\n",
            "35:\tlearn: 0.4073702\ttotal: 392ms\tremaining: 152ms\n",
            "36:\tlearn: 0.4031422\ttotal: 395ms\tremaining: 139ms\n",
            "37:\tlearn: 0.3994566\ttotal: 401ms\tremaining: 127ms\n",
            "38:\tlearn: 0.3960292\ttotal: 414ms\tremaining: 117ms\n",
            "39:\tlearn: 0.3923772\ttotal: 425ms\tremaining: 106ms\n",
            "40:\tlearn: 0.3864908\ttotal: 435ms\tremaining: 95.5ms\n",
            "41:\tlearn: 0.3817424\ttotal: 445ms\tremaining: 84.7ms\n",
            "42:\tlearn: 0.3784163\ttotal: 450ms\tremaining: 73.3ms\n",
            "43:\tlearn: 0.3759500\ttotal: 454ms\tremaining: 61.9ms\n",
            "44:\tlearn: 0.3732746\ttotal: 460ms\tremaining: 51.1ms\n",
            "45:\tlearn: 0.3713404\ttotal: 471ms\tremaining: 41ms\n",
            "46:\tlearn: 0.3691387\ttotal: 482ms\tremaining: 30.8ms\n",
            "47:\tlearn: 0.3658776\ttotal: 493ms\tremaining: 20.5ms\n",
            "48:\tlearn: 0.3640298\ttotal: 504ms\tremaining: 10.3ms\n",
            "49:\tlearn: 0.3613331\ttotal: 514ms\tremaining: 0us\n",
            "0:\tlearn: 1.1326958\ttotal: 15.5ms\tremaining: 760ms\n",
            "1:\tlearn: 1.0581352\ttotal: 17.5ms\tremaining: 420ms\n",
            "2:\tlearn: 0.9920356\ttotal: 24.2ms\tremaining: 379ms\n",
            "3:\tlearn: 0.9335234\ttotal: 28.8ms\tremaining: 332ms\n",
            "4:\tlearn: 0.8824805\ttotal: 40.3ms\tremaining: 362ms\n",
            "5:\tlearn: 0.8413172\ttotal: 49ms\tremaining: 359ms\n",
            "6:\tlearn: 0.7980229\ttotal: 64.3ms\tremaining: 395ms\n",
            "7:\tlearn: 0.7603478\ttotal: 72.7ms\tremaining: 381ms\n",
            "8:\tlearn: 0.7305857\ttotal: 74ms\tremaining: 337ms\n",
            "9:\tlearn: 0.7002153\ttotal: 79.3ms\tremaining: 317ms\n",
            "10:\tlearn: 0.6707713\ttotal: 99.4ms\tremaining: 352ms\n",
            "11:\tlearn: 0.6446154\ttotal: 122ms\tremaining: 388ms\n",
            "12:\tlearn: 0.6199604\ttotal: 130ms\tremaining: 369ms\n",
            "13:\tlearn: 0.6001798\ttotal: 144ms\tremaining: 369ms\n",
            "14:\tlearn: 0.5809652\ttotal: 156ms\tremaining: 363ms\n",
            "15:\tlearn: 0.5645532\ttotal: 166ms\tremaining: 352ms\n",
            "16:\tlearn: 0.5495867\ttotal: 176ms\tremaining: 343ms\n",
            "17:\tlearn: 0.5366935\ttotal: 187ms\tremaining: 332ms\n",
            "18:\tlearn: 0.5252402\ttotal: 230ms\tremaining: 375ms\n",
            "19:\tlearn: 0.5134976\ttotal: 237ms\tremaining: 356ms\n",
            "20:\tlearn: 0.5022419\ttotal: 241ms\tremaining: 333ms\n",
            "21:\tlearn: 0.4934886\ttotal: 248ms\tremaining: 315ms\n",
            "22:\tlearn: 0.4833749\ttotal: 264ms\tremaining: 310ms\n",
            "23:\tlearn: 0.4735533\ttotal: 272ms\tremaining: 295ms\n",
            "24:\tlearn: 0.4656952\ttotal: 285ms\tremaining: 285ms\n",
            "25:\tlearn: 0.4577290\ttotal: 296ms\tremaining: 273ms\n",
            "26:\tlearn: 0.4504522\ttotal: 324ms\tremaining: 276ms\n",
            "27:\tlearn: 0.4431676\ttotal: 334ms\tremaining: 263ms\n",
            "28:\tlearn: 0.4371560\ttotal: 345ms\tremaining: 250ms\n",
            "29:\tlearn: 0.4318582\ttotal: 364ms\tremaining: 242ms\n",
            "30:\tlearn: 0.4255729\ttotal: 374ms\tremaining: 229ms\n",
            "31:\tlearn: 0.4211793\ttotal: 383ms\tremaining: 215ms\n",
            "32:\tlearn: 0.4161657\ttotal: 393ms\tremaining: 203ms\n",
            "33:\tlearn: 0.4129952\ttotal: 397ms\tremaining: 187ms\n",
            "34:\tlearn: 0.4079863\ttotal: 413ms\tremaining: 177ms\n",
            "35:\tlearn: 0.4044979\ttotal: 425ms\tremaining: 165ms\n",
            "36:\tlearn: 0.4019920\ttotal: 437ms\tremaining: 154ms\n",
            "37:\tlearn: 0.3974133\ttotal: 446ms\tremaining: 141ms\n",
            "38:\tlearn: 0.3936350\ttotal: 456ms\tremaining: 129ms\n",
            "39:\tlearn: 0.3893071\ttotal: 469ms\tremaining: 117ms\n",
            "40:\tlearn: 0.3855545\ttotal: 480ms\tremaining: 105ms\n",
            "41:\tlearn: 0.3827514\ttotal: 495ms\tremaining: 94.3ms\n",
            "42:\tlearn: 0.3800832\ttotal: 505ms\tremaining: 82.3ms\n",
            "43:\tlearn: 0.3775218\ttotal: 515ms\tremaining: 70.3ms\n",
            "44:\tlearn: 0.3752024\ttotal: 520ms\tremaining: 57.8ms\n",
            "45:\tlearn: 0.3732419\ttotal: 524ms\tremaining: 45.6ms\n",
            "46:\tlearn: 0.3707455\ttotal: 530ms\tremaining: 33.8ms\n",
            "47:\tlearn: 0.3690791\ttotal: 541ms\tremaining: 22.5ms\n",
            "48:\tlearn: 0.3660370\ttotal: 546ms\tremaining: 11.1ms\n",
            "49:\tlearn: 0.3644524\ttotal: 552ms\tremaining: 0us\n",
            "0:\tlearn: 1.0521079\ttotal: 30.8ms\tremaining: 1.51s\n",
            "1:\tlearn: 0.9864275\ttotal: 48.5ms\tremaining: 1.16s\n",
            "2:\tlearn: 0.9266642\ttotal: 61.9ms\tremaining: 970ms\n",
            "3:\tlearn: 0.8746035\ttotal: 64.8ms\tremaining: 745ms\n",
            "4:\tlearn: 0.8247692\ttotal: 79.1ms\tremaining: 712ms\n",
            "5:\tlearn: 0.7830651\ttotal: 94.1ms\tremaining: 690ms\n",
            "6:\tlearn: 0.7414261\ttotal: 107ms\tremaining: 657ms\n",
            "7:\tlearn: 0.7064585\ttotal: 122ms\tremaining: 638ms\n",
            "8:\tlearn: 0.6775646\ttotal: 154ms\tremaining: 702ms\n",
            "9:\tlearn: 0.6500848\ttotal: 172ms\tremaining: 686ms\n",
            "10:\tlearn: 0.6233436\ttotal: 190ms\tremaining: 674ms\n",
            "11:\tlearn: 0.6014238\ttotal: 203ms\tremaining: 642ms\n",
            "12:\tlearn: 0.5788770\ttotal: 227ms\tremaining: 645ms\n",
            "13:\tlearn: 0.5608705\ttotal: 242ms\tremaining: 621ms\n",
            "14:\tlearn: 0.5449960\ttotal: 251ms\tremaining: 585ms\n",
            "15:\tlearn: 0.5299764\ttotal: 263ms\tremaining: 558ms\n",
            "16:\tlearn: 0.5167847\ttotal: 275ms\tremaining: 534ms\n",
            "17:\tlearn: 0.5047850\ttotal: 290ms\tremaining: 516ms\n",
            "18:\tlearn: 0.4933301\ttotal: 309ms\tremaining: 505ms\n",
            "19:\tlearn: 0.4842505\ttotal: 312ms\tremaining: 468ms\n",
            "20:\tlearn: 0.4742333\ttotal: 322ms\tremaining: 445ms\n",
            "21:\tlearn: 0.4651577\ttotal: 332ms\tremaining: 422ms\n",
            "22:\tlearn: 0.4573963\ttotal: 341ms\tremaining: 401ms\n",
            "23:\tlearn: 0.4493159\ttotal: 351ms\tremaining: 380ms\n",
            "24:\tlearn: 0.4433560\ttotal: 363ms\tremaining: 363ms\n",
            "25:\tlearn: 0.4373930\ttotal: 373ms\tremaining: 344ms\n",
            "26:\tlearn: 0.4295788\ttotal: 383ms\tremaining: 326ms\n",
            "27:\tlearn: 0.4237240\ttotal: 393ms\tremaining: 309ms\n",
            "28:\tlearn: 0.4181841\ttotal: 404ms\tremaining: 292ms\n",
            "29:\tlearn: 0.4141460\ttotal: 422ms\tremaining: 281ms\n",
            "30:\tlearn: 0.4101532\ttotal: 432ms\tremaining: 265ms\n",
            "31:\tlearn: 0.4062490\ttotal: 439ms\tremaining: 247ms\n",
            "32:\tlearn: 0.4025887\ttotal: 450ms\tremaining: 232ms\n",
            "33:\tlearn: 0.3997349\ttotal: 476ms\tremaining: 224ms\n",
            "34:\tlearn: 0.3961595\ttotal: 484ms\tremaining: 207ms\n",
            "35:\tlearn: 0.3923901\ttotal: 494ms\tremaining: 192ms\n",
            "36:\tlearn: 0.3886777\ttotal: 504ms\tremaining: 177ms\n",
            "37:\tlearn: 0.3853421\ttotal: 523ms\tremaining: 165ms\n",
            "38:\tlearn: 0.3829539\ttotal: 537ms\tremaining: 151ms\n",
            "39:\tlearn: 0.3798572\ttotal: 544ms\tremaining: 136ms\n",
            "40:\tlearn: 0.3772581\ttotal: 558ms\tremaining: 122ms\n",
            "41:\tlearn: 0.3739610\ttotal: 564ms\tremaining: 107ms\n",
            "42:\tlearn: 0.3716995\ttotal: 573ms\tremaining: 93.3ms\n",
            "43:\tlearn: 0.3687102\ttotal: 579ms\tremaining: 79ms\n",
            "44:\tlearn: 0.3663658\ttotal: 592ms\tremaining: 65.8ms\n",
            "45:\tlearn: 0.3639976\ttotal: 603ms\tremaining: 52.4ms\n",
            "46:\tlearn: 0.3612756\ttotal: 614ms\tremaining: 39.2ms\n",
            "47:\tlearn: 0.3586366\ttotal: 629ms\tremaining: 26.2ms\n",
            "48:\tlearn: 0.3567554\ttotal: 641ms\tremaining: 13.1ms\n",
            "49:\tlearn: 0.3537854\ttotal: 652ms\tremaining: 0us\n",
            "0:\tlearn: 1.1091159\ttotal: 16.4ms\tremaining: 805ms\n",
            "1:\tlearn: 1.0322748\ttotal: 20.3ms\tremaining: 488ms\n",
            "2:\tlearn: 0.9702119\ttotal: 33.6ms\tremaining: 526ms\n",
            "3:\tlearn: 0.9164060\ttotal: 44.1ms\tremaining: 507ms\n",
            "4:\tlearn: 0.8606641\ttotal: 54.5ms\tremaining: 490ms\n",
            "5:\tlearn: 0.8123918\ttotal: 67.7ms\tremaining: 496ms\n",
            "6:\tlearn: 0.7704688\ttotal: 85.5ms\tremaining: 525ms\n",
            "7:\tlearn: 0.7339386\ttotal: 99.6ms\tremaining: 523ms\n",
            "8:\tlearn: 0.6989444\ttotal: 110ms\tremaining: 499ms\n",
            "9:\tlearn: 0.6683920\ttotal: 120ms\tremaining: 479ms\n",
            "10:\tlearn: 0.6408518\ttotal: 130ms\tremaining: 460ms\n",
            "11:\tlearn: 0.6131755\ttotal: 140ms\tremaining: 445ms\n",
            "12:\tlearn: 0.5920669\ttotal: 149ms\tremaining: 423ms\n",
            "13:\tlearn: 0.5724651\ttotal: 157ms\tremaining: 403ms\n",
            "14:\tlearn: 0.5525575\ttotal: 168ms\tremaining: 392ms\n",
            "15:\tlearn: 0.5350332\ttotal: 172ms\tremaining: 366ms\n",
            "16:\tlearn: 0.5211740\ttotal: 186ms\tremaining: 362ms\n",
            "17:\tlearn: 0.5088247\ttotal: 191ms\tremaining: 340ms\n",
            "18:\tlearn: 0.4960191\ttotal: 197ms\tremaining: 321ms\n",
            "19:\tlearn: 0.4840227\ttotal: 200ms\tremaining: 300ms\n",
            "20:\tlearn: 0.4737626\ttotal: 205ms\tremaining: 283ms\n",
            "21:\tlearn: 0.4644591\ttotal: 209ms\tremaining: 266ms\n",
            "22:\tlearn: 0.4561710\ttotal: 214ms\tremaining: 251ms\n",
            "23:\tlearn: 0.4488759\ttotal: 217ms\tremaining: 235ms\n",
            "24:\tlearn: 0.4411844\ttotal: 223ms\tremaining: 223ms\n",
            "25:\tlearn: 0.4350026\ttotal: 228ms\tremaining: 210ms\n",
            "26:\tlearn: 0.4281069\ttotal: 231ms\tremaining: 197ms\n",
            "27:\tlearn: 0.4211834\ttotal: 237ms\tremaining: 187ms\n",
            "28:\tlearn: 0.4135186\ttotal: 241ms\tremaining: 175ms\n",
            "29:\tlearn: 0.4087935\ttotal: 246ms\tremaining: 164ms\n",
            "30:\tlearn: 0.4047743\ttotal: 250ms\tremaining: 153ms\n",
            "31:\tlearn: 0.3996573\ttotal: 256ms\tremaining: 144ms\n",
            "32:\tlearn: 0.3947474\ttotal: 260ms\tremaining: 134ms\n",
            "33:\tlearn: 0.3900595\ttotal: 267ms\tremaining: 126ms\n",
            "34:\tlearn: 0.3865553\ttotal: 278ms\tremaining: 119ms\n",
            "35:\tlearn: 0.3828618\ttotal: 282ms\tremaining: 110ms\n",
            "36:\tlearn: 0.3794255\ttotal: 287ms\tremaining: 101ms\n",
            "37:\tlearn: 0.3766635\ttotal: 298ms\tremaining: 94.2ms\n",
            "38:\tlearn: 0.3730721\ttotal: 309ms\tremaining: 87.1ms\n",
            "39:\tlearn: 0.3698222\ttotal: 315ms\tremaining: 78.8ms\n",
            "40:\tlearn: 0.3672132\ttotal: 319ms\tremaining: 70.1ms\n",
            "41:\tlearn: 0.3635204\ttotal: 324ms\tremaining: 61.7ms\n",
            "42:\tlearn: 0.3607559\ttotal: 329ms\tremaining: 53.6ms\n",
            "43:\tlearn: 0.3588371\ttotal: 333ms\tremaining: 45.4ms\n",
            "44:\tlearn: 0.3563436\ttotal: 338ms\tremaining: 37.5ms\n",
            "45:\tlearn: 0.3536347\ttotal: 341ms\tremaining: 29.7ms\n",
            "46:\tlearn: 0.3513130\ttotal: 346ms\tremaining: 22.1ms\n",
            "47:\tlearn: 0.3491476\ttotal: 351ms\tremaining: 14.6ms\n",
            "48:\tlearn: 0.3469050\ttotal: 356ms\tremaining: 7.26ms\n",
            "49:\tlearn: 0.3446662\ttotal: 360ms\tremaining: 0us\n",
            "0:\tlearn: 1.1811925\ttotal: 5.64ms\tremaining: 558ms\n",
            "1:\tlearn: 1.1731276\ttotal: 10.8ms\tremaining: 530ms\n",
            "2:\tlearn: 1.1656301\ttotal: 30.2ms\tremaining: 976ms\n",
            "3:\tlearn: 1.1578273\ttotal: 39.1ms\tremaining: 939ms\n",
            "4:\tlearn: 1.1508432\ttotal: 47.8ms\tremaining: 908ms\n",
            "5:\tlearn: 1.1434320\ttotal: 54.5ms\tremaining: 854ms\n",
            "6:\tlearn: 1.1357352\ttotal: 77.8ms\tremaining: 1.03s\n",
            "7:\tlearn: 1.1283011\ttotal: 87.5ms\tremaining: 1.01s\n",
            "8:\tlearn: 1.1210419\ttotal: 96.3ms\tremaining: 974ms\n",
            "9:\tlearn: 1.1139553\ttotal: 109ms\tremaining: 978ms\n",
            "10:\tlearn: 1.1069452\ttotal: 119ms\tremaining: 965ms\n",
            "11:\tlearn: 1.0994638\ttotal: 123ms\tremaining: 904ms\n",
            "12:\tlearn: 1.0928993\ttotal: 137ms\tremaining: 919ms\n",
            "13:\tlearn: 1.0859003\ttotal: 147ms\tremaining: 905ms\n",
            "14:\tlearn: 1.0795148\ttotal: 155ms\tremaining: 876ms\n",
            "15:\tlearn: 1.0722062\ttotal: 159ms\tremaining: 835ms\n",
            "16:\tlearn: 1.0656809\ttotal: 167ms\tremaining: 815ms\n",
            "17:\tlearn: 1.0598314\ttotal: 178ms\tremaining: 812ms\n",
            "18:\tlearn: 1.0531044\ttotal: 190ms\tremaining: 808ms\n",
            "19:\tlearn: 1.0463672\ttotal: 204ms\tremaining: 815ms\n",
            "20:\tlearn: 1.0399440\ttotal: 208ms\tremaining: 783ms\n",
            "21:\tlearn: 1.0342489\ttotal: 226ms\tremaining: 802ms\n",
            "22:\tlearn: 1.0282982\ttotal: 232ms\tremaining: 775ms\n",
            "23:\tlearn: 1.0229945\ttotal: 237ms\tremaining: 751ms\n",
            "24:\tlearn: 1.0170669\ttotal: 242ms\tremaining: 725ms\n",
            "25:\tlearn: 1.0104798\ttotal: 246ms\tremaining: 701ms\n",
            "26:\tlearn: 1.0042434\ttotal: 251ms\tremaining: 677ms\n",
            "27:\tlearn: 0.9979945\ttotal: 257ms\tremaining: 660ms\n",
            "28:\tlearn: 0.9920052\ttotal: 260ms\tremaining: 637ms\n",
            "29:\tlearn: 0.9858915\ttotal: 265ms\tremaining: 618ms\n",
            "30:\tlearn: 0.9803128\ttotal: 269ms\tremaining: 598ms\n",
            "31:\tlearn: 0.9744930\ttotal: 273ms\tremaining: 581ms\n",
            "32:\tlearn: 0.9689819\ttotal: 277ms\tremaining: 563ms\n",
            "33:\tlearn: 0.9634365\ttotal: 281ms\tremaining: 545ms\n",
            "34:\tlearn: 0.9580731\ttotal: 286ms\tremaining: 532ms\n",
            "35:\tlearn: 0.9522917\ttotal: 290ms\tremaining: 515ms\n",
            "36:\tlearn: 0.9466432\ttotal: 295ms\tremaining: 503ms\n",
            "37:\tlearn: 0.9409734\ttotal: 299ms\tremaining: 488ms\n",
            "38:\tlearn: 0.9353513\ttotal: 302ms\tremaining: 473ms\n",
            "39:\tlearn: 0.9300268\ttotal: 308ms\tremaining: 462ms\n",
            "40:\tlearn: 0.9245169\ttotal: 311ms\tremaining: 448ms\n",
            "41:\tlearn: 0.9189340\ttotal: 317ms\tremaining: 437ms\n",
            "42:\tlearn: 0.9138221\ttotal: 320ms\tremaining: 424ms\n",
            "43:\tlearn: 0.9087022\ttotal: 323ms\tremaining: 412ms\n",
            "44:\tlearn: 0.9036623\ttotal: 329ms\tremaining: 402ms\n",
            "45:\tlearn: 0.8984557\ttotal: 332ms\tremaining: 390ms\n",
            "46:\tlearn: 0.8937439\ttotal: 337ms\tremaining: 380ms\n",
            "47:\tlearn: 0.8891105\ttotal: 341ms\tremaining: 369ms\n",
            "48:\tlearn: 0.8844541\ttotal: 346ms\tremaining: 360ms\n",
            "49:\tlearn: 0.8796637\ttotal: 347ms\tremaining: 347ms\n",
            "50:\tlearn: 0.8751659\ttotal: 351ms\tremaining: 337ms\n",
            "51:\tlearn: 0.8698242\ttotal: 355ms\tremaining: 328ms\n",
            "52:\tlearn: 0.8650360\ttotal: 359ms\tremaining: 318ms\n",
            "53:\tlearn: 0.8602660\ttotal: 362ms\tremaining: 309ms\n",
            "54:\tlearn: 0.8554405\ttotal: 373ms\tremaining: 305ms\n",
            "55:\tlearn: 0.8506026\ttotal: 383ms\tremaining: 301ms\n",
            "56:\tlearn: 0.8463848\ttotal: 402ms\tremaining: 303ms\n",
            "57:\tlearn: 0.8416534\ttotal: 421ms\tremaining: 305ms\n",
            "58:\tlearn: 0.8371830\ttotal: 425ms\tremaining: 296ms\n",
            "59:\tlearn: 0.8327011\ttotal: 438ms\tremaining: 292ms\n",
            "60:\tlearn: 0.8287647\ttotal: 451ms\tremaining: 288ms\n",
            "61:\tlearn: 0.8247270\ttotal: 462ms\tremaining: 283ms\n",
            "62:\tlearn: 0.8206223\ttotal: 480ms\tremaining: 282ms\n",
            "63:\tlearn: 0.8166267\ttotal: 493ms\tremaining: 278ms\n",
            "64:\tlearn: 0.8124499\ttotal: 514ms\tremaining: 277ms\n",
            "65:\tlearn: 0.8082171\ttotal: 530ms\tremaining: 273ms\n",
            "66:\tlearn: 0.8042426\ttotal: 558ms\tremaining: 275ms\n",
            "67:\tlearn: 0.8000478\ttotal: 567ms\tremaining: 267ms\n",
            "68:\tlearn: 0.7964217\ttotal: 569ms\tremaining: 256ms\n",
            "69:\tlearn: 0.7920087\ttotal: 581ms\tremaining: 249ms\n",
            "70:\tlearn: 0.7879604\ttotal: 592ms\tremaining: 242ms\n",
            "71:\tlearn: 0.7844107\ttotal: 599ms\tremaining: 233ms\n",
            "72:\tlearn: 0.7804452\ttotal: 610ms\tremaining: 226ms\n",
            "73:\tlearn: 0.7765521\ttotal: 631ms\tremaining: 222ms\n",
            "74:\tlearn: 0.7731963\ttotal: 643ms\tremaining: 214ms\n",
            "75:\tlearn: 0.7692279\ttotal: 654ms\tremaining: 207ms\n",
            "76:\tlearn: 0.7658471\ttotal: 663ms\tremaining: 198ms\n",
            "77:\tlearn: 0.7624850\ttotal: 681ms\tremaining: 192ms\n",
            "78:\tlearn: 0.7587851\ttotal: 696ms\tremaining: 185ms\n",
            "79:\tlearn: 0.7552088\ttotal: 706ms\tremaining: 177ms\n",
            "80:\tlearn: 0.7518367\ttotal: 722ms\tremaining: 169ms\n",
            "81:\tlearn: 0.7485487\ttotal: 749ms\tremaining: 164ms\n",
            "82:\tlearn: 0.7448950\ttotal: 764ms\tremaining: 156ms\n",
            "83:\tlearn: 0.7412440\ttotal: 781ms\tremaining: 149ms\n",
            "84:\tlearn: 0.7377293\ttotal: 804ms\tremaining: 142ms\n",
            "85:\tlearn: 0.7345679\ttotal: 835ms\tremaining: 136ms\n",
            "86:\tlearn: 0.7312703\ttotal: 861ms\tremaining: 129ms\n",
            "87:\tlearn: 0.7280179\ttotal: 896ms\tremaining: 122ms\n",
            "88:\tlearn: 0.7244676\ttotal: 904ms\tremaining: 112ms\n",
            "89:\tlearn: 0.7215065\ttotal: 915ms\tremaining: 102ms\n",
            "90:\tlearn: 0.7181126\ttotal: 927ms\tremaining: 91.7ms\n",
            "91:\tlearn: 0.7148712\ttotal: 935ms\tremaining: 81.3ms\n",
            "92:\tlearn: 0.7118322\ttotal: 940ms\tremaining: 70.7ms\n",
            "93:\tlearn: 0.7085959\ttotal: 944ms\tremaining: 60.3ms\n",
            "94:\tlearn: 0.7055273\ttotal: 948ms\tremaining: 49.9ms\n",
            "95:\tlearn: 0.7024050\ttotal: 952ms\tremaining: 39.7ms\n",
            "96:\tlearn: 0.6992350\ttotal: 957ms\tremaining: 29.6ms\n",
            "97:\tlearn: 0.6962565\ttotal: 961ms\tremaining: 19.6ms\n",
            "98:\tlearn: 0.6930839\ttotal: 967ms\tremaining: 9.77ms\n",
            "99:\tlearn: 0.6900116\ttotal: 971ms\tremaining: 0us\n",
            "0:\tlearn: 1.1948033\ttotal: 8.58ms\tremaining: 849ms\n",
            "1:\tlearn: 1.1868804\ttotal: 21.7ms\tremaining: 1.06s\n",
            "2:\tlearn: 1.1786868\ttotal: 39.5ms\tremaining: 1.28s\n",
            "3:\tlearn: 1.1711221\ttotal: 48.2ms\tremaining: 1.16s\n",
            "4:\tlearn: 1.1642144\ttotal: 51.8ms\tremaining: 985ms\n",
            "5:\tlearn: 1.1565381\ttotal: 63ms\tremaining: 987ms\n",
            "6:\tlearn: 1.1486746\ttotal: 74.1ms\tremaining: 984ms\n",
            "7:\tlearn: 1.1409993\ttotal: 87.7ms\tremaining: 1.01s\n",
            "8:\tlearn: 1.1335541\ttotal: 93.5ms\tremaining: 946ms\n",
            "9:\tlearn: 1.1261032\ttotal: 117ms\tremaining: 1.05s\n",
            "10:\tlearn: 1.1191365\ttotal: 144ms\tremaining: 1.16s\n",
            "11:\tlearn: 1.1121681\ttotal: 149ms\tremaining: 1.09s\n",
            "12:\tlearn: 1.1053784\ttotal: 153ms\tremaining: 1.02s\n",
            "13:\tlearn: 1.0987585\ttotal: 158ms\tremaining: 972ms\n",
            "14:\tlearn: 1.0916959\ttotal: 167ms\tremaining: 946ms\n",
            "15:\tlearn: 1.0845434\ttotal: 172ms\tremaining: 902ms\n",
            "16:\tlearn: 1.0773326\ttotal: 176ms\tremaining: 860ms\n",
            "17:\tlearn: 1.0708203\ttotal: 181ms\tremaining: 823ms\n",
            "18:\tlearn: 1.0640323\ttotal: 189ms\tremaining: 804ms\n",
            "19:\tlearn: 1.0571240\ttotal: 196ms\tremaining: 785ms\n",
            "20:\tlearn: 1.0508071\ttotal: 202ms\tremaining: 758ms\n",
            "21:\tlearn: 1.0443540\ttotal: 203ms\tremaining: 719ms\n",
            "22:\tlearn: 1.0379073\ttotal: 209ms\tremaining: 699ms\n",
            "23:\tlearn: 1.0322213\ttotal: 214ms\tremaining: 679ms\n",
            "24:\tlearn: 1.0256041\ttotal: 216ms\tremaining: 649ms\n",
            "25:\tlearn: 1.0193364\ttotal: 222ms\tremaining: 631ms\n",
            "26:\tlearn: 1.0130042\ttotal: 235ms\tremaining: 635ms\n",
            "27:\tlearn: 1.0066394\ttotal: 248ms\tremaining: 637ms\n",
            "28:\tlearn: 1.0002395\ttotal: 268ms\tremaining: 655ms\n",
            "29:\tlearn: 0.9942054\ttotal: 290ms\tremaining: 678ms\n",
            "30:\tlearn: 0.9880574\ttotal: 299ms\tremaining: 665ms\n",
            "31:\tlearn: 0.9820847\ttotal: 308ms\tremaining: 655ms\n",
            "32:\tlearn: 0.9763213\ttotal: 318ms\tremaining: 645ms\n",
            "33:\tlearn: 0.9705706\ttotal: 321ms\tremaining: 624ms\n",
            "34:\tlearn: 0.9649609\ttotal: 333ms\tremaining: 618ms\n",
            "35:\tlearn: 0.9591670\ttotal: 341ms\tremaining: 606ms\n",
            "36:\tlearn: 0.9535965\ttotal: 349ms\tremaining: 595ms\n",
            "37:\tlearn: 0.9476858\ttotal: 357ms\tremaining: 582ms\n",
            "38:\tlearn: 0.9419056\ttotal: 367ms\tremaining: 575ms\n",
            "39:\tlearn: 0.9365906\ttotal: 372ms\tremaining: 558ms\n",
            "40:\tlearn: 0.9313213\ttotal: 383ms\tremaining: 551ms\n",
            "41:\tlearn: 0.9260838\ttotal: 390ms\tremaining: 539ms\n",
            "42:\tlearn: 0.9206054\ttotal: 402ms\tremaining: 533ms\n",
            "43:\tlearn: 0.9151004\ttotal: 411ms\tremaining: 524ms\n",
            "44:\tlearn: 0.9103112\ttotal: 412ms\tremaining: 504ms\n",
            "45:\tlearn: 0.9048578\ttotal: 428ms\tremaining: 502ms\n",
            "46:\tlearn: 0.9001707\ttotal: 434ms\tremaining: 489ms\n",
            "47:\tlearn: 0.8956511\ttotal: 442ms\tremaining: 479ms\n",
            "48:\tlearn: 0.8907327\ttotal: 465ms\tremaining: 484ms\n",
            "49:\tlearn: 0.8859428\ttotal: 496ms\tremaining: 496ms\n",
            "50:\tlearn: 0.8813043\ttotal: 506ms\tremaining: 486ms\n",
            "51:\tlearn: 0.8762404\ttotal: 516ms\tremaining: 476ms\n",
            "52:\tlearn: 0.8714694\ttotal: 518ms\tremaining: 459ms\n",
            "53:\tlearn: 0.8666659\ttotal: 530ms\tremaining: 452ms\n",
            "54:\tlearn: 0.8620861\ttotal: 532ms\tremaining: 436ms\n",
            "55:\tlearn: 0.8571273\ttotal: 536ms\tremaining: 421ms\n",
            "56:\tlearn: 0.8525924\ttotal: 540ms\tremaining: 407ms\n",
            "57:\tlearn: 0.8477973\ttotal: 552ms\tremaining: 399ms\n",
            "58:\tlearn: 0.8432724\ttotal: 566ms\tremaining: 394ms\n",
            "59:\tlearn: 0.8389868\ttotal: 578ms\tremaining: 386ms\n",
            "60:\tlearn: 0.8344782\ttotal: 587ms\tremaining: 375ms\n",
            "61:\tlearn: 0.8303185\ttotal: 601ms\tremaining: 368ms\n",
            "62:\tlearn: 0.8261651\ttotal: 610ms\tremaining: 358ms\n",
            "63:\tlearn: 0.8219163\ttotal: 621ms\tremaining: 349ms\n",
            "64:\tlearn: 0.8173845\ttotal: 631ms\tremaining: 340ms\n",
            "65:\tlearn: 0.8134084\ttotal: 641ms\tremaining: 330ms\n",
            "66:\tlearn: 0.8091419\ttotal: 645ms\tremaining: 318ms\n",
            "67:\tlearn: 0.8050205\ttotal: 658ms\tremaining: 310ms\n",
            "68:\tlearn: 0.8012089\ttotal: 662ms\tremaining: 297ms\n",
            "69:\tlearn: 0.7975957\ttotal: 674ms\tremaining: 289ms\n",
            "70:\tlearn: 0.7936797\ttotal: 683ms\tremaining: 279ms\n",
            "71:\tlearn: 0.7897372\ttotal: 704ms\tremaining: 274ms\n",
            "72:\tlearn: 0.7858742\ttotal: 713ms\tremaining: 264ms\n",
            "73:\tlearn: 0.7819953\ttotal: 738ms\tremaining: 259ms\n",
            "74:\tlearn: 0.7780605\ttotal: 750ms\tremaining: 250ms\n",
            "75:\tlearn: 0.7743833\ttotal: 765ms\tremaining: 242ms\n",
            "76:\tlearn: 0.7707699\ttotal: 773ms\tremaining: 231ms\n",
            "77:\tlearn: 0.7672110\ttotal: 783ms\tremaining: 221ms\n",
            "78:\tlearn: 0.7636429\ttotal: 785ms\tremaining: 209ms\n",
            "79:\tlearn: 0.7596917\ttotal: 802ms\tremaining: 201ms\n",
            "80:\tlearn: 0.7563513\ttotal: 819ms\tremaining: 192ms\n",
            "81:\tlearn: 0.7529448\ttotal: 831ms\tremaining: 182ms\n",
            "82:\tlearn: 0.7495118\ttotal: 853ms\tremaining: 175ms\n",
            "83:\tlearn: 0.7460516\ttotal: 872ms\tremaining: 166ms\n",
            "84:\tlearn: 0.7424672\ttotal: 890ms\tremaining: 157ms\n",
            "85:\tlearn: 0.7386043\ttotal: 901ms\tremaining: 147ms\n",
            "86:\tlearn: 0.7351002\ttotal: 912ms\tremaining: 136ms\n",
            "87:\tlearn: 0.7319417\ttotal: 944ms\tremaining: 129ms\n",
            "88:\tlearn: 0.7284965\ttotal: 962ms\tremaining: 119ms\n",
            "89:\tlearn: 0.7252012\ttotal: 980ms\tremaining: 109ms\n",
            "90:\tlearn: 0.7218138\ttotal: 1s\tremaining: 99.3ms\n",
            "91:\tlearn: 0.7185143\ttotal: 1.01s\tremaining: 88.3ms\n",
            "92:\tlearn: 0.7153742\ttotal: 1.03s\tremaining: 77.6ms\n",
            "93:\tlearn: 0.7125928\ttotal: 1.04s\tremaining: 66.7ms\n",
            "94:\tlearn: 0.7094082\ttotal: 1.06s\tremaining: 56ms\n",
            "95:\tlearn: 0.7062175\ttotal: 1.08s\tremaining: 44.9ms\n",
            "96:\tlearn: 0.7031546\ttotal: 1.1s\tremaining: 34.1ms\n",
            "97:\tlearn: 0.6998049\ttotal: 1.12s\tremaining: 22.8ms\n",
            "98:\tlearn: 0.6967410\ttotal: 1.14s\tremaining: 11.5ms\n",
            "99:\tlearn: 0.6937934\ttotal: 1.16s\tremaining: 0us\n",
            "0:\tlearn: 1.2021182\ttotal: 3.63ms\tremaining: 359ms\n",
            "1:\tlearn: 1.1938555\ttotal: 7.1ms\tremaining: 348ms\n",
            "2:\tlearn: 1.1859689\ttotal: 18.6ms\tremaining: 601ms\n",
            "3:\tlearn: 1.1777824\ttotal: 37.3ms\tremaining: 896ms\n",
            "4:\tlearn: 1.1704444\ttotal: 50.2ms\tremaining: 954ms\n",
            "5:\tlearn: 1.1631228\ttotal: 54.5ms\tremaining: 854ms\n",
            "6:\tlearn: 1.1555988\ttotal: 60.2ms\tremaining: 800ms\n",
            "7:\tlearn: 1.1476531\ttotal: 83.8ms\tremaining: 964ms\n",
            "8:\tlearn: 1.1405305\ttotal: 84.9ms\tremaining: 858ms\n",
            "9:\tlearn: 1.1334035\ttotal: 107ms\tremaining: 963ms\n",
            "10:\tlearn: 1.1260166\ttotal: 123ms\tremaining: 996ms\n",
            "11:\tlearn: 1.1188022\ttotal: 134ms\tremaining: 985ms\n",
            "12:\tlearn: 1.1112787\ttotal: 147ms\tremaining: 981ms\n",
            "13:\tlearn: 1.1042604\ttotal: 158ms\tremaining: 969ms\n",
            "14:\tlearn: 1.0968172\ttotal: 167ms\tremaining: 947ms\n",
            "15:\tlearn: 1.0898048\ttotal: 171ms\tremaining: 900ms\n",
            "16:\tlearn: 1.0833869\ttotal: 183ms\tremaining: 892ms\n",
            "17:\tlearn: 1.0761682\ttotal: 192ms\tremaining: 874ms\n",
            "18:\tlearn: 1.0691355\ttotal: 202ms\tremaining: 861ms\n",
            "19:\tlearn: 1.0627954\ttotal: 215ms\tremaining: 860ms\n",
            "20:\tlearn: 1.0562888\ttotal: 225ms\tremaining: 845ms\n",
            "21:\tlearn: 1.0499731\ttotal: 235ms\tremaining: 831ms\n",
            "22:\tlearn: 1.0432530\ttotal: 244ms\tremaining: 816ms\n",
            "23:\tlearn: 1.0365435\ttotal: 249ms\tremaining: 787ms\n",
            "24:\tlearn: 1.0305677\ttotal: 260ms\tremaining: 781ms\n",
            "25:\tlearn: 1.0237389\ttotal: 269ms\tremaining: 765ms\n",
            "26:\tlearn: 1.0172034\ttotal: 277ms\tremaining: 748ms\n",
            "27:\tlearn: 1.0109815\ttotal: 286ms\tremaining: 735ms\n",
            "28:\tlearn: 1.0049400\ttotal: 297ms\tremaining: 727ms\n",
            "29:\tlearn: 0.9989020\ttotal: 306ms\tremaining: 713ms\n",
            "30:\tlearn: 0.9929950\ttotal: 316ms\tremaining: 702ms\n",
            "31:\tlearn: 0.9868785\ttotal: 325ms\tremaining: 690ms\n",
            "32:\tlearn: 0.9805111\ttotal: 338ms\tremaining: 687ms\n",
            "33:\tlearn: 0.9745530\ttotal: 348ms\tremaining: 675ms\n",
            "34:\tlearn: 0.9691502\ttotal: 359ms\tremaining: 667ms\n",
            "35:\tlearn: 0.9637073\ttotal: 369ms\tremaining: 656ms\n",
            "36:\tlearn: 0.9580423\ttotal: 380ms\tremaining: 646ms\n",
            "37:\tlearn: 0.9519723\ttotal: 400ms\tremaining: 653ms\n",
            "38:\tlearn: 0.9464684\ttotal: 406ms\tremaining: 636ms\n",
            "39:\tlearn: 0.9407873\ttotal: 413ms\tremaining: 620ms\n",
            "40:\tlearn: 0.9355922\ttotal: 424ms\tremaining: 610ms\n",
            "41:\tlearn: 0.9304304\ttotal: 429ms\tremaining: 592ms\n",
            "42:\tlearn: 0.9251111\ttotal: 433ms\tremaining: 574ms\n",
            "43:\tlearn: 0.9199165\ttotal: 438ms\tremaining: 557ms\n",
            "44:\tlearn: 0.9147306\ttotal: 440ms\tremaining: 537ms\n",
            "45:\tlearn: 0.9092890\ttotal: 442ms\tremaining: 519ms\n",
            "46:\tlearn: 0.9040876\ttotal: 445ms\tremaining: 502ms\n",
            "47:\tlearn: 0.8990719\ttotal: 448ms\tremaining: 485ms\n",
            "48:\tlearn: 0.8944792\ttotal: 460ms\tremaining: 478ms\n",
            "49:\tlearn: 0.8900029\ttotal: 471ms\tremaining: 471ms\n",
            "50:\tlearn: 0.8852376\ttotal: 482ms\tremaining: 463ms\n",
            "51:\tlearn: 0.8803043\ttotal: 492ms\tremaining: 454ms\n",
            "52:\tlearn: 0.8760371\ttotal: 501ms\tremaining: 444ms\n",
            "53:\tlearn: 0.8713243\ttotal: 512ms\tremaining: 436ms\n",
            "54:\tlearn: 0.8669879\ttotal: 523ms\tremaining: 428ms\n",
            "55:\tlearn: 0.8624924\ttotal: 542ms\tremaining: 426ms\n",
            "56:\tlearn: 0.8583928\ttotal: 544ms\tremaining: 410ms\n",
            "57:\tlearn: 0.8539292\ttotal: 553ms\tremaining: 401ms\n",
            "58:\tlearn: 0.8492753\ttotal: 562ms\tremaining: 391ms\n",
            "59:\tlearn: 0.8447808\ttotal: 574ms\tremaining: 382ms\n",
            "60:\tlearn: 0.8403718\ttotal: 585ms\tremaining: 374ms\n",
            "61:\tlearn: 0.8358524\ttotal: 596ms\tremaining: 365ms\n",
            "62:\tlearn: 0.8313962\ttotal: 607ms\tremaining: 356ms\n",
            "63:\tlearn: 0.8272361\ttotal: 618ms\tremaining: 347ms\n",
            "64:\tlearn: 0.8229367\ttotal: 628ms\tremaining: 338ms\n",
            "65:\tlearn: 0.8189387\ttotal: 638ms\tremaining: 329ms\n",
            "66:\tlearn: 0.8150310\ttotal: 649ms\tremaining: 319ms\n",
            "67:\tlearn: 0.8110412\ttotal: 657ms\tremaining: 309ms\n",
            "68:\tlearn: 0.8070509\ttotal: 668ms\tremaining: 300ms\n",
            "69:\tlearn: 0.8028345\ttotal: 679ms\tremaining: 291ms\n",
            "70:\tlearn: 0.7990542\ttotal: 691ms\tremaining: 282ms\n",
            "71:\tlearn: 0.7949697\ttotal: 701ms\tremaining: 273ms\n",
            "72:\tlearn: 0.7910955\ttotal: 713ms\tremaining: 264ms\n",
            "73:\tlearn: 0.7871645\ttotal: 722ms\tremaining: 254ms\n",
            "74:\tlearn: 0.7833109\ttotal: 726ms\tremaining: 242ms\n",
            "75:\tlearn: 0.7796092\ttotal: 733ms\tremaining: 231ms\n",
            "76:\tlearn: 0.7760436\ttotal: 738ms\tremaining: 220ms\n",
            "77:\tlearn: 0.7725602\ttotal: 741ms\tremaining: 209ms\n",
            "78:\tlearn: 0.7690794\ttotal: 753ms\tremaining: 200ms\n",
            "79:\tlearn: 0.7655914\ttotal: 762ms\tremaining: 190ms\n",
            "80:\tlearn: 0.7617753\ttotal: 768ms\tremaining: 180ms\n",
            "81:\tlearn: 0.7579842\ttotal: 778ms\tremaining: 171ms\n",
            "82:\tlearn: 0.7545169\ttotal: 782ms\tremaining: 160ms\n",
            "83:\tlearn: 0.7507553\ttotal: 785ms\tremaining: 149ms\n",
            "84:\tlearn: 0.7473973\ttotal: 789ms\tremaining: 139ms\n",
            "85:\tlearn: 0.7437024\ttotal: 794ms\tremaining: 129ms\n",
            "86:\tlearn: 0.7405052\ttotal: 799ms\tremaining: 119ms\n",
            "87:\tlearn: 0.7369142\ttotal: 804ms\tremaining: 110ms\n",
            "88:\tlearn: 0.7335857\ttotal: 815ms\tremaining: 101ms\n",
            "89:\tlearn: 0.7302868\ttotal: 831ms\tremaining: 92.3ms\n",
            "90:\tlearn: 0.7267705\ttotal: 842ms\tremaining: 83.3ms\n",
            "91:\tlearn: 0.7234208\ttotal: 855ms\tremaining: 74.4ms\n",
            "92:\tlearn: 0.7203850\ttotal: 869ms\tremaining: 65.4ms\n",
            "93:\tlearn: 0.7173333\ttotal: 886ms\tremaining: 56.6ms\n",
            "94:\tlearn: 0.7143199\ttotal: 903ms\tremaining: 47.5ms\n",
            "95:\tlearn: 0.7110529\ttotal: 922ms\tremaining: 38.4ms\n",
            "96:\tlearn: 0.7081326\ttotal: 931ms\tremaining: 28.8ms\n",
            "97:\tlearn: 0.7048095\ttotal: 945ms\tremaining: 19.3ms\n",
            "98:\tlearn: 0.7019552\ttotal: 956ms\tremaining: 9.66ms\n",
            "99:\tlearn: 0.6990712\ttotal: 964ms\tremaining: 0us\n",
            "0:\tlearn: 1.1154270\ttotal: 11.3ms\tremaining: 1.12s\n",
            "1:\tlearn: 1.1081992\ttotal: 37.3ms\tremaining: 1.83s\n",
            "2:\tlearn: 1.1005579\ttotal: 41.7ms\tremaining: 1.35s\n",
            "3:\tlearn: 1.0933088\ttotal: 54.2ms\tremaining: 1.3s\n",
            "4:\tlearn: 1.0867963\ttotal: 59.4ms\tremaining: 1.13s\n",
            "5:\tlearn: 1.0803676\ttotal: 68.2ms\tremaining: 1.07s\n",
            "6:\tlearn: 1.0733330\ttotal: 74.3ms\tremaining: 988ms\n",
            "7:\tlearn: 1.0662091\ttotal: 86.5ms\tremaining: 995ms\n",
            "8:\tlearn: 1.0593072\ttotal: 93.6ms\tremaining: 946ms\n",
            "9:\tlearn: 1.0525912\ttotal: 107ms\tremaining: 960ms\n",
            "10:\tlearn: 1.0460696\ttotal: 116ms\tremaining: 941ms\n",
            "11:\tlearn: 1.0395222\ttotal: 118ms\tremaining: 868ms\n",
            "12:\tlearn: 1.0329659\ttotal: 127ms\tremaining: 849ms\n",
            "13:\tlearn: 1.0262868\ttotal: 137ms\tremaining: 842ms\n",
            "14:\tlearn: 1.0200686\ttotal: 156ms\tremaining: 882ms\n",
            "15:\tlearn: 1.0134447\ttotal: 168ms\tremaining: 882ms\n",
            "16:\tlearn: 1.0070533\ttotal: 182ms\tremaining: 888ms\n",
            "17:\tlearn: 1.0002182\ttotal: 190ms\tremaining: 864ms\n",
            "18:\tlearn: 0.9941103\ttotal: 195ms\tremaining: 831ms\n",
            "19:\tlearn: 0.9881533\ttotal: 215ms\tremaining: 859ms\n",
            "20:\tlearn: 0.9819406\ttotal: 218ms\tremaining: 819ms\n",
            "21:\tlearn: 0.9764819\ttotal: 232ms\tremaining: 822ms\n",
            "22:\tlearn: 0.9707462\ttotal: 237ms\tremaining: 793ms\n",
            "23:\tlearn: 0.9649453\ttotal: 248ms\tremaining: 784ms\n",
            "24:\tlearn: 0.9590697\ttotal: 253ms\tremaining: 760ms\n",
            "25:\tlearn: 0.9537789\ttotal: 268ms\tremaining: 762ms\n",
            "26:\tlearn: 0.9476648\ttotal: 281ms\tremaining: 759ms\n",
            "27:\tlearn: 0.9421209\ttotal: 286ms\tremaining: 736ms\n",
            "28:\tlearn: 0.9365554\ttotal: 304ms\tremaining: 744ms\n",
            "29:\tlearn: 0.9309459\ttotal: 316ms\tremaining: 737ms\n",
            "30:\tlearn: 0.9255205\ttotal: 329ms\tremaining: 731ms\n",
            "31:\tlearn: 0.9202569\ttotal: 335ms\tremaining: 711ms\n",
            "32:\tlearn: 0.9152051\ttotal: 339ms\tremaining: 689ms\n",
            "33:\tlearn: 0.9098925\ttotal: 352ms\tremaining: 683ms\n",
            "34:\tlearn: 0.9048139\ttotal: 363ms\tremaining: 674ms\n",
            "35:\tlearn: 0.8997409\ttotal: 368ms\tremaining: 654ms\n",
            "36:\tlearn: 0.8947655\ttotal: 375ms\tremaining: 639ms\n",
            "37:\tlearn: 0.8897268\ttotal: 381ms\tremaining: 622ms\n",
            "38:\tlearn: 0.8844258\ttotal: 407ms\tremaining: 637ms\n",
            "39:\tlearn: 0.8795428\ttotal: 418ms\tremaining: 627ms\n",
            "40:\tlearn: 0.8746564\ttotal: 426ms\tremaining: 613ms\n",
            "41:\tlearn: 0.8700432\ttotal: 439ms\tremaining: 607ms\n",
            "42:\tlearn: 0.8651963\ttotal: 449ms\tremaining: 595ms\n",
            "43:\tlearn: 0.8601983\ttotal: 459ms\tremaining: 584ms\n",
            "44:\tlearn: 0.8558090\ttotal: 462ms\tremaining: 565ms\n",
            "45:\tlearn: 0.8508197\ttotal: 480ms\tremaining: 563ms\n",
            "46:\tlearn: 0.8461796\ttotal: 490ms\tremaining: 553ms\n",
            "47:\tlearn: 0.8420661\ttotal: 501ms\tremaining: 542ms\n",
            "48:\tlearn: 0.8376900\ttotal: 511ms\tremaining: 532ms\n",
            "49:\tlearn: 0.8333064\ttotal: 535ms\tremaining: 535ms\n",
            "50:\tlearn: 0.8288953\ttotal: 551ms\tremaining: 529ms\n",
            "51:\tlearn: 0.8244244\ttotal: 560ms\tremaining: 517ms\n",
            "52:\tlearn: 0.8203915\ttotal: 567ms\tremaining: 503ms\n",
            "53:\tlearn: 0.8159218\ttotal: 578ms\tremaining: 492ms\n",
            "54:\tlearn: 0.8116842\ttotal: 582ms\tremaining: 476ms\n",
            "55:\tlearn: 0.8071531\ttotal: 597ms\tremaining: 469ms\n",
            "56:\tlearn: 0.8031969\ttotal: 601ms\tremaining: 453ms\n",
            "57:\tlearn: 0.7996044\ttotal: 602ms\tremaining: 436ms\n",
            "58:\tlearn: 0.7956224\ttotal: 613ms\tremaining: 426ms\n",
            "59:\tlearn: 0.7918728\ttotal: 621ms\tremaining: 414ms\n",
            "60:\tlearn: 0.7883795\ttotal: 632ms\tremaining: 404ms\n",
            "61:\tlearn: 0.7847686\ttotal: 643ms\tremaining: 394ms\n",
            "62:\tlearn: 0.7808386\ttotal: 651ms\tremaining: 382ms\n",
            "63:\tlearn: 0.7767926\ttotal: 672ms\tremaining: 378ms\n",
            "64:\tlearn: 0.7727655\ttotal: 683ms\tremaining: 368ms\n",
            "65:\tlearn: 0.7692245\ttotal: 694ms\tremaining: 358ms\n",
            "66:\tlearn: 0.7655038\ttotal: 698ms\tremaining: 344ms\n",
            "67:\tlearn: 0.7620741\ttotal: 707ms\tremaining: 333ms\n",
            "68:\tlearn: 0.7584030\ttotal: 714ms\tremaining: 321ms\n",
            "69:\tlearn: 0.7546443\ttotal: 724ms\tremaining: 310ms\n",
            "70:\tlearn: 0.7512800\ttotal: 734ms\tremaining: 300ms\n",
            "71:\tlearn: 0.7473840\ttotal: 744ms\tremaining: 289ms\n",
            "72:\tlearn: 0.7434689\ttotal: 757ms\tremaining: 280ms\n",
            "73:\tlearn: 0.7400982\ttotal: 766ms\tremaining: 269ms\n",
            "74:\tlearn: 0.7366405\ttotal: 780ms\tremaining: 260ms\n",
            "75:\tlearn: 0.7332311\ttotal: 791ms\tremaining: 250ms\n",
            "76:\tlearn: 0.7298505\ttotal: 802ms\tremaining: 240ms\n",
            "77:\tlearn: 0.7270190\ttotal: 813ms\tremaining: 229ms\n",
            "78:\tlearn: 0.7235866\ttotal: 826ms\tremaining: 219ms\n",
            "79:\tlearn: 0.7204906\ttotal: 836ms\tremaining: 209ms\n",
            "80:\tlearn: 0.7171649\ttotal: 844ms\tremaining: 198ms\n",
            "81:\tlearn: 0.7141441\ttotal: 858ms\tremaining: 188ms\n",
            "82:\tlearn: 0.7111351\ttotal: 869ms\tremaining: 178ms\n",
            "83:\tlearn: 0.7079388\ttotal: 871ms\tremaining: 166ms\n",
            "84:\tlearn: 0.7044311\ttotal: 881ms\tremaining: 155ms\n",
            "85:\tlearn: 0.7011278\ttotal: 896ms\tremaining: 146ms\n",
            "86:\tlearn: 0.6982286\ttotal: 901ms\tremaining: 135ms\n",
            "87:\tlearn: 0.6950492\ttotal: 917ms\tremaining: 125ms\n",
            "88:\tlearn: 0.6918976\ttotal: 923ms\tremaining: 114ms\n",
            "89:\tlearn: 0.6887972\ttotal: 937ms\tremaining: 104ms\n",
            "90:\tlearn: 0.6857124\ttotal: 951ms\tremaining: 94.1ms\n",
            "91:\tlearn: 0.6829487\ttotal: 959ms\tremaining: 83.4ms\n",
            "92:\tlearn: 0.6801797\ttotal: 968ms\tremaining: 72.9ms\n",
            "93:\tlearn: 0.6775331\ttotal: 980ms\tremaining: 62.5ms\n",
            "94:\tlearn: 0.6746423\ttotal: 987ms\tremaining: 52ms\n",
            "95:\tlearn: 0.6716955\ttotal: 997ms\tremaining: 41.5ms\n",
            "96:\tlearn: 0.6689149\ttotal: 1.01s\tremaining: 31.2ms\n",
            "97:\tlearn: 0.6659480\ttotal: 1.02s\tremaining: 20.8ms\n",
            "98:\tlearn: 0.6632445\ttotal: 1.02s\tremaining: 10.3ms\n",
            "99:\tlearn: 0.6604910\ttotal: 1.03s\tremaining: 0us\n",
            "0:\tlearn: 1.1771981\ttotal: 15.6ms\tremaining: 1.54s\n",
            "1:\tlearn: 1.1687422\ttotal: 18.5ms\tremaining: 909ms\n",
            "2:\tlearn: 1.1611901\ttotal: 36.2ms\tremaining: 1.17s\n",
            "3:\tlearn: 1.1534411\ttotal: 40.6ms\tremaining: 974ms\n",
            "4:\tlearn: 1.1454339\ttotal: 53.2ms\tremaining: 1.01s\n",
            "5:\tlearn: 1.1387039\ttotal: 61.6ms\tremaining: 965ms\n",
            "6:\tlearn: 1.1314737\ttotal: 75.6ms\tremaining: 1s\n",
            "7:\tlearn: 1.1235532\ttotal: 88.4ms\tremaining: 1.02s\n",
            "8:\tlearn: 1.1164578\ttotal: 97.8ms\tremaining: 989ms\n",
            "9:\tlearn: 1.1092208\ttotal: 109ms\tremaining: 983ms\n",
            "10:\tlearn: 1.1020870\ttotal: 120ms\tremaining: 971ms\n",
            "11:\tlearn: 1.0955784\ttotal: 130ms\tremaining: 955ms\n",
            "12:\tlearn: 1.0884854\ttotal: 142ms\tremaining: 949ms\n",
            "13:\tlearn: 1.0817795\ttotal: 151ms\tremaining: 925ms\n",
            "14:\tlearn: 1.0747243\ttotal: 157ms\tremaining: 892ms\n",
            "15:\tlearn: 1.0676128\ttotal: 171ms\tremaining: 900ms\n",
            "16:\tlearn: 1.0615284\ttotal: 182ms\tremaining: 889ms\n",
            "17:\tlearn: 1.0550795\ttotal: 192ms\tremaining: 876ms\n",
            "18:\tlearn: 1.0484345\ttotal: 204ms\tremaining: 869ms\n",
            "19:\tlearn: 1.0418251\ttotal: 208ms\tremaining: 831ms\n",
            "20:\tlearn: 1.0353824\ttotal: 214ms\tremaining: 804ms\n",
            "21:\tlearn: 1.0290087\ttotal: 225ms\tremaining: 797ms\n",
            "22:\tlearn: 1.0227209\ttotal: 226ms\tremaining: 758ms\n",
            "23:\tlearn: 1.0162496\ttotal: 240ms\tremaining: 760ms\n",
            "24:\tlearn: 1.0101533\ttotal: 255ms\tremaining: 765ms\n",
            "25:\tlearn: 1.0039470\ttotal: 269ms\tremaining: 765ms\n",
            "26:\tlearn: 0.9977154\ttotal: 279ms\tremaining: 754ms\n",
            "27:\tlearn: 0.9919390\ttotal: 290ms\tremaining: 746ms\n",
            "28:\tlearn: 0.9861830\ttotal: 301ms\tremaining: 737ms\n",
            "29:\tlearn: 0.9806262\ttotal: 312ms\tremaining: 729ms\n",
            "30:\tlearn: 0.9745779\ttotal: 323ms\tremaining: 720ms\n",
            "31:\tlearn: 0.9687549\ttotal: 333ms\tremaining: 707ms\n",
            "32:\tlearn: 0.9629793\ttotal: 344ms\tremaining: 699ms\n",
            "33:\tlearn: 0.9571566\ttotal: 349ms\tremaining: 678ms\n",
            "34:\tlearn: 0.9514242\ttotal: 354ms\tremaining: 657ms\n",
            "35:\tlearn: 0.9454967\ttotal: 357ms\tremaining: 635ms\n",
            "36:\tlearn: 0.9397082\ttotal: 362ms\tremaining: 616ms\n",
            "37:\tlearn: 0.9342836\ttotal: 366ms\tremaining: 597ms\n",
            "38:\tlearn: 0.9293068\ttotal: 371ms\tremaining: 581ms\n",
            "39:\tlearn: 0.9240071\ttotal: 375ms\tremaining: 562ms\n",
            "40:\tlearn: 0.9188088\ttotal: 380ms\tremaining: 547ms\n",
            "41:\tlearn: 0.9132206\ttotal: 382ms\tremaining: 528ms\n",
            "42:\tlearn: 0.9080545\ttotal: 386ms\tremaining: 511ms\n",
            "43:\tlearn: 0.9027865\ttotal: 390ms\tremaining: 496ms\n",
            "44:\tlearn: 0.8974117\ttotal: 395ms\tremaining: 483ms\n",
            "45:\tlearn: 0.8925288\ttotal: 399ms\tremaining: 468ms\n",
            "46:\tlearn: 0.8874177\ttotal: 404ms\tremaining: 456ms\n",
            "47:\tlearn: 0.8822644\ttotal: 408ms\tremaining: 442ms\n",
            "48:\tlearn: 0.8773759\ttotal: 413ms\tremaining: 429ms\n",
            "49:\tlearn: 0.8725960\ttotal: 417ms\tremaining: 417ms\n",
            "50:\tlearn: 0.8678677\ttotal: 425ms\tremaining: 409ms\n",
            "51:\tlearn: 0.8634867\ttotal: 438ms\tremaining: 404ms\n",
            "52:\tlearn: 0.8584470\ttotal: 441ms\tremaining: 391ms\n",
            "53:\tlearn: 0.8537142\ttotal: 446ms\tremaining: 380ms\n",
            "54:\tlearn: 0.8488933\ttotal: 450ms\tremaining: 368ms\n",
            "55:\tlearn: 0.8439683\ttotal: 455ms\tremaining: 358ms\n",
            "56:\tlearn: 0.8397769\ttotal: 459ms\tremaining: 346ms\n",
            "57:\tlearn: 0.8348460\ttotal: 468ms\tremaining: 339ms\n",
            "58:\tlearn: 0.8303191\ttotal: 481ms\tremaining: 334ms\n",
            "59:\tlearn: 0.8262945\ttotal: 492ms\tremaining: 328ms\n",
            "60:\tlearn: 0.8218359\ttotal: 503ms\tremaining: 321ms\n",
            "61:\tlearn: 0.8179772\ttotal: 513ms\tremaining: 315ms\n",
            "62:\tlearn: 0.8136775\ttotal: 523ms\tremaining: 307ms\n",
            "63:\tlearn: 0.8094930\ttotal: 526ms\tremaining: 296ms\n",
            "64:\tlearn: 0.8053486\ttotal: 539ms\tremaining: 290ms\n",
            "65:\tlearn: 0.8011812\ttotal: 550ms\tremaining: 283ms\n",
            "66:\tlearn: 0.7972185\ttotal: 560ms\tremaining: 276ms\n",
            "67:\tlearn: 0.7929112\ttotal: 570ms\tremaining: 268ms\n",
            "68:\tlearn: 0.7887594\ttotal: 581ms\tremaining: 261ms\n",
            "69:\tlearn: 0.7844611\ttotal: 591ms\tremaining: 253ms\n",
            "70:\tlearn: 0.7803550\ttotal: 602ms\tremaining: 246ms\n",
            "71:\tlearn: 0.7763578\ttotal: 625ms\tremaining: 243ms\n",
            "72:\tlearn: 0.7721394\ttotal: 635ms\tremaining: 235ms\n",
            "73:\tlearn: 0.7683079\ttotal: 646ms\tremaining: 227ms\n",
            "74:\tlearn: 0.7642622\ttotal: 656ms\tremaining: 219ms\n",
            "75:\tlearn: 0.7602721\ttotal: 667ms\tremaining: 211ms\n",
            "76:\tlearn: 0.7563389\ttotal: 677ms\tremaining: 202ms\n",
            "77:\tlearn: 0.7526170\ttotal: 692ms\tremaining: 195ms\n",
            "78:\tlearn: 0.7491599\ttotal: 703ms\tremaining: 187ms\n",
            "79:\tlearn: 0.7454935\ttotal: 713ms\tremaining: 178ms\n",
            "80:\tlearn: 0.7418814\ttotal: 724ms\tremaining: 170ms\n",
            "81:\tlearn: 0.7381447\ttotal: 734ms\tremaining: 161ms\n",
            "82:\tlearn: 0.7346716\ttotal: 745ms\tremaining: 153ms\n",
            "83:\tlearn: 0.7310545\ttotal: 750ms\tremaining: 143ms\n",
            "84:\tlearn: 0.7277811\ttotal: 764ms\tremaining: 135ms\n",
            "85:\tlearn: 0.7243180\ttotal: 773ms\tremaining: 126ms\n",
            "86:\tlearn: 0.7212743\ttotal: 783ms\tremaining: 117ms\n",
            "87:\tlearn: 0.7177863\ttotal: 794ms\tremaining: 108ms\n",
            "88:\tlearn: 0.7144248\ttotal: 805ms\tremaining: 99.5ms\n",
            "89:\tlearn: 0.7109988\ttotal: 823ms\tremaining: 91.5ms\n",
            "90:\tlearn: 0.7074666\ttotal: 833ms\tremaining: 82.4ms\n",
            "91:\tlearn: 0.7038671\ttotal: 845ms\tremaining: 73.4ms\n",
            "92:\tlearn: 0.7007977\ttotal: 855ms\tremaining: 64.4ms\n",
            "93:\tlearn: 0.6978774\ttotal: 866ms\tremaining: 55.3ms\n",
            "94:\tlearn: 0.6948383\ttotal: 874ms\tremaining: 46ms\n",
            "95:\tlearn: 0.6915808\ttotal: 884ms\tremaining: 36.8ms\n",
            "96:\tlearn: 0.6884214\ttotal: 895ms\tremaining: 27.7ms\n",
            "97:\tlearn: 0.6853956\ttotal: 902ms\tremaining: 18.4ms\n",
            "98:\tlearn: 0.6824403\ttotal: 913ms\tremaining: 9.22ms\n",
            "99:\tlearn: 0.6794347\ttotal: 922ms\tremaining: 0us\n",
            "0:\tlearn: 1.1534314\ttotal: 4.01ms\tremaining: 397ms\n",
            "1:\tlearn: 1.1145823\ttotal: 17.8ms\tremaining: 871ms\n",
            "2:\tlearn: 1.0781290\ttotal: 22.4ms\tremaining: 726ms\n",
            "3:\tlearn: 1.0482640\ttotal: 30.2ms\tremaining: 725ms\n",
            "4:\tlearn: 1.0188022\ttotal: 34.1ms\tremaining: 648ms\n",
            "5:\tlearn: 0.9877129\ttotal: 39.7ms\tremaining: 623ms\n",
            "6:\tlearn: 0.9598303\ttotal: 43.6ms\tremaining: 579ms\n",
            "7:\tlearn: 0.9316988\ttotal: 49.1ms\tremaining: 564ms\n",
            "8:\tlearn: 0.9045311\ttotal: 61.7ms\tremaining: 623ms\n",
            "9:\tlearn: 0.8807412\ttotal: 66.2ms\tremaining: 596ms\n",
            "10:\tlearn: 0.8575307\ttotal: 71.9ms\tremaining: 582ms\n",
            "11:\tlearn: 0.8346986\ttotal: 75.7ms\tremaining: 555ms\n",
            "12:\tlearn: 0.8131474\ttotal: 81.4ms\tremaining: 545ms\n",
            "13:\tlearn: 0.7936631\ttotal: 85.3ms\tremaining: 524ms\n",
            "14:\tlearn: 0.7741517\ttotal: 90.8ms\tremaining: 514ms\n",
            "15:\tlearn: 0.7546885\ttotal: 103ms\tremaining: 540ms\n",
            "16:\tlearn: 0.7353991\ttotal: 115ms\tremaining: 561ms\n",
            "17:\tlearn: 0.7196336\ttotal: 130ms\tremaining: 593ms\n",
            "18:\tlearn: 0.7032100\ttotal: 144ms\tremaining: 613ms\n",
            "19:\tlearn: 0.6866780\ttotal: 158ms\tremaining: 633ms\n",
            "20:\tlearn: 0.6725578\ttotal: 169ms\tremaining: 636ms\n",
            "21:\tlearn: 0.6609522\ttotal: 171ms\tremaining: 608ms\n",
            "22:\tlearn: 0.6483524\ttotal: 186ms\tremaining: 623ms\n",
            "23:\tlearn: 0.6375724\ttotal: 198ms\tremaining: 628ms\n",
            "24:\tlearn: 0.6270418\ttotal: 208ms\tremaining: 625ms\n",
            "25:\tlearn: 0.6144221\ttotal: 224ms\tremaining: 638ms\n",
            "26:\tlearn: 0.6040061\ttotal: 228ms\tremaining: 616ms\n",
            "27:\tlearn: 0.5943454\ttotal: 233ms\tremaining: 600ms\n",
            "28:\tlearn: 0.5845191\ttotal: 253ms\tremaining: 619ms\n",
            "29:\tlearn: 0.5745851\ttotal: 268ms\tremaining: 624ms\n",
            "30:\tlearn: 0.5654018\ttotal: 277ms\tremaining: 616ms\n",
            "31:\tlearn: 0.5579366\ttotal: 280ms\tremaining: 595ms\n",
            "32:\tlearn: 0.5499287\ttotal: 286ms\tremaining: 580ms\n",
            "33:\tlearn: 0.5414641\ttotal: 289ms\tremaining: 561ms\n",
            "34:\tlearn: 0.5345986\ttotal: 294ms\tremaining: 547ms\n",
            "35:\tlearn: 0.5271691\ttotal: 298ms\tremaining: 530ms\n",
            "36:\tlearn: 0.5202381\ttotal: 304ms\tremaining: 517ms\n",
            "37:\tlearn: 0.5137004\ttotal: 307ms\tremaining: 501ms\n",
            "38:\tlearn: 0.5078296\ttotal: 313ms\tremaining: 489ms\n",
            "39:\tlearn: 0.5029494\ttotal: 317ms\tremaining: 475ms\n",
            "40:\tlearn: 0.4974271\ttotal: 321ms\tremaining: 462ms\n",
            "41:\tlearn: 0.4927351\ttotal: 326ms\tremaining: 450ms\n",
            "42:\tlearn: 0.4875585\ttotal: 331ms\tremaining: 438ms\n",
            "43:\tlearn: 0.4825414\ttotal: 355ms\tremaining: 452ms\n",
            "44:\tlearn: 0.4781661\ttotal: 366ms\tremaining: 447ms\n",
            "45:\tlearn: 0.4741839\ttotal: 376ms\tremaining: 441ms\n",
            "46:\tlearn: 0.4706366\ttotal: 388ms\tremaining: 437ms\n",
            "47:\tlearn: 0.4674920\ttotal: 399ms\tremaining: 433ms\n",
            "48:\tlearn: 0.4637628\ttotal: 409ms\tremaining: 426ms\n",
            "49:\tlearn: 0.4600448\ttotal: 413ms\tremaining: 413ms\n",
            "50:\tlearn: 0.4574627\ttotal: 425ms\tremaining: 408ms\n",
            "51:\tlearn: 0.4539227\ttotal: 435ms\tremaining: 402ms\n",
            "52:\tlearn: 0.4504960\ttotal: 451ms\tremaining: 400ms\n",
            "53:\tlearn: 0.4467289\ttotal: 461ms\tremaining: 393ms\n",
            "54:\tlearn: 0.4438495\ttotal: 473ms\tremaining: 387ms\n",
            "55:\tlearn: 0.4404464\ttotal: 482ms\tremaining: 379ms\n",
            "56:\tlearn: 0.4378284\ttotal: 494ms\tremaining: 373ms\n",
            "57:\tlearn: 0.4343023\ttotal: 502ms\tremaining: 363ms\n",
            "58:\tlearn: 0.4307957\ttotal: 516ms\tremaining: 358ms\n",
            "59:\tlearn: 0.4274809\ttotal: 527ms\tremaining: 351ms\n",
            "60:\tlearn: 0.4250496\ttotal: 535ms\tremaining: 342ms\n",
            "61:\tlearn: 0.4228033\ttotal: 543ms\tremaining: 333ms\n",
            "62:\tlearn: 0.4207992\ttotal: 544ms\tremaining: 319ms\n",
            "63:\tlearn: 0.4189063\ttotal: 548ms\tremaining: 308ms\n",
            "64:\tlearn: 0.4165941\ttotal: 553ms\tremaining: 298ms\n",
            "65:\tlearn: 0.4144954\ttotal: 557ms\tremaining: 287ms\n",
            "66:\tlearn: 0.4122561\ttotal: 561ms\tremaining: 276ms\n",
            "67:\tlearn: 0.4093959\ttotal: 567ms\tremaining: 267ms\n",
            "68:\tlearn: 0.4074969\ttotal: 572ms\tremaining: 257ms\n",
            "69:\tlearn: 0.4062697\ttotal: 573ms\tremaining: 246ms\n",
            "70:\tlearn: 0.4038647\ttotal: 578ms\tremaining: 236ms\n",
            "71:\tlearn: 0.4026810\ttotal: 583ms\tremaining: 227ms\n",
            "72:\tlearn: 0.4003111\ttotal: 593ms\tremaining: 219ms\n",
            "73:\tlearn: 0.3983559\ttotal: 596ms\tremaining: 210ms\n",
            "74:\tlearn: 0.3963057\ttotal: 600ms\tremaining: 200ms\n",
            "75:\tlearn: 0.3938962\ttotal: 606ms\tremaining: 191ms\n",
            "76:\tlearn: 0.3918098\ttotal: 612ms\tremaining: 183ms\n",
            "77:\tlearn: 0.3896788\ttotal: 615ms\tremaining: 173ms\n",
            "78:\tlearn: 0.3880332\ttotal: 619ms\tremaining: 165ms\n",
            "79:\tlearn: 0.3863678\ttotal: 624ms\tremaining: 156ms\n",
            "80:\tlearn: 0.3848002\ttotal: 628ms\tremaining: 147ms\n",
            "81:\tlearn: 0.3832468\ttotal: 647ms\tremaining: 142ms\n",
            "82:\tlearn: 0.3816313\ttotal: 651ms\tremaining: 133ms\n",
            "83:\tlearn: 0.3804193\ttotal: 656ms\tremaining: 125ms\n",
            "84:\tlearn: 0.3788417\ttotal: 660ms\tremaining: 116ms\n",
            "85:\tlearn: 0.3774626\ttotal: 665ms\tremaining: 108ms\n",
            "86:\tlearn: 0.3761856\ttotal: 668ms\tremaining: 99.9ms\n",
            "87:\tlearn: 0.3747166\ttotal: 673ms\tremaining: 91.8ms\n",
            "88:\tlearn: 0.3733808\ttotal: 677ms\tremaining: 83.7ms\n",
            "89:\tlearn: 0.3715697\ttotal: 682ms\tremaining: 75.7ms\n",
            "90:\tlearn: 0.3705765\ttotal: 685ms\tremaining: 67.8ms\n",
            "91:\tlearn: 0.3693809\ttotal: 690ms\tremaining: 60ms\n",
            "92:\tlearn: 0.3683608\ttotal: 693ms\tremaining: 52.2ms\n",
            "93:\tlearn: 0.3669210\ttotal: 698ms\tremaining: 44.6ms\n",
            "94:\tlearn: 0.3659790\ttotal: 704ms\tremaining: 37.1ms\n",
            "95:\tlearn: 0.3640214\ttotal: 708ms\tremaining: 29.5ms\n",
            "96:\tlearn: 0.3628547\ttotal: 719ms\tremaining: 22.2ms\n",
            "97:\tlearn: 0.3616517\ttotal: 732ms\tremaining: 14.9ms\n",
            "98:\tlearn: 0.3603571\ttotal: 747ms\tremaining: 7.54ms\n",
            "99:\tlearn: 0.3593440\ttotal: 761ms\tremaining: 0us\n",
            "0:\tlearn: 1.1656690\ttotal: 13.4ms\tremaining: 1.32s\n",
            "1:\tlearn: 1.1276511\ttotal: 29.4ms\tremaining: 1.44s\n",
            "2:\tlearn: 1.0926105\ttotal: 55.7ms\tremaining: 1.8s\n",
            "3:\tlearn: 1.0583985\ttotal: 68.4ms\tremaining: 1.64s\n",
            "4:\tlearn: 1.0293827\ttotal: 76.6ms\tremaining: 1.46s\n",
            "5:\tlearn: 0.9979422\ttotal: 85.2ms\tremaining: 1.33s\n",
            "6:\tlearn: 0.9670341\ttotal: 97.1ms\tremaining: 1.29s\n",
            "7:\tlearn: 0.9379754\ttotal: 108ms\tremaining: 1.24s\n",
            "8:\tlearn: 0.9094968\ttotal: 118ms\tremaining: 1.19s\n",
            "9:\tlearn: 0.8856354\ttotal: 128ms\tremaining: 1.16s\n",
            "10:\tlearn: 0.8631469\ttotal: 136ms\tremaining: 1.1s\n",
            "11:\tlearn: 0.8398534\ttotal: 140ms\tremaining: 1.02s\n",
            "12:\tlearn: 0.8170228\ttotal: 143ms\tremaining: 959ms\n",
            "13:\tlearn: 0.7966822\ttotal: 149ms\tremaining: 917ms\n",
            "14:\tlearn: 0.7764747\ttotal: 153ms\tremaining: 866ms\n",
            "15:\tlearn: 0.7564327\ttotal: 158ms\tremaining: 831ms\n",
            "16:\tlearn: 0.7380844\ttotal: 160ms\tremaining: 783ms\n",
            "17:\tlearn: 0.7206338\ttotal: 164ms\tremaining: 747ms\n",
            "18:\tlearn: 0.7052867\ttotal: 169ms\tremaining: 721ms\n",
            "19:\tlearn: 0.6915988\ttotal: 176ms\tremaining: 702ms\n",
            "20:\tlearn: 0.6763551\ttotal: 183ms\tremaining: 690ms\n",
            "21:\tlearn: 0.6634213\ttotal: 194ms\tremaining: 687ms\n",
            "22:\tlearn: 0.6498204\ttotal: 203ms\tremaining: 681ms\n",
            "23:\tlearn: 0.6376361\ttotal: 216ms\tremaining: 683ms\n",
            "24:\tlearn: 0.6262502\ttotal: 227ms\tremaining: 682ms\n",
            "25:\tlearn: 0.6155611\ttotal: 238ms\tremaining: 677ms\n",
            "26:\tlearn: 0.6042354\ttotal: 248ms\tremaining: 671ms\n",
            "27:\tlearn: 0.5931156\ttotal: 258ms\tremaining: 664ms\n",
            "28:\tlearn: 0.5828729\ttotal: 268ms\tremaining: 656ms\n",
            "29:\tlearn: 0.5726640\ttotal: 276ms\tremaining: 645ms\n",
            "30:\tlearn: 0.5637674\ttotal: 281ms\tremaining: 627ms\n",
            "31:\tlearn: 0.5551177\ttotal: 285ms\tremaining: 607ms\n",
            "32:\tlearn: 0.5481044\ttotal: 292ms\tremaining: 592ms\n",
            "33:\tlearn: 0.5413189\ttotal: 312ms\tremaining: 605ms\n",
            "34:\tlearn: 0.5345150\ttotal: 322ms\tremaining: 598ms\n",
            "35:\tlearn: 0.5282372\ttotal: 332ms\tremaining: 591ms\n",
            "36:\tlearn: 0.5208710\ttotal: 344ms\tremaining: 585ms\n",
            "37:\tlearn: 0.5165041\ttotal: 346ms\tremaining: 565ms\n",
            "38:\tlearn: 0.5108896\ttotal: 349ms\tremaining: 546ms\n",
            "39:\tlearn: 0.5050265\ttotal: 363ms\tremaining: 544ms\n",
            "40:\tlearn: 0.4998265\ttotal: 373ms\tremaining: 536ms\n",
            "41:\tlearn: 0.4941985\ttotal: 385ms\tremaining: 532ms\n",
            "42:\tlearn: 0.4891088\ttotal: 396ms\tremaining: 525ms\n",
            "43:\tlearn: 0.4845069\ttotal: 417ms\tremaining: 531ms\n",
            "44:\tlearn: 0.4808632\ttotal: 426ms\tremaining: 520ms\n",
            "45:\tlearn: 0.4766018\ttotal: 442ms\tremaining: 519ms\n",
            "46:\tlearn: 0.4726377\ttotal: 452ms\tremaining: 509ms\n",
            "47:\tlearn: 0.4686540\ttotal: 474ms\tremaining: 514ms\n",
            "48:\tlearn: 0.4652481\ttotal: 484ms\tremaining: 504ms\n",
            "49:\tlearn: 0.4608992\ttotal: 494ms\tremaining: 494ms\n",
            "50:\tlearn: 0.4580111\ttotal: 511ms\tremaining: 491ms\n",
            "51:\tlearn: 0.4548242\ttotal: 528ms\tremaining: 487ms\n",
            "52:\tlearn: 0.4517321\ttotal: 541ms\tremaining: 479ms\n",
            "53:\tlearn: 0.4480312\ttotal: 557ms\tremaining: 475ms\n",
            "54:\tlearn: 0.4451667\ttotal: 567ms\tremaining: 464ms\n",
            "55:\tlearn: 0.4419726\ttotal: 575ms\tremaining: 452ms\n",
            "56:\tlearn: 0.4390098\ttotal: 594ms\tremaining: 448ms\n",
            "57:\tlearn: 0.4359564\ttotal: 608ms\tremaining: 440ms\n",
            "58:\tlearn: 0.4330703\ttotal: 619ms\tremaining: 430ms\n",
            "59:\tlearn: 0.4300054\ttotal: 630ms\tremaining: 420ms\n",
            "60:\tlearn: 0.4275386\ttotal: 641ms\tremaining: 410ms\n",
            "61:\tlearn: 0.4248125\ttotal: 651ms\tremaining: 399ms\n",
            "62:\tlearn: 0.4216055\ttotal: 661ms\tremaining: 388ms\n",
            "63:\tlearn: 0.4196896\ttotal: 672ms\tremaining: 378ms\n",
            "64:\tlearn: 0.4176159\ttotal: 682ms\tremaining: 367ms\n",
            "65:\tlearn: 0.4154252\ttotal: 692ms\tremaining: 357ms\n",
            "66:\tlearn: 0.4135026\ttotal: 702ms\tremaining: 346ms\n",
            "67:\tlearn: 0.4110708\ttotal: 712ms\tremaining: 335ms\n",
            "68:\tlearn: 0.4087773\ttotal: 727ms\tremaining: 327ms\n",
            "69:\tlearn: 0.4075786\ttotal: 729ms\tremaining: 312ms\n",
            "70:\tlearn: 0.4054662\ttotal: 740ms\tremaining: 302ms\n",
            "71:\tlearn: 0.4035882\ttotal: 751ms\tremaining: 292ms\n",
            "72:\tlearn: 0.4020064\ttotal: 760ms\tremaining: 281ms\n",
            "73:\tlearn: 0.4002629\ttotal: 770ms\tremaining: 271ms\n",
            "74:\tlearn: 0.3985800\ttotal: 794ms\tremaining: 265ms\n",
            "75:\tlearn: 0.3963133\ttotal: 806ms\tremaining: 254ms\n",
            "76:\tlearn: 0.3950567\ttotal: 818ms\tremaining: 244ms\n",
            "77:\tlearn: 0.3932115\ttotal: 829ms\tremaining: 234ms\n",
            "78:\tlearn: 0.3909380\ttotal: 841ms\tremaining: 224ms\n",
            "79:\tlearn: 0.3894282\ttotal: 850ms\tremaining: 213ms\n",
            "80:\tlearn: 0.3879699\ttotal: 859ms\tremaining: 201ms\n",
            "81:\tlearn: 0.3866253\ttotal: 887ms\tremaining: 195ms\n",
            "82:\tlearn: 0.3847372\ttotal: 906ms\tremaining: 185ms\n",
            "83:\tlearn: 0.3838424\ttotal: 925ms\tremaining: 176ms\n",
            "84:\tlearn: 0.3824117\ttotal: 941ms\tremaining: 166ms\n",
            "85:\tlearn: 0.3810798\ttotal: 951ms\tremaining: 155ms\n",
            "86:\tlearn: 0.3797074\ttotal: 970ms\tremaining: 145ms\n",
            "87:\tlearn: 0.3782749\ttotal: 984ms\tremaining: 134ms\n",
            "88:\tlearn: 0.3769878\ttotal: 991ms\tremaining: 123ms\n",
            "89:\tlearn: 0.3763118\ttotal: 995ms\tremaining: 111ms\n",
            "90:\tlearn: 0.3747133\ttotal: 1s\tremaining: 99.5ms\n",
            "91:\tlearn: 0.3736238\ttotal: 1.02s\tremaining: 88.4ms\n",
            "92:\tlearn: 0.3726361\ttotal: 1.02s\tremaining: 77ms\n",
            "93:\tlearn: 0.3714451\ttotal: 1.03s\tremaining: 65.7ms\n",
            "94:\tlearn: 0.3703293\ttotal: 1.04s\tremaining: 54.8ms\n",
            "95:\tlearn: 0.3688911\ttotal: 1.05s\tremaining: 43.7ms\n",
            "96:\tlearn: 0.3678039\ttotal: 1.06s\tremaining: 32.8ms\n",
            "97:\tlearn: 0.3669467\ttotal: 1.07s\tremaining: 21.8ms\n",
            "98:\tlearn: 0.3660419\ttotal: 1.07s\tremaining: 10.8ms\n",
            "99:\tlearn: 0.3650508\ttotal: 1.08s\tremaining: 0us\n",
            "0:\tlearn: 1.1710704\ttotal: 5.13ms\tremaining: 508ms\n",
            "1:\tlearn: 1.1315399\ttotal: 21.3ms\tremaining: 1.04s\n",
            "2:\tlearn: 1.0946485\ttotal: 46.1ms\tremaining: 1.49s\n",
            "3:\tlearn: 1.0587466\ttotal: 62.5ms\tremaining: 1.5s\n",
            "4:\tlearn: 1.0273996\ttotal: 80.9ms\tremaining: 1.54s\n",
            "5:\tlearn: 0.9998088\ttotal: 90.4ms\tremaining: 1.42s\n",
            "6:\tlearn: 0.9702939\ttotal: 106ms\tremaining: 1.41s\n",
            "7:\tlearn: 0.9421793\ttotal: 125ms\tremaining: 1.44s\n",
            "8:\tlearn: 0.9178181\ttotal: 128ms\tremaining: 1.3s\n",
            "9:\tlearn: 0.8928162\ttotal: 144ms\tremaining: 1.3s\n",
            "10:\tlearn: 0.8681893\ttotal: 166ms\tremaining: 1.34s\n",
            "11:\tlearn: 0.8458786\ttotal: 181ms\tremaining: 1.33s\n",
            "12:\tlearn: 0.8222738\ttotal: 195ms\tremaining: 1.3s\n",
            "13:\tlearn: 0.8016325\ttotal: 215ms\tremaining: 1.32s\n",
            "14:\tlearn: 0.7804708\ttotal: 229ms\tremaining: 1.29s\n",
            "15:\tlearn: 0.7622997\ttotal: 241ms\tremaining: 1.26s\n",
            "16:\tlearn: 0.7453074\ttotal: 262ms\tremaining: 1.28s\n",
            "17:\tlearn: 0.7273317\ttotal: 280ms\tremaining: 1.27s\n",
            "18:\tlearn: 0.7112283\ttotal: 299ms\tremaining: 1.27s\n",
            "19:\tlearn: 0.6946089\ttotal: 317ms\tremaining: 1.27s\n",
            "20:\tlearn: 0.6805346\ttotal: 334ms\tremaining: 1.26s\n",
            "21:\tlearn: 0.6671457\ttotal: 345ms\tremaining: 1.22s\n",
            "22:\tlearn: 0.6550144\ttotal: 358ms\tremaining: 1.2s\n",
            "23:\tlearn: 0.6421296\ttotal: 375ms\tremaining: 1.19s\n",
            "24:\tlearn: 0.6309314\ttotal: 385ms\tremaining: 1.16s\n",
            "25:\tlearn: 0.6195933\ttotal: 398ms\tremaining: 1.13s\n",
            "26:\tlearn: 0.6091088\ttotal: 410ms\tremaining: 1.11s\n",
            "27:\tlearn: 0.5995625\ttotal: 424ms\tremaining: 1.09s\n",
            "28:\tlearn: 0.5913021\ttotal: 429ms\tremaining: 1.05s\n",
            "29:\tlearn: 0.5824665\ttotal: 448ms\tremaining: 1.04s\n",
            "30:\tlearn: 0.5736071\ttotal: 464ms\tremaining: 1.03s\n",
            "31:\tlearn: 0.5651632\ttotal: 480ms\tremaining: 1.02s\n",
            "32:\tlearn: 0.5562673\ttotal: 491ms\tremaining: 998ms\n",
            "33:\tlearn: 0.5494378\ttotal: 505ms\tremaining: 980ms\n",
            "34:\tlearn: 0.5426000\ttotal: 517ms\tremaining: 960ms\n",
            "35:\tlearn: 0.5359120\ttotal: 527ms\tremaining: 937ms\n",
            "36:\tlearn: 0.5294388\ttotal: 537ms\tremaining: 914ms\n",
            "37:\tlearn: 0.5245982\ttotal: 539ms\tremaining: 880ms\n",
            "38:\tlearn: 0.5182286\ttotal: 571ms\tremaining: 894ms\n",
            "39:\tlearn: 0.5120181\ttotal: 590ms\tremaining: 884ms\n",
            "40:\tlearn: 0.5060659\ttotal: 605ms\tremaining: 870ms\n",
            "41:\tlearn: 0.5008026\ttotal: 617ms\tremaining: 852ms\n",
            "42:\tlearn: 0.4958118\ttotal: 629ms\tremaining: 833ms\n",
            "43:\tlearn: 0.4916341\ttotal: 638ms\tremaining: 812ms\n",
            "44:\tlearn: 0.4859885\ttotal: 651ms\tremaining: 796ms\n",
            "45:\tlearn: 0.4815404\ttotal: 665ms\tremaining: 780ms\n",
            "46:\tlearn: 0.4768490\ttotal: 679ms\tremaining: 765ms\n",
            "47:\tlearn: 0.4729325\ttotal: 690ms\tremaining: 748ms\n",
            "48:\tlearn: 0.4690039\ttotal: 703ms\tremaining: 731ms\n",
            "49:\tlearn: 0.4651035\ttotal: 720ms\tremaining: 720ms\n",
            "50:\tlearn: 0.4616525\ttotal: 736ms\tremaining: 707ms\n",
            "51:\tlearn: 0.4583852\ttotal: 770ms\tremaining: 710ms\n",
            "52:\tlearn: 0.4543922\ttotal: 808ms\tremaining: 716ms\n",
            "53:\tlearn: 0.4511888\ttotal: 822ms\tremaining: 700ms\n",
            "54:\tlearn: 0.4475437\ttotal: 840ms\tremaining: 687ms\n",
            "55:\tlearn: 0.4443620\ttotal: 854ms\tremaining: 671ms\n",
            "56:\tlearn: 0.4409305\ttotal: 880ms\tremaining: 664ms\n",
            "57:\tlearn: 0.4378037\ttotal: 891ms\tremaining: 645ms\n",
            "58:\tlearn: 0.4354359\ttotal: 901ms\tremaining: 626ms\n",
            "59:\tlearn: 0.4326070\ttotal: 913ms\tremaining: 608ms\n",
            "60:\tlearn: 0.4299212\ttotal: 924ms\tremaining: 591ms\n",
            "61:\tlearn: 0.4273708\ttotal: 936ms\tremaining: 573ms\n",
            "62:\tlearn: 0.4246600\ttotal: 950ms\tremaining: 558ms\n",
            "63:\tlearn: 0.4225440\ttotal: 966ms\tremaining: 544ms\n",
            "64:\tlearn: 0.4206161\ttotal: 978ms\tremaining: 527ms\n",
            "65:\tlearn: 0.4181499\ttotal: 1s\tremaining: 516ms\n",
            "66:\tlearn: 0.4158273\ttotal: 1.02s\tremaining: 502ms\n",
            "67:\tlearn: 0.4138433\ttotal: 1.04s\tremaining: 490ms\n",
            "68:\tlearn: 0.4113626\ttotal: 1.06s\tremaining: 477ms\n",
            "69:\tlearn: 0.4091882\ttotal: 1.07s\tremaining: 461ms\n",
            "70:\tlearn: 0.4075157\ttotal: 1.09s\tremaining: 447ms\n",
            "71:\tlearn: 0.4052129\ttotal: 1.1s\tremaining: 430ms\n",
            "72:\tlearn: 0.4035956\ttotal: 1.13s\tremaining: 417ms\n",
            "73:\tlearn: 0.4017594\ttotal: 1.14s\tremaining: 400ms\n",
            "74:\tlearn: 0.3999659\ttotal: 1.16s\tremaining: 385ms\n",
            "75:\tlearn: 0.3976976\ttotal: 1.18s\tremaining: 371ms\n",
            "76:\tlearn: 0.3960736\ttotal: 1.19s\tremaining: 355ms\n",
            "77:\tlearn: 0.3945717\ttotal: 1.2s\tremaining: 339ms\n",
            "78:\tlearn: 0.3932636\ttotal: 1.22s\tremaining: 324ms\n",
            "79:\tlearn: 0.3919179\ttotal: 1.27s\tremaining: 318ms\n",
            "80:\tlearn: 0.3906637\ttotal: 1.3s\tremaining: 304ms\n",
            "81:\tlearn: 0.3892110\ttotal: 1.31s\tremaining: 288ms\n",
            "82:\tlearn: 0.3877282\ttotal: 1.33s\tremaining: 272ms\n",
            "83:\tlearn: 0.3860034\ttotal: 1.34s\tremaining: 255ms\n",
            "84:\tlearn: 0.3838708\ttotal: 1.35s\tremaining: 239ms\n",
            "85:\tlearn: 0.3822162\ttotal: 1.36s\tremaining: 222ms\n",
            "86:\tlearn: 0.3809781\ttotal: 1.38s\tremaining: 206ms\n",
            "87:\tlearn: 0.3794602\ttotal: 1.39s\tremaining: 189ms\n",
            "88:\tlearn: 0.3774643\ttotal: 1.4s\tremaining: 173ms\n",
            "89:\tlearn: 0.3761895\ttotal: 1.41s\tremaining: 157ms\n",
            "90:\tlearn: 0.3750711\ttotal: 1.42s\tremaining: 141ms\n",
            "91:\tlearn: 0.3737339\ttotal: 1.43s\tremaining: 125ms\n",
            "92:\tlearn: 0.3726098\ttotal: 1.44s\tremaining: 109ms\n",
            "93:\tlearn: 0.3709522\ttotal: 1.46s\tremaining: 93.3ms\n",
            "94:\tlearn: 0.3697153\ttotal: 1.48s\tremaining: 77.9ms\n",
            "95:\tlearn: 0.3683787\ttotal: 1.5s\tremaining: 62.3ms\n",
            "96:\tlearn: 0.3670059\ttotal: 1.5s\tremaining: 46.6ms\n",
            "97:\tlearn: 0.3659171\ttotal: 1.51s\tremaining: 30.9ms\n",
            "98:\tlearn: 0.3649564\ttotal: 1.52s\tremaining: 15.4ms\n",
            "99:\tlearn: 0.3638067\ttotal: 1.54s\tremaining: 0us\n",
            "0:\tlearn: 1.0870978\ttotal: 9.6ms\tremaining: 950ms\n",
            "1:\tlearn: 1.0524191\ttotal: 24.2ms\tremaining: 1.19s\n",
            "2:\tlearn: 1.0174762\ttotal: 33.5ms\tremaining: 1.08s\n",
            "3:\tlearn: 0.9869325\ttotal: 46.7ms\tremaining: 1.12s\n",
            "4:\tlearn: 0.9594547\ttotal: 58.8ms\tremaining: 1.12s\n",
            "5:\tlearn: 0.9335256\ttotal: 63.9ms\tremaining: 1s\n",
            "6:\tlearn: 0.9065748\ttotal: 79.6ms\tremaining: 1.06s\n",
            "7:\tlearn: 0.8802653\ttotal: 82.8ms\tremaining: 953ms\n",
            "8:\tlearn: 0.8542242\ttotal: 96.4ms\tremaining: 974ms\n",
            "9:\tlearn: 0.8307849\ttotal: 104ms\tremaining: 936ms\n",
            "10:\tlearn: 0.8083665\ttotal: 115ms\tremaining: 928ms\n",
            "11:\tlearn: 0.7871859\ttotal: 120ms\tremaining: 878ms\n",
            "12:\tlearn: 0.7681722\ttotal: 125ms\tremaining: 836ms\n",
            "13:\tlearn: 0.7488394\ttotal: 127ms\tremaining: 782ms\n",
            "14:\tlearn: 0.7314901\ttotal: 134ms\tremaining: 757ms\n",
            "15:\tlearn: 0.7138861\ttotal: 138ms\tremaining: 723ms\n",
            "16:\tlearn: 0.6985504\ttotal: 140ms\tremaining: 682ms\n",
            "17:\tlearn: 0.6838198\ttotal: 147ms\tremaining: 671ms\n",
            "18:\tlearn: 0.6696629\ttotal: 156ms\tremaining: 665ms\n",
            "19:\tlearn: 0.6554800\ttotal: 178ms\tremaining: 713ms\n",
            "20:\tlearn: 0.6419311\ttotal: 200ms\tremaining: 754ms\n",
            "21:\tlearn: 0.6304241\ttotal: 211ms\tremaining: 747ms\n",
            "22:\tlearn: 0.6190455\ttotal: 231ms\tremaining: 774ms\n",
            "23:\tlearn: 0.6064188\ttotal: 253ms\tremaining: 801ms\n",
            "24:\tlearn: 0.5959541\ttotal: 288ms\tremaining: 865ms\n",
            "25:\tlearn: 0.5859470\ttotal: 302ms\tremaining: 860ms\n",
            "26:\tlearn: 0.5770758\ttotal: 311ms\tremaining: 840ms\n",
            "27:\tlearn: 0.5679741\ttotal: 316ms\tremaining: 812ms\n",
            "28:\tlearn: 0.5602439\ttotal: 321ms\tremaining: 786ms\n",
            "29:\tlearn: 0.5517218\ttotal: 326ms\tremaining: 761ms\n",
            "30:\tlearn: 0.5444009\ttotal: 331ms\tremaining: 738ms\n",
            "31:\tlearn: 0.5374556\ttotal: 339ms\tremaining: 721ms\n",
            "32:\tlearn: 0.5312318\ttotal: 348ms\tremaining: 707ms\n",
            "33:\tlearn: 0.5243361\ttotal: 361ms\tremaining: 700ms\n",
            "34:\tlearn: 0.5185190\ttotal: 362ms\tremaining: 673ms\n",
            "35:\tlearn: 0.5122459\ttotal: 374ms\tremaining: 666ms\n",
            "36:\tlearn: 0.5067290\ttotal: 385ms\tremaining: 655ms\n",
            "37:\tlearn: 0.5014560\ttotal: 395ms\tremaining: 645ms\n",
            "38:\tlearn: 0.4959263\ttotal: 406ms\tremaining: 635ms\n",
            "39:\tlearn: 0.4907444\ttotal: 422ms\tremaining: 632ms\n",
            "40:\tlearn: 0.4873721\ttotal: 424ms\tremaining: 609ms\n",
            "41:\tlearn: 0.4833506\ttotal: 433ms\tremaining: 598ms\n",
            "42:\tlearn: 0.4795298\ttotal: 448ms\tremaining: 594ms\n",
            "43:\tlearn: 0.4751245\ttotal: 455ms\tremaining: 579ms\n",
            "44:\tlearn: 0.4718227\ttotal: 458ms\tremaining: 560ms\n",
            "45:\tlearn: 0.4678815\ttotal: 463ms\tremaining: 543ms\n",
            "46:\tlearn: 0.4639624\ttotal: 465ms\tremaining: 524ms\n",
            "47:\tlearn: 0.4607048\ttotal: 468ms\tremaining: 507ms\n",
            "48:\tlearn: 0.4563041\ttotal: 483ms\tremaining: 503ms\n",
            "49:\tlearn: 0.4526734\ttotal: 488ms\tremaining: 488ms\n",
            "50:\tlearn: 0.4497371\ttotal: 499ms\tremaining: 479ms\n",
            "51:\tlearn: 0.4482866\ttotal: 500ms\tremaining: 461ms\n",
            "52:\tlearn: 0.4456917\ttotal: 503ms\tremaining: 446ms\n",
            "53:\tlearn: 0.4423684\ttotal: 507ms\tremaining: 432ms\n",
            "54:\tlearn: 0.4395149\ttotal: 515ms\tremaining: 421ms\n",
            "55:\tlearn: 0.4365238\ttotal: 529ms\tremaining: 416ms\n",
            "56:\tlearn: 0.4334705\ttotal: 539ms\tremaining: 407ms\n",
            "57:\tlearn: 0.4296330\ttotal: 549ms\tremaining: 398ms\n",
            "58:\tlearn: 0.4272635\ttotal: 559ms\tremaining: 388ms\n",
            "59:\tlearn: 0.4248827\ttotal: 572ms\tremaining: 382ms\n",
            "60:\tlearn: 0.4225205\ttotal: 577ms\tremaining: 369ms\n",
            "61:\tlearn: 0.4198406\ttotal: 592ms\tremaining: 363ms\n",
            "62:\tlearn: 0.4179679\ttotal: 616ms\tremaining: 362ms\n",
            "63:\tlearn: 0.4154774\ttotal: 624ms\tremaining: 351ms\n",
            "64:\tlearn: 0.4135038\ttotal: 636ms\tremaining: 343ms\n",
            "65:\tlearn: 0.4111591\ttotal: 650ms\tremaining: 335ms\n",
            "66:\tlearn: 0.4085352\ttotal: 657ms\tremaining: 324ms\n",
            "67:\tlearn: 0.4071514\ttotal: 658ms\tremaining: 310ms\n",
            "68:\tlearn: 0.4053580\ttotal: 662ms\tremaining: 297ms\n",
            "69:\tlearn: 0.4033751\ttotal: 675ms\tremaining: 289ms\n",
            "70:\tlearn: 0.4020291\ttotal: 679ms\tremaining: 278ms\n",
            "71:\tlearn: 0.4003160\ttotal: 689ms\tremaining: 268ms\n",
            "72:\tlearn: 0.3988843\ttotal: 697ms\tremaining: 258ms\n",
            "73:\tlearn: 0.3974604\ttotal: 707ms\tremaining: 248ms\n",
            "74:\tlearn: 0.3955103\ttotal: 711ms\tremaining: 237ms\n",
            "75:\tlearn: 0.3945873\ttotal: 714ms\tremaining: 225ms\n",
            "76:\tlearn: 0.3927334\ttotal: 722ms\tremaining: 216ms\n",
            "77:\tlearn: 0.3903449\ttotal: 726ms\tremaining: 205ms\n",
            "78:\tlearn: 0.3883725\ttotal: 735ms\tremaining: 195ms\n",
            "79:\tlearn: 0.3868919\ttotal: 746ms\tremaining: 187ms\n",
            "80:\tlearn: 0.3852471\ttotal: 756ms\tremaining: 177ms\n",
            "81:\tlearn: 0.3832204\ttotal: 766ms\tremaining: 168ms\n",
            "82:\tlearn: 0.3817002\ttotal: 788ms\tremaining: 161ms\n",
            "83:\tlearn: 0.3802723\ttotal: 799ms\tremaining: 152ms\n",
            "84:\tlearn: 0.3787480\ttotal: 810ms\tremaining: 143ms\n",
            "85:\tlearn: 0.3775119\ttotal: 829ms\tremaining: 135ms\n",
            "86:\tlearn: 0.3757881\ttotal: 834ms\tremaining: 125ms\n",
            "87:\tlearn: 0.3744558\ttotal: 850ms\tremaining: 116ms\n",
            "88:\tlearn: 0.3728746\ttotal: 876ms\tremaining: 108ms\n",
            "89:\tlearn: 0.3713516\ttotal: 886ms\tremaining: 98.5ms\n",
            "90:\tlearn: 0.3699562\ttotal: 892ms\tremaining: 88.3ms\n",
            "91:\tlearn: 0.3685247\ttotal: 909ms\tremaining: 79ms\n",
            "92:\tlearn: 0.3672472\ttotal: 924ms\tremaining: 69.6ms\n",
            "93:\tlearn: 0.3660432\ttotal: 947ms\tremaining: 60.5ms\n",
            "94:\tlearn: 0.3648370\ttotal: 955ms\tremaining: 50.3ms\n",
            "95:\tlearn: 0.3632657\ttotal: 972ms\tremaining: 40.5ms\n",
            "96:\tlearn: 0.3622304\ttotal: 990ms\tremaining: 30.6ms\n",
            "97:\tlearn: 0.3611314\ttotal: 1s\tremaining: 20.5ms\n",
            "98:\tlearn: 0.3603979\ttotal: 1.01s\tremaining: 10.3ms\n",
            "99:\tlearn: 0.3592688\ttotal: 1.03s\tremaining: 0us\n",
            "0:\tlearn: 1.1467325\ttotal: 7.06ms\tremaining: 699ms\n",
            "1:\tlearn: 1.1069980\ttotal: 14.8ms\tremaining: 725ms\n",
            "2:\tlearn: 1.0725172\ttotal: 20.1ms\tremaining: 651ms\n",
            "3:\tlearn: 1.0416726\ttotal: 33.2ms\tremaining: 797ms\n",
            "4:\tlearn: 1.0114719\ttotal: 43.7ms\tremaining: 830ms\n",
            "5:\tlearn: 0.9802444\ttotal: 53.1ms\tremaining: 833ms\n",
            "6:\tlearn: 0.9517405\ttotal: 64ms\tremaining: 850ms\n",
            "7:\tlearn: 0.9231660\ttotal: 74.5ms\tremaining: 856ms\n",
            "8:\tlearn: 0.8967369\ttotal: 82.8ms\tremaining: 838ms\n",
            "9:\tlearn: 0.8715663\ttotal: 90.6ms\tremaining: 815ms\n",
            "10:\tlearn: 0.8472455\ttotal: 105ms\tremaining: 848ms\n",
            "11:\tlearn: 0.8235901\ttotal: 115ms\tremaining: 845ms\n",
            "12:\tlearn: 0.8026618\ttotal: 126ms\tremaining: 842ms\n",
            "13:\tlearn: 0.7814355\ttotal: 137ms\tremaining: 840ms\n",
            "14:\tlearn: 0.7613954\ttotal: 146ms\tremaining: 825ms\n",
            "15:\tlearn: 0.7412477\ttotal: 166ms\tremaining: 870ms\n",
            "16:\tlearn: 0.7228067\ttotal: 172ms\tremaining: 842ms\n",
            "17:\tlearn: 0.7065938\ttotal: 176ms\tremaining: 801ms\n",
            "18:\tlearn: 0.6885506\ttotal: 182ms\tremaining: 776ms\n",
            "19:\tlearn: 0.6722277\ttotal: 196ms\tremaining: 784ms\n",
            "20:\tlearn: 0.6578178\ttotal: 209ms\tremaining: 787ms\n",
            "21:\tlearn: 0.6445848\ttotal: 212ms\tremaining: 753ms\n",
            "22:\tlearn: 0.6327737\ttotal: 237ms\tremaining: 792ms\n",
            "23:\tlearn: 0.6206895\ttotal: 252ms\tremaining: 800ms\n",
            "24:\tlearn: 0.6094432\ttotal: 273ms\tremaining: 820ms\n",
            "25:\tlearn: 0.5979820\ttotal: 288ms\tremaining: 820ms\n",
            "26:\tlearn: 0.5869580\ttotal: 303ms\tremaining: 818ms\n",
            "27:\tlearn: 0.5770295\ttotal: 328ms\tremaining: 845ms\n",
            "28:\tlearn: 0.5680652\ttotal: 342ms\tremaining: 838ms\n",
            "29:\tlearn: 0.5575249\ttotal: 359ms\tremaining: 838ms\n",
            "30:\tlearn: 0.5492181\ttotal: 368ms\tremaining: 819ms\n",
            "31:\tlearn: 0.5415319\ttotal: 382ms\tremaining: 813ms\n",
            "32:\tlearn: 0.5333275\ttotal: 411ms\tremaining: 834ms\n",
            "33:\tlearn: 0.5254848\ttotal: 418ms\tremaining: 812ms\n",
            "34:\tlearn: 0.5184911\ttotal: 430ms\tremaining: 798ms\n",
            "35:\tlearn: 0.5114919\ttotal: 433ms\tremaining: 770ms\n",
            "36:\tlearn: 0.5039887\ttotal: 437ms\tremaining: 744ms\n",
            "37:\tlearn: 0.4977607\ttotal: 453ms\tremaining: 739ms\n",
            "38:\tlearn: 0.4918202\ttotal: 457ms\tremaining: 715ms\n",
            "39:\tlearn: 0.4865158\ttotal: 461ms\tremaining: 692ms\n",
            "40:\tlearn: 0.4810396\ttotal: 474ms\tremaining: 682ms\n",
            "41:\tlearn: 0.4758150\ttotal: 478ms\tremaining: 660ms\n",
            "42:\tlearn: 0.4706897\ttotal: 483ms\tremaining: 640ms\n",
            "43:\tlearn: 0.4663241\ttotal: 487ms\tremaining: 619ms\n",
            "44:\tlearn: 0.4616647\ttotal: 491ms\tremaining: 600ms\n",
            "45:\tlearn: 0.4567720\ttotal: 497ms\tremaining: 583ms\n",
            "46:\tlearn: 0.4530486\ttotal: 502ms\tremaining: 566ms\n",
            "47:\tlearn: 0.4492675\ttotal: 506ms\tremaining: 549ms\n",
            "48:\tlearn: 0.4453970\ttotal: 512ms\tremaining: 533ms\n",
            "49:\tlearn: 0.4416312\ttotal: 515ms\tremaining: 515ms\n",
            "50:\tlearn: 0.4381230\ttotal: 520ms\tremaining: 499ms\n",
            "51:\tlearn: 0.4344165\ttotal: 523ms\tremaining: 483ms\n",
            "52:\tlearn: 0.4312822\ttotal: 528ms\tremaining: 468ms\n",
            "53:\tlearn: 0.4280932\ttotal: 534ms\tremaining: 455ms\n",
            "54:\tlearn: 0.4261934\ttotal: 542ms\tremaining: 443ms\n",
            "55:\tlearn: 0.4230750\ttotal: 552ms\tremaining: 434ms\n",
            "56:\tlearn: 0.4201517\ttotal: 587ms\tremaining: 443ms\n",
            "57:\tlearn: 0.4172381\ttotal: 597ms\tremaining: 432ms\n",
            "58:\tlearn: 0.4146104\ttotal: 634ms\tremaining: 440ms\n",
            "59:\tlearn: 0.4117487\ttotal: 646ms\tremaining: 431ms\n",
            "60:\tlearn: 0.4094504\ttotal: 656ms\tremaining: 420ms\n",
            "61:\tlearn: 0.4068727\ttotal: 667ms\tremaining: 409ms\n",
            "62:\tlearn: 0.4046801\ttotal: 677ms\tremaining: 397ms\n",
            "63:\tlearn: 0.4025771\ttotal: 691ms\tremaining: 389ms\n",
            "64:\tlearn: 0.4002420\ttotal: 702ms\tremaining: 378ms\n",
            "65:\tlearn: 0.3977196\ttotal: 721ms\tremaining: 371ms\n",
            "66:\tlearn: 0.3956208\ttotal: 731ms\tremaining: 360ms\n",
            "67:\tlearn: 0.3935399\ttotal: 742ms\tremaining: 349ms\n",
            "68:\tlearn: 0.3911684\ttotal: 757ms\tremaining: 340ms\n",
            "69:\tlearn: 0.3890551\ttotal: 764ms\tremaining: 327ms\n",
            "70:\tlearn: 0.3868734\ttotal: 775ms\tremaining: 317ms\n",
            "71:\tlearn: 0.3853794\ttotal: 802ms\tremaining: 312ms\n",
            "72:\tlearn: 0.3843177\ttotal: 805ms\tremaining: 298ms\n",
            "73:\tlearn: 0.3826882\ttotal: 817ms\tremaining: 287ms\n",
            "74:\tlearn: 0.3812183\ttotal: 831ms\tremaining: 277ms\n",
            "75:\tlearn: 0.3786277\ttotal: 842ms\tremaining: 266ms\n",
            "76:\tlearn: 0.3770874\ttotal: 858ms\tremaining: 256ms\n",
            "77:\tlearn: 0.3752303\ttotal: 870ms\tremaining: 245ms\n",
            "78:\tlearn: 0.3737977\ttotal: 889ms\tremaining: 236ms\n",
            "79:\tlearn: 0.3721975\ttotal: 892ms\tremaining: 223ms\n",
            "80:\tlearn: 0.3707111\ttotal: 897ms\tremaining: 210ms\n",
            "81:\tlearn: 0.3692125\ttotal: 901ms\tremaining: 198ms\n",
            "82:\tlearn: 0.3676802\ttotal: 905ms\tremaining: 185ms\n",
            "83:\tlearn: 0.3664451\ttotal: 911ms\tremaining: 173ms\n",
            "84:\tlearn: 0.3647284\ttotal: 914ms\tremaining: 161ms\n",
            "85:\tlearn: 0.3636096\ttotal: 918ms\tremaining: 149ms\n",
            "86:\tlearn: 0.3623397\ttotal: 921ms\tremaining: 138ms\n",
            "87:\tlearn: 0.3611847\ttotal: 931ms\tremaining: 127ms\n",
            "88:\tlearn: 0.3598418\ttotal: 942ms\tremaining: 116ms\n",
            "89:\tlearn: 0.3585984\ttotal: 953ms\tremaining: 106ms\n",
            "90:\tlearn: 0.3577489\ttotal: 963ms\tremaining: 95.3ms\n",
            "91:\tlearn: 0.3570412\ttotal: 974ms\tremaining: 84.7ms\n",
            "92:\tlearn: 0.3560489\ttotal: 983ms\tremaining: 74ms\n",
            "93:\tlearn: 0.3547223\ttotal: 1.01s\tremaining: 64.5ms\n",
            "94:\tlearn: 0.3537491\ttotal: 1.02s\tremaining: 53.7ms\n",
            "95:\tlearn: 0.3524546\ttotal: 1.03s\tremaining: 43.1ms\n",
            "96:\tlearn: 0.3510753\ttotal: 1.04s\tremaining: 32.3ms\n",
            "97:\tlearn: 0.3503826\ttotal: 1.05s\tremaining: 21.4ms\n",
            "98:\tlearn: 0.3491704\ttotal: 1.07s\tremaining: 10.8ms\n",
            "99:\tlearn: 0.3483435\ttotal: 1.08s\tremaining: 0us\n",
            "0:\tlearn: 1.1191846\ttotal: 4.11ms\tremaining: 406ms\n",
            "1:\tlearn: 1.0452029\ttotal: 9.22ms\tremaining: 452ms\n",
            "2:\tlearn: 0.9845394\ttotal: 19.2ms\tremaining: 620ms\n",
            "3:\tlearn: 0.9317197\ttotal: 35.9ms\tremaining: 861ms\n",
            "4:\tlearn: 0.8849220\ttotal: 40.4ms\tremaining: 768ms\n",
            "5:\tlearn: 0.8379313\ttotal: 54.1ms\tremaining: 848ms\n",
            "6:\tlearn: 0.7972742\ttotal: 73.9ms\tremaining: 981ms\n",
            "7:\tlearn: 0.7569038\ttotal: 92.4ms\tremaining: 1.06s\n",
            "8:\tlearn: 0.7184576\ttotal: 112ms\tremaining: 1.13s\n",
            "9:\tlearn: 0.6889329\ttotal: 125ms\tremaining: 1.12s\n",
            "10:\tlearn: 0.6602859\ttotal: 135ms\tremaining: 1.09s\n",
            "11:\tlearn: 0.6353305\ttotal: 140ms\tremaining: 1.03s\n",
            "12:\tlearn: 0.6123527\ttotal: 151ms\tremaining: 1.01s\n",
            "13:\tlearn: 0.5908512\ttotal: 159ms\tremaining: 974ms\n",
            "14:\tlearn: 0.5718959\ttotal: 175ms\tremaining: 992ms\n",
            "15:\tlearn: 0.5543632\ttotal: 191ms\tremaining: 1s\n",
            "16:\tlearn: 0.5385055\ttotal: 211ms\tremaining: 1.03s\n",
            "17:\tlearn: 0.5253771\ttotal: 219ms\tremaining: 997ms\n",
            "18:\tlearn: 0.5110949\ttotal: 229ms\tremaining: 977ms\n",
            "19:\tlearn: 0.4984792\ttotal: 239ms\tremaining: 957ms\n",
            "20:\tlearn: 0.4874620\ttotal: 247ms\tremaining: 928ms\n",
            "21:\tlearn: 0.4796183\ttotal: 248ms\tremaining: 879ms\n",
            "22:\tlearn: 0.4719566\ttotal: 253ms\tremaining: 849ms\n",
            "23:\tlearn: 0.4640156\ttotal: 257ms\tremaining: 815ms\n",
            "24:\tlearn: 0.4573047\ttotal: 268ms\tremaining: 803ms\n",
            "25:\tlearn: 0.4498544\ttotal: 279ms\tremaining: 795ms\n",
            "26:\tlearn: 0.4429272\ttotal: 288ms\tremaining: 779ms\n",
            "27:\tlearn: 0.4356733\ttotal: 293ms\tremaining: 753ms\n",
            "28:\tlearn: 0.4311015\ttotal: 304ms\tremaining: 744ms\n",
            "29:\tlearn: 0.4247462\ttotal: 311ms\tremaining: 726ms\n",
            "30:\tlearn: 0.4190468\ttotal: 315ms\tremaining: 700ms\n",
            "31:\tlearn: 0.4154056\ttotal: 320ms\tremaining: 680ms\n",
            "32:\tlearn: 0.4105526\ttotal: 326ms\tremaining: 661ms\n",
            "33:\tlearn: 0.4063557\ttotal: 336ms\tremaining: 652ms\n",
            "34:\tlearn: 0.4023261\ttotal: 342ms\tremaining: 635ms\n",
            "35:\tlearn: 0.3994098\ttotal: 368ms\tremaining: 655ms\n",
            "36:\tlearn: 0.3952323\ttotal: 379ms\tremaining: 645ms\n",
            "37:\tlearn: 0.3919421\ttotal: 408ms\tremaining: 665ms\n",
            "38:\tlearn: 0.3885386\ttotal: 411ms\tremaining: 644ms\n",
            "39:\tlearn: 0.3849884\ttotal: 426ms\tremaining: 639ms\n",
            "40:\tlearn: 0.3811318\ttotal: 430ms\tremaining: 619ms\n",
            "41:\tlearn: 0.3785658\ttotal: 436ms\tremaining: 602ms\n",
            "42:\tlearn: 0.3761936\ttotal: 439ms\tremaining: 582ms\n",
            "43:\tlearn: 0.3740997\ttotal: 445ms\tremaining: 567ms\n",
            "44:\tlearn: 0.3714154\ttotal: 449ms\tremaining: 549ms\n",
            "45:\tlearn: 0.3692956\ttotal: 454ms\tremaining: 532ms\n",
            "46:\tlearn: 0.3666561\ttotal: 459ms\tremaining: 518ms\n",
            "47:\tlearn: 0.3642574\ttotal: 475ms\tremaining: 514ms\n",
            "48:\tlearn: 0.3624645\ttotal: 483ms\tremaining: 503ms\n",
            "49:\tlearn: 0.3600117\ttotal: 494ms\tremaining: 494ms\n",
            "50:\tlearn: 0.3583602\ttotal: 505ms\tremaining: 485ms\n",
            "51:\tlearn: 0.3565799\ttotal: 516ms\tremaining: 476ms\n",
            "52:\tlearn: 0.3542099\ttotal: 523ms\tremaining: 464ms\n",
            "53:\tlearn: 0.3519519\ttotal: 538ms\tremaining: 458ms\n",
            "54:\tlearn: 0.3487315\ttotal: 548ms\tremaining: 448ms\n",
            "55:\tlearn: 0.3466943\ttotal: 554ms\tremaining: 436ms\n",
            "56:\tlearn: 0.3448082\ttotal: 568ms\tremaining: 429ms\n",
            "57:\tlearn: 0.3434107\ttotal: 578ms\tremaining: 419ms\n",
            "58:\tlearn: 0.3412820\ttotal: 587ms\tremaining: 408ms\n",
            "59:\tlearn: 0.3393664\ttotal: 600ms\tremaining: 400ms\n",
            "60:\tlearn: 0.3377542\ttotal: 610ms\tremaining: 390ms\n",
            "61:\tlearn: 0.3355670\ttotal: 621ms\tremaining: 381ms\n",
            "62:\tlearn: 0.3338146\ttotal: 632ms\tremaining: 371ms\n",
            "63:\tlearn: 0.3319122\ttotal: 641ms\tremaining: 360ms\n",
            "64:\tlearn: 0.3298124\ttotal: 651ms\tremaining: 350ms\n",
            "65:\tlearn: 0.3281996\ttotal: 659ms\tremaining: 340ms\n",
            "66:\tlearn: 0.3263161\ttotal: 668ms\tremaining: 329ms\n",
            "67:\tlearn: 0.3247485\ttotal: 677ms\tremaining: 319ms\n",
            "68:\tlearn: 0.3238432\ttotal: 689ms\tremaining: 310ms\n",
            "69:\tlearn: 0.3225191\ttotal: 699ms\tremaining: 300ms\n",
            "70:\tlearn: 0.3204798\ttotal: 705ms\tremaining: 288ms\n",
            "71:\tlearn: 0.3198371\ttotal: 718ms\tremaining: 279ms\n",
            "72:\tlearn: 0.3186813\ttotal: 729ms\tremaining: 270ms\n",
            "73:\tlearn: 0.3159918\ttotal: 739ms\tremaining: 260ms\n",
            "74:\tlearn: 0.3145967\ttotal: 749ms\tremaining: 250ms\n",
            "75:\tlearn: 0.3137817\ttotal: 756ms\tremaining: 239ms\n",
            "76:\tlearn: 0.3127656\ttotal: 770ms\tremaining: 230ms\n",
            "77:\tlearn: 0.3107963\ttotal: 780ms\tremaining: 220ms\n",
            "78:\tlearn: 0.3096910\ttotal: 790ms\tremaining: 210ms\n",
            "79:\tlearn: 0.3086571\ttotal: 800ms\tremaining: 200ms\n",
            "80:\tlearn: 0.3073439\ttotal: 811ms\tremaining: 190ms\n",
            "81:\tlearn: 0.3058846\ttotal: 820ms\tremaining: 180ms\n",
            "82:\tlearn: 0.3045436\ttotal: 833ms\tremaining: 171ms\n",
            "83:\tlearn: 0.3036427\ttotal: 844ms\tremaining: 161ms\n",
            "84:\tlearn: 0.3022197\ttotal: 858ms\tremaining: 151ms\n",
            "85:\tlearn: 0.3016250\ttotal: 871ms\tremaining: 142ms\n",
            "86:\tlearn: 0.2993007\ttotal: 880ms\tremaining: 132ms\n",
            "87:\tlearn: 0.2979669\ttotal: 889ms\tremaining: 121ms\n",
            "88:\tlearn: 0.2974026\ttotal: 899ms\tremaining: 111ms\n",
            "89:\tlearn: 0.2959277\ttotal: 911ms\tremaining: 101ms\n",
            "90:\tlearn: 0.2952572\ttotal: 924ms\tremaining: 91.4ms\n",
            "91:\tlearn: 0.2946242\ttotal: 934ms\tremaining: 81.2ms\n",
            "92:\tlearn: 0.2933976\ttotal: 944ms\tremaining: 71ms\n",
            "93:\tlearn: 0.2916667\ttotal: 956ms\tremaining: 61ms\n",
            "94:\tlearn: 0.2905473\ttotal: 967ms\tremaining: 50.9ms\n",
            "95:\tlearn: 0.2888096\ttotal: 975ms\tremaining: 40.6ms\n",
            "96:\tlearn: 0.2881699\ttotal: 988ms\tremaining: 30.6ms\n",
            "97:\tlearn: 0.2872100\ttotal: 999ms\tremaining: 20.4ms\n",
            "98:\tlearn: 0.2856999\ttotal: 1.01s\tremaining: 10.2ms\n",
            "99:\tlearn: 0.2846284\ttotal: 1.02s\tremaining: 0us\n",
            "0:\tlearn: 1.1297785\ttotal: 18.2ms\tremaining: 1.8s\n",
            "1:\tlearn: 1.0577669\ttotal: 27.5ms\tremaining: 1.35s\n",
            "2:\tlearn: 0.9879120\ttotal: 51.3ms\tremaining: 1.66s\n",
            "3:\tlearn: 0.9309446\ttotal: 57.5ms\tremaining: 1.38s\n",
            "4:\tlearn: 0.8841054\ttotal: 66.1ms\tremaining: 1.25s\n",
            "5:\tlearn: 0.8348276\ttotal: 72.4ms\tremaining: 1.13s\n",
            "6:\tlearn: 0.7937721\ttotal: 89.4ms\tremaining: 1.19s\n",
            "7:\tlearn: 0.7572887\ttotal: 105ms\tremaining: 1.21s\n",
            "8:\tlearn: 0.7227732\ttotal: 113ms\tremaining: 1.15s\n",
            "9:\tlearn: 0.6934628\ttotal: 117ms\tremaining: 1.05s\n",
            "10:\tlearn: 0.6664908\ttotal: 121ms\tremaining: 982ms\n",
            "11:\tlearn: 0.6421962\ttotal: 124ms\tremaining: 906ms\n",
            "12:\tlearn: 0.6185392\ttotal: 128ms\tremaining: 857ms\n",
            "13:\tlearn: 0.5959976\ttotal: 140ms\tremaining: 860ms\n",
            "14:\tlearn: 0.5780382\ttotal: 146ms\tremaining: 828ms\n",
            "15:\tlearn: 0.5589460\ttotal: 155ms\tremaining: 815ms\n",
            "16:\tlearn: 0.5433016\ttotal: 166ms\tremaining: 812ms\n",
            "17:\tlearn: 0.5291896\ttotal: 168ms\tremaining: 764ms\n",
            "18:\tlearn: 0.5159404\ttotal: 176ms\tremaining: 751ms\n",
            "19:\tlearn: 0.5036997\ttotal: 191ms\tremaining: 763ms\n",
            "20:\tlearn: 0.4930402\ttotal: 199ms\tremaining: 748ms\n",
            "21:\tlearn: 0.4844112\ttotal: 217ms\tremaining: 770ms\n",
            "22:\tlearn: 0.4763229\ttotal: 230ms\tremaining: 769ms\n",
            "23:\tlearn: 0.4677193\ttotal: 243ms\tremaining: 768ms\n",
            "24:\tlearn: 0.4601491\ttotal: 263ms\tremaining: 788ms\n",
            "25:\tlearn: 0.4535819\ttotal: 275ms\tremaining: 784ms\n",
            "26:\tlearn: 0.4466291\ttotal: 290ms\tremaining: 785ms\n",
            "27:\tlearn: 0.4407926\ttotal: 303ms\tremaining: 780ms\n",
            "28:\tlearn: 0.4341417\ttotal: 315ms\tremaining: 772ms\n",
            "29:\tlearn: 0.4299260\ttotal: 324ms\tremaining: 755ms\n",
            "30:\tlearn: 0.4263395\ttotal: 325ms\tremaining: 724ms\n",
            "31:\tlearn: 0.4229027\ttotal: 329ms\tremaining: 699ms\n",
            "32:\tlearn: 0.4180782\ttotal: 333ms\tremaining: 676ms\n",
            "33:\tlearn: 0.4143342\ttotal: 339ms\tremaining: 658ms\n",
            "34:\tlearn: 0.4108291\ttotal: 349ms\tremaining: 648ms\n",
            "35:\tlearn: 0.4073702\ttotal: 352ms\tremaining: 626ms\n",
            "36:\tlearn: 0.4031422\ttotal: 361ms\tremaining: 614ms\n",
            "37:\tlearn: 0.3994566\ttotal: 371ms\tremaining: 605ms\n",
            "38:\tlearn: 0.3960292\ttotal: 378ms\tremaining: 592ms\n",
            "39:\tlearn: 0.3923772\ttotal: 388ms\tremaining: 583ms\n",
            "40:\tlearn: 0.3864908\ttotal: 393ms\tremaining: 566ms\n",
            "41:\tlearn: 0.3817424\ttotal: 399ms\tremaining: 551ms\n",
            "42:\tlearn: 0.3784163\ttotal: 415ms\tremaining: 550ms\n",
            "43:\tlearn: 0.3759500\ttotal: 425ms\tremaining: 542ms\n",
            "44:\tlearn: 0.3732746\ttotal: 443ms\tremaining: 542ms\n",
            "45:\tlearn: 0.3713404\ttotal: 454ms\tremaining: 533ms\n",
            "46:\tlearn: 0.3691387\ttotal: 464ms\tremaining: 524ms\n",
            "47:\tlearn: 0.3658776\ttotal: 475ms\tremaining: 515ms\n",
            "48:\tlearn: 0.3640298\ttotal: 486ms\tremaining: 506ms\n",
            "49:\tlearn: 0.3613331\ttotal: 509ms\tremaining: 509ms\n",
            "50:\tlearn: 0.3591606\ttotal: 525ms\tremaining: 505ms\n",
            "51:\tlearn: 0.3571989\ttotal: 537ms\tremaining: 496ms\n",
            "52:\tlearn: 0.3566189\ttotal: 539ms\tremaining: 478ms\n",
            "53:\tlearn: 0.3546152\ttotal: 555ms\tremaining: 473ms\n",
            "54:\tlearn: 0.3532933\ttotal: 580ms\tremaining: 474ms\n",
            "55:\tlearn: 0.3513479\ttotal: 594ms\tremaining: 467ms\n",
            "56:\tlearn: 0.3497318\ttotal: 603ms\tremaining: 455ms\n",
            "57:\tlearn: 0.3480848\ttotal: 616ms\tremaining: 446ms\n",
            "58:\tlearn: 0.3468303\ttotal: 627ms\tremaining: 436ms\n",
            "59:\tlearn: 0.3445978\ttotal: 637ms\tremaining: 425ms\n",
            "60:\tlearn: 0.3417891\ttotal: 647ms\tremaining: 414ms\n",
            "61:\tlearn: 0.3399433\ttotal: 653ms\tremaining: 400ms\n",
            "62:\tlearn: 0.3380034\ttotal: 661ms\tremaining: 388ms\n",
            "63:\tlearn: 0.3366718\ttotal: 674ms\tremaining: 379ms\n",
            "64:\tlearn: 0.3343505\ttotal: 697ms\tremaining: 376ms\n",
            "65:\tlearn: 0.3327501\ttotal: 701ms\tremaining: 361ms\n",
            "66:\tlearn: 0.3316847\ttotal: 707ms\tremaining: 348ms\n",
            "67:\tlearn: 0.3296085\ttotal: 732ms\tremaining: 345ms\n",
            "68:\tlearn: 0.3284726\ttotal: 753ms\tremaining: 338ms\n",
            "69:\tlearn: 0.3270304\ttotal: 769ms\tremaining: 330ms\n",
            "70:\tlearn: 0.3250343\ttotal: 799ms\tremaining: 326ms\n",
            "71:\tlearn: 0.3233158\ttotal: 811ms\tremaining: 315ms\n",
            "72:\tlearn: 0.3217758\ttotal: 822ms\tremaining: 304ms\n",
            "73:\tlearn: 0.3193486\ttotal: 848ms\tremaining: 298ms\n",
            "74:\tlearn: 0.3174943\ttotal: 860ms\tremaining: 287ms\n",
            "75:\tlearn: 0.3155667\ttotal: 881ms\tremaining: 278ms\n",
            "76:\tlearn: 0.3141929\ttotal: 890ms\tremaining: 266ms\n",
            "77:\tlearn: 0.3129670\ttotal: 901ms\tremaining: 254ms\n",
            "78:\tlearn: 0.3111583\ttotal: 909ms\tremaining: 242ms\n",
            "79:\tlearn: 0.3093061\ttotal: 912ms\tremaining: 228ms\n",
            "80:\tlearn: 0.3069878\ttotal: 916ms\tremaining: 215ms\n",
            "81:\tlearn: 0.3056910\ttotal: 919ms\tremaining: 202ms\n",
            "82:\tlearn: 0.3035349\ttotal: 922ms\tremaining: 189ms\n",
            "83:\tlearn: 0.3022290\ttotal: 926ms\tremaining: 176ms\n",
            "84:\tlearn: 0.3008500\ttotal: 929ms\tremaining: 164ms\n",
            "85:\tlearn: 0.3000771\ttotal: 933ms\tremaining: 152ms\n",
            "86:\tlearn: 0.2986711\ttotal: 936ms\tremaining: 140ms\n",
            "87:\tlearn: 0.2972999\ttotal: 939ms\tremaining: 128ms\n",
            "88:\tlearn: 0.2961541\ttotal: 943ms\tremaining: 117ms\n",
            "89:\tlearn: 0.2940283\ttotal: 946ms\tremaining: 105ms\n",
            "90:\tlearn: 0.2922007\ttotal: 949ms\tremaining: 93.9ms\n",
            "91:\tlearn: 0.2903848\ttotal: 953ms\tremaining: 82.9ms\n",
            "92:\tlearn: 0.2893435\ttotal: 957ms\tremaining: 72ms\n",
            "93:\tlearn: 0.2873190\ttotal: 961ms\tremaining: 61.3ms\n",
            "94:\tlearn: 0.2857927\ttotal: 971ms\tremaining: 51.1ms\n",
            "95:\tlearn: 0.2839772\ttotal: 979ms\tremaining: 40.8ms\n",
            "96:\tlearn: 0.2824489\ttotal: 983ms\tremaining: 30.4ms\n",
            "97:\tlearn: 0.2814367\ttotal: 986ms\tremaining: 20.1ms\n",
            "98:\tlearn: 0.2801552\ttotal: 990ms\tremaining: 10ms\n",
            "99:\tlearn: 0.2791467\ttotal: 994ms\tremaining: 0us\n",
            "0:\tlearn: 1.1326958\ttotal: 3.86ms\tremaining: 382ms\n",
            "1:\tlearn: 1.0581352\ttotal: 5ms\tremaining: 245ms\n",
            "2:\tlearn: 0.9920356\ttotal: 8.92ms\tremaining: 288ms\n",
            "3:\tlearn: 0.9335234\ttotal: 12.7ms\tremaining: 305ms\n",
            "4:\tlearn: 0.8824805\ttotal: 16.5ms\tremaining: 314ms\n",
            "5:\tlearn: 0.8413172\ttotal: 20.5ms\tremaining: 321ms\n",
            "6:\tlearn: 0.7980229\ttotal: 24.2ms\tremaining: 322ms\n",
            "7:\tlearn: 0.7603478\ttotal: 28ms\tremaining: 323ms\n",
            "8:\tlearn: 0.7305857\ttotal: 29ms\tremaining: 293ms\n",
            "9:\tlearn: 0.7002153\ttotal: 32.7ms\tremaining: 294ms\n",
            "10:\tlearn: 0.6707713\ttotal: 36.4ms\tremaining: 295ms\n",
            "11:\tlearn: 0.6446154\ttotal: 40.1ms\tremaining: 294ms\n",
            "12:\tlearn: 0.6199604\ttotal: 41.8ms\tremaining: 279ms\n",
            "13:\tlearn: 0.6001798\ttotal: 45.5ms\tremaining: 279ms\n",
            "14:\tlearn: 0.5809652\ttotal: 49.3ms\tremaining: 279ms\n",
            "15:\tlearn: 0.5645532\ttotal: 53.1ms\tremaining: 279ms\n",
            "16:\tlearn: 0.5495867\ttotal: 56.9ms\tremaining: 278ms\n",
            "17:\tlearn: 0.5366935\ttotal: 60.8ms\tremaining: 277ms\n",
            "18:\tlearn: 0.5252402\ttotal: 64.5ms\tremaining: 275ms\n",
            "19:\tlearn: 0.5134976\ttotal: 68.3ms\tremaining: 273ms\n",
            "20:\tlearn: 0.5022419\ttotal: 72.1ms\tremaining: 271ms\n",
            "21:\tlearn: 0.4934886\ttotal: 77.9ms\tremaining: 276ms\n",
            "22:\tlearn: 0.4833749\ttotal: 83.7ms\tremaining: 280ms\n",
            "23:\tlearn: 0.4735533\ttotal: 87.6ms\tremaining: 277ms\n",
            "24:\tlearn: 0.4656952\ttotal: 91.4ms\tremaining: 274ms\n",
            "25:\tlearn: 0.4577290\ttotal: 95.2ms\tremaining: 271ms\n",
            "26:\tlearn: 0.4504522\ttotal: 99ms\tremaining: 268ms\n",
            "27:\tlearn: 0.4431676\ttotal: 104ms\tremaining: 268ms\n",
            "28:\tlearn: 0.4371560\ttotal: 109ms\tremaining: 266ms\n",
            "29:\tlearn: 0.4318582\ttotal: 113ms\tremaining: 263ms\n",
            "30:\tlearn: 0.4255729\ttotal: 117ms\tremaining: 260ms\n",
            "31:\tlearn: 0.4211793\ttotal: 121ms\tremaining: 256ms\n",
            "32:\tlearn: 0.4161657\ttotal: 124ms\tremaining: 253ms\n",
            "33:\tlearn: 0.4129952\ttotal: 127ms\tremaining: 246ms\n",
            "34:\tlearn: 0.4079863\ttotal: 131ms\tremaining: 243ms\n",
            "35:\tlearn: 0.4044979\ttotal: 135ms\tremaining: 239ms\n",
            "36:\tlearn: 0.4019920\ttotal: 138ms\tremaining: 236ms\n",
            "37:\tlearn: 0.3974133\ttotal: 147ms\tremaining: 240ms\n",
            "38:\tlearn: 0.3936350\ttotal: 155ms\tremaining: 242ms\n",
            "39:\tlearn: 0.3893071\ttotal: 158ms\tremaining: 237ms\n",
            "40:\tlearn: 0.3855545\ttotal: 162ms\tremaining: 233ms\n",
            "41:\tlearn: 0.3827514\ttotal: 166ms\tremaining: 229ms\n",
            "42:\tlearn: 0.3800832\ttotal: 169ms\tremaining: 224ms\n",
            "43:\tlearn: 0.3775218\ttotal: 174ms\tremaining: 221ms\n",
            "44:\tlearn: 0.3752024\ttotal: 177ms\tremaining: 217ms\n",
            "45:\tlearn: 0.3732419\ttotal: 181ms\tremaining: 213ms\n",
            "46:\tlearn: 0.3707455\ttotal: 185ms\tremaining: 209ms\n",
            "47:\tlearn: 0.3690791\ttotal: 189ms\tremaining: 205ms\n",
            "48:\tlearn: 0.3660370\ttotal: 193ms\tremaining: 201ms\n",
            "49:\tlearn: 0.3644524\ttotal: 197ms\tremaining: 197ms\n",
            "50:\tlearn: 0.3620615\ttotal: 200ms\tremaining: 193ms\n",
            "51:\tlearn: 0.3606137\ttotal: 204ms\tremaining: 189ms\n",
            "52:\tlearn: 0.3584176\ttotal: 208ms\tremaining: 185ms\n",
            "53:\tlearn: 0.3563195\ttotal: 212ms\tremaining: 180ms\n",
            "54:\tlearn: 0.3534140\ttotal: 216ms\tremaining: 176ms\n",
            "55:\tlearn: 0.3520793\ttotal: 219ms\tremaining: 172ms\n",
            "56:\tlearn: 0.3492366\ttotal: 223ms\tremaining: 168ms\n",
            "57:\tlearn: 0.3475941\ttotal: 227ms\tremaining: 164ms\n",
            "58:\tlearn: 0.3459756\ttotal: 231ms\tremaining: 160ms\n",
            "59:\tlearn: 0.3433998\ttotal: 235ms\tremaining: 156ms\n",
            "60:\tlearn: 0.3415663\ttotal: 238ms\tremaining: 152ms\n",
            "61:\tlearn: 0.3398814\ttotal: 242ms\tremaining: 148ms\n",
            "62:\tlearn: 0.3385036\ttotal: 246ms\tremaining: 144ms\n",
            "63:\tlearn: 0.3367416\ttotal: 250ms\tremaining: 141ms\n",
            "64:\tlearn: 0.3349364\ttotal: 254ms\tremaining: 137ms\n",
            "65:\tlearn: 0.3333027\ttotal: 257ms\tremaining: 133ms\n",
            "66:\tlearn: 0.3311267\ttotal: 261ms\tremaining: 129ms\n",
            "67:\tlearn: 0.3297978\ttotal: 265ms\tremaining: 125ms\n",
            "68:\tlearn: 0.3286358\ttotal: 269ms\tremaining: 121ms\n",
            "69:\tlearn: 0.3273223\ttotal: 273ms\tremaining: 117ms\n",
            "70:\tlearn: 0.3251496\ttotal: 276ms\tremaining: 113ms\n",
            "71:\tlearn: 0.3238223\ttotal: 280ms\tremaining: 109ms\n",
            "72:\tlearn: 0.3223597\ttotal: 284ms\tremaining: 105ms\n",
            "73:\tlearn: 0.3206382\ttotal: 288ms\tremaining: 101ms\n",
            "74:\tlearn: 0.3188445\ttotal: 292ms\tremaining: 97.3ms\n",
            "75:\tlearn: 0.3167188\ttotal: 296ms\tremaining: 93.4ms\n",
            "76:\tlearn: 0.3155764\ttotal: 300ms\tremaining: 89.5ms\n",
            "77:\tlearn: 0.3143450\ttotal: 303ms\tremaining: 85.6ms\n",
            "78:\tlearn: 0.3126882\ttotal: 307ms\tremaining: 81.7ms\n",
            "79:\tlearn: 0.3110599\ttotal: 311ms\tremaining: 77.8ms\n",
            "80:\tlearn: 0.3090184\ttotal: 315ms\tremaining: 73.9ms\n",
            "81:\tlearn: 0.3074820\ttotal: 319ms\tremaining: 70ms\n",
            "82:\tlearn: 0.3060209\ttotal: 323ms\tremaining: 66.1ms\n",
            "83:\tlearn: 0.3040829\ttotal: 326ms\tremaining: 62.1ms\n",
            "84:\tlearn: 0.3027686\ttotal: 330ms\tremaining: 58.2ms\n",
            "85:\tlearn: 0.3009817\ttotal: 334ms\tremaining: 54.3ms\n",
            "86:\tlearn: 0.2992516\ttotal: 337ms\tremaining: 50.4ms\n",
            "87:\tlearn: 0.2983392\ttotal: 344ms\tremaining: 46.9ms\n",
            "88:\tlearn: 0.2962296\ttotal: 355ms\tremaining: 43.9ms\n",
            "89:\tlearn: 0.2950610\ttotal: 359ms\tremaining: 39.9ms\n",
            "90:\tlearn: 0.2934798\ttotal: 362ms\tremaining: 35.8ms\n",
            "91:\tlearn: 0.2913191\ttotal: 366ms\tremaining: 31.8ms\n",
            "92:\tlearn: 0.2909901\ttotal: 369ms\tremaining: 27.8ms\n",
            "93:\tlearn: 0.2895321\ttotal: 373ms\tremaining: 23.8ms\n",
            "94:\tlearn: 0.2880906\ttotal: 376ms\tremaining: 19.8ms\n",
            "95:\tlearn: 0.2872559\ttotal: 380ms\tremaining: 15.8ms\n",
            "96:\tlearn: 0.2859222\ttotal: 384ms\tremaining: 11.9ms\n",
            "97:\tlearn: 0.2846067\ttotal: 387ms\tremaining: 7.91ms\n",
            "98:\tlearn: 0.2825427\ttotal: 391ms\tremaining: 3.95ms\n",
            "99:\tlearn: 0.2814258\ttotal: 395ms\tremaining: 0us\n",
            "0:\tlearn: 1.0521079\ttotal: 4.38ms\tremaining: 434ms\n",
            "1:\tlearn: 0.9864275\ttotal: 8.24ms\tremaining: 404ms\n",
            "2:\tlearn: 0.9266642\ttotal: 12ms\tremaining: 388ms\n",
            "3:\tlearn: 0.8746035\ttotal: 13.3ms\tremaining: 319ms\n",
            "4:\tlearn: 0.8247692\ttotal: 17ms\tremaining: 324ms\n",
            "5:\tlearn: 0.7830651\ttotal: 20.7ms\tremaining: 324ms\n",
            "6:\tlearn: 0.7414261\ttotal: 24.3ms\tremaining: 323ms\n",
            "7:\tlearn: 0.7064585\ttotal: 28ms\tremaining: 322ms\n",
            "8:\tlearn: 0.6775646\ttotal: 31.6ms\tremaining: 320ms\n",
            "9:\tlearn: 0.6500848\ttotal: 35.3ms\tremaining: 318ms\n",
            "10:\tlearn: 0.6233436\ttotal: 39ms\tremaining: 315ms\n",
            "11:\tlearn: 0.6014238\ttotal: 42.8ms\tremaining: 314ms\n",
            "12:\tlearn: 0.5788770\ttotal: 46.6ms\tremaining: 312ms\n",
            "13:\tlearn: 0.5608705\ttotal: 48.9ms\tremaining: 301ms\n",
            "14:\tlearn: 0.5449960\ttotal: 52.7ms\tremaining: 299ms\n",
            "15:\tlearn: 0.5299764\ttotal: 56.5ms\tremaining: 297ms\n",
            "16:\tlearn: 0.5167847\ttotal: 60.3ms\tremaining: 294ms\n",
            "17:\tlearn: 0.5047850\ttotal: 64.2ms\tremaining: 293ms\n",
            "18:\tlearn: 0.4933301\ttotal: 68.3ms\tremaining: 291ms\n",
            "19:\tlearn: 0.4842505\ttotal: 69.5ms\tremaining: 278ms\n",
            "20:\tlearn: 0.4742333\ttotal: 73.2ms\tremaining: 276ms\n",
            "21:\tlearn: 0.4651577\ttotal: 76.9ms\tremaining: 273ms\n",
            "22:\tlearn: 0.4573963\ttotal: 80.7ms\tremaining: 270ms\n",
            "23:\tlearn: 0.4493159\ttotal: 84.4ms\tremaining: 267ms\n",
            "24:\tlearn: 0.4433560\ttotal: 88.1ms\tremaining: 264ms\n",
            "25:\tlearn: 0.4373930\ttotal: 91.8ms\tremaining: 261ms\n",
            "26:\tlearn: 0.4295788\ttotal: 95.4ms\tremaining: 258ms\n",
            "27:\tlearn: 0.4237240\ttotal: 99ms\tremaining: 255ms\n",
            "28:\tlearn: 0.4181841\ttotal: 103ms\tremaining: 252ms\n",
            "29:\tlearn: 0.4141460\ttotal: 106ms\tremaining: 248ms\n",
            "30:\tlearn: 0.4101532\ttotal: 112ms\tremaining: 248ms\n",
            "31:\tlearn: 0.4062490\ttotal: 118ms\tremaining: 251ms\n",
            "32:\tlearn: 0.4025887\ttotal: 130ms\tremaining: 263ms\n",
            "33:\tlearn: 0.3997349\ttotal: 134ms\tremaining: 259ms\n",
            "34:\tlearn: 0.3961595\ttotal: 137ms\tremaining: 255ms\n",
            "35:\tlearn: 0.3923901\ttotal: 141ms\tremaining: 251ms\n",
            "36:\tlearn: 0.3886777\ttotal: 145ms\tremaining: 246ms\n",
            "37:\tlearn: 0.3853421\ttotal: 148ms\tremaining: 242ms\n",
            "38:\tlearn: 0.3829539\ttotal: 152ms\tremaining: 237ms\n",
            "39:\tlearn: 0.3798572\ttotal: 155ms\tremaining: 233ms\n",
            "40:\tlearn: 0.3772581\ttotal: 159ms\tremaining: 229ms\n",
            "41:\tlearn: 0.3739610\ttotal: 163ms\tremaining: 225ms\n",
            "42:\tlearn: 0.3716995\ttotal: 166ms\tremaining: 221ms\n",
            "43:\tlearn: 0.3687102\ttotal: 170ms\tremaining: 216ms\n",
            "44:\tlearn: 0.3663658\ttotal: 172ms\tremaining: 210ms\n",
            "45:\tlearn: 0.3639976\ttotal: 175ms\tremaining: 206ms\n",
            "46:\tlearn: 0.3612756\ttotal: 179ms\tremaining: 202ms\n",
            "47:\tlearn: 0.3586366\ttotal: 183ms\tremaining: 198ms\n",
            "48:\tlearn: 0.3567554\ttotal: 186ms\tremaining: 194ms\n",
            "49:\tlearn: 0.3537854\ttotal: 190ms\tremaining: 190ms\n",
            "50:\tlearn: 0.3521120\ttotal: 194ms\tremaining: 186ms\n",
            "51:\tlearn: 0.3499653\ttotal: 198ms\tremaining: 182ms\n",
            "52:\tlearn: 0.3491330\ttotal: 199ms\tremaining: 177ms\n",
            "53:\tlearn: 0.3466706\ttotal: 203ms\tremaining: 173ms\n",
            "54:\tlearn: 0.3451045\ttotal: 207ms\tremaining: 169ms\n",
            "55:\tlearn: 0.3431581\ttotal: 210ms\tremaining: 165ms\n",
            "56:\tlearn: 0.3412403\ttotal: 215ms\tremaining: 162ms\n",
            "57:\tlearn: 0.3392462\ttotal: 219ms\tremaining: 159ms\n",
            "58:\tlearn: 0.3363803\ttotal: 223ms\tremaining: 155ms\n",
            "59:\tlearn: 0.3344277\ttotal: 227ms\tremaining: 151ms\n",
            "60:\tlearn: 0.3330196\ttotal: 231ms\tremaining: 147ms\n",
            "61:\tlearn: 0.3308192\ttotal: 235ms\tremaining: 144ms\n",
            "62:\tlearn: 0.3290494\ttotal: 238ms\tremaining: 140ms\n",
            "63:\tlearn: 0.3274625\ttotal: 243ms\tremaining: 137ms\n",
            "64:\tlearn: 0.3264181\ttotal: 251ms\tremaining: 135ms\n",
            "65:\tlearn: 0.3242051\ttotal: 258ms\tremaining: 133ms\n",
            "66:\tlearn: 0.3224123\ttotal: 263ms\tremaining: 130ms\n",
            "67:\tlearn: 0.3211902\ttotal: 266ms\tremaining: 125ms\n",
            "68:\tlearn: 0.3203366\ttotal: 271ms\tremaining: 122ms\n",
            "69:\tlearn: 0.3189407\ttotal: 278ms\tremaining: 119ms\n",
            "70:\tlearn: 0.3176972\ttotal: 282ms\tremaining: 115ms\n",
            "71:\tlearn: 0.3166101\ttotal: 287ms\tremaining: 112ms\n",
            "72:\tlearn: 0.3152748\ttotal: 292ms\tremaining: 108ms\n",
            "73:\tlearn: 0.3138449\ttotal: 297ms\tremaining: 104ms\n",
            "74:\tlearn: 0.3119256\ttotal: 301ms\tremaining: 100ms\n",
            "75:\tlearn: 0.3107143\ttotal: 313ms\tremaining: 98.7ms\n",
            "76:\tlearn: 0.3087618\ttotal: 318ms\tremaining: 95.1ms\n",
            "77:\tlearn: 0.3076155\ttotal: 323ms\tremaining: 91.2ms\n",
            "78:\tlearn: 0.3064927\ttotal: 327ms\tremaining: 87ms\n",
            "79:\tlearn: 0.3045577\ttotal: 331ms\tremaining: 82.8ms\n",
            "80:\tlearn: 0.3029555\ttotal: 335ms\tremaining: 78.5ms\n",
            "81:\tlearn: 0.3012181\ttotal: 339ms\tremaining: 74.4ms\n",
            "82:\tlearn: 0.3001087\ttotal: 343ms\tremaining: 70.2ms\n",
            "83:\tlearn: 0.2983243\ttotal: 347ms\tremaining: 66ms\n",
            "84:\tlearn: 0.2968409\ttotal: 354ms\tremaining: 62.4ms\n",
            "85:\tlearn: 0.2947983\ttotal: 357ms\tremaining: 58.2ms\n",
            "86:\tlearn: 0.2929137\ttotal: 361ms\tremaining: 54ms\n",
            "87:\tlearn: 0.2915121\ttotal: 366ms\tremaining: 49.9ms\n",
            "88:\tlearn: 0.2905460\ttotal: 377ms\tremaining: 46.6ms\n",
            "89:\tlearn: 0.2894085\ttotal: 385ms\tremaining: 42.8ms\n",
            "90:\tlearn: 0.2889223\ttotal: 392ms\tremaining: 38.8ms\n",
            "91:\tlearn: 0.2882047\ttotal: 398ms\tremaining: 34.6ms\n",
            "92:\tlearn: 0.2871941\ttotal: 403ms\tremaining: 30.3ms\n",
            "93:\tlearn: 0.2857442\ttotal: 407ms\tremaining: 26ms\n",
            "94:\tlearn: 0.2849269\ttotal: 411ms\tremaining: 21.6ms\n",
            "95:\tlearn: 0.2828050\ttotal: 415ms\tremaining: 17.3ms\n",
            "96:\tlearn: 0.2819376\ttotal: 419ms\tremaining: 12.9ms\n",
            "97:\tlearn: 0.2811276\ttotal: 422ms\tremaining: 8.62ms\n",
            "98:\tlearn: 0.2788683\ttotal: 426ms\tremaining: 4.3ms\n",
            "99:\tlearn: 0.2782694\ttotal: 430ms\tremaining: 0us\n",
            "0:\tlearn: 1.1091159\ttotal: 4.33ms\tremaining: 429ms\n",
            "1:\tlearn: 1.0322748\ttotal: 6.18ms\tremaining: 303ms\n",
            "2:\tlearn: 0.9702119\ttotal: 9.99ms\tremaining: 323ms\n",
            "3:\tlearn: 0.9164060\ttotal: 14ms\tremaining: 335ms\n",
            "4:\tlearn: 0.8606641\ttotal: 17.7ms\tremaining: 336ms\n",
            "5:\tlearn: 0.8123918\ttotal: 21.3ms\tremaining: 334ms\n",
            "6:\tlearn: 0.7704688\ttotal: 25ms\tremaining: 332ms\n",
            "7:\tlearn: 0.7339386\ttotal: 28.7ms\tremaining: 330ms\n",
            "8:\tlearn: 0.6989444\ttotal: 32.3ms\tremaining: 327ms\n",
            "9:\tlearn: 0.6683920\ttotal: 36.1ms\tremaining: 325ms\n",
            "10:\tlearn: 0.6408518\ttotal: 39.8ms\tremaining: 322ms\n",
            "11:\tlearn: 0.6131755\ttotal: 45.3ms\tremaining: 332ms\n",
            "12:\tlearn: 0.5920669\ttotal: 52.5ms\tremaining: 351ms\n",
            "13:\tlearn: 0.5724651\ttotal: 61.5ms\tremaining: 378ms\n",
            "14:\tlearn: 0.5525575\ttotal: 65.5ms\tremaining: 371ms\n",
            "15:\tlearn: 0.5350332\ttotal: 68ms\tremaining: 357ms\n",
            "16:\tlearn: 0.5211740\ttotal: 71.7ms\tremaining: 350ms\n",
            "17:\tlearn: 0.5088247\ttotal: 75.3ms\tremaining: 343ms\n",
            "18:\tlearn: 0.4960191\ttotal: 79.3ms\tremaining: 338ms\n",
            "19:\tlearn: 0.4840227\ttotal: 82.9ms\tremaining: 332ms\n",
            "20:\tlearn: 0.4737626\ttotal: 86.5ms\tremaining: 326ms\n",
            "21:\tlearn: 0.4644591\ttotal: 90.2ms\tremaining: 320ms\n",
            "22:\tlearn: 0.4561710\ttotal: 93.9ms\tremaining: 314ms\n",
            "23:\tlearn: 0.4488759\ttotal: 97.5ms\tremaining: 309ms\n",
            "24:\tlearn: 0.4411844\ttotal: 101ms\tremaining: 303ms\n",
            "25:\tlearn: 0.4350026\ttotal: 105ms\tremaining: 298ms\n",
            "26:\tlearn: 0.4281069\ttotal: 109ms\tremaining: 294ms\n",
            "27:\tlearn: 0.4211834\ttotal: 112ms\tremaining: 289ms\n",
            "28:\tlearn: 0.4135186\ttotal: 116ms\tremaining: 284ms\n",
            "29:\tlearn: 0.4087935\ttotal: 120ms\tremaining: 280ms\n",
            "30:\tlearn: 0.4047743\ttotal: 124ms\tremaining: 275ms\n",
            "31:\tlearn: 0.3996573\ttotal: 127ms\tremaining: 270ms\n",
            "32:\tlearn: 0.3947474\ttotal: 131ms\tremaining: 266ms\n",
            "33:\tlearn: 0.3900595\ttotal: 135ms\tremaining: 262ms\n",
            "34:\tlearn: 0.3865553\ttotal: 138ms\tremaining: 257ms\n",
            "35:\tlearn: 0.3828618\ttotal: 142ms\tremaining: 253ms\n",
            "36:\tlearn: 0.3794255\ttotal: 146ms\tremaining: 248ms\n",
            "37:\tlearn: 0.3766635\ttotal: 150ms\tremaining: 244ms\n",
            "38:\tlearn: 0.3730721\ttotal: 153ms\tremaining: 240ms\n",
            "39:\tlearn: 0.3698222\ttotal: 157ms\tremaining: 236ms\n",
            "40:\tlearn: 0.3672132\ttotal: 163ms\tremaining: 235ms\n",
            "41:\tlearn: 0.3635204\ttotal: 167ms\tremaining: 230ms\n",
            "42:\tlearn: 0.3607559\ttotal: 170ms\tremaining: 226ms\n",
            "43:\tlearn: 0.3588371\ttotal: 174ms\tremaining: 222ms\n",
            "44:\tlearn: 0.3563436\ttotal: 179ms\tremaining: 218ms\n",
            "45:\tlearn: 0.3536347\ttotal: 182ms\tremaining: 214ms\n",
            "46:\tlearn: 0.3513130\ttotal: 186ms\tremaining: 210ms\n",
            "47:\tlearn: 0.3491476\ttotal: 190ms\tremaining: 205ms\n",
            "48:\tlearn: 0.3469050\ttotal: 193ms\tremaining: 201ms\n",
            "49:\tlearn: 0.3446662\ttotal: 197ms\tremaining: 197ms\n",
            "50:\tlearn: 0.3433675\ttotal: 201ms\tremaining: 193ms\n",
            "51:\tlearn: 0.3415820\ttotal: 205ms\tremaining: 189ms\n",
            "52:\tlearn: 0.3399489\ttotal: 208ms\tremaining: 185ms\n",
            "53:\tlearn: 0.3374355\ttotal: 212ms\tremaining: 181ms\n",
            "54:\tlearn: 0.3370340\ttotal: 213ms\tremaining: 174ms\n",
            "55:\tlearn: 0.3348941\ttotal: 217ms\tremaining: 171ms\n",
            "56:\tlearn: 0.3341401\ttotal: 219ms\tremaining: 165ms\n",
            "57:\tlearn: 0.3322648\ttotal: 223ms\tremaining: 161ms\n",
            "58:\tlearn: 0.3303142\ttotal: 227ms\tremaining: 158ms\n",
            "59:\tlearn: 0.3289351\ttotal: 230ms\tremaining: 154ms\n",
            "60:\tlearn: 0.3281561\ttotal: 234ms\tremaining: 150ms\n",
            "61:\tlearn: 0.3262274\ttotal: 244ms\tremaining: 149ms\n",
            "62:\tlearn: 0.3242465\ttotal: 250ms\tremaining: 147ms\n",
            "63:\tlearn: 0.3234565\ttotal: 256ms\tremaining: 144ms\n",
            "64:\tlearn: 0.3219147\ttotal: 259ms\tremaining: 140ms\n",
            "65:\tlearn: 0.3196185\ttotal: 264ms\tremaining: 136ms\n",
            "66:\tlearn: 0.3181436\ttotal: 270ms\tremaining: 133ms\n",
            "67:\tlearn: 0.3171589\ttotal: 274ms\tremaining: 129ms\n",
            "68:\tlearn: 0.3154945\ttotal: 278ms\tremaining: 125ms\n",
            "69:\tlearn: 0.3138879\ttotal: 282ms\tremaining: 121ms\n",
            "70:\tlearn: 0.3124550\ttotal: 286ms\tremaining: 117ms\n",
            "71:\tlearn: 0.3103239\ttotal: 289ms\tremaining: 113ms\n",
            "72:\tlearn: 0.3092154\ttotal: 293ms\tremaining: 108ms\n",
            "73:\tlearn: 0.3081021\ttotal: 297ms\tremaining: 104ms\n",
            "74:\tlearn: 0.3063942\ttotal: 301ms\tremaining: 100ms\n",
            "75:\tlearn: 0.3053510\ttotal: 305ms\tremaining: 96.2ms\n",
            "76:\tlearn: 0.3044393\ttotal: 308ms\tremaining: 92.1ms\n",
            "77:\tlearn: 0.3032148\ttotal: 312ms\tremaining: 88ms\n",
            "78:\tlearn: 0.3023231\ttotal: 316ms\tremaining: 83.9ms\n",
            "79:\tlearn: 0.3008362\ttotal: 319ms\tremaining: 79.9ms\n",
            "80:\tlearn: 0.2980178\ttotal: 323ms\tremaining: 75.8ms\n",
            "81:\tlearn: 0.2971252\ttotal: 327ms\tremaining: 71.8ms\n",
            "82:\tlearn: 0.2958049\ttotal: 331ms\tremaining: 67.7ms\n",
            "83:\tlearn: 0.2945078\ttotal: 334ms\tremaining: 63.7ms\n",
            "84:\tlearn: 0.2930023\ttotal: 338ms\tremaining: 59.7ms\n",
            "85:\tlearn: 0.2913852\ttotal: 342ms\tremaining: 55.7ms\n",
            "86:\tlearn: 0.2899658\ttotal: 346ms\tremaining: 51.6ms\n",
            "87:\tlearn: 0.2888229\ttotal: 349ms\tremaining: 47.7ms\n",
            "88:\tlearn: 0.2871672\ttotal: 353ms\tremaining: 43.6ms\n",
            "89:\tlearn: 0.2850384\ttotal: 357ms\tremaining: 39.6ms\n",
            "90:\tlearn: 0.2831857\ttotal: 361ms\tremaining: 35.7ms\n",
            "91:\tlearn: 0.2811139\ttotal: 364ms\tremaining: 31.7ms\n",
            "92:\tlearn: 0.2805331\ttotal: 368ms\tremaining: 27.7ms\n",
            "93:\tlearn: 0.2791287\ttotal: 371ms\tremaining: 23.7ms\n",
            "94:\tlearn: 0.2783954\ttotal: 375ms\tremaining: 19.7ms\n",
            "95:\tlearn: 0.2768874\ttotal: 379ms\tremaining: 15.8ms\n",
            "96:\tlearn: 0.2753348\ttotal: 383ms\tremaining: 11.8ms\n",
            "97:\tlearn: 0.2748115\ttotal: 386ms\tremaining: 7.88ms\n",
            "98:\tlearn: 0.2735000\ttotal: 390ms\tremaining: 3.94ms\n",
            "99:\tlearn: 0.2720581\ttotal: 393ms\tremaining: 0us\n",
            "0:\tlearn: 1.1815153\ttotal: 22.2ms\tremaining: 645ms\n",
            "1:\tlearn: 1.1742313\ttotal: 37.3ms\tremaining: 522ms\n",
            "2:\tlearn: 1.1672126\ttotal: 49.3ms\tremaining: 444ms\n",
            "3:\tlearn: 1.1605805\ttotal: 61.4ms\tremaining: 399ms\n",
            "4:\tlearn: 1.1528142\ttotal: 67.9ms\tremaining: 339ms\n",
            "5:\tlearn: 1.1463037\ttotal: 80.3ms\tremaining: 321ms\n",
            "6:\tlearn: 1.1393615\ttotal: 92.8ms\tremaining: 305ms\n",
            "7:\tlearn: 1.1327902\ttotal: 105ms\tremaining: 288ms\n",
            "8:\tlearn: 1.1257711\ttotal: 117ms\tremaining: 273ms\n",
            "9:\tlearn: 1.1192543\ttotal: 129ms\tremaining: 258ms\n",
            "10:\tlearn: 1.1121791\ttotal: 141ms\tremaining: 243ms\n",
            "11:\tlearn: 1.1055086\ttotal: 143ms\tremaining: 214ms\n",
            "12:\tlearn: 1.0984028\ttotal: 155ms\tremaining: 202ms\n",
            "13:\tlearn: 1.0918063\ttotal: 167ms\tremaining: 190ms\n",
            "14:\tlearn: 1.0856601\ttotal: 184ms\tremaining: 184ms\n",
            "15:\tlearn: 1.0792667\ttotal: 196ms\tremaining: 171ms\n",
            "16:\tlearn: 1.0727807\ttotal: 202ms\tremaining: 155ms\n",
            "17:\tlearn: 1.0667973\ttotal: 215ms\tremaining: 143ms\n",
            "18:\tlearn: 1.0606950\ttotal: 237ms\tremaining: 137ms\n",
            "19:\tlearn: 1.0547422\ttotal: 250ms\tremaining: 125ms\n",
            "20:\tlearn: 1.0479556\ttotal: 261ms\tremaining: 112ms\n",
            "21:\tlearn: 1.0416863\ttotal: 273ms\tremaining: 99.3ms\n",
            "22:\tlearn: 1.0358593\ttotal: 285ms\tremaining: 86.7ms\n",
            "23:\tlearn: 1.0298901\ttotal: 296ms\tremaining: 74.1ms\n",
            "24:\tlearn: 1.0242734\ttotal: 308ms\tremaining: 61.6ms\n",
            "25:\tlearn: 1.0183456\ttotal: 310ms\tremaining: 47.7ms\n",
            "26:\tlearn: 1.0116457\ttotal: 316ms\tremaining: 35.1ms\n",
            "27:\tlearn: 1.0058641\ttotal: 330ms\tremaining: 23.6ms\n",
            "28:\tlearn: 0.9999756\ttotal: 342ms\tremaining: 11.8ms\n",
            "29:\tlearn: 0.9938392\ttotal: 354ms\tremaining: 0us\n",
            "0:\tlearn: 1.1948992\ttotal: 13.7ms\tremaining: 398ms\n",
            "1:\tlearn: 1.1877405\ttotal: 25.7ms\tremaining: 360ms\n",
            "2:\tlearn: 1.1802069\ttotal: 37.8ms\tremaining: 340ms\n",
            "3:\tlearn: 1.1732208\ttotal: 54.7ms\tremaining: 356ms\n",
            "4:\tlearn: 1.1652358\ttotal: 58.4ms\tremaining: 292ms\n",
            "5:\tlearn: 1.1573974\ttotal: 62.3ms\tremaining: 249ms\n",
            "6:\tlearn: 1.1504801\ttotal: 86.2ms\tremaining: 283ms\n",
            "7:\tlearn: 1.1432533\ttotal: 99.2ms\tremaining: 273ms\n",
            "8:\tlearn: 1.1357400\ttotal: 115ms\tremaining: 267ms\n",
            "9:\tlearn: 1.1288140\ttotal: 127ms\tremaining: 254ms\n",
            "10:\tlearn: 1.1215735\ttotal: 139ms\tremaining: 240ms\n",
            "11:\tlearn: 1.1149243\ttotal: 150ms\tremaining: 226ms\n",
            "12:\tlearn: 1.1079010\ttotal: 162ms\tremaining: 212ms\n",
            "13:\tlearn: 1.1016637\ttotal: 174ms\tremaining: 199ms\n",
            "14:\tlearn: 1.0950590\ttotal: 187ms\tremaining: 187ms\n",
            "15:\tlearn: 1.0888329\ttotal: 199ms\tremaining: 174ms\n",
            "16:\tlearn: 1.0820660\ttotal: 212ms\tremaining: 162ms\n",
            "17:\tlearn: 1.0757185\ttotal: 224ms\tremaining: 150ms\n",
            "18:\tlearn: 1.0693084\ttotal: 238ms\tremaining: 138ms\n",
            "19:\tlearn: 1.0635135\ttotal: 253ms\tremaining: 127ms\n",
            "20:\tlearn: 1.0565677\ttotal: 275ms\tremaining: 118ms\n",
            "21:\tlearn: 1.0506330\ttotal: 287ms\tremaining: 104ms\n",
            "22:\tlearn: 1.0447243\ttotal: 299ms\tremaining: 91.1ms\n",
            "23:\tlearn: 1.0385227\ttotal: 314ms\tremaining: 78.5ms\n",
            "24:\tlearn: 1.0324432\ttotal: 326ms\tremaining: 65.3ms\n",
            "25:\tlearn: 1.0261936\ttotal: 339ms\tremaining: 52.1ms\n",
            "26:\tlearn: 1.0199592\ttotal: 351ms\tremaining: 39ms\n",
            "27:\tlearn: 1.0143961\ttotal: 363ms\tremaining: 25.9ms\n",
            "28:\tlearn: 1.0085115\ttotal: 376ms\tremaining: 13ms\n",
            "29:\tlearn: 1.0028135\ttotal: 382ms\tremaining: 0us\n",
            "0:\tlearn: 1.2025546\ttotal: 12.6ms\tremaining: 366ms\n",
            "1:\tlearn: 1.1949026\ttotal: 25.3ms\tremaining: 355ms\n",
            "2:\tlearn: 1.1871530\ttotal: 48.6ms\tremaining: 438ms\n",
            "3:\tlearn: 1.1803107\ttotal: 63.1ms\tremaining: 410ms\n",
            "4:\tlearn: 1.1731607\ttotal: 76ms\tremaining: 380ms\n",
            "5:\tlearn: 1.1658499\ttotal: 88.5ms\tremaining: 354ms\n",
            "6:\tlearn: 1.1584931\ttotal: 102ms\tremaining: 334ms\n",
            "7:\tlearn: 1.1508343\ttotal: 115ms\tremaining: 317ms\n",
            "8:\tlearn: 1.1431852\ttotal: 127ms\tremaining: 297ms\n",
            "9:\tlearn: 1.1356983\ttotal: 132ms\tremaining: 263ms\n",
            "10:\tlearn: 1.1284262\ttotal: 145ms\tremaining: 250ms\n",
            "11:\tlearn: 1.1209332\ttotal: 157ms\tremaining: 236ms\n",
            "12:\tlearn: 1.1140996\ttotal: 160ms\tremaining: 209ms\n",
            "13:\tlearn: 1.1076809\ttotal: 172ms\tremaining: 197ms\n",
            "14:\tlearn: 1.1008914\ttotal: 184ms\tremaining: 184ms\n",
            "15:\tlearn: 1.0941250\ttotal: 196ms\tremaining: 172ms\n",
            "16:\tlearn: 1.0875971\ttotal: 208ms\tremaining: 159ms\n",
            "17:\tlearn: 1.0807064\ttotal: 212ms\tremaining: 141ms\n",
            "18:\tlearn: 1.0739572\ttotal: 224ms\tremaining: 130ms\n",
            "19:\tlearn: 1.0671280\ttotal: 227ms\tremaining: 114ms\n",
            "20:\tlearn: 1.0608510\ttotal: 241ms\tremaining: 103ms\n",
            "21:\tlearn: 1.0547433\ttotal: 264ms\tremaining: 96.1ms\n",
            "22:\tlearn: 1.0483306\ttotal: 278ms\tremaining: 84.5ms\n",
            "23:\tlearn: 1.0417391\ttotal: 291ms\tremaining: 72.6ms\n",
            "24:\tlearn: 1.0355068\ttotal: 304ms\tremaining: 60.7ms\n",
            "25:\tlearn: 1.0295067\ttotal: 305ms\tremaining: 46.9ms\n",
            "26:\tlearn: 1.0235041\ttotal: 318ms\tremaining: 35.3ms\n",
            "27:\tlearn: 1.0175766\ttotal: 331ms\tremaining: 23.7ms\n",
            "28:\tlearn: 1.0115808\ttotal: 333ms\tremaining: 11.5ms\n",
            "29:\tlearn: 1.0052538\ttotal: 349ms\tremaining: 0us\n",
            "0:\tlearn: 1.1157903\ttotal: 12.6ms\tremaining: 365ms\n",
            "1:\tlearn: 1.1088671\ttotal: 27.6ms\tremaining: 386ms\n",
            "2:\tlearn: 1.1018589\ttotal: 39.2ms\tremaining: 353ms\n",
            "3:\tlearn: 1.0958659\ttotal: 51.8ms\tremaining: 337ms\n",
            "4:\tlearn: 1.0893544\ttotal: 63.7ms\tremaining: 318ms\n",
            "5:\tlearn: 1.0828622\ttotal: 75ms\tremaining: 300ms\n",
            "6:\tlearn: 1.0758113\ttotal: 95.3ms\tremaining: 313ms\n",
            "7:\tlearn: 1.0691402\ttotal: 108ms\tremaining: 298ms\n",
            "8:\tlearn: 1.0626987\ttotal: 120ms\tremaining: 281ms\n",
            "9:\tlearn: 1.0560174\ttotal: 124ms\tremaining: 248ms\n",
            "10:\tlearn: 1.0494602\ttotal: 137ms\tremaining: 236ms\n",
            "11:\tlearn: 1.0428898\ttotal: 149ms\tremaining: 223ms\n",
            "12:\tlearn: 1.0364665\ttotal: 160ms\tremaining: 210ms\n",
            "13:\tlearn: 1.0299360\ttotal: 178ms\tremaining: 203ms\n",
            "14:\tlearn: 1.0236552\ttotal: 185ms\tremaining: 185ms\n",
            "15:\tlearn: 1.0183319\ttotal: 197ms\tremaining: 172ms\n",
            "16:\tlearn: 1.0126044\ttotal: 209ms\tremaining: 159ms\n",
            "17:\tlearn: 1.0063138\ttotal: 220ms\tremaining: 147ms\n",
            "18:\tlearn: 1.0000264\ttotal: 231ms\tremaining: 134ms\n",
            "19:\tlearn: 0.9940488\ttotal: 243ms\tremaining: 121ms\n",
            "20:\tlearn: 0.9883560\ttotal: 259ms\tremaining: 111ms\n",
            "21:\tlearn: 0.9825862\ttotal: 278ms\tremaining: 101ms\n",
            "22:\tlearn: 0.9764602\ttotal: 281ms\tremaining: 85.4ms\n",
            "23:\tlearn: 0.9711844\ttotal: 299ms\tremaining: 74.8ms\n",
            "24:\tlearn: 0.9654916\ttotal: 320ms\tremaining: 64.1ms\n",
            "25:\tlearn: 0.9598448\ttotal: 333ms\tremaining: 51.2ms\n",
            "26:\tlearn: 0.9543725\ttotal: 345ms\tremaining: 38.3ms\n",
            "27:\tlearn: 0.9495352\ttotal: 356ms\tremaining: 25.4ms\n",
            "28:\tlearn: 0.9442455\ttotal: 368ms\tremaining: 12.7ms\n",
            "29:\tlearn: 0.9386876\ttotal: 379ms\tremaining: 0us\n",
            "0:\tlearn: 1.1774319\ttotal: 12ms\tremaining: 347ms\n",
            "1:\tlearn: 1.1703482\ttotal: 23.8ms\tremaining: 334ms\n",
            "2:\tlearn: 1.1627866\ttotal: 35.6ms\tremaining: 320ms\n",
            "3:\tlearn: 1.1560036\ttotal: 47.4ms\tremaining: 308ms\n",
            "4:\tlearn: 1.1481986\ttotal: 50ms\tremaining: 250ms\n",
            "5:\tlearn: 1.1403085\ttotal: 52.2ms\tremaining: 209ms\n",
            "6:\tlearn: 1.1331323\ttotal: 69.2ms\tremaining: 227ms\n",
            "7:\tlearn: 1.1262101\ttotal: 81.4ms\tremaining: 224ms\n",
            "8:\tlearn: 1.1185204\ttotal: 103ms\tremaining: 241ms\n",
            "9:\tlearn: 1.1108204\ttotal: 116ms\tremaining: 232ms\n",
            "10:\tlearn: 1.1041240\ttotal: 128ms\tremaining: 221ms\n",
            "11:\tlearn: 1.0973536\ttotal: 140ms\tremaining: 210ms\n",
            "12:\tlearn: 1.0904279\ttotal: 151ms\tremaining: 198ms\n",
            "13:\tlearn: 1.0842123\ttotal: 163ms\tremaining: 187ms\n",
            "14:\tlearn: 1.0777204\ttotal: 175ms\tremaining: 175ms\n",
            "15:\tlearn: 1.0708567\ttotal: 187ms\tremaining: 164ms\n",
            "16:\tlearn: 1.0647459\ttotal: 200ms\tremaining: 153ms\n",
            "17:\tlearn: 1.0590216\ttotal: 212ms\tremaining: 141ms\n",
            "18:\tlearn: 1.0528715\ttotal: 224ms\tremaining: 129ms\n",
            "19:\tlearn: 1.0466248\ttotal: 236ms\tremaining: 118ms\n",
            "20:\tlearn: 1.0400454\ttotal: 250ms\tremaining: 107ms\n",
            "21:\tlearn: 1.0342379\ttotal: 265ms\tremaining: 96.3ms\n",
            "22:\tlearn: 1.0282777\ttotal: 276ms\tremaining: 84.1ms\n",
            "23:\tlearn: 1.0224542\ttotal: 288ms\tremaining: 72ms\n",
            "24:\tlearn: 1.0163405\ttotal: 301ms\tremaining: 60.1ms\n",
            "25:\tlearn: 1.0102928\ttotal: 304ms\tremaining: 46.7ms\n",
            "26:\tlearn: 1.0036245\ttotal: 317ms\tremaining: 35.3ms\n",
            "27:\tlearn: 0.9975832\ttotal: 329ms\tremaining: 23.5ms\n",
            "28:\tlearn: 0.9915532\ttotal: 341ms\tremaining: 11.8ms\n",
            "29:\tlearn: 0.9855358\ttotal: 352ms\tremaining: 0us\n",
            "0:\tlearn: 1.1550191\ttotal: 12.4ms\tremaining: 359ms\n",
            "1:\tlearn: 1.1206086\ttotal: 24.2ms\tremaining: 338ms\n",
            "2:\tlearn: 1.0880061\ttotal: 35.7ms\tremaining: 321ms\n",
            "3:\tlearn: 1.0580633\ttotal: 47.5ms\tremaining: 309ms\n",
            "4:\tlearn: 1.0243869\ttotal: 53.5ms\tremaining: 268ms\n",
            "5:\tlearn: 0.9981554\ttotal: 64.9ms\tremaining: 260ms\n",
            "6:\tlearn: 0.9706387\ttotal: 76.3ms\tremaining: 251ms\n",
            "7:\tlearn: 0.9456346\ttotal: 88.2ms\tremaining: 243ms\n",
            "8:\tlearn: 0.9178827\ttotal: 99.6ms\tremaining: 232ms\n",
            "9:\tlearn: 0.8909000\ttotal: 101ms\tremaining: 203ms\n",
            "10:\tlearn: 0.8692588\ttotal: 123ms\tremaining: 212ms\n",
            "11:\tlearn: 0.8471166\ttotal: 135ms\tremaining: 203ms\n",
            "12:\tlearn: 0.8251116\ttotal: 147ms\tremaining: 193ms\n",
            "13:\tlearn: 0.8040271\ttotal: 160ms\tremaining: 182ms\n",
            "14:\tlearn: 0.7831308\ttotal: 171ms\tremaining: 171ms\n",
            "15:\tlearn: 0.7645271\ttotal: 183ms\tremaining: 160ms\n",
            "16:\tlearn: 0.7461556\ttotal: 192ms\tremaining: 147ms\n",
            "17:\tlearn: 0.7292132\ttotal: 206ms\tremaining: 137ms\n",
            "18:\tlearn: 0.7140633\ttotal: 218ms\tremaining: 126ms\n",
            "19:\tlearn: 0.6990791\ttotal: 230ms\tremaining: 115ms\n",
            "20:\tlearn: 0.6828905\ttotal: 242ms\tremaining: 104ms\n",
            "21:\tlearn: 0.6682793\ttotal: 253ms\tremaining: 92ms\n",
            "22:\tlearn: 0.6540971\ttotal: 265ms\tremaining: 80.5ms\n",
            "23:\tlearn: 0.6407347\ttotal: 277ms\tremaining: 69.2ms\n",
            "24:\tlearn: 0.6285044\ttotal: 289ms\tremaining: 57.9ms\n",
            "25:\tlearn: 0.6167186\ttotal: 291ms\tremaining: 44.8ms\n",
            "26:\tlearn: 0.6046553\ttotal: 303ms\tremaining: 33.7ms\n",
            "27:\tlearn: 0.5946841\ttotal: 315ms\tremaining: 22.5ms\n",
            "28:\tlearn: 0.5844344\ttotal: 338ms\tremaining: 11.7ms\n",
            "29:\tlearn: 0.5739206\ttotal: 350ms\tremaining: 0us\n",
            "0:\tlearn: 1.1661331\ttotal: 11.6ms\tremaining: 336ms\n",
            "1:\tlearn: 1.1318096\ttotal: 22.7ms\tremaining: 317ms\n",
            "2:\tlearn: 1.0973114\ttotal: 34.9ms\tremaining: 314ms\n",
            "3:\tlearn: 1.0675407\ttotal: 46.3ms\tremaining: 301ms\n",
            "4:\tlearn: 1.0333895\ttotal: 52.5ms\tremaining: 263ms\n",
            "5:\tlearn: 1.0054259\ttotal: 75.7ms\tremaining: 303ms\n",
            "6:\tlearn: 0.9764574\ttotal: 87.9ms\tremaining: 289ms\n",
            "7:\tlearn: 0.9492732\ttotal: 99.5ms\tremaining: 274ms\n",
            "8:\tlearn: 0.9238262\ttotal: 111ms\tremaining: 258ms\n",
            "9:\tlearn: 0.8981307\ttotal: 112ms\tremaining: 224ms\n",
            "10:\tlearn: 0.8745046\ttotal: 124ms\tremaining: 214ms\n",
            "11:\tlearn: 0.8538692\ttotal: 139ms\tremaining: 208ms\n",
            "12:\tlearn: 0.8295349\ttotal: 155ms\tremaining: 203ms\n",
            "13:\tlearn: 0.8100101\ttotal: 169ms\tremaining: 193ms\n",
            "14:\tlearn: 0.7902337\ttotal: 180ms\tremaining: 180ms\n",
            "15:\tlearn: 0.7698226\ttotal: 191ms\tremaining: 167ms\n",
            "16:\tlearn: 0.7509742\ttotal: 197ms\tremaining: 151ms\n",
            "17:\tlearn: 0.7344584\ttotal: 208ms\tremaining: 139ms\n",
            "18:\tlearn: 0.7175734\ttotal: 219ms\tremaining: 127ms\n",
            "19:\tlearn: 0.7033115\ttotal: 230ms\tremaining: 115ms\n",
            "20:\tlearn: 0.6859803\ttotal: 242ms\tremaining: 104ms\n",
            "21:\tlearn: 0.6709841\ttotal: 255ms\tremaining: 92.8ms\n",
            "22:\tlearn: 0.6561659\ttotal: 267ms\tremaining: 81.2ms\n",
            "23:\tlearn: 0.6430126\ttotal: 278ms\tremaining: 69.6ms\n",
            "24:\tlearn: 0.6310995\ttotal: 290ms\tremaining: 58.1ms\n",
            "25:\tlearn: 0.6192651\ttotal: 292ms\tremaining: 44.9ms\n",
            "26:\tlearn: 0.6081081\ttotal: 298ms\tremaining: 33.1ms\n",
            "27:\tlearn: 0.5973351\ttotal: 310ms\tremaining: 22.1ms\n",
            "28:\tlearn: 0.5866098\ttotal: 321ms\tremaining: 11.1ms\n",
            "29:\tlearn: 0.5772000\ttotal: 333ms\tremaining: 0us\n",
            "0:\tlearn: 1.1732308\ttotal: 11.7ms\tremaining: 340ms\n",
            "1:\tlearn: 1.1363514\ttotal: 23.7ms\tremaining: 332ms\n",
            "2:\tlearn: 1.0988508\ttotal: 35.2ms\tremaining: 317ms\n",
            "3:\tlearn: 1.0682952\ttotal: 46.7ms\tremaining: 304ms\n",
            "4:\tlearn: 1.0369489\ttotal: 58.3ms\tremaining: 292ms\n",
            "5:\tlearn: 1.0066190\ttotal: 69.9ms\tremaining: 280ms\n",
            "6:\tlearn: 0.9777206\ttotal: 81.5ms\tremaining: 268ms\n",
            "7:\tlearn: 0.9489114\ttotal: 96.8ms\tremaining: 266ms\n",
            "8:\tlearn: 0.9211139\ttotal: 109ms\tremaining: 254ms\n",
            "9:\tlearn: 0.8936276\ttotal: 113ms\tremaining: 226ms\n",
            "10:\tlearn: 0.8690029\ttotal: 125ms\tremaining: 216ms\n",
            "11:\tlearn: 0.8451580\ttotal: 137ms\tremaining: 206ms\n",
            "12:\tlearn: 0.8225518\ttotal: 149ms\tremaining: 195ms\n",
            "13:\tlearn: 0.8017962\ttotal: 161ms\tremaining: 183ms\n",
            "14:\tlearn: 0.7799529\ttotal: 167ms\tremaining: 167ms\n",
            "15:\tlearn: 0.7631187\ttotal: 178ms\tremaining: 156ms\n",
            "16:\tlearn: 0.7448100\ttotal: 190ms\tremaining: 146ms\n",
            "17:\tlearn: 0.7283063\ttotal: 192ms\tremaining: 128ms\n",
            "18:\tlearn: 0.7110279\ttotal: 204ms\tremaining: 118ms\n",
            "19:\tlearn: 0.6956466\ttotal: 206ms\tremaining: 103ms\n",
            "20:\tlearn: 0.6812351\ttotal: 227ms\tremaining: 97.3ms\n",
            "21:\tlearn: 0.6671435\ttotal: 229ms\tremaining: 83.1ms\n",
            "22:\tlearn: 0.6542583\ttotal: 240ms\tremaining: 73.1ms\n",
            "23:\tlearn: 0.6412960\ttotal: 252ms\tremaining: 63ms\n",
            "24:\tlearn: 0.6290119\ttotal: 264ms\tremaining: 52.7ms\n",
            "25:\tlearn: 0.6173102\ttotal: 275ms\tremaining: 42.3ms\n",
            "26:\tlearn: 0.6056841\ttotal: 287ms\tremaining: 31.8ms\n",
            "27:\tlearn: 0.5962667\ttotal: 289ms\tremaining: 20.6ms\n",
            "28:\tlearn: 0.5857311\ttotal: 301ms\tremaining: 10.4ms\n",
            "29:\tlearn: 0.5757804\ttotal: 302ms\tremaining: 0us\n",
            "0:\tlearn: 1.0888842\ttotal: 11.3ms\tremaining: 329ms\n",
            "1:\tlearn: 1.0555332\ttotal: 22.6ms\tremaining: 317ms\n",
            "2:\tlearn: 1.0229894\ttotal: 33.8ms\tremaining: 305ms\n",
            "3:\tlearn: 0.9961431\ttotal: 45.3ms\tremaining: 294ms\n",
            "4:\tlearn: 0.9654376\ttotal: 51.4ms\tremaining: 257ms\n",
            "5:\tlearn: 0.9383076\ttotal: 62.8ms\tremaining: 251ms\n",
            "6:\tlearn: 0.9122336\ttotal: 74.2ms\tremaining: 244ms\n",
            "7:\tlearn: 0.8883516\ttotal: 85.6ms\tremaining: 235ms\n",
            "8:\tlearn: 0.8627718\ttotal: 104ms\tremaining: 243ms\n",
            "9:\tlearn: 0.8390155\ttotal: 111ms\tremaining: 222ms\n",
            "10:\tlearn: 0.8167164\ttotal: 122ms\tremaining: 211ms\n",
            "11:\tlearn: 0.7944083\ttotal: 133ms\tremaining: 200ms\n",
            "12:\tlearn: 0.7736219\ttotal: 144ms\tremaining: 189ms\n",
            "13:\tlearn: 0.7541395\ttotal: 155ms\tremaining: 177ms\n",
            "14:\tlearn: 0.7365763\ttotal: 163ms\tremaining: 163ms\n",
            "15:\tlearn: 0.7208330\ttotal: 175ms\tremaining: 153ms\n",
            "16:\tlearn: 0.7052673\ttotal: 186ms\tremaining: 142ms\n",
            "17:\tlearn: 0.6885323\ttotal: 201ms\tremaining: 134ms\n",
            "18:\tlearn: 0.6729544\ttotal: 213ms\tremaining: 123ms\n",
            "19:\tlearn: 0.6580666\ttotal: 225ms\tremaining: 113ms\n",
            "20:\tlearn: 0.6444465\ttotal: 236ms\tremaining: 101ms\n",
            "21:\tlearn: 0.6310561\ttotal: 247ms\tremaining: 90ms\n",
            "22:\tlearn: 0.6178219\ttotal: 258ms\tremaining: 78.7ms\n",
            "23:\tlearn: 0.6055862\ttotal: 270ms\tremaining: 67.5ms\n",
            "24:\tlearn: 0.5946469\ttotal: 273ms\tremaining: 54.7ms\n",
            "25:\tlearn: 0.5846114\ttotal: 285ms\tremaining: 43.8ms\n",
            "26:\tlearn: 0.5755183\ttotal: 296ms\tremaining: 32.9ms\n",
            "27:\tlearn: 0.5666772\ttotal: 317ms\tremaining: 22.7ms\n",
            "28:\tlearn: 0.5568225\ttotal: 329ms\tremaining: 11.3ms\n",
            "29:\tlearn: 0.5482042\ttotal: 330ms\tremaining: 0us\n",
            "0:\tlearn: 1.1478826\ttotal: 11.2ms\tremaining: 323ms\n",
            "1:\tlearn: 1.1127509\ttotal: 22.4ms\tremaining: 314ms\n",
            "2:\tlearn: 1.0792044\ttotal: 33.3ms\tremaining: 300ms\n",
            "3:\tlearn: 1.0487522\ttotal: 44.2ms\tremaining: 287ms\n",
            "4:\tlearn: 1.0158845\ttotal: 46.4ms\tremaining: 232ms\n",
            "5:\tlearn: 0.9860428\ttotal: 57.3ms\tremaining: 229ms\n",
            "6:\tlearn: 0.9574755\ttotal: 68.4ms\tremaining: 225ms\n",
            "7:\tlearn: 0.9299491\ttotal: 79.3ms\tremaining: 218ms\n",
            "8:\tlearn: 0.9038732\ttotal: 90.3ms\tremaining: 211ms\n",
            "9:\tlearn: 0.8775382\ttotal: 91.8ms\tremaining: 184ms\n",
            "10:\tlearn: 0.8521467\ttotal: 103ms\tremaining: 178ms\n",
            "11:\tlearn: 0.8290482\ttotal: 106ms\tremaining: 158ms\n",
            "12:\tlearn: 0.8074516\ttotal: 117ms\tremaining: 153ms\n",
            "13:\tlearn: 0.7859029\ttotal: 119ms\tremaining: 136ms\n",
            "14:\tlearn: 0.7677132\ttotal: 130ms\tremaining: 130ms\n",
            "15:\tlearn: 0.7493566\ttotal: 141ms\tremaining: 124ms\n",
            "16:\tlearn: 0.7328343\ttotal: 162ms\tremaining: 124ms\n",
            "17:\tlearn: 0.7162965\ttotal: 181ms\tremaining: 121ms\n",
            "18:\tlearn: 0.6991579\ttotal: 192ms\tremaining: 111ms\n",
            "19:\tlearn: 0.6846931\ttotal: 204ms\tremaining: 102ms\n",
            "20:\tlearn: 0.6693093\ttotal: 206ms\tremaining: 88.3ms\n",
            "21:\tlearn: 0.6557481\ttotal: 217ms\tremaining: 78.9ms\n",
            "22:\tlearn: 0.6412132\ttotal: 228ms\tremaining: 69.5ms\n",
            "23:\tlearn: 0.6277871\ttotal: 244ms\tremaining: 60.9ms\n",
            "24:\tlearn: 0.6161135\ttotal: 255ms\tremaining: 51ms\n",
            "25:\tlearn: 0.6056290\ttotal: 266ms\tremaining: 41ms\n",
            "26:\tlearn: 0.5948910\ttotal: 277ms\tremaining: 30.8ms\n",
            "27:\tlearn: 0.5845726\ttotal: 288ms\tremaining: 20.6ms\n",
            "28:\tlearn: 0.5750095\ttotal: 299ms\tremaining: 10.3ms\n",
            "29:\tlearn: 0.5652776\ttotal: 310ms\tremaining: 0us\n",
            "0:\tlearn: 1.1222901\ttotal: 11.4ms\tremaining: 330ms\n",
            "1:\tlearn: 1.0556293\ttotal: 23.4ms\tremaining: 327ms\n",
            "2:\tlearn: 0.9938204\ttotal: 41.6ms\tremaining: 375ms\n",
            "3:\tlearn: 0.9418970\ttotal: 52.6ms\tremaining: 342ms\n",
            "4:\tlearn: 0.8882246\ttotal: 54.7ms\tremaining: 273ms\n",
            "5:\tlearn: 0.8374233\ttotal: 56.6ms\tremaining: 226ms\n",
            "6:\tlearn: 0.7954464\ttotal: 67.7ms\tremaining: 222ms\n",
            "7:\tlearn: 0.7584911\ttotal: 78.4ms\tremaining: 216ms\n",
            "8:\tlearn: 0.7223788\ttotal: 89.2ms\tremaining: 208ms\n",
            "9:\tlearn: 0.6888904\ttotal: 100ms\tremaining: 200ms\n",
            "10:\tlearn: 0.6619785\ttotal: 111ms\tremaining: 192ms\n",
            "11:\tlearn: 0.6383678\ttotal: 122ms\tremaining: 183ms\n",
            "12:\tlearn: 0.6130988\ttotal: 133ms\tremaining: 173ms\n",
            "13:\tlearn: 0.5929996\ttotal: 144ms\tremaining: 164ms\n",
            "14:\tlearn: 0.5745404\ttotal: 155ms\tremaining: 155ms\n",
            "15:\tlearn: 0.5575266\ttotal: 166ms\tremaining: 145ms\n",
            "16:\tlearn: 0.5405637\ttotal: 177ms\tremaining: 136ms\n",
            "17:\tlearn: 0.5255076\ttotal: 188ms\tremaining: 126ms\n",
            "18:\tlearn: 0.5128573\ttotal: 199ms\tremaining: 115ms\n",
            "19:\tlearn: 0.4974932\ttotal: 210ms\tremaining: 105ms\n",
            "20:\tlearn: 0.4850916\ttotal: 221ms\tremaining: 94.8ms\n",
            "21:\tlearn: 0.4729518\ttotal: 240ms\tremaining: 87.1ms\n",
            "22:\tlearn: 0.4606799\ttotal: 253ms\tremaining: 76.9ms\n",
            "23:\tlearn: 0.4527266\ttotal: 264ms\tremaining: 66ms\n",
            "24:\tlearn: 0.4439238\ttotal: 278ms\tremaining: 55.6ms\n",
            "25:\tlearn: 0.4356466\ttotal: 289ms\tremaining: 44.5ms\n",
            "26:\tlearn: 0.4303323\ttotal: 291ms\tremaining: 32.4ms\n",
            "27:\tlearn: 0.4238449\ttotal: 302ms\tremaining: 21.6ms\n",
            "28:\tlearn: 0.4183272\ttotal: 304ms\tremaining: 10.5ms\n",
            "29:\tlearn: 0.4115548\ttotal: 315ms\tremaining: 0us\n",
            "0:\tlearn: 1.1306657\ttotal: 11.6ms\tremaining: 337ms\n",
            "1:\tlearn: 1.0634231\ttotal: 23.8ms\tremaining: 333ms\n",
            "2:\tlearn: 1.0011841\ttotal: 35.2ms\tremaining: 317ms\n",
            "3:\tlearn: 0.9430721\ttotal: 46.7ms\tremaining: 303ms\n",
            "4:\tlearn: 0.8874037\ttotal: 52.9ms\tremaining: 265ms\n",
            "5:\tlearn: 0.8439407\ttotal: 64.2ms\tremaining: 257ms\n",
            "6:\tlearn: 0.8015813\ttotal: 75.7ms\tremaining: 249ms\n",
            "7:\tlearn: 0.7654209\ttotal: 89.2ms\tremaining: 245ms\n",
            "8:\tlearn: 0.7284290\ttotal: 106ms\tremaining: 247ms\n",
            "9:\tlearn: 0.6966199\ttotal: 108ms\tremaining: 215ms\n",
            "10:\tlearn: 0.6680427\ttotal: 119ms\tremaining: 206ms\n",
            "11:\tlearn: 0.6437389\ttotal: 131ms\tremaining: 196ms\n",
            "12:\tlearn: 0.6164233\ttotal: 144ms\tremaining: 188ms\n",
            "13:\tlearn: 0.5962139\ttotal: 155ms\tremaining: 177ms\n",
            "14:\tlearn: 0.5751864\ttotal: 167ms\tremaining: 167ms\n",
            "15:\tlearn: 0.5559910\ttotal: 178ms\tremaining: 156ms\n",
            "16:\tlearn: 0.5387270\ttotal: 184ms\tremaining: 141ms\n",
            "17:\tlearn: 0.5243731\ttotal: 196ms\tremaining: 131ms\n",
            "18:\tlearn: 0.5101154\ttotal: 208ms\tremaining: 120ms\n",
            "19:\tlearn: 0.4972322\ttotal: 219ms\tremaining: 110ms\n",
            "20:\tlearn: 0.4849641\ttotal: 231ms\tremaining: 98.9ms\n",
            "21:\tlearn: 0.4741710\ttotal: 242ms\tremaining: 88ms\n",
            "22:\tlearn: 0.4619723\ttotal: 253ms\tremaining: 77.1ms\n",
            "23:\tlearn: 0.4542843\ttotal: 265ms\tremaining: 66.2ms\n",
            "24:\tlearn: 0.4450756\ttotal: 280ms\tremaining: 56ms\n",
            "25:\tlearn: 0.4390553\ttotal: 283ms\tremaining: 43.5ms\n",
            "26:\tlearn: 0.4311542\ttotal: 291ms\tremaining: 32.3ms\n",
            "27:\tlearn: 0.4241122\ttotal: 309ms\tremaining: 22.1ms\n",
            "28:\tlearn: 0.4171327\ttotal: 329ms\tremaining: 11.3ms\n",
            "29:\tlearn: 0.4118332\ttotal: 340ms\tremaining: 0us\n",
            "0:\tlearn: 1.1369578\ttotal: 11.6ms\tremaining: 337ms\n",
            "1:\tlearn: 1.0666705\ttotal: 23.3ms\tremaining: 326ms\n",
            "2:\tlearn: 1.0014770\ttotal: 34.9ms\tremaining: 314ms\n",
            "3:\tlearn: 0.9433036\ttotal: 47.9ms\tremaining: 311ms\n",
            "4:\tlearn: 0.8895453\ttotal: 50.9ms\tremaining: 255ms\n",
            "5:\tlearn: 0.8394172\ttotal: 54.6ms\tremaining: 218ms\n",
            "6:\tlearn: 0.7982341\ttotal: 68.3ms\tremaining: 225ms\n",
            "7:\tlearn: 0.7576997\ttotal: 80.1ms\tremaining: 220ms\n",
            "8:\tlearn: 0.7211154\ttotal: 92ms\tremaining: 215ms\n",
            "9:\tlearn: 0.6915006\ttotal: 104ms\tremaining: 208ms\n",
            "10:\tlearn: 0.6625632\ttotal: 115ms\tremaining: 199ms\n",
            "11:\tlearn: 0.6362412\ttotal: 134ms\tremaining: 202ms\n",
            "12:\tlearn: 0.6102676\ttotal: 147ms\tremaining: 192ms\n",
            "13:\tlearn: 0.5892198\ttotal: 159ms\tremaining: 181ms\n",
            "14:\tlearn: 0.5707759\ttotal: 170ms\tremaining: 170ms\n",
            "15:\tlearn: 0.5521317\ttotal: 182ms\tremaining: 159ms\n",
            "16:\tlearn: 0.5359905\ttotal: 194ms\tremaining: 148ms\n",
            "17:\tlearn: 0.5209339\ttotal: 206ms\tremaining: 137ms\n",
            "18:\tlearn: 0.5073364\ttotal: 218ms\tremaining: 126ms\n",
            "19:\tlearn: 0.4937301\ttotal: 230ms\tremaining: 115ms\n",
            "20:\tlearn: 0.4823022\ttotal: 241ms\tremaining: 103ms\n",
            "21:\tlearn: 0.4712486\ttotal: 253ms\tremaining: 92ms\n",
            "22:\tlearn: 0.4612824\ttotal: 265ms\tremaining: 80.6ms\n",
            "23:\tlearn: 0.4540688\ttotal: 276ms\tremaining: 69.1ms\n",
            "24:\tlearn: 0.4449425\ttotal: 288ms\tremaining: 57.7ms\n",
            "25:\tlearn: 0.4397200\ttotal: 290ms\tremaining: 44.5ms\n",
            "26:\tlearn: 0.4317844\ttotal: 301ms\tremaining: 33.5ms\n",
            "27:\tlearn: 0.4244570\ttotal: 314ms\tremaining: 22.4ms\n",
            "28:\tlearn: 0.4178800\ttotal: 326ms\tremaining: 11.3ms\n",
            "29:\tlearn: 0.4115021\ttotal: 346ms\tremaining: 0us\n",
            "0:\tlearn: 1.0556000\ttotal: 11.3ms\tremaining: 327ms\n",
            "1:\tlearn: 0.9921731\ttotal: 22.1ms\tremaining: 309ms\n",
            "2:\tlearn: 0.9318544\ttotal: 32.9ms\tremaining: 296ms\n",
            "3:\tlearn: 0.8855854\ttotal: 43.7ms\tremaining: 284ms\n",
            "4:\tlearn: 0.8344041\ttotal: 49.4ms\tremaining: 247ms\n",
            "5:\tlearn: 0.7921200\ttotal: 60.1ms\tremaining: 241ms\n",
            "6:\tlearn: 0.7530690\ttotal: 70.8ms\tremaining: 232ms\n",
            "7:\tlearn: 0.7215615\ttotal: 81.3ms\tremaining: 224ms\n",
            "8:\tlearn: 0.6869308\ttotal: 92ms\tremaining: 215ms\n",
            "9:\tlearn: 0.6565393\ttotal: 97.7ms\tremaining: 195ms\n",
            "10:\tlearn: 0.6296639\ttotal: 109ms\tremaining: 187ms\n",
            "11:\tlearn: 0.6038882\ttotal: 119ms\tremaining: 179ms\n",
            "12:\tlearn: 0.5817260\ttotal: 130ms\tremaining: 170ms\n",
            "13:\tlearn: 0.5623047\ttotal: 141ms\tremaining: 161ms\n",
            "14:\tlearn: 0.5437806\ttotal: 147ms\tremaining: 147ms\n",
            "15:\tlearn: 0.5276394\ttotal: 158ms\tremaining: 138ms\n",
            "16:\tlearn: 0.5137419\ttotal: 179ms\tremaining: 137ms\n",
            "17:\tlearn: 0.5001549\ttotal: 190ms\tremaining: 127ms\n",
            "18:\tlearn: 0.4873154\ttotal: 201ms\tremaining: 116ms\n",
            "19:\tlearn: 0.4744581\ttotal: 212ms\tremaining: 106ms\n",
            "20:\tlearn: 0.4635919\ttotal: 222ms\tremaining: 95.3ms\n",
            "21:\tlearn: 0.4549762\ttotal: 233ms\tremaining: 84.8ms\n",
            "22:\tlearn: 0.4457579\ttotal: 244ms\tremaining: 74.3ms\n",
            "23:\tlearn: 0.4377799\ttotal: 255ms\tremaining: 63.8ms\n",
            "24:\tlearn: 0.4307393\ttotal: 266ms\tremaining: 53.3ms\n",
            "25:\tlearn: 0.4237205\ttotal: 277ms\tremaining: 42.7ms\n",
            "26:\tlearn: 0.4163492\ttotal: 288ms\tremaining: 32ms\n",
            "27:\tlearn: 0.4108825\ttotal: 299ms\tremaining: 21.4ms\n",
            "28:\tlearn: 0.4035620\ttotal: 311ms\tremaining: 10.7ms\n",
            "29:\tlearn: 0.3964455\ttotal: 322ms\tremaining: 0us\n",
            "0:\tlearn: 1.1113653\ttotal: 12.1ms\tremaining: 351ms\n",
            "1:\tlearn: 1.0447330\ttotal: 24.1ms\tremaining: 338ms\n",
            "2:\tlearn: 0.9841393\ttotal: 46ms\tremaining: 414ms\n",
            "3:\tlearn: 0.9313239\ttotal: 60.5ms\tremaining: 393ms\n",
            "4:\tlearn: 0.8765598\ttotal: 63ms\tremaining: 315ms\n",
            "5:\tlearn: 0.8258082\ttotal: 65.2ms\tremaining: 261ms\n",
            "6:\tlearn: 0.7829934\ttotal: 76.8ms\tremaining: 252ms\n",
            "7:\tlearn: 0.7446864\ttotal: 88ms\tremaining: 242ms\n",
            "8:\tlearn: 0.7072756\ttotal: 99ms\tremaining: 231ms\n",
            "9:\tlearn: 0.6740318\ttotal: 110ms\tremaining: 220ms\n",
            "10:\tlearn: 0.6471142\ttotal: 121ms\tremaining: 210ms\n",
            "11:\tlearn: 0.6177466\ttotal: 133ms\tremaining: 199ms\n",
            "12:\tlearn: 0.5943156\ttotal: 144ms\tremaining: 188ms\n",
            "13:\tlearn: 0.5709257\ttotal: 155ms\tremaining: 177ms\n",
            "14:\tlearn: 0.5519780\ttotal: 166ms\tremaining: 166ms\n",
            "15:\tlearn: 0.5347746\ttotal: 177ms\tremaining: 155ms\n",
            "16:\tlearn: 0.5179129\ttotal: 189ms\tremaining: 144ms\n",
            "17:\tlearn: 0.5044291\ttotal: 203ms\tremaining: 135ms\n",
            "18:\tlearn: 0.4899518\ttotal: 222ms\tremaining: 129ms\n",
            "19:\tlearn: 0.4761146\ttotal: 242ms\tremaining: 121ms\n",
            "20:\tlearn: 0.4653992\ttotal: 254ms\tremaining: 109ms\n",
            "21:\tlearn: 0.4553138\ttotal: 265ms\tremaining: 96.4ms\n",
            "22:\tlearn: 0.4454417\ttotal: 276ms\tremaining: 84ms\n",
            "23:\tlearn: 0.4373473\ttotal: 287ms\tremaining: 71.7ms\n",
            "24:\tlearn: 0.4289792\ttotal: 298ms\tremaining: 59.5ms\n",
            "25:\tlearn: 0.4224543\ttotal: 310ms\tremaining: 47.8ms\n",
            "26:\tlearn: 0.4145828\ttotal: 321ms\tremaining: 35.7ms\n",
            "27:\tlearn: 0.4086065\ttotal: 332ms\tremaining: 23.7ms\n",
            "28:\tlearn: 0.4016781\ttotal: 343ms\tremaining: 11.8ms\n",
            "29:\tlearn: 0.3946322\ttotal: 355ms\tremaining: 0us\n",
            "0:\tlearn: 1.1815153\ttotal: 11.2ms\tremaining: 549ms\n",
            "1:\tlearn: 1.1742313\ttotal: 22.6ms\tremaining: 543ms\n",
            "2:\tlearn: 1.1672126\ttotal: 33.6ms\tremaining: 527ms\n",
            "3:\tlearn: 1.1605805\ttotal: 44.6ms\tremaining: 513ms\n",
            "4:\tlearn: 1.1528142\ttotal: 50.7ms\tremaining: 457ms\n",
            "5:\tlearn: 1.1463037\ttotal: 68.5ms\tremaining: 503ms\n",
            "6:\tlearn: 1.1393615\ttotal: 84.8ms\tremaining: 521ms\n",
            "7:\tlearn: 1.1327902\ttotal: 96ms\tremaining: 504ms\n",
            "8:\tlearn: 1.1257711\ttotal: 107ms\tremaining: 488ms\n",
            "9:\tlearn: 1.1192543\ttotal: 118ms\tremaining: 473ms\n",
            "10:\tlearn: 1.1121791\ttotal: 129ms\tremaining: 458ms\n",
            "11:\tlearn: 1.1055086\ttotal: 131ms\tremaining: 414ms\n",
            "12:\tlearn: 1.0984028\ttotal: 142ms\tremaining: 404ms\n",
            "13:\tlearn: 1.0918063\ttotal: 153ms\tremaining: 393ms\n",
            "14:\tlearn: 1.0856601\ttotal: 164ms\tremaining: 383ms\n",
            "15:\tlearn: 1.0792667\ttotal: 176ms\tremaining: 374ms\n",
            "16:\tlearn: 1.0727807\ttotal: 182ms\tremaining: 354ms\n",
            "17:\tlearn: 1.0667973\ttotal: 193ms\tremaining: 344ms\n",
            "18:\tlearn: 1.0606950\ttotal: 205ms\tremaining: 334ms\n",
            "19:\tlearn: 1.0547422\ttotal: 216ms\tremaining: 324ms\n",
            "20:\tlearn: 1.0479556\ttotal: 227ms\tremaining: 313ms\n",
            "21:\tlearn: 1.0416863\ttotal: 238ms\tremaining: 303ms\n",
            "22:\tlearn: 1.0358593\ttotal: 249ms\tremaining: 292ms\n",
            "23:\tlearn: 1.0298901\ttotal: 260ms\tremaining: 282ms\n",
            "24:\tlearn: 1.0242734\ttotal: 279ms\tremaining: 279ms\n",
            "25:\tlearn: 1.0183456\ttotal: 281ms\tremaining: 260ms\n",
            "26:\tlearn: 1.0116457\ttotal: 287ms\tremaining: 245ms\n",
            "27:\tlearn: 1.0058641\ttotal: 298ms\tremaining: 234ms\n",
            "28:\tlearn: 0.9999756\ttotal: 310ms\tremaining: 224ms\n",
            "29:\tlearn: 0.9938392\ttotal: 321ms\tremaining: 214ms\n",
            "30:\tlearn: 0.9881463\ttotal: 332ms\tremaining: 204ms\n",
            "31:\tlearn: 0.9820127\ttotal: 333ms\tremaining: 188ms\n",
            "32:\tlearn: 0.9760292\ttotal: 340ms\tremaining: 175ms\n",
            "33:\tlearn: 0.9702471\ttotal: 342ms\tremaining: 161ms\n",
            "34:\tlearn: 0.9641238\ttotal: 353ms\tremaining: 151ms\n",
            "35:\tlearn: 0.9589244\ttotal: 354ms\tremaining: 138ms\n",
            "36:\tlearn: 0.9536396\ttotal: 365ms\tremaining: 128ms\n",
            "37:\tlearn: 0.9480101\ttotal: 376ms\tremaining: 119ms\n",
            "38:\tlearn: 0.9423020\ttotal: 388ms\tremaining: 109ms\n",
            "39:\tlearn: 0.9367184\ttotal: 399ms\tremaining: 99.7ms\n",
            "40:\tlearn: 0.9316460\ttotal: 410ms\tremaining: 90ms\n",
            "41:\tlearn: 0.9265254\ttotal: 421ms\tremaining: 80.1ms\n",
            "42:\tlearn: 0.9214855\ttotal: 432ms\tremaining: 70.3ms\n",
            "43:\tlearn: 0.9163539\ttotal: 443ms\tremaining: 60.4ms\n",
            "44:\tlearn: 0.9119592\ttotal: 444ms\tremaining: 49.4ms\n",
            "45:\tlearn: 0.9071759\ttotal: 446ms\tremaining: 38.8ms\n",
            "46:\tlearn: 0.9022489\ttotal: 449ms\tremaining: 28.7ms\n",
            "47:\tlearn: 0.8971271\ttotal: 460ms\tremaining: 19.2ms\n",
            "48:\tlearn: 0.8927731\ttotal: 471ms\tremaining: 9.61ms\n",
            "49:\tlearn: 0.8883350\ttotal: 490ms\tremaining: 0us\n",
            "0:\tlearn: 1.1948992\ttotal: 11.7ms\tremaining: 573ms\n",
            "1:\tlearn: 1.1877405\ttotal: 23.3ms\tremaining: 560ms\n",
            "2:\tlearn: 1.1802069\ttotal: 34.8ms\tremaining: 545ms\n",
            "3:\tlearn: 1.1732208\ttotal: 49.7ms\tremaining: 571ms\n",
            "4:\tlearn: 1.1652358\ttotal: 52ms\tremaining: 468ms\n",
            "5:\tlearn: 1.1573974\ttotal: 54.2ms\tremaining: 398ms\n",
            "6:\tlearn: 1.1504801\ttotal: 65.6ms\tremaining: 403ms\n",
            "7:\tlearn: 1.1432533\ttotal: 77.3ms\tremaining: 406ms\n",
            "8:\tlearn: 1.1357400\ttotal: 89.9ms\tremaining: 410ms\n",
            "9:\tlearn: 1.1288140\ttotal: 102ms\tremaining: 406ms\n",
            "10:\tlearn: 1.1215735\ttotal: 113ms\tremaining: 401ms\n",
            "11:\tlearn: 1.1149243\ttotal: 125ms\tremaining: 395ms\n",
            "12:\tlearn: 1.1079010\ttotal: 136ms\tremaining: 388ms\n",
            "13:\tlearn: 1.1016637\ttotal: 148ms\tremaining: 380ms\n",
            "14:\tlearn: 1.0950590\ttotal: 159ms\tremaining: 372ms\n",
            "15:\tlearn: 1.0888329\ttotal: 178ms\tremaining: 379ms\n",
            "16:\tlearn: 1.0820660\ttotal: 190ms\tremaining: 369ms\n",
            "17:\tlearn: 1.0757185\ttotal: 201ms\tremaining: 358ms\n",
            "18:\tlearn: 1.0693084\ttotal: 213ms\tremaining: 347ms\n",
            "19:\tlearn: 1.0635135\ttotal: 224ms\tremaining: 336ms\n",
            "20:\tlearn: 1.0565677\ttotal: 236ms\tremaining: 326ms\n",
            "21:\tlearn: 1.0506330\ttotal: 247ms\tremaining: 315ms\n",
            "22:\tlearn: 1.0447243\ttotal: 259ms\tremaining: 304ms\n",
            "23:\tlearn: 1.0385227\ttotal: 270ms\tremaining: 293ms\n",
            "24:\tlearn: 1.0324432\ttotal: 282ms\tremaining: 282ms\n",
            "25:\tlearn: 1.0261936\ttotal: 297ms\tremaining: 274ms\n",
            "26:\tlearn: 1.0199592\ttotal: 317ms\tremaining: 270ms\n",
            "27:\tlearn: 1.0143961\ttotal: 328ms\tremaining: 258ms\n",
            "28:\tlearn: 1.0085115\ttotal: 340ms\tremaining: 246ms\n",
            "29:\tlearn: 1.0028135\ttotal: 346ms\tremaining: 231ms\n",
            "30:\tlearn: 0.9966966\ttotal: 357ms\tremaining: 219ms\n",
            "31:\tlearn: 0.9905695\ttotal: 361ms\tremaining: 203ms\n",
            "32:\tlearn: 0.9849567\ttotal: 375ms\tremaining: 193ms\n",
            "33:\tlearn: 0.9794651\ttotal: 390ms\tremaining: 184ms\n",
            "34:\tlearn: 0.9740481\ttotal: 402ms\tremaining: 172ms\n",
            "35:\tlearn: 0.9684356\ttotal: 414ms\tremaining: 161ms\n",
            "36:\tlearn: 0.9631742\ttotal: 426ms\tremaining: 150ms\n",
            "37:\tlearn: 0.9570022\ttotal: 430ms\tremaining: 136ms\n",
            "38:\tlearn: 0.9517141\ttotal: 442ms\tremaining: 125ms\n",
            "39:\tlearn: 0.9464449\ttotal: 453ms\tremaining: 113ms\n",
            "40:\tlearn: 0.9406960\ttotal: 455ms\tremaining: 99.9ms\n",
            "41:\tlearn: 0.9356009\ttotal: 466ms\tremaining: 88.9ms\n",
            "42:\tlearn: 0.9305000\ttotal: 473ms\tremaining: 77ms\n",
            "43:\tlearn: 0.9252938\ttotal: 474ms\tremaining: 64.6ms\n",
            "44:\tlearn: 0.9198806\ttotal: 476ms\tremaining: 52.9ms\n",
            "45:\tlearn: 0.9148915\ttotal: 488ms\tremaining: 42.4ms\n",
            "46:\tlearn: 0.9097779\ttotal: 499ms\tremaining: 31.9ms\n",
            "47:\tlearn: 0.9047261\ttotal: 511ms\tremaining: 21.3ms\n",
            "48:\tlearn: 0.8995398\ttotal: 517ms\tremaining: 10.6ms\n",
            "49:\tlearn: 0.8945310\ttotal: 521ms\tremaining: 0us\n",
            "0:\tlearn: 1.2025546\ttotal: 11.7ms\tremaining: 575ms\n",
            "1:\tlearn: 1.1949026\ttotal: 31.5ms\tremaining: 756ms\n",
            "2:\tlearn: 1.1871530\ttotal: 42.9ms\tremaining: 672ms\n",
            "3:\tlearn: 1.1803107\ttotal: 54.4ms\tremaining: 626ms\n",
            "4:\tlearn: 1.1731607\ttotal: 66.5ms\tremaining: 598ms\n",
            "5:\tlearn: 1.1658499\ttotal: 78.4ms\tremaining: 575ms\n",
            "6:\tlearn: 1.1584931\ttotal: 90.1ms\tremaining: 554ms\n",
            "7:\tlearn: 1.1508343\ttotal: 102ms\tremaining: 534ms\n",
            "8:\tlearn: 1.1431852\ttotal: 115ms\tremaining: 525ms\n",
            "9:\tlearn: 1.1356983\ttotal: 120ms\tremaining: 479ms\n",
            "10:\tlearn: 1.1284262\ttotal: 132ms\tremaining: 466ms\n",
            "11:\tlearn: 1.1209332\ttotal: 143ms\tremaining: 454ms\n",
            "12:\tlearn: 1.1140996\ttotal: 146ms\tremaining: 414ms\n",
            "13:\tlearn: 1.1076809\ttotal: 157ms\tremaining: 404ms\n",
            "14:\tlearn: 1.1008914\ttotal: 169ms\tremaining: 394ms\n",
            "15:\tlearn: 1.0941250\ttotal: 180ms\tremaining: 384ms\n",
            "16:\tlearn: 1.0875971\ttotal: 192ms\tremaining: 373ms\n",
            "17:\tlearn: 1.0807064\ttotal: 196ms\tremaining: 348ms\n",
            "18:\tlearn: 1.0739572\ttotal: 208ms\tremaining: 339ms\n",
            "19:\tlearn: 1.0671280\ttotal: 210ms\tremaining: 315ms\n",
            "20:\tlearn: 1.0608510\ttotal: 222ms\tremaining: 306ms\n",
            "21:\tlearn: 1.0547433\ttotal: 241ms\tremaining: 307ms\n",
            "22:\tlearn: 1.0483306\ttotal: 257ms\tremaining: 301ms\n",
            "23:\tlearn: 1.0417391\ttotal: 269ms\tremaining: 291ms\n",
            "24:\tlearn: 1.0355068\ttotal: 280ms\tremaining: 280ms\n",
            "25:\tlearn: 1.0295067\ttotal: 282ms\tremaining: 260ms\n",
            "26:\tlearn: 1.0235041\ttotal: 293ms\tremaining: 250ms\n",
            "27:\tlearn: 1.0175766\ttotal: 305ms\tremaining: 239ms\n",
            "28:\tlearn: 1.0115808\ttotal: 306ms\tremaining: 221ms\n",
            "29:\tlearn: 1.0052538\ttotal: 317ms\tremaining: 212ms\n",
            "30:\tlearn: 0.9997931\ttotal: 329ms\tremaining: 201ms\n",
            "31:\tlearn: 0.9942626\ttotal: 340ms\tremaining: 191ms\n",
            "32:\tlearn: 0.9884324\ttotal: 351ms\tremaining: 181ms\n",
            "33:\tlearn: 0.9824015\ttotal: 365ms\tremaining: 172ms\n",
            "34:\tlearn: 0.9763730\ttotal: 377ms\tremaining: 162ms\n",
            "35:\tlearn: 0.9713649\ttotal: 388ms\tremaining: 151ms\n",
            "36:\tlearn: 0.9659058\ttotal: 400ms\tremaining: 140ms\n",
            "37:\tlearn: 0.9605456\ttotal: 411ms\tremaining: 130ms\n",
            "38:\tlearn: 0.9552088\ttotal: 423ms\tremaining: 119ms\n",
            "39:\tlearn: 0.9498589\ttotal: 435ms\tremaining: 109ms\n",
            "40:\tlearn: 0.9444630\ttotal: 455ms\tremaining: 99.9ms\n",
            "41:\tlearn: 0.9391464\ttotal: 460ms\tremaining: 87.5ms\n",
            "42:\tlearn: 0.9346811\ttotal: 471ms\tremaining: 76.7ms\n",
            "43:\tlearn: 0.9296864\ttotal: 483ms\tremaining: 65.9ms\n",
            "44:\tlearn: 0.9243903\ttotal: 496ms\tremaining: 55.1ms\n",
            "45:\tlearn: 0.9190507\ttotal: 498ms\tremaining: 43.3ms\n",
            "46:\tlearn: 0.9141700\ttotal: 510ms\tremaining: 32.6ms\n",
            "47:\tlearn: 0.9089052\ttotal: 522ms\tremaining: 21.8ms\n",
            "48:\tlearn: 0.9034451\ttotal: 524ms\tremaining: 10.7ms\n",
            "49:\tlearn: 0.8982191\ttotal: 540ms\tremaining: 0us\n",
            "0:\tlearn: 1.1157903\ttotal: 11.1ms\tremaining: 546ms\n",
            "1:\tlearn: 1.1088671\ttotal: 22.3ms\tremaining: 535ms\n",
            "2:\tlearn: 1.1018589\ttotal: 33.6ms\tremaining: 526ms\n",
            "3:\tlearn: 1.0958659\ttotal: 44.7ms\tremaining: 514ms\n",
            "4:\tlearn: 1.0893544\ttotal: 55.8ms\tremaining: 502ms\n",
            "5:\tlearn: 1.0828622\ttotal: 67.1ms\tremaining: 492ms\n",
            "6:\tlearn: 1.0758113\ttotal: 78.6ms\tremaining: 483ms\n",
            "7:\tlearn: 1.0691402\ttotal: 97.1ms\tremaining: 510ms\n",
            "8:\tlearn: 1.0626987\ttotal: 109ms\tremaining: 495ms\n",
            "9:\tlearn: 1.0560174\ttotal: 112ms\tremaining: 449ms\n",
            "10:\tlearn: 1.0494602\ttotal: 124ms\tremaining: 439ms\n",
            "11:\tlearn: 1.0428898\ttotal: 135ms\tremaining: 428ms\n",
            "12:\tlearn: 1.0364665\ttotal: 146ms\tremaining: 416ms\n",
            "13:\tlearn: 1.0299360\ttotal: 157ms\tremaining: 405ms\n",
            "14:\tlearn: 1.0236552\ttotal: 169ms\tremaining: 395ms\n",
            "15:\tlearn: 1.0183319\ttotal: 188ms\tremaining: 398ms\n",
            "16:\tlearn: 1.0126044\ttotal: 199ms\tremaining: 386ms\n",
            "17:\tlearn: 1.0063138\ttotal: 210ms\tremaining: 373ms\n",
            "18:\tlearn: 1.0000264\ttotal: 223ms\tremaining: 364ms\n",
            "19:\tlearn: 0.9940488\ttotal: 235ms\tremaining: 352ms\n",
            "20:\tlearn: 0.9883560\ttotal: 246ms\tremaining: 340ms\n",
            "21:\tlearn: 0.9825862\ttotal: 258ms\tremaining: 329ms\n",
            "22:\tlearn: 0.9764602\ttotal: 260ms\tremaining: 306ms\n",
            "23:\tlearn: 0.9711844\ttotal: 272ms\tremaining: 295ms\n",
            "24:\tlearn: 0.9654916\ttotal: 283ms\tremaining: 283ms\n",
            "25:\tlearn: 0.9598448\ttotal: 299ms\tremaining: 276ms\n",
            "26:\tlearn: 0.9543725\ttotal: 317ms\tremaining: 270ms\n",
            "27:\tlearn: 0.9495352\ttotal: 329ms\tremaining: 258ms\n",
            "28:\tlearn: 0.9442455\ttotal: 340ms\tremaining: 246ms\n",
            "29:\tlearn: 0.9386876\ttotal: 351ms\tremaining: 234ms\n",
            "30:\tlearn: 0.9331705\ttotal: 362ms\tremaining: 222ms\n",
            "31:\tlearn: 0.9276568\ttotal: 366ms\tremaining: 206ms\n",
            "32:\tlearn: 0.9223758\ttotal: 378ms\tremaining: 195ms\n",
            "33:\tlearn: 0.9173629\ttotal: 389ms\tremaining: 183ms\n",
            "34:\tlearn: 0.9123076\ttotal: 400ms\tremaining: 172ms\n",
            "35:\tlearn: 0.9072502\ttotal: 411ms\tremaining: 160ms\n",
            "36:\tlearn: 0.9020448\ttotal: 423ms\tremaining: 148ms\n",
            "37:\tlearn: 0.8969284\ttotal: 434ms\tremaining: 137ms\n",
            "38:\tlearn: 0.8921021\ttotal: 445ms\tremaining: 126ms\n",
            "39:\tlearn: 0.8873711\ttotal: 457ms\tremaining: 114ms\n",
            "40:\tlearn: 0.8825455\ttotal: 469ms\tremaining: 103ms\n",
            "41:\tlearn: 0.8776707\ttotal: 480ms\tremaining: 91.5ms\n",
            "42:\tlearn: 0.8723397\ttotal: 483ms\tremaining: 78.6ms\n",
            "43:\tlearn: 0.8674579\ttotal: 495ms\tremaining: 67.4ms\n",
            "44:\tlearn: 0.8629279\ttotal: 513ms\tremaining: 57ms\n",
            "45:\tlearn: 0.8582220\ttotal: 525ms\tremaining: 45.7ms\n",
            "46:\tlearn: 0.8538102\ttotal: 537ms\tremaining: 34.3ms\n",
            "47:\tlearn: 0.8496748\ttotal: 548ms\tremaining: 22.8ms\n",
            "48:\tlearn: 0.8451608\ttotal: 560ms\tremaining: 11.4ms\n",
            "49:\tlearn: 0.8412453\ttotal: 571ms\tremaining: 0us\n",
            "0:\tlearn: 1.1774319\ttotal: 13.3ms\tremaining: 651ms\n",
            "1:\tlearn: 1.1703482\ttotal: 27.2ms\tremaining: 653ms\n",
            "2:\tlearn: 1.1627866\ttotal: 38.6ms\tremaining: 605ms\n",
            "3:\tlearn: 1.1560036\ttotal: 50ms\tremaining: 575ms\n",
            "4:\tlearn: 1.1481986\ttotal: 52.3ms\tremaining: 471ms\n",
            "5:\tlearn: 1.1403085\ttotal: 54.6ms\tremaining: 400ms\n",
            "6:\tlearn: 1.1331323\ttotal: 66.1ms\tremaining: 406ms\n",
            "7:\tlearn: 1.1262101\ttotal: 77.4ms\tremaining: 406ms\n",
            "8:\tlearn: 1.1185204\ttotal: 89ms\tremaining: 405ms\n",
            "9:\tlearn: 1.1108204\ttotal: 100ms\tremaining: 401ms\n",
            "10:\tlearn: 1.1041240\ttotal: 120ms\tremaining: 425ms\n",
            "11:\tlearn: 1.0973536\ttotal: 132ms\tremaining: 417ms\n",
            "12:\tlearn: 1.0904279\ttotal: 143ms\tremaining: 407ms\n",
            "13:\tlearn: 1.0842123\ttotal: 154ms\tremaining: 397ms\n",
            "14:\tlearn: 1.0777204\ttotal: 166ms\tremaining: 388ms\n",
            "15:\tlearn: 1.0708567\ttotal: 177ms\tremaining: 377ms\n",
            "16:\tlearn: 1.0647459\ttotal: 189ms\tremaining: 367ms\n",
            "17:\tlearn: 1.0590216\ttotal: 200ms\tremaining: 356ms\n",
            "18:\tlearn: 1.0528715\ttotal: 212ms\tremaining: 345ms\n",
            "19:\tlearn: 1.0466248\ttotal: 223ms\tremaining: 335ms\n",
            "20:\tlearn: 1.0400454\ttotal: 234ms\tremaining: 324ms\n",
            "21:\tlearn: 1.0342379\ttotal: 245ms\tremaining: 312ms\n",
            "22:\tlearn: 1.0282777\ttotal: 256ms\tremaining: 301ms\n",
            "23:\tlearn: 1.0224542\ttotal: 268ms\tremaining: 290ms\n",
            "24:\tlearn: 1.0163405\ttotal: 279ms\tremaining: 279ms\n",
            "25:\tlearn: 1.0102928\ttotal: 281ms\tremaining: 259ms\n",
            "26:\tlearn: 1.0036245\ttotal: 287ms\tremaining: 245ms\n",
            "27:\tlearn: 0.9975832\ttotal: 298ms\tremaining: 234ms\n",
            "28:\tlearn: 0.9915532\ttotal: 311ms\tremaining: 225ms\n",
            "29:\tlearn: 0.9855358\ttotal: 332ms\tremaining: 221ms\n",
            "30:\tlearn: 0.9794317\ttotal: 348ms\tremaining: 213ms\n",
            "31:\tlearn: 0.9738500\ttotal: 365ms\tremaining: 205ms\n",
            "32:\tlearn: 0.9677584\ttotal: 376ms\tremaining: 194ms\n",
            "33:\tlearn: 0.9623223\ttotal: 389ms\tremaining: 183ms\n",
            "34:\tlearn: 0.9570827\ttotal: 403ms\tremaining: 173ms\n",
            "35:\tlearn: 0.9516152\ttotal: 415ms\tremaining: 161ms\n",
            "36:\tlearn: 0.9463979\ttotal: 427ms\tremaining: 150ms\n",
            "37:\tlearn: 0.9408938\ttotal: 439ms\tremaining: 139ms\n",
            "38:\tlearn: 0.9356794\ttotal: 451ms\tremaining: 127ms\n",
            "39:\tlearn: 0.9306162\ttotal: 463ms\tremaining: 116ms\n",
            "40:\tlearn: 0.9254463\ttotal: 476ms\tremaining: 104ms\n",
            "41:\tlearn: 0.9203234\ttotal: 488ms\tremaining: 92.9ms\n",
            "42:\tlearn: 0.9147621\ttotal: 490ms\tremaining: 79.8ms\n",
            "43:\tlearn: 0.9093809\ttotal: 502ms\tremaining: 68.5ms\n",
            "44:\tlearn: 0.9043040\ttotal: 515ms\tremaining: 57.2ms\n",
            "45:\tlearn: 0.8992571\ttotal: 527ms\tremaining: 45.8ms\n",
            "46:\tlearn: 0.8943397\ttotal: 548ms\tremaining: 35ms\n",
            "47:\tlearn: 0.8899205\ttotal: 567ms\tremaining: 23.6ms\n",
            "48:\tlearn: 0.8849380\ttotal: 579ms\tremaining: 11.8ms\n",
            "49:\tlearn: 0.8803395\ttotal: 593ms\tremaining: 0us\n",
            "0:\tlearn: 1.1550191\ttotal: 12.7ms\tremaining: 624ms\n",
            "1:\tlearn: 1.1206086\ttotal: 25ms\tremaining: 600ms\n",
            "2:\tlearn: 1.0880061\ttotal: 36.7ms\tremaining: 575ms\n",
            "3:\tlearn: 1.0580633\ttotal: 48.3ms\tremaining: 556ms\n",
            "4:\tlearn: 1.0243869\ttotal: 54.5ms\tremaining: 490ms\n",
            "5:\tlearn: 0.9981554\ttotal: 69.6ms\tremaining: 510ms\n",
            "6:\tlearn: 0.9706387\ttotal: 81.8ms\tremaining: 502ms\n",
            "7:\tlearn: 0.9456346\ttotal: 102ms\tremaining: 534ms\n",
            "8:\tlearn: 0.9178827\ttotal: 116ms\tremaining: 529ms\n",
            "9:\tlearn: 0.8909000\ttotal: 118ms\tremaining: 472ms\n",
            "10:\tlearn: 0.8692588\ttotal: 130ms\tremaining: 461ms\n",
            "11:\tlearn: 0.8471166\ttotal: 143ms\tremaining: 452ms\n",
            "12:\tlearn: 0.8251116\ttotal: 155ms\tremaining: 441ms\n",
            "13:\tlearn: 0.8040271\ttotal: 167ms\tremaining: 430ms\n",
            "14:\tlearn: 0.7831308\ttotal: 180ms\tremaining: 419ms\n",
            "15:\tlearn: 0.7645271\ttotal: 192ms\tremaining: 407ms\n",
            "16:\tlearn: 0.7461556\ttotal: 199ms\tremaining: 386ms\n",
            "17:\tlearn: 0.7292132\ttotal: 211ms\tremaining: 376ms\n",
            "18:\tlearn: 0.7140633\ttotal: 223ms\tremaining: 364ms\n",
            "19:\tlearn: 0.6990791\ttotal: 235ms\tremaining: 352ms\n",
            "20:\tlearn: 0.6828905\ttotal: 246ms\tremaining: 340ms\n",
            "21:\tlearn: 0.6682793\ttotal: 258ms\tremaining: 328ms\n",
            "22:\tlearn: 0.6540971\ttotal: 270ms\tremaining: 317ms\n",
            "23:\tlearn: 0.6407347\ttotal: 282ms\tremaining: 306ms\n",
            "24:\tlearn: 0.6285044\ttotal: 294ms\tremaining: 294ms\n",
            "25:\tlearn: 0.6167186\ttotal: 296ms\tremaining: 273ms\n",
            "26:\tlearn: 0.6046553\ttotal: 317ms\tremaining: 270ms\n",
            "27:\tlearn: 0.5946841\ttotal: 330ms\tremaining: 259ms\n",
            "28:\tlearn: 0.5844344\ttotal: 342ms\tremaining: 247ms\n",
            "29:\tlearn: 0.5739206\ttotal: 354ms\tremaining: 236ms\n",
            "30:\tlearn: 0.5642975\ttotal: 365ms\tremaining: 224ms\n",
            "31:\tlearn: 0.5558544\ttotal: 377ms\tremaining: 212ms\n",
            "32:\tlearn: 0.5471242\ttotal: 389ms\tremaining: 200ms\n",
            "33:\tlearn: 0.5402581\ttotal: 390ms\tremaining: 184ms\n",
            "34:\tlearn: 0.5326637\ttotal: 402ms\tremaining: 172ms\n",
            "35:\tlearn: 0.5255528\ttotal: 413ms\tremaining: 161ms\n",
            "36:\tlearn: 0.5191854\ttotal: 425ms\tremaining: 149ms\n",
            "37:\tlearn: 0.5114763\ttotal: 443ms\tremaining: 140ms\n",
            "38:\tlearn: 0.5050472\ttotal: 455ms\tremaining: 128ms\n",
            "39:\tlearn: 0.4997144\ttotal: 458ms\tremaining: 114ms\n",
            "40:\tlearn: 0.4938746\ttotal: 469ms\tremaining: 103ms\n",
            "41:\tlearn: 0.4877619\ttotal: 481ms\tremaining: 91.7ms\n",
            "42:\tlearn: 0.4822682\ttotal: 485ms\tremaining: 79ms\n",
            "43:\tlearn: 0.4765095\ttotal: 491ms\tremaining: 67ms\n",
            "44:\tlearn: 0.4722535\ttotal: 503ms\tremaining: 55.9ms\n",
            "45:\tlearn: 0.4679829\ttotal: 517ms\tremaining: 44.9ms\n",
            "46:\tlearn: 0.4639252\ttotal: 536ms\tremaining: 34.2ms\n",
            "47:\tlearn: 0.4594536\ttotal: 548ms\tremaining: 22.8ms\n",
            "48:\tlearn: 0.4548400\ttotal: 559ms\tremaining: 11.4ms\n",
            "49:\tlearn: 0.4506684\ttotal: 571ms\tremaining: 0us\n",
            "0:\tlearn: 1.1661331\ttotal: 12.8ms\tremaining: 626ms\n",
            "1:\tlearn: 1.1318096\ttotal: 26.1ms\tremaining: 627ms\n",
            "2:\tlearn: 1.0973114\ttotal: 38.3ms\tremaining: 600ms\n",
            "3:\tlearn: 1.0675407\ttotal: 50.1ms\tremaining: 576ms\n",
            "4:\tlearn: 1.0333895\ttotal: 56.3ms\tremaining: 507ms\n",
            "5:\tlearn: 1.0054259\ttotal: 68.1ms\tremaining: 500ms\n",
            "6:\tlearn: 0.9764574\ttotal: 80.7ms\tremaining: 496ms\n",
            "7:\tlearn: 0.9492732\ttotal: 93.1ms\tremaining: 489ms\n",
            "8:\tlearn: 0.9238262\ttotal: 106ms\tremaining: 483ms\n",
            "9:\tlearn: 0.8981307\ttotal: 109ms\tremaining: 436ms\n",
            "10:\tlearn: 0.8745046\ttotal: 130ms\tremaining: 461ms\n",
            "11:\tlearn: 0.8538692\ttotal: 142ms\tremaining: 450ms\n",
            "12:\tlearn: 0.8295349\ttotal: 153ms\tremaining: 437ms\n",
            "13:\tlearn: 0.8100101\ttotal: 165ms\tremaining: 424ms\n",
            "14:\tlearn: 0.7902337\ttotal: 180ms\tremaining: 421ms\n",
            "15:\tlearn: 0.7698226\ttotal: 192ms\tremaining: 409ms\n",
            "16:\tlearn: 0.7509742\ttotal: 199ms\tremaining: 386ms\n",
            "17:\tlearn: 0.7344584\ttotal: 211ms\tremaining: 374ms\n",
            "18:\tlearn: 0.7175734\ttotal: 222ms\tremaining: 363ms\n",
            "19:\tlearn: 0.7033115\ttotal: 234ms\tremaining: 351ms\n",
            "20:\tlearn: 0.6859803\ttotal: 245ms\tremaining: 339ms\n",
            "21:\tlearn: 0.6709841\ttotal: 257ms\tremaining: 327ms\n",
            "22:\tlearn: 0.6561659\ttotal: 269ms\tremaining: 316ms\n",
            "23:\tlearn: 0.6430126\ttotal: 281ms\tremaining: 304ms\n",
            "24:\tlearn: 0.6310995\ttotal: 293ms\tremaining: 293ms\n",
            "25:\tlearn: 0.6192651\ttotal: 297ms\tremaining: 274ms\n",
            "26:\tlearn: 0.6081081\ttotal: 317ms\tremaining: 270ms\n",
            "27:\tlearn: 0.5973351\ttotal: 332ms\tremaining: 261ms\n",
            "28:\tlearn: 0.5866098\ttotal: 344ms\tremaining: 249ms\n",
            "29:\tlearn: 0.5772000\ttotal: 355ms\tremaining: 237ms\n",
            "30:\tlearn: 0.5676277\ttotal: 356ms\tremaining: 218ms\n",
            "31:\tlearn: 0.5584169\ttotal: 362ms\tremaining: 204ms\n",
            "32:\tlearn: 0.5484550\ttotal: 374ms\tremaining: 192ms\n",
            "33:\tlearn: 0.5401663\ttotal: 395ms\tremaining: 186ms\n",
            "34:\tlearn: 0.5333635\ttotal: 411ms\tremaining: 176ms\n",
            "35:\tlearn: 0.5260235\ttotal: 431ms\tremaining: 168ms\n",
            "36:\tlearn: 0.5199657\ttotal: 443ms\tremaining: 156ms\n",
            "37:\tlearn: 0.5125223\ttotal: 455ms\tremaining: 144ms\n",
            "38:\tlearn: 0.5051006\ttotal: 467ms\tremaining: 132ms\n",
            "39:\tlearn: 0.4989851\ttotal: 479ms\tremaining: 120ms\n",
            "40:\tlearn: 0.4924010\ttotal: 490ms\tremaining: 107ms\n",
            "41:\tlearn: 0.4861881\ttotal: 501ms\tremaining: 95.4ms\n",
            "42:\tlearn: 0.4820043\ttotal: 503ms\tremaining: 81.9ms\n",
            "43:\tlearn: 0.4761741\ttotal: 522ms\tremaining: 71.2ms\n",
            "44:\tlearn: 0.4711851\ttotal: 538ms\tremaining: 59.8ms\n",
            "45:\tlearn: 0.4660390\ttotal: 551ms\tremaining: 47.9ms\n",
            "46:\tlearn: 0.4608409\ttotal: 565ms\tremaining: 36.1ms\n",
            "47:\tlearn: 0.4561193\ttotal: 577ms\tremaining: 24ms\n",
            "48:\tlearn: 0.4511809\ttotal: 589ms\tremaining: 12ms\n",
            "49:\tlearn: 0.4464294\ttotal: 600ms\tremaining: 0us\n",
            "0:\tlearn: 1.1732308\ttotal: 11.7ms\tremaining: 573ms\n",
            "1:\tlearn: 1.1363514\ttotal: 23.6ms\tremaining: 567ms\n",
            "2:\tlearn: 1.0988508\ttotal: 35.4ms\tremaining: 555ms\n",
            "3:\tlearn: 1.0682952\ttotal: 46.9ms\tremaining: 539ms\n",
            "4:\tlearn: 1.0369489\ttotal: 58.6ms\tremaining: 527ms\n",
            "5:\tlearn: 1.0066190\ttotal: 70.3ms\tremaining: 515ms\n",
            "6:\tlearn: 0.9777206\ttotal: 81.8ms\tremaining: 503ms\n",
            "7:\tlearn: 0.9489114\ttotal: 101ms\tremaining: 530ms\n",
            "8:\tlearn: 0.9211139\ttotal: 112ms\tremaining: 511ms\n",
            "9:\tlearn: 0.8936276\ttotal: 116ms\tremaining: 463ms\n",
            "10:\tlearn: 0.8690029\ttotal: 127ms\tremaining: 452ms\n",
            "11:\tlearn: 0.8451580\ttotal: 139ms\tremaining: 441ms\n",
            "12:\tlearn: 0.8225518\ttotal: 151ms\tremaining: 429ms\n",
            "13:\tlearn: 0.8017962\ttotal: 162ms\tremaining: 418ms\n",
            "14:\tlearn: 0.7799529\ttotal: 169ms\tremaining: 394ms\n",
            "15:\tlearn: 0.7631187\ttotal: 181ms\tremaining: 384ms\n",
            "16:\tlearn: 0.7448100\ttotal: 192ms\tremaining: 373ms\n",
            "17:\tlearn: 0.7283063\ttotal: 194ms\tremaining: 344ms\n",
            "18:\tlearn: 0.7110279\ttotal: 209ms\tremaining: 341ms\n",
            "19:\tlearn: 0.6956466\ttotal: 212ms\tremaining: 317ms\n",
            "20:\tlearn: 0.6812351\ttotal: 225ms\tremaining: 311ms\n",
            "21:\tlearn: 0.6671435\ttotal: 226ms\tremaining: 288ms\n",
            "22:\tlearn: 0.6542583\ttotal: 242ms\tremaining: 285ms\n",
            "23:\tlearn: 0.6412960\ttotal: 254ms\tremaining: 275ms\n",
            "24:\tlearn: 0.6290119\ttotal: 265ms\tremaining: 265ms\n",
            "25:\tlearn: 0.6173102\ttotal: 277ms\tremaining: 256ms\n",
            "26:\tlearn: 0.6056841\ttotal: 290ms\tremaining: 247ms\n",
            "27:\tlearn: 0.5962667\ttotal: 292ms\tremaining: 230ms\n",
            "28:\tlearn: 0.5857311\ttotal: 313ms\tremaining: 226ms\n",
            "29:\tlearn: 0.5757804\ttotal: 315ms\tremaining: 210ms\n",
            "30:\tlearn: 0.5662900\ttotal: 327ms\tremaining: 200ms\n",
            "31:\tlearn: 0.5566301\ttotal: 339ms\tremaining: 190ms\n",
            "32:\tlearn: 0.5479878\ttotal: 350ms\tremaining: 180ms\n",
            "33:\tlearn: 0.5394510\ttotal: 362ms\tremaining: 170ms\n",
            "34:\tlearn: 0.5317815\ttotal: 374ms\tremaining: 160ms\n",
            "35:\tlearn: 0.5241555\ttotal: 386ms\tremaining: 150ms\n",
            "36:\tlearn: 0.5168023\ttotal: 398ms\tremaining: 140ms\n",
            "37:\tlearn: 0.5099558\ttotal: 409ms\tremaining: 129ms\n",
            "38:\tlearn: 0.5034794\ttotal: 421ms\tremaining: 119ms\n",
            "39:\tlearn: 0.4971271\ttotal: 433ms\tremaining: 108ms\n",
            "40:\tlearn: 0.4917808\ttotal: 444ms\tremaining: 97.6ms\n",
            "41:\tlearn: 0.4862985\ttotal: 456ms\tremaining: 86.9ms\n",
            "42:\tlearn: 0.4819912\ttotal: 458ms\tremaining: 74.5ms\n",
            "43:\tlearn: 0.4764327\ttotal: 470ms\tremaining: 64ms\n",
            "44:\tlearn: 0.4721467\ttotal: 471ms\tremaining: 52.3ms\n",
            "45:\tlearn: 0.4675097\ttotal: 483ms\tremaining: 42ms\n",
            "46:\tlearn: 0.4636195\ttotal: 486ms\tremaining: 31ms\n",
            "47:\tlearn: 0.4590744\ttotal: 499ms\tremaining: 20.8ms\n",
            "48:\tlearn: 0.4547267\ttotal: 514ms\tremaining: 10.5ms\n",
            "49:\tlearn: 0.4502971\ttotal: 535ms\tremaining: 0us\n",
            "0:\tlearn: 1.0888842\ttotal: 12.6ms\tremaining: 618ms\n",
            "1:\tlearn: 1.0555332\ttotal: 25.3ms\tremaining: 607ms\n",
            "2:\tlearn: 1.0229894\ttotal: 37.6ms\tremaining: 590ms\n",
            "3:\tlearn: 0.9961431\ttotal: 50.1ms\tremaining: 576ms\n",
            "4:\tlearn: 0.9654376\ttotal: 56.7ms\tremaining: 511ms\n",
            "5:\tlearn: 0.9383076\ttotal: 69.8ms\tremaining: 512ms\n",
            "6:\tlearn: 0.9122336\ttotal: 82.5ms\tremaining: 507ms\n",
            "7:\tlearn: 0.8883516\ttotal: 108ms\tremaining: 565ms\n",
            "8:\tlearn: 0.8627718\ttotal: 123ms\tremaining: 558ms\n",
            "9:\tlearn: 0.8390155\ttotal: 129ms\tremaining: 517ms\n",
            "10:\tlearn: 0.8167164\ttotal: 141ms\tremaining: 501ms\n",
            "11:\tlearn: 0.7944083\ttotal: 163ms\tremaining: 515ms\n",
            "12:\tlearn: 0.7736219\ttotal: 176ms\tremaining: 501ms\n",
            "13:\tlearn: 0.7541395\ttotal: 188ms\tremaining: 485ms\n",
            "14:\tlearn: 0.7365763\ttotal: 195ms\tremaining: 455ms\n",
            "15:\tlearn: 0.7208330\ttotal: 207ms\tremaining: 441ms\n",
            "16:\tlearn: 0.7052673\ttotal: 220ms\tremaining: 427ms\n",
            "17:\tlearn: 0.6885323\ttotal: 233ms\tremaining: 414ms\n",
            "18:\tlearn: 0.6729544\ttotal: 245ms\tremaining: 400ms\n",
            "19:\tlearn: 0.6580666\ttotal: 257ms\tremaining: 385ms\n",
            "20:\tlearn: 0.6444465\ttotal: 269ms\tremaining: 371ms\n",
            "21:\tlearn: 0.6310561\ttotal: 281ms\tremaining: 358ms\n",
            "22:\tlearn: 0.6178219\ttotal: 294ms\tremaining: 345ms\n",
            "23:\tlearn: 0.6055862\ttotal: 308ms\tremaining: 334ms\n",
            "24:\tlearn: 0.5946469\ttotal: 315ms\tremaining: 315ms\n",
            "25:\tlearn: 0.5846114\ttotal: 327ms\tremaining: 302ms\n",
            "26:\tlearn: 0.5755183\ttotal: 340ms\tremaining: 290ms\n",
            "27:\tlearn: 0.5666772\ttotal: 352ms\tremaining: 277ms\n",
            "28:\tlearn: 0.5568225\ttotal: 375ms\tremaining: 272ms\n",
            "29:\tlearn: 0.5482042\ttotal: 379ms\tremaining: 253ms\n",
            "30:\tlearn: 0.5395614\ttotal: 394ms\tremaining: 242ms\n",
            "31:\tlearn: 0.5312850\ttotal: 407ms\tremaining: 229ms\n",
            "32:\tlearn: 0.5240757\ttotal: 420ms\tremaining: 216ms\n",
            "33:\tlearn: 0.5176245\ttotal: 432ms\tremaining: 203ms\n",
            "34:\tlearn: 0.5109213\ttotal: 444ms\tremaining: 190ms\n",
            "35:\tlearn: 0.5041191\ttotal: 456ms\tremaining: 177ms\n",
            "36:\tlearn: 0.4974223\ttotal: 468ms\tremaining: 165ms\n",
            "37:\tlearn: 0.4912875\ttotal: 481ms\tremaining: 152ms\n",
            "38:\tlearn: 0.4859505\ttotal: 493ms\tremaining: 139ms\n",
            "39:\tlearn: 0.4810181\ttotal: 505ms\tremaining: 126ms\n",
            "40:\tlearn: 0.4760778\ttotal: 509ms\tremaining: 112ms\n",
            "41:\tlearn: 0.4701744\ttotal: 521ms\tremaining: 99.3ms\n",
            "42:\tlearn: 0.4655024\ttotal: 534ms\tremaining: 86.9ms\n",
            "43:\tlearn: 0.4602171\ttotal: 547ms\tremaining: 74.6ms\n",
            "44:\tlearn: 0.4560809\ttotal: 561ms\tremaining: 62.3ms\n",
            "45:\tlearn: 0.4515724\ttotal: 568ms\tremaining: 49.4ms\n",
            "46:\tlearn: 0.4477672\ttotal: 590ms\tremaining: 37.6ms\n",
            "47:\tlearn: 0.4440367\ttotal: 593ms\tremaining: 24.7ms\n",
            "48:\tlearn: 0.4400263\ttotal: 606ms\tremaining: 12.4ms\n",
            "49:\tlearn: 0.4365134\ttotal: 618ms\tremaining: 0us\n",
            "0:\tlearn: 1.1478826\ttotal: 12.5ms\tremaining: 611ms\n",
            "1:\tlearn: 1.1127509\ttotal: 24.3ms\tremaining: 582ms\n",
            "2:\tlearn: 1.0792044\ttotal: 35.9ms\tremaining: 562ms\n",
            "3:\tlearn: 1.0487522\ttotal: 47.8ms\tremaining: 550ms\n",
            "4:\tlearn: 1.0158845\ttotal: 49.9ms\tremaining: 449ms\n",
            "5:\tlearn: 0.9860428\ttotal: 61.3ms\tremaining: 449ms\n",
            "6:\tlearn: 0.9574755\ttotal: 73ms\tremaining: 448ms\n",
            "7:\tlearn: 0.9299491\ttotal: 85.2ms\tremaining: 447ms\n",
            "8:\tlearn: 0.9038732\ttotal: 97.7ms\tremaining: 445ms\n",
            "9:\tlearn: 0.8775382\ttotal: 99.1ms\tremaining: 396ms\n",
            "10:\tlearn: 0.8521467\ttotal: 113ms\tremaining: 399ms\n",
            "11:\tlearn: 0.8290482\ttotal: 115ms\tremaining: 364ms\n",
            "12:\tlearn: 0.8074516\ttotal: 127ms\tremaining: 362ms\n",
            "13:\tlearn: 0.7859029\ttotal: 135ms\tremaining: 347ms\n",
            "14:\tlearn: 0.7677132\ttotal: 152ms\tremaining: 354ms\n",
            "15:\tlearn: 0.7493566\ttotal: 164ms\tremaining: 348ms\n",
            "16:\tlearn: 0.7328343\ttotal: 177ms\tremaining: 343ms\n",
            "17:\tlearn: 0.7162965\ttotal: 188ms\tremaining: 335ms\n",
            "18:\tlearn: 0.6991579\ttotal: 200ms\tremaining: 327ms\n",
            "19:\tlearn: 0.6846931\ttotal: 214ms\tremaining: 322ms\n",
            "20:\tlearn: 0.6693093\ttotal: 217ms\tremaining: 300ms\n",
            "21:\tlearn: 0.6557481\ttotal: 230ms\tremaining: 292ms\n",
            "22:\tlearn: 0.6412132\ttotal: 242ms\tremaining: 284ms\n",
            "23:\tlearn: 0.6277871\ttotal: 255ms\tremaining: 277ms\n",
            "24:\tlearn: 0.6161135\ttotal: 268ms\tremaining: 268ms\n",
            "25:\tlearn: 0.6056290\ttotal: 280ms\tremaining: 258ms\n",
            "26:\tlearn: 0.5948910\ttotal: 291ms\tremaining: 248ms\n",
            "27:\tlearn: 0.5845726\ttotal: 309ms\tremaining: 242ms\n",
            "28:\tlearn: 0.5750095\ttotal: 320ms\tremaining: 231ms\n",
            "29:\tlearn: 0.5652776\ttotal: 334ms\tremaining: 223ms\n",
            "30:\tlearn: 0.5553920\ttotal: 350ms\tremaining: 215ms\n",
            "31:\tlearn: 0.5468465\ttotal: 362ms\tremaining: 204ms\n",
            "32:\tlearn: 0.5385676\ttotal: 374ms\tremaining: 192ms\n",
            "33:\tlearn: 0.5302411\ttotal: 385ms\tremaining: 181ms\n",
            "34:\tlearn: 0.5228218\ttotal: 398ms\tremaining: 171ms\n",
            "35:\tlearn: 0.5162832\ttotal: 410ms\tremaining: 159ms\n",
            "36:\tlearn: 0.5085813\ttotal: 416ms\tremaining: 146ms\n",
            "37:\tlearn: 0.5001470\ttotal: 430ms\tremaining: 136ms\n",
            "38:\tlearn: 0.4939664\ttotal: 445ms\tremaining: 126ms\n",
            "39:\tlearn: 0.4871048\ttotal: 459ms\tremaining: 115ms\n",
            "40:\tlearn: 0.4815688\ttotal: 471ms\tremaining: 103ms\n",
            "41:\tlearn: 0.4761394\ttotal: 483ms\tremaining: 92ms\n",
            "42:\tlearn: 0.4711783\ttotal: 487ms\tremaining: 79.3ms\n",
            "43:\tlearn: 0.4663253\ttotal: 498ms\tremaining: 67.9ms\n",
            "44:\tlearn: 0.4611090\ttotal: 510ms\tremaining: 56.6ms\n",
            "45:\tlearn: 0.4557821\ttotal: 521ms\tremaining: 45.3ms\n",
            "46:\tlearn: 0.4512934\ttotal: 525ms\tremaining: 33.5ms\n",
            "47:\tlearn: 0.4463368\ttotal: 544ms\tremaining: 22.7ms\n",
            "48:\tlearn: 0.4416529\ttotal: 556ms\tremaining: 11.4ms\n",
            "49:\tlearn: 0.4377599\ttotal: 568ms\tremaining: 0us\n",
            "0:\tlearn: 1.1222901\ttotal: 11.2ms\tremaining: 549ms\n",
            "1:\tlearn: 1.0556293\ttotal: 22.1ms\tremaining: 530ms\n",
            "2:\tlearn: 0.9938204\ttotal: 37ms\tremaining: 579ms\n",
            "3:\tlearn: 0.9418970\ttotal: 48.6ms\tremaining: 559ms\n",
            "4:\tlearn: 0.8882246\ttotal: 50.6ms\tremaining: 455ms\n",
            "5:\tlearn: 0.8374233\ttotal: 52.8ms\tremaining: 387ms\n",
            "6:\tlearn: 0.7954464\ttotal: 64.2ms\tremaining: 395ms\n",
            "7:\tlearn: 0.7584911\ttotal: 75.5ms\tremaining: 396ms\n",
            "8:\tlearn: 0.7223788\ttotal: 87.1ms\tremaining: 397ms\n",
            "9:\tlearn: 0.6888904\ttotal: 98.5ms\tremaining: 394ms\n",
            "10:\tlearn: 0.6619785\ttotal: 111ms\tremaining: 392ms\n",
            "11:\tlearn: 0.6383678\ttotal: 122ms\tremaining: 387ms\n",
            "12:\tlearn: 0.6130988\ttotal: 133ms\tremaining: 380ms\n",
            "13:\tlearn: 0.5929996\ttotal: 152ms\tremaining: 392ms\n",
            "14:\tlearn: 0.5745404\ttotal: 164ms\tremaining: 383ms\n",
            "15:\tlearn: 0.5575266\ttotal: 176ms\tremaining: 374ms\n",
            "16:\tlearn: 0.5405637\ttotal: 188ms\tremaining: 364ms\n",
            "17:\tlearn: 0.5255076\ttotal: 199ms\tremaining: 354ms\n",
            "18:\tlearn: 0.5128573\ttotal: 210ms\tremaining: 343ms\n",
            "19:\tlearn: 0.4974932\ttotal: 222ms\tremaining: 333ms\n",
            "20:\tlearn: 0.4850916\ttotal: 233ms\tremaining: 322ms\n",
            "21:\tlearn: 0.4729518\ttotal: 245ms\tremaining: 312ms\n",
            "22:\tlearn: 0.4606799\ttotal: 256ms\tremaining: 301ms\n",
            "23:\tlearn: 0.4527266\ttotal: 268ms\tremaining: 290ms\n",
            "24:\tlearn: 0.4439238\ttotal: 279ms\tremaining: 279ms\n",
            "25:\tlearn: 0.4356466\ttotal: 291ms\tremaining: 268ms\n",
            "26:\tlearn: 0.4303323\ttotal: 293ms\tremaining: 250ms\n",
            "27:\tlearn: 0.4238449\ttotal: 305ms\tremaining: 239ms\n",
            "28:\tlearn: 0.4183272\ttotal: 307ms\tremaining: 222ms\n",
            "29:\tlearn: 0.4115548\ttotal: 318ms\tremaining: 212ms\n",
            "30:\tlearn: 0.4051441\ttotal: 330ms\tremaining: 202ms\n",
            "31:\tlearn: 0.4003581\ttotal: 341ms\tremaining: 192ms\n",
            "32:\tlearn: 0.3941713\ttotal: 363ms\tremaining: 187ms\n",
            "33:\tlearn: 0.3885056\ttotal: 376ms\tremaining: 177ms\n",
            "34:\tlearn: 0.3840441\ttotal: 388ms\tremaining: 166ms\n",
            "35:\tlearn: 0.3797245\ttotal: 399ms\tremaining: 155ms\n",
            "36:\tlearn: 0.3750371\ttotal: 410ms\tremaining: 144ms\n",
            "37:\tlearn: 0.3717678\ttotal: 422ms\tremaining: 133ms\n",
            "38:\tlearn: 0.3680942\ttotal: 433ms\tremaining: 122ms\n",
            "39:\tlearn: 0.3653413\ttotal: 446ms\tremaining: 112ms\n",
            "40:\tlearn: 0.3620750\ttotal: 457ms\tremaining: 100ms\n",
            "41:\tlearn: 0.3591384\ttotal: 468ms\tremaining: 89.2ms\n",
            "42:\tlearn: 0.3559487\ttotal: 480ms\tremaining: 78.1ms\n",
            "43:\tlearn: 0.3528250\ttotal: 491ms\tremaining: 66.9ms\n",
            "44:\tlearn: 0.3518905\ttotal: 492ms\tremaining: 54.6ms\n",
            "45:\tlearn: 0.3482961\ttotal: 503ms\tremaining: 43.7ms\n",
            "46:\tlearn: 0.3455074\ttotal: 514ms\tremaining: 32.8ms\n",
            "47:\tlearn: 0.3419876\ttotal: 525ms\tremaining: 21.9ms\n",
            "48:\tlearn: 0.3398087\ttotal: 535ms\tremaining: 10.9ms\n",
            "49:\tlearn: 0.3362310\ttotal: 547ms\tremaining: 0us\n",
            "0:\tlearn: 1.1306657\ttotal: 11.4ms\tremaining: 557ms\n",
            "1:\tlearn: 1.0634231\ttotal: 23.1ms\tremaining: 554ms\n",
            "2:\tlearn: 1.0011841\ttotal: 34.5ms\tremaining: 541ms\n",
            "3:\tlearn: 0.9430721\ttotal: 45.8ms\tremaining: 527ms\n",
            "4:\tlearn: 0.8874037\ttotal: 52.1ms\tremaining: 469ms\n",
            "5:\tlearn: 0.8439407\ttotal: 63.6ms\tremaining: 467ms\n",
            "6:\tlearn: 0.8015813\ttotal: 77.2ms\tremaining: 474ms\n",
            "7:\tlearn: 0.7654209\ttotal: 88.7ms\tremaining: 466ms\n",
            "8:\tlearn: 0.7284290\ttotal: 99.9ms\tremaining: 455ms\n",
            "9:\tlearn: 0.6966199\ttotal: 101ms\tremaining: 405ms\n",
            "10:\tlearn: 0.6680427\ttotal: 112ms\tremaining: 397ms\n",
            "11:\tlearn: 0.6437389\ttotal: 123ms\tremaining: 390ms\n",
            "12:\tlearn: 0.6164233\ttotal: 135ms\tremaining: 383ms\n",
            "13:\tlearn: 0.5962139\ttotal: 146ms\tremaining: 376ms\n",
            "14:\tlearn: 0.5751864\ttotal: 159ms\tremaining: 370ms\n",
            "15:\tlearn: 0.5559910\ttotal: 170ms\tremaining: 362ms\n",
            "16:\tlearn: 0.5387270\ttotal: 177ms\tremaining: 343ms\n",
            "17:\tlearn: 0.5243731\ttotal: 190ms\tremaining: 338ms\n",
            "18:\tlearn: 0.5101154\ttotal: 202ms\tremaining: 329ms\n",
            "19:\tlearn: 0.4972322\ttotal: 223ms\tremaining: 335ms\n",
            "20:\tlearn: 0.4849641\ttotal: 238ms\tremaining: 328ms\n",
            "21:\tlearn: 0.4741710\ttotal: 257ms\tremaining: 327ms\n",
            "22:\tlearn: 0.4619723\ttotal: 269ms\tremaining: 315ms\n",
            "23:\tlearn: 0.4542843\ttotal: 280ms\tremaining: 304ms\n",
            "24:\tlearn: 0.4450756\ttotal: 292ms\tremaining: 292ms\n",
            "25:\tlearn: 0.4390553\ttotal: 293ms\tremaining: 271ms\n",
            "26:\tlearn: 0.4311542\ttotal: 300ms\tremaining: 255ms\n",
            "27:\tlearn: 0.4241122\ttotal: 312ms\tremaining: 245ms\n",
            "28:\tlearn: 0.4171327\ttotal: 323ms\tremaining: 234ms\n",
            "29:\tlearn: 0.4118332\ttotal: 335ms\tremaining: 223ms\n",
            "30:\tlearn: 0.4051332\ttotal: 347ms\tremaining: 213ms\n",
            "31:\tlearn: 0.4000486\ttotal: 359ms\tremaining: 202ms\n",
            "32:\tlearn: 0.3941195\ttotal: 373ms\tremaining: 192ms\n",
            "33:\tlearn: 0.3890015\ttotal: 384ms\tremaining: 181ms\n",
            "34:\tlearn: 0.3848390\ttotal: 396ms\tremaining: 170ms\n",
            "35:\tlearn: 0.3810413\ttotal: 411ms\tremaining: 160ms\n",
            "36:\tlearn: 0.3759436\ttotal: 427ms\tremaining: 150ms\n",
            "37:\tlearn: 0.3700386\ttotal: 442ms\tremaining: 140ms\n",
            "38:\tlearn: 0.3656078\ttotal: 453ms\tremaining: 128ms\n",
            "39:\tlearn: 0.3607760\ttotal: 464ms\tremaining: 116ms\n",
            "40:\tlearn: 0.3571451\ttotal: 476ms\tremaining: 104ms\n",
            "41:\tlearn: 0.3539849\ttotal: 487ms\tremaining: 92.8ms\n",
            "42:\tlearn: 0.3519074\ttotal: 491ms\tremaining: 80ms\n",
            "43:\tlearn: 0.3488443\ttotal: 503ms\tremaining: 68.6ms\n",
            "44:\tlearn: 0.3458731\ttotal: 514ms\tremaining: 57.2ms\n",
            "45:\tlearn: 0.3422500\ttotal: 526ms\tremaining: 45.7ms\n",
            "46:\tlearn: 0.3393149\ttotal: 538ms\tremaining: 34.3ms\n",
            "47:\tlearn: 0.3364049\ttotal: 550ms\tremaining: 22.9ms\n",
            "48:\tlearn: 0.3320760\ttotal: 561ms\tremaining: 11.5ms\n",
            "49:\tlearn: 0.3283040\ttotal: 572ms\tremaining: 0us\n",
            "0:\tlearn: 1.1369578\ttotal: 11.6ms\tremaining: 569ms\n",
            "1:\tlearn: 1.0666705\ttotal: 30.3ms\tremaining: 726ms\n",
            "2:\tlearn: 1.0014770\ttotal: 42.8ms\tremaining: 671ms\n",
            "3:\tlearn: 0.9433036\ttotal: 54ms\tremaining: 621ms\n",
            "4:\tlearn: 0.8895453\ttotal: 56.2ms\tremaining: 506ms\n",
            "5:\tlearn: 0.8394172\ttotal: 58.2ms\tremaining: 427ms\n",
            "6:\tlearn: 0.7982341\ttotal: 69.6ms\tremaining: 427ms\n",
            "7:\tlearn: 0.7576997\ttotal: 81.4ms\tremaining: 427ms\n",
            "8:\tlearn: 0.7211154\ttotal: 93.5ms\tremaining: 426ms\n",
            "9:\tlearn: 0.6915006\ttotal: 108ms\tremaining: 432ms\n",
            "10:\tlearn: 0.6625632\ttotal: 121ms\tremaining: 429ms\n",
            "11:\tlearn: 0.6362412\ttotal: 135ms\tremaining: 429ms\n",
            "12:\tlearn: 0.6102676\ttotal: 147ms\tremaining: 418ms\n",
            "13:\tlearn: 0.5892198\ttotal: 159ms\tremaining: 408ms\n",
            "14:\tlearn: 0.5707759\ttotal: 171ms\tremaining: 398ms\n",
            "15:\tlearn: 0.5521317\ttotal: 183ms\tremaining: 389ms\n",
            "16:\tlearn: 0.5359905\ttotal: 195ms\tremaining: 378ms\n",
            "17:\tlearn: 0.5209339\ttotal: 206ms\tremaining: 367ms\n",
            "18:\tlearn: 0.5073364\ttotal: 218ms\tremaining: 355ms\n",
            "19:\tlearn: 0.4937301\ttotal: 234ms\tremaining: 350ms\n",
            "20:\tlearn: 0.4823022\ttotal: 251ms\tremaining: 346ms\n",
            "21:\tlearn: 0.4712486\ttotal: 263ms\tremaining: 335ms\n",
            "22:\tlearn: 0.4612824\ttotal: 275ms\tremaining: 323ms\n",
            "23:\tlearn: 0.4540688\ttotal: 287ms\tremaining: 310ms\n",
            "24:\tlearn: 0.4449425\ttotal: 299ms\tremaining: 299ms\n",
            "25:\tlearn: 0.4397200\ttotal: 300ms\tremaining: 277ms\n",
            "26:\tlearn: 0.4317844\ttotal: 311ms\tremaining: 265ms\n",
            "27:\tlearn: 0.4244570\ttotal: 323ms\tremaining: 254ms\n",
            "28:\tlearn: 0.4178800\ttotal: 335ms\tremaining: 242ms\n",
            "29:\tlearn: 0.4115021\ttotal: 346ms\tremaining: 231ms\n",
            "30:\tlearn: 0.4051664\ttotal: 359ms\tremaining: 220ms\n",
            "31:\tlearn: 0.3999228\ttotal: 370ms\tremaining: 208ms\n",
            "32:\tlearn: 0.3934611\ttotal: 382ms\tremaining: 197ms\n",
            "33:\tlearn: 0.3883342\ttotal: 394ms\tremaining: 185ms\n",
            "34:\tlearn: 0.3830465\ttotal: 406ms\tremaining: 174ms\n",
            "35:\tlearn: 0.3777380\ttotal: 417ms\tremaining: 162ms\n",
            "36:\tlearn: 0.3733301\ttotal: 429ms\tremaining: 151ms\n",
            "37:\tlearn: 0.3691757\ttotal: 451ms\tremaining: 142ms\n",
            "38:\tlearn: 0.3652478\ttotal: 464ms\tremaining: 131ms\n",
            "39:\tlearn: 0.3609088\ttotal: 476ms\tremaining: 119ms\n",
            "40:\tlearn: 0.3581290\ttotal: 479ms\tremaining: 105ms\n",
            "41:\tlearn: 0.3549071\ttotal: 490ms\tremaining: 93.4ms\n",
            "42:\tlearn: 0.3528788\ttotal: 492ms\tremaining: 80.2ms\n",
            "43:\tlearn: 0.3505263\ttotal: 504ms\tremaining: 68.7ms\n",
            "44:\tlearn: 0.3472258\ttotal: 515ms\tremaining: 57.2ms\n",
            "45:\tlearn: 0.3445261\ttotal: 527ms\tremaining: 45.8ms\n",
            "46:\tlearn: 0.3411920\ttotal: 538ms\tremaining: 34.4ms\n",
            "47:\tlearn: 0.3385516\ttotal: 552ms\tremaining: 23ms\n",
            "48:\tlearn: 0.3359401\ttotal: 564ms\tremaining: 11.5ms\n",
            "49:\tlearn: 0.3337312\ttotal: 576ms\tremaining: 0us\n",
            "0:\tlearn: 1.0556000\ttotal: 14.4ms\tremaining: 705ms\n",
            "1:\tlearn: 0.9921731\ttotal: 33ms\tremaining: 793ms\n",
            "2:\tlearn: 0.9318544\ttotal: 52.3ms\tremaining: 819ms\n",
            "3:\tlearn: 0.8855854\ttotal: 63.6ms\tremaining: 732ms\n",
            "4:\tlearn: 0.8344041\ttotal: 69.7ms\tremaining: 628ms\n",
            "5:\tlearn: 0.7921200\ttotal: 80.9ms\tremaining: 593ms\n",
            "6:\tlearn: 0.7530690\ttotal: 92.2ms\tremaining: 567ms\n",
            "7:\tlearn: 0.7215615\ttotal: 103ms\tremaining: 542ms\n",
            "8:\tlearn: 0.6869308\ttotal: 114ms\tremaining: 521ms\n",
            "9:\tlearn: 0.6565393\ttotal: 120ms\tremaining: 481ms\n",
            "10:\tlearn: 0.6296639\ttotal: 131ms\tremaining: 466ms\n",
            "11:\tlearn: 0.6038882\ttotal: 143ms\tremaining: 452ms\n",
            "12:\tlearn: 0.5817260\ttotal: 154ms\tremaining: 438ms\n",
            "13:\tlearn: 0.5623047\ttotal: 167ms\tremaining: 430ms\n",
            "14:\tlearn: 0.5437806\ttotal: 175ms\tremaining: 408ms\n",
            "15:\tlearn: 0.5276394\ttotal: 187ms\tremaining: 398ms\n",
            "16:\tlearn: 0.5137419\ttotal: 199ms\tremaining: 386ms\n",
            "17:\tlearn: 0.5001549\ttotal: 211ms\tremaining: 375ms\n",
            "18:\tlearn: 0.4873154\ttotal: 222ms\tremaining: 362ms\n",
            "19:\tlearn: 0.4744581\ttotal: 233ms\tremaining: 350ms\n",
            "20:\tlearn: 0.4635919\ttotal: 245ms\tremaining: 338ms\n",
            "21:\tlearn: 0.4549762\ttotal: 263ms\tremaining: 335ms\n",
            "22:\tlearn: 0.4457579\ttotal: 275ms\tremaining: 322ms\n",
            "23:\tlearn: 0.4377799\ttotal: 286ms\tremaining: 310ms\n",
            "24:\tlearn: 0.4307393\ttotal: 301ms\tremaining: 301ms\n",
            "25:\tlearn: 0.4237205\ttotal: 313ms\tremaining: 289ms\n",
            "26:\tlearn: 0.4163492\ttotal: 324ms\tremaining: 276ms\n",
            "27:\tlearn: 0.4108825\ttotal: 335ms\tremaining: 264ms\n",
            "28:\tlearn: 0.4035620\ttotal: 347ms\tremaining: 251ms\n",
            "29:\tlearn: 0.3964455\ttotal: 358ms\tremaining: 239ms\n",
            "30:\tlearn: 0.3912355\ttotal: 370ms\tremaining: 227ms\n",
            "31:\tlearn: 0.3867979\ttotal: 381ms\tremaining: 214ms\n",
            "32:\tlearn: 0.3825171\ttotal: 393ms\tremaining: 202ms\n",
            "33:\tlearn: 0.3774194\ttotal: 405ms\tremaining: 190ms\n",
            "34:\tlearn: 0.3730849\ttotal: 416ms\tremaining: 178ms\n",
            "35:\tlearn: 0.3683747\ttotal: 427ms\tremaining: 166ms\n",
            "36:\tlearn: 0.3650103\ttotal: 438ms\tremaining: 154ms\n",
            "37:\tlearn: 0.3610940\ttotal: 450ms\tremaining: 142ms\n",
            "38:\tlearn: 0.3576293\ttotal: 462ms\tremaining: 130ms\n",
            "39:\tlearn: 0.3541074\ttotal: 482ms\tremaining: 120ms\n",
            "40:\tlearn: 0.3521306\ttotal: 489ms\tremaining: 107ms\n",
            "41:\tlearn: 0.3489038\ttotal: 502ms\tremaining: 95.6ms\n",
            "42:\tlearn: 0.3464321\ttotal: 513ms\tremaining: 83.5ms\n",
            "43:\tlearn: 0.3437260\ttotal: 524ms\tremaining: 71.4ms\n",
            "44:\tlearn: 0.3407128\ttotal: 535ms\tremaining: 59.4ms\n",
            "45:\tlearn: 0.3377969\ttotal: 545ms\tremaining: 47.4ms\n",
            "46:\tlearn: 0.3352531\ttotal: 548ms\tremaining: 35ms\n",
            "47:\tlearn: 0.3329171\ttotal: 559ms\tremaining: 23.3ms\n",
            "48:\tlearn: 0.3293497\ttotal: 570ms\tremaining: 11.6ms\n",
            "49:\tlearn: 0.3286543\ttotal: 571ms\tremaining: 0us\n",
            "0:\tlearn: 1.1113653\ttotal: 11.1ms\tremaining: 544ms\n",
            "1:\tlearn: 1.0447330\ttotal: 23.4ms\tremaining: 561ms\n",
            "2:\tlearn: 0.9841393\ttotal: 34.4ms\tremaining: 539ms\n",
            "3:\tlearn: 0.9313239\ttotal: 45.1ms\tremaining: 519ms\n",
            "4:\tlearn: 0.8765598\ttotal: 47.4ms\tremaining: 426ms\n",
            "5:\tlearn: 0.8258082\ttotal: 49.6ms\tremaining: 364ms\n",
            "6:\tlearn: 0.7829934\ttotal: 68.1ms\tremaining: 419ms\n",
            "7:\tlearn: 0.7446864\ttotal: 79.4ms\tremaining: 417ms\n",
            "8:\tlearn: 0.7072756\ttotal: 93.5ms\tremaining: 426ms\n",
            "9:\tlearn: 0.6740318\ttotal: 104ms\tremaining: 418ms\n",
            "10:\tlearn: 0.6471142\ttotal: 115ms\tremaining: 409ms\n",
            "11:\tlearn: 0.6177466\ttotal: 126ms\tremaining: 399ms\n",
            "12:\tlearn: 0.5943156\ttotal: 137ms\tremaining: 390ms\n",
            "13:\tlearn: 0.5709257\ttotal: 148ms\tremaining: 381ms\n",
            "14:\tlearn: 0.5519780\ttotal: 160ms\tremaining: 373ms\n",
            "15:\tlearn: 0.5347746\ttotal: 171ms\tremaining: 363ms\n",
            "16:\tlearn: 0.5179129\ttotal: 182ms\tremaining: 353ms\n",
            "17:\tlearn: 0.5044291\ttotal: 193ms\tremaining: 343ms\n",
            "18:\tlearn: 0.4899518\ttotal: 204ms\tremaining: 332ms\n",
            "19:\tlearn: 0.4761146\ttotal: 216ms\tremaining: 325ms\n",
            "20:\tlearn: 0.4653992\ttotal: 228ms\tremaining: 315ms\n",
            "21:\tlearn: 0.4553138\ttotal: 240ms\tremaining: 305ms\n",
            "22:\tlearn: 0.4454417\ttotal: 250ms\tremaining: 294ms\n",
            "23:\tlearn: 0.4373473\ttotal: 261ms\tremaining: 283ms\n",
            "24:\tlearn: 0.4289792\ttotal: 280ms\tremaining: 280ms\n",
            "25:\tlearn: 0.4224543\ttotal: 298ms\tremaining: 275ms\n",
            "26:\tlearn: 0.4145828\ttotal: 310ms\tremaining: 264ms\n",
            "27:\tlearn: 0.4086065\ttotal: 321ms\tremaining: 252ms\n",
            "28:\tlearn: 0.4016781\ttotal: 332ms\tremaining: 240ms\n",
            "29:\tlearn: 0.3946322\ttotal: 342ms\tremaining: 228ms\n",
            "30:\tlearn: 0.3893051\ttotal: 354ms\tremaining: 217ms\n",
            "31:\tlearn: 0.3843540\ttotal: 365ms\tremaining: 205ms\n",
            "32:\tlearn: 0.3808781\ttotal: 367ms\tremaining: 189ms\n",
            "33:\tlearn: 0.3758999\ttotal: 378ms\tremaining: 178ms\n",
            "34:\tlearn: 0.3717535\ttotal: 390ms\tremaining: 167ms\n",
            "35:\tlearn: 0.3678084\ttotal: 413ms\tremaining: 161ms\n",
            "36:\tlearn: 0.3636679\ttotal: 424ms\tremaining: 149ms\n",
            "37:\tlearn: 0.3591175\ttotal: 436ms\tremaining: 138ms\n",
            "38:\tlearn: 0.3553486\ttotal: 447ms\tremaining: 126ms\n",
            "39:\tlearn: 0.3522085\ttotal: 459ms\tremaining: 115ms\n",
            "40:\tlearn: 0.3491318\ttotal: 470ms\tremaining: 103ms\n",
            "41:\tlearn: 0.3462289\ttotal: 489ms\tremaining: 93.2ms\n",
            "42:\tlearn: 0.3431867\ttotal: 501ms\tremaining: 81.6ms\n",
            "43:\tlearn: 0.3396766\ttotal: 513ms\tremaining: 69.9ms\n",
            "44:\tlearn: 0.3381104\ttotal: 516ms\tremaining: 57.4ms\n",
            "45:\tlearn: 0.3342287\ttotal: 527ms\tremaining: 45.9ms\n",
            "46:\tlearn: 0.3317038\ttotal: 539ms\tremaining: 34.4ms\n",
            "47:\tlearn: 0.3286746\ttotal: 554ms\tremaining: 23.1ms\n",
            "48:\tlearn: 0.3258557\ttotal: 566ms\tremaining: 11.6ms\n",
            "49:\tlearn: 0.3228513\ttotal: 578ms\tremaining: 0us\n",
            "0:\tlearn: 1.1815153\ttotal: 11.1ms\tremaining: 1.1s\n",
            "1:\tlearn: 1.1742313\ttotal: 22.1ms\tremaining: 1.08s\n",
            "2:\tlearn: 1.1672126\ttotal: 33.4ms\tremaining: 1.08s\n",
            "3:\tlearn: 1.1605805\ttotal: 44.6ms\tremaining: 1.07s\n",
            "4:\tlearn: 1.1528142\ttotal: 50.6ms\tremaining: 961ms\n",
            "5:\tlearn: 1.1463037\ttotal: 61.6ms\tremaining: 965ms\n",
            "6:\tlearn: 1.1393615\ttotal: 73.1ms\tremaining: 971ms\n",
            "7:\tlearn: 1.1327902\ttotal: 95.7ms\tremaining: 1.1s\n",
            "8:\tlearn: 1.1257711\ttotal: 108ms\tremaining: 1.09s\n",
            "9:\tlearn: 1.1192543\ttotal: 119ms\tremaining: 1.07s\n",
            "10:\tlearn: 1.1121791\ttotal: 130ms\tremaining: 1.05s\n",
            "11:\tlearn: 1.1055086\ttotal: 132ms\tremaining: 966ms\n",
            "12:\tlearn: 1.0984028\ttotal: 143ms\tremaining: 955ms\n",
            "13:\tlearn: 1.0918063\ttotal: 154ms\tremaining: 945ms\n",
            "14:\tlearn: 1.0856601\ttotal: 165ms\tremaining: 935ms\n",
            "15:\tlearn: 1.0792667\ttotal: 176ms\tremaining: 924ms\n",
            "16:\tlearn: 1.0727807\ttotal: 182ms\tremaining: 889ms\n",
            "17:\tlearn: 1.0667973\ttotal: 193ms\tremaining: 881ms\n",
            "18:\tlearn: 1.0606950\ttotal: 205ms\tremaining: 873ms\n",
            "19:\tlearn: 1.0547422\ttotal: 216ms\tremaining: 864ms\n",
            "20:\tlearn: 1.0479556\ttotal: 227ms\tremaining: 854ms\n",
            "21:\tlearn: 1.0416863\ttotal: 238ms\tremaining: 845ms\n",
            "22:\tlearn: 1.0358593\ttotal: 250ms\tremaining: 836ms\n",
            "23:\tlearn: 1.0298901\ttotal: 261ms\tremaining: 827ms\n",
            "24:\tlearn: 1.0242734\ttotal: 272ms\tremaining: 817ms\n",
            "25:\tlearn: 1.0183456\ttotal: 274ms\tremaining: 780ms\n",
            "26:\tlearn: 1.0116457\ttotal: 280ms\tremaining: 758ms\n",
            "27:\tlearn: 1.0058641\ttotal: 291ms\tremaining: 750ms\n",
            "28:\tlearn: 0.9999756\ttotal: 315ms\tremaining: 771ms\n",
            "29:\tlearn: 0.9938392\ttotal: 327ms\tremaining: 763ms\n",
            "30:\tlearn: 0.9881463\ttotal: 338ms\tremaining: 753ms\n",
            "31:\tlearn: 0.9820127\ttotal: 340ms\tremaining: 722ms\n",
            "32:\tlearn: 0.9760292\ttotal: 345ms\tremaining: 701ms\n",
            "33:\tlearn: 0.9702471\ttotal: 348ms\tremaining: 675ms\n",
            "34:\tlearn: 0.9641238\ttotal: 361ms\tremaining: 671ms\n",
            "35:\tlearn: 0.9589244\ttotal: 362ms\tremaining: 644ms\n",
            "36:\tlearn: 0.9536396\ttotal: 374ms\tremaining: 636ms\n",
            "37:\tlearn: 0.9480101\ttotal: 386ms\tremaining: 630ms\n",
            "38:\tlearn: 0.9423020\ttotal: 397ms\tremaining: 622ms\n",
            "39:\tlearn: 0.9367184\ttotal: 409ms\tremaining: 614ms\n",
            "40:\tlearn: 0.9316460\ttotal: 421ms\tremaining: 605ms\n",
            "41:\tlearn: 0.9265254\ttotal: 432ms\tremaining: 596ms\n",
            "42:\tlearn: 0.9214855\ttotal: 443ms\tremaining: 587ms\n",
            "43:\tlearn: 0.9163539\ttotal: 454ms\tremaining: 578ms\n",
            "44:\tlearn: 0.9119592\ttotal: 456ms\tremaining: 557ms\n",
            "45:\tlearn: 0.9071759\ttotal: 458ms\tremaining: 538ms\n",
            "46:\tlearn: 0.9022489\ttotal: 460ms\tremaining: 519ms\n",
            "47:\tlearn: 0.8971271\ttotal: 471ms\tremaining: 511ms\n",
            "48:\tlearn: 0.8927731\ttotal: 482ms\tremaining: 502ms\n",
            "49:\tlearn: 0.8883350\ttotal: 493ms\tremaining: 493ms\n",
            "50:\tlearn: 0.8837199\ttotal: 505ms\tremaining: 485ms\n",
            "51:\tlearn: 0.8792608\ttotal: 522ms\tremaining: 482ms\n",
            "52:\tlearn: 0.8746168\ttotal: 538ms\tremaining: 477ms\n",
            "53:\tlearn: 0.8700189\ttotal: 549ms\tremaining: 468ms\n",
            "54:\tlearn: 0.8652732\ttotal: 560ms\tremaining: 458ms\n",
            "55:\tlearn: 0.8608810\ttotal: 571ms\tremaining: 449ms\n",
            "56:\tlearn: 0.8564364\ttotal: 582ms\tremaining: 439ms\n",
            "57:\tlearn: 0.8520133\ttotal: 593ms\tremaining: 430ms\n",
            "58:\tlearn: 0.8473111\ttotal: 597ms\tremaining: 415ms\n",
            "59:\tlearn: 0.8436558\ttotal: 608ms\tremaining: 405ms\n",
            "60:\tlearn: 0.8390306\ttotal: 619ms\tremaining: 396ms\n",
            "61:\tlearn: 0.8342516\ttotal: 630ms\tremaining: 386ms\n",
            "62:\tlearn: 0.8302089\ttotal: 636ms\tremaining: 374ms\n",
            "63:\tlearn: 0.8260411\ttotal: 649ms\tremaining: 365ms\n",
            "64:\tlearn: 0.8218837\ttotal: 660ms\tremaining: 355ms\n",
            "65:\tlearn: 0.8175499\ttotal: 672ms\tremaining: 346ms\n",
            "66:\tlearn: 0.8137096\ttotal: 683ms\tremaining: 337ms\n",
            "67:\tlearn: 0.8096920\ttotal: 684ms\tremaining: 322ms\n",
            "68:\tlearn: 0.8059397\ttotal: 696ms\tremaining: 313ms\n",
            "69:\tlearn: 0.8019546\ttotal: 707ms\tremaining: 303ms\n",
            "70:\tlearn: 0.7977691\ttotal: 718ms\tremaining: 293ms\n",
            "71:\tlearn: 0.7943196\ttotal: 737ms\tremaining: 286ms\n",
            "72:\tlearn: 0.7903395\ttotal: 749ms\tremaining: 277ms\n",
            "73:\tlearn: 0.7868727\ttotal: 763ms\tremaining: 268ms\n",
            "74:\tlearn: 0.7826307\ttotal: 777ms\tremaining: 259ms\n",
            "75:\tlearn: 0.7791252\ttotal: 796ms\tremaining: 251ms\n",
            "76:\tlearn: 0.7751415\ttotal: 807ms\tremaining: 241ms\n",
            "77:\tlearn: 0.7714871\ttotal: 819ms\tremaining: 231ms\n",
            "78:\tlearn: 0.7682216\ttotal: 820ms\tremaining: 218ms\n",
            "79:\tlearn: 0.7644059\ttotal: 831ms\tremaining: 208ms\n",
            "80:\tlearn: 0.7609164\ttotal: 842ms\tremaining: 198ms\n",
            "81:\tlearn: 0.7571622\ttotal: 845ms\tremaining: 185ms\n",
            "82:\tlearn: 0.7536326\ttotal: 856ms\tremaining: 175ms\n",
            "83:\tlearn: 0.7502715\ttotal: 867ms\tremaining: 165ms\n",
            "84:\tlearn: 0.7465916\ttotal: 878ms\tremaining: 155ms\n",
            "85:\tlearn: 0.7431833\ttotal: 884ms\tremaining: 144ms\n",
            "86:\tlearn: 0.7398280\ttotal: 895ms\tremaining: 134ms\n",
            "87:\tlearn: 0.7364275\ttotal: 906ms\tremaining: 123ms\n",
            "88:\tlearn: 0.7328339\ttotal: 917ms\tremaining: 113ms\n",
            "89:\tlearn: 0.7294884\ttotal: 929ms\tremaining: 103ms\n",
            "90:\tlearn: 0.7261203\ttotal: 932ms\tremaining: 92.1ms\n",
            "91:\tlearn: 0.7227263\ttotal: 948ms\tremaining: 82.4ms\n",
            "92:\tlearn: 0.7194399\ttotal: 960ms\tremaining: 72.2ms\n",
            "93:\tlearn: 0.7164631\ttotal: 970ms\tremaining: 61.9ms\n",
            "94:\tlearn: 0.7132705\ttotal: 982ms\tremaining: 51.7ms\n",
            "95:\tlearn: 0.7100086\ttotal: 993ms\tremaining: 41.4ms\n",
            "96:\tlearn: 0.7070920\ttotal: 1s\tremaining: 31.1ms\n",
            "97:\tlearn: 0.7039016\ttotal: 1.01s\tremaining: 20.7ms\n",
            "98:\tlearn: 0.7010008\ttotal: 1.03s\tremaining: 10.4ms\n",
            "99:\tlearn: 0.6979930\ttotal: 1.04s\tremaining: 0us\n",
            "0:\tlearn: 1.1948992\ttotal: 11.6ms\tremaining: 1.15s\n",
            "1:\tlearn: 1.1877405\ttotal: 23.2ms\tremaining: 1.14s\n",
            "2:\tlearn: 1.1802069\ttotal: 34.9ms\tremaining: 1.13s\n",
            "3:\tlearn: 1.1732208\ttotal: 50.4ms\tremaining: 1.21s\n",
            "4:\tlearn: 1.1652358\ttotal: 52.9ms\tremaining: 1s\n",
            "5:\tlearn: 1.1573974\ttotal: 55.2ms\tremaining: 865ms\n",
            "6:\tlearn: 1.1504801\ttotal: 72.1ms\tremaining: 958ms\n",
            "7:\tlearn: 1.1432533\ttotal: 94ms\tremaining: 1.08s\n",
            "8:\tlearn: 1.1357400\ttotal: 106ms\tremaining: 1.07s\n",
            "9:\tlearn: 1.1288140\ttotal: 117ms\tremaining: 1.05s\n",
            "10:\tlearn: 1.1215735\ttotal: 129ms\tremaining: 1.04s\n",
            "11:\tlearn: 1.1149243\ttotal: 141ms\tremaining: 1.03s\n",
            "12:\tlearn: 1.1079010\ttotal: 152ms\tremaining: 1.02s\n",
            "13:\tlearn: 1.1016637\ttotal: 165ms\tremaining: 1.01s\n",
            "14:\tlearn: 1.0950590\ttotal: 176ms\tremaining: 1000ms\n",
            "15:\tlearn: 1.0888329\ttotal: 188ms\tremaining: 987ms\n",
            "16:\tlearn: 1.0820660\ttotal: 200ms\tremaining: 976ms\n",
            "17:\tlearn: 1.0757185\ttotal: 213ms\tremaining: 971ms\n",
            "18:\tlearn: 1.0693084\ttotal: 225ms\tremaining: 958ms\n",
            "19:\tlearn: 1.0635135\ttotal: 236ms\tremaining: 945ms\n",
            "20:\tlearn: 1.0565677\ttotal: 248ms\tremaining: 933ms\n",
            "21:\tlearn: 1.0506330\ttotal: 260ms\tremaining: 920ms\n",
            "22:\tlearn: 1.0447243\ttotal: 277ms\tremaining: 927ms\n",
            "23:\tlearn: 1.0385227\ttotal: 293ms\tremaining: 928ms\n",
            "24:\tlearn: 1.0324432\ttotal: 304ms\tremaining: 913ms\n",
            "25:\tlearn: 1.0261936\ttotal: 318ms\tremaining: 904ms\n",
            "26:\tlearn: 1.0199592\ttotal: 329ms\tremaining: 890ms\n",
            "27:\tlearn: 1.0143961\ttotal: 341ms\tremaining: 876ms\n",
            "28:\tlearn: 1.0085115\ttotal: 352ms\tremaining: 862ms\n",
            "29:\tlearn: 1.0028135\ttotal: 358ms\tremaining: 836ms\n",
            "30:\tlearn: 0.9966966\ttotal: 369ms\tremaining: 822ms\n",
            "31:\tlearn: 0.9905695\ttotal: 374ms\tremaining: 795ms\n",
            "32:\tlearn: 0.9849567\ttotal: 387ms\tremaining: 786ms\n",
            "33:\tlearn: 0.9794651\ttotal: 399ms\tremaining: 775ms\n",
            "34:\tlearn: 0.9740481\ttotal: 410ms\tremaining: 762ms\n",
            "35:\tlearn: 0.9684356\ttotal: 421ms\tremaining: 749ms\n",
            "36:\tlearn: 0.9631742\ttotal: 433ms\tremaining: 737ms\n",
            "37:\tlearn: 0.9570022\ttotal: 436ms\tremaining: 711ms\n",
            "38:\tlearn: 0.9517141\ttotal: 447ms\tremaining: 700ms\n",
            "39:\tlearn: 0.9464449\ttotal: 459ms\tremaining: 689ms\n",
            "40:\tlearn: 0.9406960\ttotal: 461ms\tremaining: 663ms\n",
            "41:\tlearn: 0.9356009\ttotal: 472ms\tremaining: 652ms\n",
            "42:\tlearn: 0.9305000\ttotal: 484ms\tremaining: 642ms\n",
            "43:\tlearn: 0.9252938\ttotal: 486ms\tremaining: 618ms\n",
            "44:\tlearn: 0.9198806\ttotal: 487ms\tremaining: 596ms\n",
            "45:\tlearn: 0.9148915\ttotal: 499ms\tremaining: 586ms\n",
            "46:\tlearn: 0.9097779\ttotal: 511ms\tremaining: 576ms\n",
            "47:\tlearn: 0.9047261\ttotal: 522ms\tremaining: 566ms\n",
            "48:\tlearn: 0.8995398\ttotal: 529ms\tremaining: 551ms\n",
            "49:\tlearn: 0.8945310\ttotal: 533ms\tremaining: 533ms\n",
            "50:\tlearn: 0.8893859\ttotal: 546ms\tremaining: 525ms\n",
            "51:\tlearn: 0.8849394\ttotal: 560ms\tremaining: 516ms\n",
            "52:\tlearn: 0.8798103\ttotal: 573ms\tremaining: 508ms\n",
            "53:\tlearn: 0.8747862\ttotal: 584ms\tremaining: 498ms\n",
            "54:\tlearn: 0.8703583\ttotal: 596ms\tremaining: 488ms\n",
            "55:\tlearn: 0.8655194\ttotal: 608ms\tremaining: 477ms\n",
            "56:\tlearn: 0.8608798\ttotal: 619ms\tremaining: 467ms\n",
            "57:\tlearn: 0.8561598\ttotal: 631ms\tremaining: 457ms\n",
            "58:\tlearn: 0.8517497\ttotal: 643ms\tremaining: 447ms\n",
            "59:\tlearn: 0.8475088\ttotal: 656ms\tremaining: 437ms\n",
            "60:\tlearn: 0.8430973\ttotal: 668ms\tremaining: 427ms\n",
            "61:\tlearn: 0.8384159\ttotal: 688ms\tremaining: 422ms\n",
            "62:\tlearn: 0.8339261\ttotal: 721ms\tremaining: 424ms\n",
            "63:\tlearn: 0.8297283\ttotal: 734ms\tremaining: 413ms\n",
            "64:\tlearn: 0.8254237\ttotal: 747ms\tremaining: 402ms\n",
            "65:\tlearn: 0.8210412\ttotal: 749ms\tremaining: 386ms\n",
            "66:\tlearn: 0.8171318\ttotal: 761ms\tremaining: 375ms\n",
            "67:\tlearn: 0.8130649\ttotal: 765ms\tremaining: 360ms\n",
            "68:\tlearn: 0.8085872\ttotal: 777ms\tremaining: 349ms\n",
            "69:\tlearn: 0.8047246\ttotal: 790ms\tremaining: 339ms\n",
            "70:\tlearn: 0.8005734\ttotal: 803ms\tremaining: 328ms\n",
            "71:\tlearn: 0.7963270\ttotal: 817ms\tremaining: 318ms\n",
            "72:\tlearn: 0.7921646\ttotal: 830ms\tremaining: 307ms\n",
            "73:\tlearn: 0.7882019\ttotal: 842ms\tremaining: 296ms\n",
            "74:\tlearn: 0.7841263\ttotal: 854ms\tremaining: 285ms\n",
            "75:\tlearn: 0.7800768\ttotal: 867ms\tremaining: 274ms\n",
            "76:\tlearn: 0.7762073\ttotal: 875ms\tremaining: 261ms\n",
            "77:\tlearn: 0.7721024\ttotal: 876ms\tremaining: 247ms\n",
            "78:\tlearn: 0.7684471\ttotal: 895ms\tremaining: 238ms\n",
            "79:\tlearn: 0.7646870\ttotal: 898ms\tremaining: 224ms\n",
            "80:\tlearn: 0.7611158\ttotal: 911ms\tremaining: 214ms\n",
            "81:\tlearn: 0.7572302\ttotal: 923ms\tremaining: 203ms\n",
            "82:\tlearn: 0.7536705\ttotal: 936ms\tremaining: 192ms\n",
            "83:\tlearn: 0.7500146\ttotal: 949ms\tremaining: 181ms\n",
            "84:\tlearn: 0.7460266\ttotal: 962ms\tremaining: 170ms\n",
            "85:\tlearn: 0.7423413\ttotal: 974ms\tremaining: 159ms\n",
            "86:\tlearn: 0.7390927\ttotal: 987ms\tremaining: 147ms\n",
            "87:\tlearn: 0.7357965\ttotal: 999ms\tremaining: 136ms\n",
            "88:\tlearn: 0.7324165\ttotal: 1.01s\tremaining: 125ms\n",
            "89:\tlearn: 0.7291236\ttotal: 1.03s\tremaining: 115ms\n",
            "90:\tlearn: 0.7257495\ttotal: 1.04s\tremaining: 103ms\n",
            "91:\tlearn: 0.7224495\ttotal: 1.06s\tremaining: 92ms\n",
            "92:\tlearn: 0.7188166\ttotal: 1.06s\tremaining: 79.9ms\n",
            "93:\tlearn: 0.7154531\ttotal: 1.07s\tremaining: 68.6ms\n",
            "94:\tlearn: 0.7123112\ttotal: 1.09s\tremaining: 57.2ms\n",
            "95:\tlearn: 0.7093987\ttotal: 1.1s\tremaining: 46ms\n",
            "96:\tlearn: 0.7062373\ttotal: 1.11s\tremaining: 34.2ms\n",
            "97:\tlearn: 0.7029958\ttotal: 1.12s\tremaining: 22.9ms\n",
            "98:\tlearn: 0.6999850\ttotal: 1.13s\tremaining: 11.4ms\n",
            "99:\tlearn: 0.6969852\ttotal: 1.14s\tremaining: 0us\n",
            "0:\tlearn: 1.2025546\ttotal: 12.7ms\tremaining: 1.25s\n",
            "1:\tlearn: 1.1949026\ttotal: 24.6ms\tremaining: 1.21s\n",
            "2:\tlearn: 1.1871530\ttotal: 36.5ms\tremaining: 1.18s\n",
            "3:\tlearn: 1.1803107\ttotal: 48.2ms\tremaining: 1.16s\n",
            "4:\tlearn: 1.1731607\ttotal: 60ms\tremaining: 1.14s\n",
            "5:\tlearn: 1.1658499\ttotal: 73.6ms\tremaining: 1.15s\n",
            "6:\tlearn: 1.1584931\ttotal: 86.6ms\tremaining: 1.15s\n",
            "7:\tlearn: 1.1508343\ttotal: 98.9ms\tremaining: 1.14s\n",
            "8:\tlearn: 1.1431852\ttotal: 111ms\tremaining: 1.12s\n",
            "9:\tlearn: 1.1356983\ttotal: 116ms\tremaining: 1.04s\n",
            "10:\tlearn: 1.1284262\ttotal: 135ms\tremaining: 1.09s\n",
            "11:\tlearn: 1.1209332\ttotal: 151ms\tremaining: 1.11s\n",
            "12:\tlearn: 1.1140996\ttotal: 153ms\tremaining: 1.02s\n",
            "13:\tlearn: 1.1076809\ttotal: 166ms\tremaining: 1.02s\n",
            "14:\tlearn: 1.1008914\ttotal: 182ms\tremaining: 1.03s\n",
            "15:\tlearn: 1.0941250\ttotal: 195ms\tremaining: 1.02s\n",
            "16:\tlearn: 1.0875971\ttotal: 207ms\tremaining: 1.01s\n",
            "17:\tlearn: 1.0807064\ttotal: 211ms\tremaining: 963ms\n",
            "18:\tlearn: 1.0739572\ttotal: 224ms\tremaining: 954ms\n",
            "19:\tlearn: 1.0671280\ttotal: 226ms\tremaining: 905ms\n",
            "20:\tlearn: 1.0608510\ttotal: 238ms\tremaining: 896ms\n",
            "21:\tlearn: 1.0547433\ttotal: 251ms\tremaining: 889ms\n",
            "22:\tlearn: 1.0483306\ttotal: 263ms\tremaining: 882ms\n",
            "23:\tlearn: 1.0417391\ttotal: 276ms\tremaining: 873ms\n",
            "24:\tlearn: 1.0355068\ttotal: 288ms\tremaining: 863ms\n",
            "25:\tlearn: 1.0295067\ttotal: 289ms\tremaining: 823ms\n",
            "26:\tlearn: 1.0235041\ttotal: 301ms\tremaining: 814ms\n",
            "27:\tlearn: 1.0175766\ttotal: 314ms\tremaining: 807ms\n",
            "28:\tlearn: 1.0115808\ttotal: 317ms\tremaining: 776ms\n",
            "29:\tlearn: 1.0052538\ttotal: 338ms\tremaining: 788ms\n",
            "30:\tlearn: 0.9997931\ttotal: 353ms\tremaining: 785ms\n",
            "31:\tlearn: 0.9942626\ttotal: 364ms\tremaining: 774ms\n",
            "32:\tlearn: 0.9884324\ttotal: 376ms\tremaining: 764ms\n",
            "33:\tlearn: 0.9824015\ttotal: 388ms\tremaining: 754ms\n",
            "34:\tlearn: 0.9763730\ttotal: 400ms\tremaining: 743ms\n",
            "35:\tlearn: 0.9713649\ttotal: 412ms\tremaining: 733ms\n",
            "36:\tlearn: 0.9659058\ttotal: 424ms\tremaining: 723ms\n",
            "37:\tlearn: 0.9605456\ttotal: 436ms\tremaining: 712ms\n",
            "38:\tlearn: 0.9552088\ttotal: 448ms\tremaining: 701ms\n",
            "39:\tlearn: 0.9498589\ttotal: 460ms\tremaining: 689ms\n",
            "40:\tlearn: 0.9444630\ttotal: 471ms\tremaining: 678ms\n",
            "41:\tlearn: 0.9391464\ttotal: 475ms\tremaining: 656ms\n",
            "42:\tlearn: 0.9346811\ttotal: 487ms\tremaining: 645ms\n",
            "43:\tlearn: 0.9296864\ttotal: 503ms\tremaining: 640ms\n",
            "44:\tlearn: 0.9243903\ttotal: 532ms\tremaining: 651ms\n",
            "45:\tlearn: 0.9190507\ttotal: 536ms\tremaining: 630ms\n",
            "46:\tlearn: 0.9141700\ttotal: 548ms\tremaining: 618ms\n",
            "47:\tlearn: 0.9089052\ttotal: 560ms\tremaining: 606ms\n",
            "48:\tlearn: 0.9034451\ttotal: 562ms\tremaining: 585ms\n",
            "49:\tlearn: 0.8982191\ttotal: 574ms\tremaining: 574ms\n",
            "50:\tlearn: 0.8935453\ttotal: 585ms\tremaining: 562ms\n",
            "51:\tlearn: 0.8883285\ttotal: 598ms\tremaining: 552ms\n",
            "52:\tlearn: 0.8831738\ttotal: 610ms\tremaining: 541ms\n",
            "53:\tlearn: 0.8785987\ttotal: 622ms\tremaining: 530ms\n",
            "54:\tlearn: 0.8741457\ttotal: 634ms\tremaining: 519ms\n",
            "55:\tlearn: 0.8697970\ttotal: 646ms\tremaining: 507ms\n",
            "56:\tlearn: 0.8649309\ttotal: 657ms\tremaining: 496ms\n",
            "57:\tlearn: 0.8602312\ttotal: 669ms\tremaining: 485ms\n",
            "58:\tlearn: 0.8559361\ttotal: 681ms\tremaining: 473ms\n",
            "59:\tlearn: 0.8517828\ttotal: 692ms\tremaining: 462ms\n",
            "60:\tlearn: 0.8470849\ttotal: 704ms\tremaining: 450ms\n",
            "61:\tlearn: 0.8424447\ttotal: 708ms\tremaining: 434ms\n",
            "62:\tlearn: 0.8377910\ttotal: 719ms\tremaining: 422ms\n",
            "63:\tlearn: 0.8333688\ttotal: 733ms\tremaining: 413ms\n",
            "64:\tlearn: 0.8290993\ttotal: 737ms\tremaining: 397ms\n",
            "65:\tlearn: 0.8245814\ttotal: 756ms\tremaining: 389ms\n",
            "66:\tlearn: 0.8206871\ttotal: 767ms\tremaining: 378ms\n",
            "67:\tlearn: 0.8172232\ttotal: 778ms\tremaining: 366ms\n",
            "68:\tlearn: 0.8131805\ttotal: 789ms\tremaining: 355ms\n",
            "69:\tlearn: 0.8087657\ttotal: 801ms\tremaining: 343ms\n",
            "70:\tlearn: 0.8047689\ttotal: 812ms\tremaining: 332ms\n",
            "71:\tlearn: 0.8007457\ttotal: 825ms\tremaining: 321ms\n",
            "72:\tlearn: 0.7965158\ttotal: 839ms\tremaining: 310ms\n",
            "73:\tlearn: 0.7928893\ttotal: 851ms\tremaining: 299ms\n",
            "74:\tlearn: 0.7890973\ttotal: 862ms\tremaining: 287ms\n",
            "75:\tlearn: 0.7852950\ttotal: 873ms\tremaining: 276ms\n",
            "76:\tlearn: 0.7813347\ttotal: 884ms\tremaining: 264ms\n",
            "77:\tlearn: 0.7775300\ttotal: 895ms\tremaining: 253ms\n",
            "78:\tlearn: 0.7737775\ttotal: 907ms\tremaining: 241ms\n",
            "79:\tlearn: 0.7699226\ttotal: 918ms\tremaining: 230ms\n",
            "80:\tlearn: 0.7661943\ttotal: 937ms\tremaining: 220ms\n",
            "81:\tlearn: 0.7623310\ttotal: 949ms\tremaining: 208ms\n",
            "82:\tlearn: 0.7586016\ttotal: 961ms\tremaining: 197ms\n",
            "83:\tlearn: 0.7549527\ttotal: 972ms\tremaining: 185ms\n",
            "84:\tlearn: 0.7514102\ttotal: 983ms\tremaining: 173ms\n",
            "85:\tlearn: 0.7479662\ttotal: 994ms\tremaining: 162ms\n",
            "86:\tlearn: 0.7444183\ttotal: 1s\tremaining: 150ms\n",
            "87:\tlearn: 0.7410794\ttotal: 1.02s\tremaining: 139ms\n",
            "88:\tlearn: 0.7374580\ttotal: 1.03s\tremaining: 127ms\n",
            "89:\tlearn: 0.7340594\ttotal: 1.03s\tremaining: 115ms\n",
            "90:\tlearn: 0.7308101\ttotal: 1.04s\tremaining: 103ms\n",
            "91:\tlearn: 0.7273078\ttotal: 1.06s\tremaining: 91.9ms\n",
            "92:\tlearn: 0.7242764\ttotal: 1.07s\tremaining: 80.4ms\n",
            "93:\tlearn: 0.7209438\ttotal: 1.08s\tremaining: 68.9ms\n",
            "94:\tlearn: 0.7176450\ttotal: 1.09s\tremaining: 57.4ms\n",
            "95:\tlearn: 0.7145237\ttotal: 1.1s\tremaining: 46ms\n",
            "96:\tlearn: 0.7115098\ttotal: 1.11s\tremaining: 34.5ms\n",
            "97:\tlearn: 0.7084270\ttotal: 1.13s\tremaining: 23ms\n",
            "98:\tlearn: 0.7052238\ttotal: 1.14s\tremaining: 11.5ms\n",
            "99:\tlearn: 0.7022163\ttotal: 1.16s\tremaining: 0us\n",
            "0:\tlearn: 1.1157903\ttotal: 11.5ms\tremaining: 1.14s\n",
            "1:\tlearn: 1.1088671\ttotal: 22.8ms\tremaining: 1.12s\n",
            "2:\tlearn: 1.1018589\ttotal: 34.1ms\tremaining: 1.1s\n",
            "3:\tlearn: 1.0958659\ttotal: 45.6ms\tremaining: 1.09s\n",
            "4:\tlearn: 1.0893544\ttotal: 57.4ms\tremaining: 1.09s\n",
            "5:\tlearn: 1.0828622\ttotal: 68.6ms\tremaining: 1.07s\n",
            "6:\tlearn: 1.0758113\ttotal: 80ms\tremaining: 1.06s\n",
            "7:\tlearn: 1.0691402\ttotal: 91.8ms\tremaining: 1.05s\n",
            "8:\tlearn: 1.0626987\ttotal: 103ms\tremaining: 1.04s\n",
            "9:\tlearn: 1.0560174\ttotal: 107ms\tremaining: 961ms\n",
            "10:\tlearn: 1.0494602\ttotal: 120ms\tremaining: 972ms\n",
            "11:\tlearn: 1.0428898\ttotal: 131ms\tremaining: 964ms\n",
            "12:\tlearn: 1.0364665\ttotal: 143ms\tremaining: 956ms\n",
            "13:\tlearn: 1.0299360\ttotal: 162ms\tremaining: 997ms\n",
            "14:\tlearn: 1.0236552\ttotal: 169ms\tremaining: 957ms\n",
            "15:\tlearn: 1.0183319\ttotal: 180ms\tremaining: 945ms\n",
            "16:\tlearn: 1.0126044\ttotal: 192ms\tremaining: 935ms\n",
            "17:\tlearn: 1.0063138\ttotal: 203ms\tremaining: 925ms\n",
            "18:\tlearn: 1.0000264\ttotal: 215ms\tremaining: 915ms\n",
            "19:\tlearn: 0.9940488\ttotal: 227ms\tremaining: 906ms\n",
            "20:\tlearn: 0.9883560\ttotal: 238ms\tremaining: 895ms\n",
            "21:\tlearn: 0.9825862\ttotal: 249ms\tremaining: 884ms\n",
            "22:\tlearn: 0.9764602\ttotal: 252ms\tremaining: 843ms\n",
            "23:\tlearn: 0.9711844\ttotal: 263ms\tremaining: 834ms\n",
            "24:\tlearn: 0.9654916\ttotal: 275ms\tremaining: 824ms\n",
            "25:\tlearn: 0.9598448\ttotal: 286ms\tremaining: 814ms\n",
            "26:\tlearn: 0.9543725\ttotal: 298ms\tremaining: 804ms\n",
            "27:\tlearn: 0.9495352\ttotal: 312ms\tremaining: 804ms\n",
            "28:\tlearn: 0.9442455\ttotal: 334ms\tremaining: 819ms\n",
            "29:\tlearn: 0.9386876\ttotal: 346ms\tremaining: 807ms\n",
            "30:\tlearn: 0.9331705\ttotal: 358ms\tremaining: 796ms\n",
            "31:\tlearn: 0.9276568\ttotal: 372ms\tremaining: 790ms\n",
            "32:\tlearn: 0.9223758\ttotal: 384ms\tremaining: 780ms\n",
            "33:\tlearn: 0.9173629\ttotal: 396ms\tremaining: 768ms\n",
            "34:\tlearn: 0.9123076\ttotal: 408ms\tremaining: 757ms\n",
            "35:\tlearn: 0.9072502\ttotal: 419ms\tremaining: 744ms\n",
            "36:\tlearn: 0.9020448\ttotal: 430ms\tremaining: 732ms\n",
            "37:\tlearn: 0.8969284\ttotal: 441ms\tremaining: 720ms\n",
            "38:\tlearn: 0.8921021\ttotal: 453ms\tremaining: 708ms\n",
            "39:\tlearn: 0.8873711\ttotal: 464ms\tremaining: 695ms\n",
            "40:\tlearn: 0.8825455\ttotal: 475ms\tremaining: 683ms\n",
            "41:\tlearn: 0.8776707\ttotal: 486ms\tremaining: 671ms\n",
            "42:\tlearn: 0.8723397\ttotal: 488ms\tremaining: 647ms\n",
            "43:\tlearn: 0.8674579\ttotal: 499ms\tremaining: 635ms\n",
            "44:\tlearn: 0.8629279\ttotal: 510ms\tremaining: 624ms\n",
            "45:\tlearn: 0.8582220\ttotal: 521ms\tremaining: 612ms\n",
            "46:\tlearn: 0.8538102\ttotal: 532ms\tremaining: 600ms\n",
            "47:\tlearn: 0.8496748\ttotal: 543ms\tremaining: 589ms\n",
            "48:\tlearn: 0.8451608\ttotal: 554ms\tremaining: 577ms\n",
            "49:\tlearn: 0.8412453\ttotal: 565ms\tremaining: 565ms\n",
            "50:\tlearn: 0.8368839\ttotal: 585ms\tremaining: 562ms\n",
            "51:\tlearn: 0.8324757\ttotal: 597ms\tremaining: 551ms\n",
            "52:\tlearn: 0.8279623\ttotal: 608ms\tremaining: 539ms\n",
            "53:\tlearn: 0.8238255\ttotal: 619ms\tremaining: 527ms\n",
            "54:\tlearn: 0.8194674\ttotal: 622ms\tremaining: 509ms\n",
            "55:\tlearn: 0.8153461\ttotal: 635ms\tremaining: 499ms\n",
            "56:\tlearn: 0.8117645\ttotal: 649ms\tremaining: 489ms\n",
            "57:\tlearn: 0.8074214\ttotal: 660ms\tremaining: 478ms\n",
            "58:\tlearn: 0.8031872\ttotal: 671ms\tremaining: 466ms\n",
            "59:\tlearn: 0.7989144\ttotal: 682ms\tremaining: 455ms\n",
            "60:\tlearn: 0.7950572\ttotal: 693ms\tremaining: 443ms\n",
            "61:\tlearn: 0.7911788\ttotal: 706ms\tremaining: 433ms\n",
            "62:\tlearn: 0.7871744\ttotal: 717ms\tremaining: 421ms\n",
            "63:\tlearn: 0.7834004\ttotal: 729ms\tremaining: 410ms\n",
            "64:\tlearn: 0.7797680\ttotal: 741ms\tremaining: 399ms\n",
            "65:\tlearn: 0.7758011\ttotal: 752ms\tremaining: 387ms\n",
            "66:\tlearn: 0.7717398\ttotal: 763ms\tremaining: 376ms\n",
            "67:\tlearn: 0.7678810\ttotal: 775ms\tremaining: 364ms\n",
            "68:\tlearn: 0.7640145\ttotal: 791ms\tremaining: 356ms\n",
            "69:\tlearn: 0.7601763\ttotal: 804ms\tremaining: 345ms\n",
            "70:\tlearn: 0.7564084\ttotal: 816ms\tremaining: 333ms\n",
            "71:\tlearn: 0.7525795\ttotal: 827ms\tremaining: 322ms\n",
            "72:\tlearn: 0.7488707\ttotal: 838ms\tremaining: 310ms\n",
            "73:\tlearn: 0.7455649\ttotal: 849ms\tremaining: 298ms\n",
            "74:\tlearn: 0.7416806\ttotal: 855ms\tremaining: 285ms\n",
            "75:\tlearn: 0.7378894\ttotal: 866ms\tremaining: 273ms\n",
            "76:\tlearn: 0.7344310\ttotal: 877ms\tremaining: 262ms\n",
            "77:\tlearn: 0.7309213\ttotal: 888ms\tremaining: 250ms\n",
            "78:\tlearn: 0.7276223\ttotal: 899ms\tremaining: 239ms\n",
            "79:\tlearn: 0.7243546\ttotal: 910ms\tremaining: 227ms\n",
            "80:\tlearn: 0.7210241\ttotal: 921ms\tremaining: 216ms\n",
            "81:\tlearn: 0.7177226\ttotal: 932ms\tremaining: 205ms\n",
            "82:\tlearn: 0.7140832\ttotal: 943ms\tremaining: 193ms\n",
            "83:\tlearn: 0.7108076\ttotal: 945ms\tremaining: 180ms\n",
            "84:\tlearn: 0.7078089\ttotal: 956ms\tremaining: 169ms\n",
            "85:\tlearn: 0.7045496\ttotal: 967ms\tremaining: 157ms\n",
            "86:\tlearn: 0.7011587\ttotal: 978ms\tremaining: 146ms\n",
            "87:\tlearn: 0.6978908\ttotal: 1s\tremaining: 137ms\n",
            "88:\tlearn: 0.6947173\ttotal: 1.02s\tremaining: 126ms\n",
            "89:\tlearn: 0.6914115\ttotal: 1.03s\tremaining: 114ms\n",
            "90:\tlearn: 0.6885443\ttotal: 1.04s\tremaining: 103ms\n",
            "91:\tlearn: 0.6855907\ttotal: 1.05s\tremaining: 91.4ms\n",
            "92:\tlearn: 0.6828260\ttotal: 1.06s\tremaining: 80ms\n",
            "93:\tlearn: 0.6797512\ttotal: 1.07s\tremaining: 68.5ms\n",
            "94:\tlearn: 0.6767656\ttotal: 1.08s\tremaining: 57.1ms\n",
            "95:\tlearn: 0.6739913\ttotal: 1.1s\tremaining: 45.7ms\n",
            "96:\tlearn: 0.6712638\ttotal: 1.11s\tremaining: 34.3ms\n",
            "97:\tlearn: 0.6683531\ttotal: 1.12s\tremaining: 22.9ms\n",
            "98:\tlearn: 0.6655727\ttotal: 1.12s\tremaining: 11.3ms\n",
            "99:\tlearn: 0.6625237\ttotal: 1.13s\tremaining: 0us\n",
            "0:\tlearn: 1.1774319\ttotal: 12.3ms\tremaining: 1.22s\n",
            "1:\tlearn: 1.1703482\ttotal: 24.7ms\tremaining: 1.21s\n",
            "2:\tlearn: 1.1627866\ttotal: 43.8ms\tremaining: 1.42s\n",
            "3:\tlearn: 1.1560036\ttotal: 58.4ms\tremaining: 1.4s\n",
            "4:\tlearn: 1.1481986\ttotal: 61ms\tremaining: 1.16s\n",
            "5:\tlearn: 1.1403085\ttotal: 63.4ms\tremaining: 993ms\n",
            "6:\tlearn: 1.1331323\ttotal: 75.5ms\tremaining: 1s\n",
            "7:\tlearn: 1.1262101\ttotal: 87.8ms\tremaining: 1.01s\n",
            "8:\tlearn: 1.1185204\ttotal: 100ms\tremaining: 1.01s\n",
            "9:\tlearn: 1.1108204\ttotal: 112ms\tremaining: 1.01s\n",
            "10:\tlearn: 1.1041240\ttotal: 124ms\tremaining: 1s\n",
            "11:\tlearn: 1.0973536\ttotal: 137ms\tremaining: 1s\n",
            "12:\tlearn: 1.0904279\ttotal: 161ms\tremaining: 1.08s\n",
            "13:\tlearn: 1.0842123\ttotal: 181ms\tremaining: 1.11s\n",
            "14:\tlearn: 1.0777204\ttotal: 193ms\tremaining: 1.09s\n",
            "15:\tlearn: 1.0708567\ttotal: 204ms\tremaining: 1.07s\n",
            "16:\tlearn: 1.0647459\ttotal: 215ms\tremaining: 1.05s\n",
            "17:\tlearn: 1.0590216\ttotal: 227ms\tremaining: 1.03s\n",
            "18:\tlearn: 1.0528715\ttotal: 239ms\tremaining: 1.02s\n",
            "19:\tlearn: 1.0466248\ttotal: 261ms\tremaining: 1.04s\n",
            "20:\tlearn: 1.0400454\ttotal: 273ms\tremaining: 1.03s\n",
            "21:\tlearn: 1.0342379\ttotal: 284ms\tremaining: 1.01s\n",
            "22:\tlearn: 1.0282777\ttotal: 297ms\tremaining: 993ms\n",
            "23:\tlearn: 1.0224542\ttotal: 309ms\tremaining: 978ms\n",
            "24:\tlearn: 1.0163405\ttotal: 321ms\tremaining: 964ms\n",
            "25:\tlearn: 1.0102928\ttotal: 323ms\tremaining: 920ms\n",
            "26:\tlearn: 1.0036245\ttotal: 329ms\tremaining: 890ms\n",
            "27:\tlearn: 0.9975832\ttotal: 341ms\tremaining: 877ms\n",
            "28:\tlearn: 0.9915532\ttotal: 353ms\tremaining: 865ms\n",
            "29:\tlearn: 0.9855358\ttotal: 376ms\tremaining: 876ms\n",
            "30:\tlearn: 0.9794317\ttotal: 394ms\tremaining: 878ms\n",
            "31:\tlearn: 0.9738500\ttotal: 415ms\tremaining: 882ms\n",
            "32:\tlearn: 0.9677584\ttotal: 427ms\tremaining: 866ms\n",
            "33:\tlearn: 0.9623223\ttotal: 438ms\tremaining: 851ms\n",
            "34:\tlearn: 0.9570827\ttotal: 450ms\tremaining: 835ms\n",
            "35:\tlearn: 0.9516152\ttotal: 474ms\tremaining: 842ms\n",
            "36:\tlearn: 0.9463979\ttotal: 487ms\tremaining: 828ms\n",
            "37:\tlearn: 0.9408938\ttotal: 504ms\tremaining: 822ms\n",
            "38:\tlearn: 0.9356794\ttotal: 516ms\tremaining: 808ms\n",
            "39:\tlearn: 0.9306162\ttotal: 529ms\tremaining: 793ms\n",
            "40:\tlearn: 0.9254463\ttotal: 541ms\tremaining: 778ms\n",
            "41:\tlearn: 0.9203234\ttotal: 553ms\tremaining: 763ms\n",
            "42:\tlearn: 0.9147621\ttotal: 555ms\tremaining: 736ms\n",
            "43:\tlearn: 0.9093809\ttotal: 568ms\tremaining: 722ms\n",
            "44:\tlearn: 0.9043040\ttotal: 580ms\tremaining: 708ms\n",
            "45:\tlearn: 0.8992571\ttotal: 591ms\tremaining: 694ms\n",
            "46:\tlearn: 0.8943397\ttotal: 603ms\tremaining: 680ms\n",
            "47:\tlearn: 0.8899205\ttotal: 615ms\tremaining: 667ms\n",
            "48:\tlearn: 0.8849380\ttotal: 629ms\tremaining: 655ms\n",
            "49:\tlearn: 0.8803395\ttotal: 641ms\tremaining: 641ms\n",
            "50:\tlearn: 0.8758247\ttotal: 653ms\tremaining: 628ms\n",
            "51:\tlearn: 0.8714302\ttotal: 655ms\tremaining: 604ms\n",
            "52:\tlearn: 0.8664971\ttotal: 661ms\tremaining: 586ms\n",
            "53:\tlearn: 0.8619421\ttotal: 678ms\tremaining: 578ms\n",
            "54:\tlearn: 0.8572881\ttotal: 699ms\tremaining: 572ms\n",
            "55:\tlearn: 0.8527175\ttotal: 714ms\tremaining: 561ms\n",
            "56:\tlearn: 0.8479244\ttotal: 726ms\tremaining: 548ms\n",
            "57:\tlearn: 0.8438028\ttotal: 738ms\tremaining: 534ms\n",
            "58:\tlearn: 0.8391787\ttotal: 750ms\tremaining: 521ms\n",
            "59:\tlearn: 0.8349452\ttotal: 761ms\tremaining: 508ms\n",
            "60:\tlearn: 0.8307728\ttotal: 765ms\tremaining: 489ms\n",
            "61:\tlearn: 0.8265197\ttotal: 777ms\tremaining: 476ms\n",
            "62:\tlearn: 0.8225734\ttotal: 789ms\tremaining: 463ms\n",
            "63:\tlearn: 0.8185774\ttotal: 804ms\tremaining: 452ms\n",
            "64:\tlearn: 0.8141405\ttotal: 817ms\tremaining: 440ms\n",
            "65:\tlearn: 0.8098621\ttotal: 828ms\tremaining: 427ms\n",
            "66:\tlearn: 0.8058218\ttotal: 830ms\tremaining: 409ms\n",
            "67:\tlearn: 0.8018227\ttotal: 842ms\tremaining: 396ms\n",
            "68:\tlearn: 0.7980459\ttotal: 853ms\tremaining: 383ms\n",
            "69:\tlearn: 0.7938184\ttotal: 865ms\tremaining: 371ms\n",
            "70:\tlearn: 0.7897586\ttotal: 877ms\tremaining: 358ms\n",
            "71:\tlearn: 0.7852517\ttotal: 895ms\tremaining: 348ms\n",
            "72:\tlearn: 0.7810918\ttotal: 900ms\tremaining: 333ms\n",
            "73:\tlearn: 0.7772802\ttotal: 912ms\tremaining: 321ms\n",
            "74:\tlearn: 0.7733863\ttotal: 924ms\tremaining: 308ms\n",
            "75:\tlearn: 0.7696790\ttotal: 936ms\tremaining: 296ms\n",
            "76:\tlearn: 0.7659192\ttotal: 952ms\tremaining: 284ms\n",
            "77:\tlearn: 0.7619746\ttotal: 965ms\tremaining: 272ms\n",
            "78:\tlearn: 0.7581546\ttotal: 977ms\tremaining: 260ms\n",
            "79:\tlearn: 0.7544933\ttotal: 988ms\tremaining: 247ms\n",
            "80:\tlearn: 0.7508402\ttotal: 1000ms\tremaining: 235ms\n",
            "81:\tlearn: 0.7468221\ttotal: 1.01s\tremaining: 222ms\n",
            "82:\tlearn: 0.7431769\ttotal: 1.02s\tremaining: 209ms\n",
            "83:\tlearn: 0.7396122\ttotal: 1.03s\tremaining: 197ms\n",
            "84:\tlearn: 0.7363274\ttotal: 1.04s\tremaining: 184ms\n",
            "85:\tlearn: 0.7329058\ttotal: 1.05s\tremaining: 172ms\n",
            "86:\tlearn: 0.7294960\ttotal: 1.07s\tremaining: 159ms\n",
            "87:\tlearn: 0.7260646\ttotal: 1.08s\tremaining: 147ms\n",
            "88:\tlearn: 0.7225461\ttotal: 1.08s\tremaining: 133ms\n",
            "89:\tlearn: 0.7188449\ttotal: 1.09s\tremaining: 121ms\n",
            "90:\tlearn: 0.7151485\ttotal: 1.11s\tremaining: 110ms\n",
            "91:\tlearn: 0.7120328\ttotal: 1.12s\tremaining: 97.8ms\n",
            "92:\tlearn: 0.7086490\ttotal: 1.14s\tremaining: 85.5ms\n",
            "93:\tlearn: 0.7051926\ttotal: 1.15s\tremaining: 73.3ms\n",
            "94:\tlearn: 0.7020840\ttotal: 1.16s\tremaining: 61.2ms\n",
            "95:\tlearn: 0.6985725\ttotal: 1.18s\tremaining: 49.2ms\n",
            "96:\tlearn: 0.6956032\ttotal: 1.19s\tremaining: 36.9ms\n",
            "97:\tlearn: 0.6925539\ttotal: 1.2s\tremaining: 24.4ms\n",
            "98:\tlearn: 0.6891984\ttotal: 1.21s\tremaining: 12.2ms\n",
            "99:\tlearn: 0.6860869\ttotal: 1.22s\tremaining: 0us\n",
            "0:\tlearn: 1.1550191\ttotal: 11.2ms\tremaining: 1.11s\n",
            "1:\tlearn: 1.1206086\ttotal: 22.5ms\tremaining: 1.1s\n",
            "2:\tlearn: 1.0880061\ttotal: 33.6ms\tremaining: 1.09s\n",
            "3:\tlearn: 1.0580633\ttotal: 45.1ms\tremaining: 1.08s\n",
            "4:\tlearn: 1.0243869\ttotal: 51.4ms\tremaining: 977ms\n",
            "5:\tlearn: 0.9981554\ttotal: 70.2ms\tremaining: 1.1s\n",
            "6:\tlearn: 0.9706387\ttotal: 81.8ms\tremaining: 1.09s\n",
            "7:\tlearn: 0.9456346\ttotal: 93.2ms\tremaining: 1.07s\n",
            "8:\tlearn: 0.9178827\ttotal: 105ms\tremaining: 1.06s\n",
            "9:\tlearn: 0.8909000\ttotal: 106ms\tremaining: 956ms\n",
            "10:\tlearn: 0.8692588\ttotal: 117ms\tremaining: 950ms\n",
            "11:\tlearn: 0.8471166\ttotal: 129ms\tremaining: 943ms\n",
            "12:\tlearn: 0.8251116\ttotal: 140ms\tremaining: 936ms\n",
            "13:\tlearn: 0.8040271\ttotal: 151ms\tremaining: 928ms\n",
            "14:\tlearn: 0.7831308\ttotal: 162ms\tremaining: 919ms\n",
            "15:\tlearn: 0.7645271\ttotal: 173ms\tremaining: 908ms\n",
            "16:\tlearn: 0.7461556\ttotal: 179ms\tremaining: 875ms\n",
            "17:\tlearn: 0.7292132\ttotal: 190ms\tremaining: 866ms\n",
            "18:\tlearn: 0.7140633\ttotal: 202ms\tremaining: 861ms\n",
            "19:\tlearn: 0.6990791\ttotal: 213ms\tremaining: 852ms\n",
            "20:\tlearn: 0.6828905\ttotal: 224ms\tremaining: 843ms\n",
            "21:\tlearn: 0.6682793\ttotal: 237ms\tremaining: 840ms\n",
            "22:\tlearn: 0.6540971\ttotal: 250ms\tremaining: 836ms\n",
            "23:\tlearn: 0.6407347\ttotal: 261ms\tremaining: 827ms\n",
            "24:\tlearn: 0.6285044\ttotal: 281ms\tremaining: 843ms\n",
            "25:\tlearn: 0.6167186\ttotal: 283ms\tremaining: 806ms\n",
            "26:\tlearn: 0.6046553\ttotal: 295ms\tremaining: 796ms\n",
            "27:\tlearn: 0.5946841\ttotal: 306ms\tremaining: 787ms\n",
            "28:\tlearn: 0.5844344\ttotal: 317ms\tremaining: 776ms\n",
            "29:\tlearn: 0.5739206\ttotal: 328ms\tremaining: 766ms\n",
            "30:\tlearn: 0.5642975\ttotal: 342ms\tremaining: 762ms\n",
            "31:\tlearn: 0.5558544\ttotal: 355ms\tremaining: 753ms\n",
            "32:\tlearn: 0.5471242\ttotal: 366ms\tremaining: 742ms\n",
            "33:\tlearn: 0.5402581\ttotal: 367ms\tremaining: 712ms\n",
            "34:\tlearn: 0.5326637\ttotal: 378ms\tremaining: 702ms\n",
            "35:\tlearn: 0.5255528\ttotal: 389ms\tremaining: 691ms\n",
            "36:\tlearn: 0.5191854\ttotal: 400ms\tremaining: 682ms\n",
            "37:\tlearn: 0.5114763\ttotal: 411ms\tremaining: 671ms\n",
            "38:\tlearn: 0.5050472\ttotal: 422ms\tremaining: 660ms\n",
            "39:\tlearn: 0.4997144\ttotal: 425ms\tremaining: 637ms\n",
            "40:\tlearn: 0.4938746\ttotal: 435ms\tremaining: 627ms\n",
            "41:\tlearn: 0.4877619\ttotal: 446ms\tremaining: 616ms\n",
            "42:\tlearn: 0.4822682\ttotal: 450ms\tremaining: 596ms\n",
            "43:\tlearn: 0.4765095\ttotal: 456ms\tremaining: 580ms\n",
            "44:\tlearn: 0.4722535\ttotal: 467ms\tremaining: 571ms\n",
            "45:\tlearn: 0.4679829\ttotal: 481ms\tremaining: 565ms\n",
            "46:\tlearn: 0.4639252\ttotal: 496ms\tremaining: 559ms\n",
            "47:\tlearn: 0.4594536\ttotal: 507ms\tremaining: 550ms\n",
            "48:\tlearn: 0.4548400\ttotal: 518ms\tremaining: 539ms\n",
            "49:\tlearn: 0.4506684\ttotal: 529ms\tremaining: 529ms\n",
            "50:\tlearn: 0.4460671\ttotal: 540ms\tremaining: 519ms\n",
            "51:\tlearn: 0.4419407\ttotal: 551ms\tremaining: 509ms\n",
            "52:\tlearn: 0.4383789\ttotal: 562ms\tremaining: 499ms\n",
            "53:\tlearn: 0.4342349\ttotal: 573ms\tremaining: 488ms\n",
            "54:\tlearn: 0.4320372\ttotal: 574ms\tremaining: 470ms\n",
            "55:\tlearn: 0.4283718\ttotal: 586ms\tremaining: 460ms\n",
            "56:\tlearn: 0.4244777\ttotal: 597ms\tremaining: 450ms\n",
            "57:\tlearn: 0.4212947\ttotal: 608ms\tremaining: 440ms\n",
            "58:\tlearn: 0.4176068\ttotal: 625ms\tremaining: 435ms\n",
            "59:\tlearn: 0.4142866\ttotal: 637ms\tremaining: 425ms\n",
            "60:\tlearn: 0.4104216\ttotal: 648ms\tremaining: 415ms\n",
            "61:\tlearn: 0.4071786\ttotal: 660ms\tremaining: 405ms\n",
            "62:\tlearn: 0.4048549\ttotal: 672ms\tremaining: 395ms\n",
            "63:\tlearn: 0.4024451\ttotal: 691ms\tremaining: 389ms\n",
            "64:\tlearn: 0.3995897\ttotal: 716ms\tremaining: 385ms\n",
            "65:\tlearn: 0.3976006\ttotal: 719ms\tremaining: 370ms\n",
            "66:\tlearn: 0.3950120\ttotal: 731ms\tremaining: 360ms\n",
            "67:\tlearn: 0.3923775\ttotal: 744ms\tremaining: 350ms\n",
            "68:\tlearn: 0.3898206\ttotal: 756ms\tremaining: 340ms\n",
            "69:\tlearn: 0.3870998\ttotal: 768ms\tremaining: 329ms\n",
            "70:\tlearn: 0.3846572\ttotal: 781ms\tremaining: 319ms\n",
            "71:\tlearn: 0.3826269\ttotal: 793ms\tremaining: 308ms\n",
            "72:\tlearn: 0.3802289\ttotal: 805ms\tremaining: 298ms\n",
            "73:\tlearn: 0.3775456\ttotal: 817ms\tremaining: 287ms\n",
            "74:\tlearn: 0.3754300\ttotal: 828ms\tremaining: 276ms\n",
            "75:\tlearn: 0.3733903\ttotal: 840ms\tremaining: 265ms\n",
            "76:\tlearn: 0.3717051\ttotal: 852ms\tremaining: 254ms\n",
            "77:\tlearn: 0.3694532\ttotal: 864ms\tremaining: 244ms\n",
            "78:\tlearn: 0.3676510\ttotal: 877ms\tremaining: 233ms\n",
            "79:\tlearn: 0.3666003\ttotal: 879ms\tremaining: 220ms\n",
            "80:\tlearn: 0.3646183\ttotal: 897ms\tremaining: 210ms\n",
            "81:\tlearn: 0.3626844\ttotal: 920ms\tremaining: 202ms\n",
            "82:\tlearn: 0.3616844\ttotal: 924ms\tremaining: 189ms\n",
            "83:\tlearn: 0.3600920\ttotal: 942ms\tremaining: 179ms\n",
            "84:\tlearn: 0.3583624\ttotal: 954ms\tremaining: 168ms\n",
            "85:\tlearn: 0.3560708\ttotal: 966ms\tremaining: 157ms\n",
            "86:\tlearn: 0.3546918\ttotal: 979ms\tremaining: 146ms\n",
            "87:\tlearn: 0.3526018\ttotal: 991ms\tremaining: 135ms\n",
            "88:\tlearn: 0.3504043\ttotal: 1s\tremaining: 124ms\n",
            "89:\tlearn: 0.3485089\ttotal: 1.02s\tremaining: 113ms\n",
            "90:\tlearn: 0.3468928\ttotal: 1.03s\tremaining: 102ms\n",
            "91:\tlearn: 0.3450455\ttotal: 1.04s\tremaining: 90.5ms\n",
            "92:\tlearn: 0.3435883\ttotal: 1.05s\tremaining: 79.3ms\n",
            "93:\tlearn: 0.3422869\ttotal: 1.06s\tremaining: 68ms\n",
            "94:\tlearn: 0.3405280\ttotal: 1.08s\tremaining: 56.7ms\n",
            "95:\tlearn: 0.3394727\ttotal: 1.09s\tremaining: 45.4ms\n",
            "96:\tlearn: 0.3381084\ttotal: 1.11s\tremaining: 34.4ms\n",
            "97:\tlearn: 0.3363897\ttotal: 1.12s\tremaining: 22.9ms\n",
            "98:\tlearn: 0.3344730\ttotal: 1.14s\tremaining: 11.5ms\n",
            "99:\tlearn: 0.3332782\ttotal: 1.15s\tremaining: 0us\n",
            "0:\tlearn: 1.1661331\ttotal: 12.9ms\tremaining: 1.27s\n",
            "1:\tlearn: 1.1318096\ttotal: 26.7ms\tremaining: 1.31s\n",
            "2:\tlearn: 1.0973114\ttotal: 39.2ms\tremaining: 1.27s\n",
            "3:\tlearn: 1.0675407\ttotal: 52ms\tremaining: 1.25s\n",
            "4:\tlearn: 1.0333895\ttotal: 58.5ms\tremaining: 1.11s\n",
            "5:\tlearn: 1.0054259\ttotal: 72.2ms\tremaining: 1.13s\n",
            "6:\tlearn: 0.9764574\ttotal: 84.8ms\tremaining: 1.13s\n",
            "7:\tlearn: 0.9492732\ttotal: 97.6ms\tremaining: 1.12s\n",
            "8:\tlearn: 0.9238262\ttotal: 111ms\tremaining: 1.12s\n",
            "9:\tlearn: 0.8981307\ttotal: 112ms\tremaining: 1.01s\n",
            "10:\tlearn: 0.8745046\ttotal: 147ms\tremaining: 1.19s\n",
            "11:\tlearn: 0.8538692\ttotal: 162ms\tremaining: 1.19s\n",
            "12:\tlearn: 0.8295349\ttotal: 174ms\tremaining: 1.17s\n",
            "13:\tlearn: 0.8100101\ttotal: 186ms\tremaining: 1.14s\n",
            "14:\tlearn: 0.7902337\ttotal: 198ms\tremaining: 1.12s\n",
            "15:\tlearn: 0.7698226\ttotal: 210ms\tremaining: 1.1s\n",
            "16:\tlearn: 0.7509742\ttotal: 216ms\tremaining: 1.06s\n",
            "17:\tlearn: 0.7344584\ttotal: 229ms\tremaining: 1.04s\n",
            "18:\tlearn: 0.7175734\ttotal: 242ms\tremaining: 1.03s\n",
            "19:\tlearn: 0.7033115\ttotal: 255ms\tremaining: 1.02s\n",
            "20:\tlearn: 0.6859803\ttotal: 267ms\tremaining: 1.01s\n",
            "21:\tlearn: 0.6709841\ttotal: 280ms\tremaining: 993ms\n",
            "22:\tlearn: 0.6561659\ttotal: 293ms\tremaining: 980ms\n",
            "23:\tlearn: 0.6430126\ttotal: 305ms\tremaining: 967ms\n",
            "24:\tlearn: 0.6310995\ttotal: 319ms\tremaining: 956ms\n",
            "25:\tlearn: 0.6192651\ttotal: 320ms\tremaining: 912ms\n",
            "26:\tlearn: 0.6081081\ttotal: 327ms\tremaining: 885ms\n",
            "27:\tlearn: 0.5973351\ttotal: 345ms\tremaining: 888ms\n",
            "28:\tlearn: 0.5866098\ttotal: 362ms\tremaining: 886ms\n",
            "29:\tlearn: 0.5772000\ttotal: 375ms\tremaining: 874ms\n",
            "30:\tlearn: 0.5676277\ttotal: 377ms\tremaining: 839ms\n",
            "31:\tlearn: 0.5584169\ttotal: 384ms\tremaining: 816ms\n",
            "32:\tlearn: 0.5484550\ttotal: 399ms\tremaining: 810ms\n",
            "33:\tlearn: 0.5401663\ttotal: 411ms\tremaining: 799ms\n",
            "34:\tlearn: 0.5333635\ttotal: 424ms\tremaining: 787ms\n",
            "35:\tlearn: 0.5260235\ttotal: 436ms\tremaining: 775ms\n",
            "36:\tlearn: 0.5199657\ttotal: 449ms\tremaining: 764ms\n",
            "37:\tlearn: 0.5125223\ttotal: 461ms\tremaining: 752ms\n",
            "38:\tlearn: 0.5051006\ttotal: 473ms\tremaining: 741ms\n",
            "39:\tlearn: 0.4989851\ttotal: 486ms\tremaining: 729ms\n",
            "40:\tlearn: 0.4924010\ttotal: 498ms\tremaining: 717ms\n",
            "41:\tlearn: 0.4861881\ttotal: 511ms\tremaining: 705ms\n",
            "42:\tlearn: 0.4820043\ttotal: 513ms\tremaining: 680ms\n",
            "43:\tlearn: 0.4761741\ttotal: 526ms\tremaining: 669ms\n",
            "44:\tlearn: 0.4711851\ttotal: 539ms\tremaining: 658ms\n",
            "45:\tlearn: 0.4660390\ttotal: 560ms\tremaining: 657ms\n",
            "46:\tlearn: 0.4608409\ttotal: 576ms\tremaining: 650ms\n",
            "47:\tlearn: 0.4561193\ttotal: 589ms\tremaining: 638ms\n",
            "48:\tlearn: 0.4511809\ttotal: 601ms\tremaining: 625ms\n",
            "49:\tlearn: 0.4464294\ttotal: 613ms\tremaining: 613ms\n",
            "50:\tlearn: 0.4413380\ttotal: 625ms\tremaining: 601ms\n",
            "51:\tlearn: 0.4375827\ttotal: 639ms\tremaining: 590ms\n",
            "52:\tlearn: 0.4332092\ttotal: 652ms\tremaining: 578ms\n",
            "53:\tlearn: 0.4296890\ttotal: 664ms\tremaining: 566ms\n",
            "54:\tlearn: 0.4255277\ttotal: 677ms\tremaining: 554ms\n",
            "55:\tlearn: 0.4224651\ttotal: 689ms\tremaining: 541ms\n",
            "56:\tlearn: 0.4191685\ttotal: 702ms\tremaining: 529ms\n",
            "57:\tlearn: 0.4166367\ttotal: 705ms\tremaining: 511ms\n",
            "58:\tlearn: 0.4138579\ttotal: 727ms\tremaining: 506ms\n",
            "59:\tlearn: 0.4104276\ttotal: 739ms\tremaining: 493ms\n",
            "60:\tlearn: 0.4076300\ttotal: 752ms\tremaining: 481ms\n",
            "61:\tlearn: 0.4047120\ttotal: 772ms\tremaining: 473ms\n",
            "62:\tlearn: 0.4026571\ttotal: 786ms\tremaining: 461ms\n",
            "63:\tlearn: 0.4003448\ttotal: 792ms\tremaining: 445ms\n",
            "64:\tlearn: 0.3976999\ttotal: 804ms\tremaining: 433ms\n",
            "65:\tlearn: 0.3949841\ttotal: 816ms\tremaining: 420ms\n",
            "66:\tlearn: 0.3917987\ttotal: 828ms\tremaining: 408ms\n",
            "67:\tlearn: 0.3897049\ttotal: 831ms\tremaining: 391ms\n",
            "68:\tlearn: 0.3872405\ttotal: 843ms\tremaining: 379ms\n",
            "69:\tlearn: 0.3847168\ttotal: 855ms\tremaining: 366ms\n",
            "70:\tlearn: 0.3824806\ttotal: 867ms\tremaining: 354ms\n",
            "71:\tlearn: 0.3802923\ttotal: 879ms\tremaining: 342ms\n",
            "72:\tlearn: 0.3776932\ttotal: 894ms\tremaining: 331ms\n",
            "73:\tlearn: 0.3754456\ttotal: 906ms\tremaining: 318ms\n",
            "74:\tlearn: 0.3734198\ttotal: 918ms\tremaining: 306ms\n",
            "75:\tlearn: 0.3722738\ttotal: 920ms\tremaining: 291ms\n",
            "76:\tlearn: 0.3694687\ttotal: 932ms\tremaining: 278ms\n",
            "77:\tlearn: 0.3676613\ttotal: 944ms\tremaining: 266ms\n",
            "78:\tlearn: 0.3655969\ttotal: 965ms\tremaining: 256ms\n",
            "79:\tlearn: 0.3641570\ttotal: 967ms\tremaining: 242ms\n",
            "80:\tlearn: 0.3622129\ttotal: 980ms\tremaining: 230ms\n",
            "81:\tlearn: 0.3603001\ttotal: 992ms\tremaining: 218ms\n",
            "82:\tlearn: 0.3592143\ttotal: 994ms\tremaining: 204ms\n",
            "83:\tlearn: 0.3576217\ttotal: 1.01s\tremaining: 192ms\n",
            "84:\tlearn: 0.3556690\ttotal: 1.02s\tremaining: 180ms\n",
            "85:\tlearn: 0.3539240\ttotal: 1.03s\tremaining: 168ms\n",
            "86:\tlearn: 0.3533672\ttotal: 1.03s\tremaining: 154ms\n",
            "87:\tlearn: 0.3519752\ttotal: 1.05s\tremaining: 143ms\n",
            "88:\tlearn: 0.3502902\ttotal: 1.06s\tremaining: 131ms\n",
            "89:\tlearn: 0.3487387\ttotal: 1.07s\tremaining: 119ms\n",
            "90:\tlearn: 0.3465586\ttotal: 1.09s\tremaining: 107ms\n",
            "91:\tlearn: 0.3448923\ttotal: 1.1s\tremaining: 95.6ms\n",
            "92:\tlearn: 0.3434764\ttotal: 1.11s\tremaining: 83.8ms\n",
            "93:\tlearn: 0.3418758\ttotal: 1.13s\tremaining: 71.9ms\n",
            "94:\tlearn: 0.3400866\ttotal: 1.14s\tremaining: 60ms\n",
            "95:\tlearn: 0.3386007\ttotal: 1.16s\tremaining: 48.1ms\n",
            "96:\tlearn: 0.3376249\ttotal: 1.18s\tremaining: 36.5ms\n",
            "97:\tlearn: 0.3363407\ttotal: 1.19s\tremaining: 24.4ms\n",
            "98:\tlearn: 0.3346450\ttotal: 1.21s\tremaining: 12.2ms\n",
            "99:\tlearn: 0.3326285\ttotal: 1.22s\tremaining: 0us\n",
            "0:\tlearn: 1.1732308\ttotal: 13.1ms\tremaining: 1.29s\n",
            "1:\tlearn: 1.1363514\ttotal: 26ms\tremaining: 1.27s\n",
            "2:\tlearn: 1.0988508\ttotal: 38.6ms\tremaining: 1.25s\n",
            "3:\tlearn: 1.0682952\ttotal: 51.5ms\tremaining: 1.24s\n",
            "4:\tlearn: 1.0369489\ttotal: 64.4ms\tremaining: 1.22s\n",
            "5:\tlearn: 1.0066190\ttotal: 77ms\tremaining: 1.21s\n",
            "6:\tlearn: 0.9777206\ttotal: 95.5ms\tremaining: 1.27s\n",
            "7:\tlearn: 0.9489114\ttotal: 117ms\tremaining: 1.34s\n",
            "8:\tlearn: 0.9211139\ttotal: 129ms\tremaining: 1.3s\n",
            "9:\tlearn: 0.8936276\ttotal: 132ms\tremaining: 1.19s\n",
            "10:\tlearn: 0.8690029\ttotal: 145ms\tremaining: 1.17s\n",
            "11:\tlearn: 0.8451580\ttotal: 157ms\tremaining: 1.15s\n",
            "12:\tlearn: 0.8225518\ttotal: 171ms\tremaining: 1.14s\n",
            "13:\tlearn: 0.8017962\ttotal: 183ms\tremaining: 1.13s\n",
            "14:\tlearn: 0.7799529\ttotal: 190ms\tremaining: 1.08s\n",
            "15:\tlearn: 0.7631187\ttotal: 203ms\tremaining: 1.06s\n",
            "16:\tlearn: 0.7448100\ttotal: 216ms\tremaining: 1.05s\n",
            "17:\tlearn: 0.7283063\ttotal: 217ms\tremaining: 990ms\n",
            "18:\tlearn: 0.7110279\ttotal: 231ms\tremaining: 984ms\n",
            "19:\tlearn: 0.6956466\ttotal: 234ms\tremaining: 935ms\n",
            "20:\tlearn: 0.6812351\ttotal: 247ms\tremaining: 928ms\n",
            "21:\tlearn: 0.6671435\ttotal: 248ms\tremaining: 879ms\n",
            "22:\tlearn: 0.6542583\ttotal: 261ms\tremaining: 875ms\n",
            "23:\tlearn: 0.6412960\ttotal: 274ms\tremaining: 869ms\n",
            "24:\tlearn: 0.6290119\ttotal: 288ms\tremaining: 863ms\n",
            "25:\tlearn: 0.6173102\ttotal: 312ms\tremaining: 889ms\n",
            "26:\tlearn: 0.6056841\ttotal: 326ms\tremaining: 881ms\n",
            "27:\tlearn: 0.5962667\ttotal: 329ms\tremaining: 845ms\n",
            "28:\tlearn: 0.5857311\ttotal: 342ms\tremaining: 838ms\n",
            "29:\tlearn: 0.5757804\ttotal: 344ms\tremaining: 804ms\n",
            "30:\tlearn: 0.5662900\ttotal: 357ms\tremaining: 795ms\n",
            "31:\tlearn: 0.5566301\ttotal: 370ms\tremaining: 785ms\n",
            "32:\tlearn: 0.5479878\ttotal: 382ms\tremaining: 776ms\n",
            "33:\tlearn: 0.5394510\ttotal: 395ms\tremaining: 767ms\n",
            "34:\tlearn: 0.5317815\ttotal: 408ms\tremaining: 757ms\n",
            "35:\tlearn: 0.5241555\ttotal: 427ms\tremaining: 759ms\n",
            "36:\tlearn: 0.5168023\ttotal: 447ms\tremaining: 760ms\n",
            "37:\tlearn: 0.5099558\ttotal: 459ms\tremaining: 749ms\n",
            "38:\tlearn: 0.5034794\ttotal: 472ms\tremaining: 738ms\n",
            "39:\tlearn: 0.4971271\ttotal: 485ms\tremaining: 727ms\n",
            "40:\tlearn: 0.4917808\ttotal: 498ms\tremaining: 716ms\n",
            "41:\tlearn: 0.4862985\ttotal: 514ms\tremaining: 710ms\n",
            "42:\tlearn: 0.4819912\ttotal: 517ms\tremaining: 685ms\n",
            "43:\tlearn: 0.4764327\ttotal: 535ms\tremaining: 680ms\n",
            "44:\tlearn: 0.4721467\ttotal: 536ms\tremaining: 655ms\n",
            "45:\tlearn: 0.4675097\ttotal: 548ms\tremaining: 643ms\n",
            "46:\tlearn: 0.4636195\ttotal: 550ms\tremaining: 620ms\n",
            "47:\tlearn: 0.4590744\ttotal: 562ms\tremaining: 609ms\n",
            "48:\tlearn: 0.4547267\ttotal: 574ms\tremaining: 598ms\n",
            "49:\tlearn: 0.4502971\ttotal: 587ms\tremaining: 587ms\n",
            "50:\tlearn: 0.4465863\ttotal: 599ms\tremaining: 576ms\n",
            "51:\tlearn: 0.4426308\ttotal: 611ms\tremaining: 564ms\n",
            "52:\tlearn: 0.4385551\ttotal: 624ms\tremaining: 553ms\n",
            "53:\tlearn: 0.4360724\ttotal: 625ms\tremaining: 532ms\n",
            "54:\tlearn: 0.4320951\ttotal: 638ms\tremaining: 522ms\n",
            "55:\tlearn: 0.4282790\ttotal: 650ms\tremaining: 511ms\n",
            "56:\tlearn: 0.4250918\ttotal: 662ms\tremaining: 500ms\n",
            "57:\tlearn: 0.4214000\ttotal: 675ms\tremaining: 488ms\n",
            "58:\tlearn: 0.4181381\ttotal: 687ms\tremaining: 477ms\n",
            "59:\tlearn: 0.4144904\ttotal: 699ms\tremaining: 466ms\n",
            "60:\tlearn: 0.4109833\ttotal: 711ms\tremaining: 455ms\n",
            "61:\tlearn: 0.4083574\ttotal: 733ms\tremaining: 449ms\n",
            "62:\tlearn: 0.4052864\ttotal: 745ms\tremaining: 438ms\n",
            "63:\tlearn: 0.4025924\ttotal: 758ms\tremaining: 426ms\n",
            "64:\tlearn: 0.4000521\ttotal: 775ms\tremaining: 417ms\n",
            "65:\tlearn: 0.3976357\ttotal: 790ms\tremaining: 407ms\n",
            "66:\tlearn: 0.3963592\ttotal: 791ms\tremaining: 390ms\n",
            "67:\tlearn: 0.3936364\ttotal: 805ms\tremaining: 379ms\n",
            "68:\tlearn: 0.3908549\ttotal: 818ms\tremaining: 367ms\n",
            "69:\tlearn: 0.3881519\ttotal: 830ms\tremaining: 356ms\n",
            "70:\tlearn: 0.3858147\ttotal: 843ms\tremaining: 344ms\n",
            "71:\tlearn: 0.3832152\ttotal: 855ms\tremaining: 333ms\n",
            "72:\tlearn: 0.3811320\ttotal: 868ms\tremaining: 321ms\n",
            "73:\tlearn: 0.3786927\ttotal: 880ms\tremaining: 309ms\n",
            "74:\tlearn: 0.3766078\ttotal: 893ms\tremaining: 298ms\n",
            "75:\tlearn: 0.3745241\ttotal: 905ms\tremaining: 286ms\n",
            "76:\tlearn: 0.3719404\ttotal: 917ms\tremaining: 274ms\n",
            "77:\tlearn: 0.3701990\ttotal: 932ms\tremaining: 263ms\n",
            "78:\tlearn: 0.3683030\ttotal: 953ms\tremaining: 253ms\n",
            "79:\tlearn: 0.3667372\ttotal: 965ms\tremaining: 241ms\n",
            "80:\tlearn: 0.3651618\ttotal: 977ms\tremaining: 229ms\n",
            "81:\tlearn: 0.3628145\ttotal: 990ms\tremaining: 217ms\n",
            "82:\tlearn: 0.3608006\ttotal: 1s\tremaining: 205ms\n",
            "83:\tlearn: 0.3587336\ttotal: 1.01s\tremaining: 193ms\n",
            "84:\tlearn: 0.3568581\ttotal: 1.03s\tremaining: 181ms\n",
            "85:\tlearn: 0.3550968\ttotal: 1.04s\tremaining: 169ms\n",
            "86:\tlearn: 0.3531152\ttotal: 1.05s\tremaining: 157ms\n",
            "87:\tlearn: 0.3517154\ttotal: 1.07s\tremaining: 146ms\n",
            "88:\tlearn: 0.3500951\ttotal: 1.08s\tremaining: 134ms\n",
            "89:\tlearn: 0.3487025\ttotal: 1.09s\tremaining: 122ms\n",
            "90:\tlearn: 0.3466680\ttotal: 1.11s\tremaining: 109ms\n",
            "91:\tlearn: 0.3450908\ttotal: 1.12s\tremaining: 97.3ms\n",
            "92:\tlearn: 0.3435667\ttotal: 1.14s\tremaining: 85.6ms\n",
            "93:\tlearn: 0.3421620\ttotal: 1.16s\tremaining: 73.9ms\n",
            "94:\tlearn: 0.3407672\ttotal: 1.17s\tremaining: 61.6ms\n",
            "95:\tlearn: 0.3397053\ttotal: 1.18s\tremaining: 49.3ms\n",
            "96:\tlearn: 0.3380475\ttotal: 1.19s\tremaining: 37ms\n",
            "97:\tlearn: 0.3366054\ttotal: 1.21s\tremaining: 24.6ms\n",
            "98:\tlearn: 0.3357093\ttotal: 1.22s\tremaining: 12.3ms\n",
            "99:\tlearn: 0.3342569\ttotal: 1.23s\tremaining: 0us\n",
            "0:\tlearn: 1.0888842\ttotal: 12.6ms\tremaining: 1.25s\n",
            "1:\tlearn: 1.0555332\ttotal: 24.9ms\tremaining: 1.22s\n",
            "2:\tlearn: 1.0229894\ttotal: 37.7ms\tremaining: 1.22s\n",
            "3:\tlearn: 0.9961431\ttotal: 50.1ms\tremaining: 1.2s\n",
            "4:\tlearn: 0.9654376\ttotal: 56.4ms\tremaining: 1.07s\n",
            "5:\tlearn: 0.9383076\ttotal: 76.5ms\tremaining: 1.2s\n",
            "6:\tlearn: 0.9122336\ttotal: 89.1ms\tremaining: 1.18s\n",
            "7:\tlearn: 0.8883516\ttotal: 101ms\tremaining: 1.16s\n",
            "8:\tlearn: 0.8627718\ttotal: 113ms\tremaining: 1.14s\n",
            "9:\tlearn: 0.8390155\ttotal: 119ms\tremaining: 1.07s\n",
            "10:\tlearn: 0.8167164\ttotal: 131ms\tremaining: 1.06s\n",
            "11:\tlearn: 0.7944083\ttotal: 154ms\tremaining: 1.13s\n",
            "12:\tlearn: 0.7736219\ttotal: 168ms\tremaining: 1.12s\n",
            "13:\tlearn: 0.7541395\ttotal: 180ms\tremaining: 1.1s\n",
            "14:\tlearn: 0.7365763\ttotal: 186ms\tremaining: 1.05s\n",
            "15:\tlearn: 0.7208330\ttotal: 200ms\tremaining: 1.05s\n",
            "16:\tlearn: 0.7052673\ttotal: 215ms\tremaining: 1.05s\n",
            "17:\tlearn: 0.6885323\ttotal: 226ms\tremaining: 1.03s\n",
            "18:\tlearn: 0.6729544\ttotal: 238ms\tremaining: 1.01s\n",
            "19:\tlearn: 0.6580666\ttotal: 250ms\tremaining: 1s\n",
            "20:\tlearn: 0.6444465\ttotal: 262ms\tremaining: 987ms\n",
            "21:\tlearn: 0.6310561\ttotal: 287ms\tremaining: 1.02s\n",
            "22:\tlearn: 0.6178219\ttotal: 300ms\tremaining: 1s\n",
            "23:\tlearn: 0.6055862\ttotal: 312ms\tremaining: 990ms\n",
            "24:\tlearn: 0.5946469\ttotal: 316ms\tremaining: 948ms\n",
            "25:\tlearn: 0.5846114\ttotal: 327ms\tremaining: 932ms\n",
            "26:\tlearn: 0.5755183\ttotal: 339ms\tremaining: 917ms\n",
            "27:\tlearn: 0.5666772\ttotal: 351ms\tremaining: 902ms\n",
            "28:\tlearn: 0.5568225\ttotal: 363ms\tremaining: 888ms\n",
            "29:\tlearn: 0.5482042\ttotal: 365ms\tremaining: 851ms\n",
            "30:\tlearn: 0.5395614\ttotal: 377ms\tremaining: 839ms\n",
            "31:\tlearn: 0.5312850\ttotal: 391ms\tremaining: 831ms\n",
            "32:\tlearn: 0.5240757\ttotal: 403ms\tremaining: 819ms\n",
            "33:\tlearn: 0.5176245\ttotal: 416ms\tremaining: 807ms\n",
            "34:\tlearn: 0.5109213\ttotal: 428ms\tremaining: 794ms\n",
            "35:\tlearn: 0.5041191\ttotal: 442ms\tremaining: 786ms\n",
            "36:\tlearn: 0.4974223\ttotal: 454ms\tremaining: 773ms\n",
            "37:\tlearn: 0.4912875\ttotal: 466ms\tremaining: 760ms\n",
            "38:\tlearn: 0.4859505\ttotal: 478ms\tremaining: 747ms\n",
            "39:\tlearn: 0.4810181\ttotal: 501ms\tremaining: 752ms\n",
            "40:\tlearn: 0.4760778\ttotal: 506ms\tremaining: 728ms\n",
            "41:\tlearn: 0.4701744\ttotal: 521ms\tremaining: 719ms\n",
            "42:\tlearn: 0.4655024\ttotal: 535ms\tremaining: 709ms\n",
            "43:\tlearn: 0.4602171\ttotal: 547ms\tremaining: 696ms\n",
            "44:\tlearn: 0.4560809\ttotal: 559ms\tremaining: 683ms\n",
            "45:\tlearn: 0.4515724\ttotal: 566ms\tremaining: 664ms\n",
            "46:\tlearn: 0.4477672\ttotal: 578ms\tremaining: 652ms\n",
            "47:\tlearn: 0.4440367\ttotal: 582ms\tremaining: 630ms\n",
            "48:\tlearn: 0.4400263\ttotal: 594ms\tremaining: 618ms\n",
            "49:\tlearn: 0.4365134\ttotal: 607ms\tremaining: 607ms\n",
            "50:\tlearn: 0.4319824\ttotal: 619ms\tremaining: 595ms\n",
            "51:\tlearn: 0.4286426\ttotal: 623ms\tremaining: 575ms\n",
            "52:\tlearn: 0.4254351\ttotal: 635ms\tremaining: 564ms\n",
            "53:\tlearn: 0.4216438\ttotal: 648ms\tremaining: 552ms\n",
            "54:\tlearn: 0.4182956\ttotal: 660ms\tremaining: 540ms\n",
            "55:\tlearn: 0.4154524\ttotal: 672ms\tremaining: 528ms\n",
            "56:\tlearn: 0.4125417\ttotal: 685ms\tremaining: 517ms\n",
            "57:\tlearn: 0.4089904\ttotal: 698ms\tremaining: 506ms\n",
            "58:\tlearn: 0.4055571\ttotal: 719ms\tremaining: 499ms\n",
            "59:\tlearn: 0.4029355\ttotal: 732ms\tremaining: 488ms\n",
            "60:\tlearn: 0.4007719\ttotal: 744ms\tremaining: 476ms\n",
            "61:\tlearn: 0.3976761\ttotal: 759ms\tremaining: 465ms\n",
            "62:\tlearn: 0.3946392\ttotal: 772ms\tremaining: 453ms\n",
            "63:\tlearn: 0.3914942\ttotal: 784ms\tremaining: 441ms\n",
            "64:\tlearn: 0.3885526\ttotal: 796ms\tremaining: 429ms\n",
            "65:\tlearn: 0.3868049\ttotal: 799ms\tremaining: 412ms\n",
            "66:\tlearn: 0.3851489\ttotal: 802ms\tremaining: 395ms\n",
            "67:\tlearn: 0.3832950\ttotal: 815ms\tremaining: 383ms\n",
            "68:\tlearn: 0.3807027\ttotal: 827ms\tremaining: 372ms\n",
            "69:\tlearn: 0.3779742\ttotal: 839ms\tremaining: 360ms\n",
            "70:\tlearn: 0.3756859\ttotal: 852ms\tremaining: 348ms\n",
            "71:\tlearn: 0.3730989\ttotal: 868ms\tremaining: 338ms\n",
            "72:\tlearn: 0.3713348\ttotal: 881ms\tremaining: 326ms\n",
            "73:\tlearn: 0.3692039\ttotal: 893ms\tremaining: 314ms\n",
            "74:\tlearn: 0.3673503\ttotal: 912ms\tremaining: 304ms\n",
            "75:\tlearn: 0.3654784\ttotal: 935ms\tremaining: 295ms\n",
            "76:\tlearn: 0.3635884\ttotal: 947ms\tremaining: 283ms\n",
            "77:\tlearn: 0.3615638\ttotal: 959ms\tremaining: 270ms\n",
            "78:\tlearn: 0.3596734\ttotal: 970ms\tremaining: 258ms\n",
            "79:\tlearn: 0.3578453\ttotal: 982ms\tremaining: 245ms\n",
            "80:\tlearn: 0.3559849\ttotal: 994ms\tremaining: 233ms\n",
            "81:\tlearn: 0.3544160\ttotal: 1s\tremaining: 221ms\n",
            "82:\tlearn: 0.3527000\ttotal: 1.02s\tremaining: 208ms\n",
            "83:\tlearn: 0.3514303\ttotal: 1.03s\tremaining: 196ms\n",
            "84:\tlearn: 0.3500743\ttotal: 1.04s\tremaining: 184ms\n",
            "85:\tlearn: 0.3484123\ttotal: 1.05s\tremaining: 171ms\n",
            "86:\tlearn: 0.3467313\ttotal: 1.06s\tremaining: 159ms\n",
            "87:\tlearn: 0.3461741\ttotal: 1.06s\tremaining: 145ms\n",
            "88:\tlearn: 0.3442263\ttotal: 1.08s\tremaining: 133ms\n",
            "89:\tlearn: 0.3425348\ttotal: 1.09s\tremaining: 121ms\n",
            "90:\tlearn: 0.3408821\ttotal: 1.1s\tremaining: 109ms\n",
            "91:\tlearn: 0.3390773\ttotal: 1.11s\tremaining: 97ms\n",
            "92:\tlearn: 0.3377482\ttotal: 1.14s\tremaining: 85.9ms\n",
            "93:\tlearn: 0.3362832\ttotal: 1.15s\tremaining: 73.5ms\n",
            "94:\tlearn: 0.3346289\ttotal: 1.16s\tremaining: 61.2ms\n",
            "95:\tlearn: 0.3330359\ttotal: 1.17s\tremaining: 48.9ms\n",
            "96:\tlearn: 0.3312976\ttotal: 1.18s\tremaining: 36.6ms\n",
            "97:\tlearn: 0.3300141\ttotal: 1.2s\tremaining: 24.4ms\n",
            "98:\tlearn: 0.3288063\ttotal: 1.21s\tremaining: 12.3ms\n",
            "99:\tlearn: 0.3272080\ttotal: 1.23s\tremaining: 0us\n",
            "0:\tlearn: 1.1478826\ttotal: 14.3ms\tremaining: 1.42s\n",
            "1:\tlearn: 1.1127509\ttotal: 25.8ms\tremaining: 1.27s\n",
            "2:\tlearn: 1.0792044\ttotal: 37.3ms\tremaining: 1.2s\n",
            "3:\tlearn: 1.0487522\ttotal: 48.7ms\tremaining: 1.17s\n",
            "4:\tlearn: 1.0158845\ttotal: 51.1ms\tremaining: 971ms\n",
            "5:\tlearn: 0.9860428\ttotal: 74.7ms\tremaining: 1.17s\n",
            "6:\tlearn: 0.9574755\ttotal: 86.1ms\tremaining: 1.14s\n",
            "7:\tlearn: 0.9299491\ttotal: 97.2ms\tremaining: 1.12s\n",
            "8:\tlearn: 0.9038732\ttotal: 109ms\tremaining: 1.1s\n",
            "9:\tlearn: 0.8775382\ttotal: 110ms\tremaining: 990ms\n",
            "10:\tlearn: 0.8521467\ttotal: 121ms\tremaining: 982ms\n",
            "11:\tlearn: 0.8290482\ttotal: 124ms\tremaining: 907ms\n",
            "12:\tlearn: 0.8074516\ttotal: 135ms\tremaining: 902ms\n",
            "13:\tlearn: 0.7859029\ttotal: 137ms\tremaining: 842ms\n",
            "14:\tlearn: 0.7677132\ttotal: 148ms\tremaining: 840ms\n",
            "15:\tlearn: 0.7493566\ttotal: 159ms\tremaining: 837ms\n",
            "16:\tlearn: 0.7328343\ttotal: 171ms\tremaining: 833ms\n",
            "17:\tlearn: 0.7162965\ttotal: 182ms\tremaining: 827ms\n",
            "18:\tlearn: 0.6991579\ttotal: 193ms\tremaining: 821ms\n",
            "19:\tlearn: 0.6846931\ttotal: 205ms\tremaining: 819ms\n",
            "20:\tlearn: 0.6693093\ttotal: 207ms\tremaining: 779ms\n",
            "21:\tlearn: 0.6557481\ttotal: 218ms\tremaining: 774ms\n",
            "22:\tlearn: 0.6412132\ttotal: 230ms\tremaining: 769ms\n",
            "23:\tlearn: 0.6277871\ttotal: 241ms\tremaining: 763ms\n",
            "24:\tlearn: 0.6161135\ttotal: 259ms\tremaining: 777ms\n",
            "25:\tlearn: 0.6056290\ttotal: 271ms\tremaining: 771ms\n",
            "26:\tlearn: 0.5948910\ttotal: 284ms\tremaining: 769ms\n",
            "27:\tlearn: 0.5845726\ttotal: 296ms\tremaining: 761ms\n",
            "28:\tlearn: 0.5750095\ttotal: 307ms\tremaining: 752ms\n",
            "29:\tlearn: 0.5652776\ttotal: 318ms\tremaining: 742ms\n",
            "30:\tlearn: 0.5553920\ttotal: 330ms\tremaining: 734ms\n",
            "31:\tlearn: 0.5468465\ttotal: 341ms\tremaining: 724ms\n",
            "32:\tlearn: 0.5385676\ttotal: 352ms\tremaining: 715ms\n",
            "33:\tlearn: 0.5302411\ttotal: 364ms\tremaining: 706ms\n",
            "34:\tlearn: 0.5228218\ttotal: 375ms\tremaining: 697ms\n",
            "35:\tlearn: 0.5162832\ttotal: 387ms\tremaining: 687ms\n",
            "36:\tlearn: 0.5085813\ttotal: 393ms\tremaining: 669ms\n",
            "37:\tlearn: 0.5001470\ttotal: 404ms\tremaining: 659ms\n",
            "38:\tlearn: 0.4939664\ttotal: 415ms\tremaining: 650ms\n",
            "39:\tlearn: 0.4871048\ttotal: 427ms\tremaining: 640ms\n",
            "40:\tlearn: 0.4815688\ttotal: 438ms\tremaining: 630ms\n",
            "41:\tlearn: 0.4761394\ttotal: 449ms\tremaining: 620ms\n",
            "42:\tlearn: 0.4711783\ttotal: 452ms\tremaining: 600ms\n",
            "43:\tlearn: 0.4663253\ttotal: 474ms\tremaining: 604ms\n",
            "44:\tlearn: 0.4611090\ttotal: 485ms\tremaining: 593ms\n",
            "45:\tlearn: 0.4557821\ttotal: 496ms\tremaining: 582ms\n",
            "46:\tlearn: 0.4512934\ttotal: 499ms\tremaining: 563ms\n",
            "47:\tlearn: 0.4463368\ttotal: 510ms\tremaining: 552ms\n",
            "48:\tlearn: 0.4416529\ttotal: 520ms\tremaining: 541ms\n",
            "49:\tlearn: 0.4377599\ttotal: 531ms\tremaining: 531ms\n",
            "50:\tlearn: 0.4332849\ttotal: 542ms\tremaining: 520ms\n",
            "51:\tlearn: 0.4288717\ttotal: 553ms\tremaining: 510ms\n",
            "52:\tlearn: 0.4253923\ttotal: 563ms\tremaining: 499ms\n",
            "53:\tlearn: 0.4205547\ttotal: 574ms\tremaining: 489ms\n",
            "54:\tlearn: 0.4167228\ttotal: 585ms\tremaining: 479ms\n",
            "55:\tlearn: 0.4133536\ttotal: 596ms\tremaining: 468ms\n",
            "56:\tlearn: 0.4102225\ttotal: 610ms\tremaining: 460ms\n",
            "57:\tlearn: 0.4068049\ttotal: 622ms\tremaining: 450ms\n",
            "58:\tlearn: 0.4036695\ttotal: 633ms\tremaining: 440ms\n",
            "59:\tlearn: 0.4009305\ttotal: 644ms\tremaining: 429ms\n",
            "60:\tlearn: 0.3979967\ttotal: 655ms\tremaining: 419ms\n",
            "61:\tlearn: 0.3948031\ttotal: 671ms\tremaining: 411ms\n",
            "62:\tlearn: 0.3913839\ttotal: 688ms\tremaining: 404ms\n",
            "63:\tlearn: 0.3883243\ttotal: 700ms\tremaining: 394ms\n",
            "64:\tlearn: 0.3856530\ttotal: 712ms\tremaining: 383ms\n",
            "65:\tlearn: 0.3836030\ttotal: 713ms\tremaining: 367ms\n",
            "66:\tlearn: 0.3806821\ttotal: 725ms\tremaining: 357ms\n",
            "67:\tlearn: 0.3781675\ttotal: 737ms\tremaining: 347ms\n",
            "68:\tlearn: 0.3755047\ttotal: 749ms\tremaining: 337ms\n",
            "69:\tlearn: 0.3733087\ttotal: 762ms\tremaining: 326ms\n",
            "70:\tlearn: 0.3710154\ttotal: 774ms\tremaining: 316ms\n",
            "71:\tlearn: 0.3691915\ttotal: 787ms\tremaining: 306ms\n",
            "72:\tlearn: 0.3676780\ttotal: 789ms\tremaining: 292ms\n",
            "73:\tlearn: 0.3651825\ttotal: 801ms\tremaining: 281ms\n",
            "74:\tlearn: 0.3624630\ttotal: 813ms\tremaining: 271ms\n",
            "75:\tlearn: 0.3603828\ttotal: 826ms\tremaining: 261ms\n",
            "76:\tlearn: 0.3588316\ttotal: 838ms\tremaining: 250ms\n",
            "77:\tlearn: 0.3569753\ttotal: 861ms\tremaining: 243ms\n",
            "78:\tlearn: 0.3552243\ttotal: 885ms\tremaining: 235ms\n",
            "79:\tlearn: 0.3541055\ttotal: 891ms\tremaining: 223ms\n",
            "80:\tlearn: 0.3519897\ttotal: 903ms\tremaining: 212ms\n",
            "81:\tlearn: 0.3504909\ttotal: 906ms\tremaining: 199ms\n",
            "82:\tlearn: 0.3490743\ttotal: 918ms\tremaining: 188ms\n",
            "83:\tlearn: 0.3474518\ttotal: 930ms\tremaining: 177ms\n",
            "84:\tlearn: 0.3454395\ttotal: 947ms\tremaining: 167ms\n",
            "85:\tlearn: 0.3432369\ttotal: 959ms\tremaining: 156ms\n",
            "86:\tlearn: 0.3425981\ttotal: 960ms\tremaining: 144ms\n",
            "87:\tlearn: 0.3409221\ttotal: 972ms\tremaining: 133ms\n",
            "88:\tlearn: 0.3393011\ttotal: 984ms\tremaining: 122ms\n",
            "89:\tlearn: 0.3373129\ttotal: 997ms\tremaining: 111ms\n",
            "90:\tlearn: 0.3358402\ttotal: 1.01s\tremaining: 99.8ms\n",
            "91:\tlearn: 0.3340535\ttotal: 1.02s\tremaining: 88.8ms\n",
            "92:\tlearn: 0.3327044\ttotal: 1.03s\tremaining: 77.8ms\n",
            "93:\tlearn: 0.3310660\ttotal: 1.04s\tremaining: 66.7ms\n",
            "94:\tlearn: 0.3294688\ttotal: 1.06s\tremaining: 55.7ms\n",
            "95:\tlearn: 0.3277840\ttotal: 1.07s\tremaining: 44.6ms\n",
            "96:\tlearn: 0.3263607\ttotal: 1.08s\tremaining: 33.6ms\n",
            "97:\tlearn: 0.3250006\ttotal: 1.1s\tremaining: 22.5ms\n",
            "98:\tlearn: 0.3235250\ttotal: 1.11s\tremaining: 11.3ms\n",
            "99:\tlearn: 0.3222401\ttotal: 1.13s\tremaining: 0us\n",
            "0:\tlearn: 1.1222901\ttotal: 57.4ms\tremaining: 5.69s\n",
            "1:\tlearn: 1.0556293\ttotal: 82.5ms\tremaining: 4.04s\n",
            "2:\tlearn: 0.9938204\ttotal: 101ms\tremaining: 3.27s\n",
            "3:\tlearn: 0.9418970\ttotal: 127ms\tremaining: 3.04s\n",
            "4:\tlearn: 0.8882246\ttotal: 132ms\tremaining: 2.51s\n",
            "5:\tlearn: 0.8374233\ttotal: 137ms\tremaining: 2.14s\n",
            "6:\tlearn: 0.7954464\ttotal: 162ms\tremaining: 2.15s\n",
            "7:\tlearn: 0.7584911\ttotal: 205ms\tremaining: 2.36s\n",
            "8:\tlearn: 0.7223788\ttotal: 242ms\tremaining: 2.45s\n",
            "9:\tlearn: 0.6888904\ttotal: 267ms\tremaining: 2.4s\n",
            "10:\tlearn: 0.6619785\ttotal: 293ms\tremaining: 2.37s\n",
            "11:\tlearn: 0.6383678\ttotal: 324ms\tremaining: 2.38s\n",
            "12:\tlearn: 0.6130988\ttotal: 351ms\tremaining: 2.35s\n",
            "13:\tlearn: 0.5929996\ttotal: 397ms\tremaining: 2.44s\n",
            "14:\tlearn: 0.5745404\ttotal: 413ms\tremaining: 2.34s\n",
            "15:\tlearn: 0.5575266\ttotal: 438ms\tremaining: 2.3s\n",
            "16:\tlearn: 0.5405637\ttotal: 459ms\tremaining: 2.24s\n",
            "17:\tlearn: 0.5255076\ttotal: 497ms\tremaining: 2.26s\n",
            "18:\tlearn: 0.5128573\ttotal: 514ms\tremaining: 2.19s\n",
            "19:\tlearn: 0.4974932\ttotal: 550ms\tremaining: 2.2s\n",
            "20:\tlearn: 0.4850916\ttotal: 567ms\tremaining: 2.13s\n",
            "21:\tlearn: 0.4729518\ttotal: 584ms\tremaining: 2.07s\n",
            "22:\tlearn: 0.4606799\ttotal: 604ms\tremaining: 2.02s\n",
            "23:\tlearn: 0.4527266\ttotal: 636ms\tremaining: 2.01s\n",
            "24:\tlearn: 0.4439238\ttotal: 650ms\tremaining: 1.95s\n",
            "25:\tlearn: 0.4356466\ttotal: 678ms\tremaining: 1.93s\n",
            "26:\tlearn: 0.4303323\ttotal: 693ms\tremaining: 1.87s\n",
            "27:\tlearn: 0.4238449\ttotal: 728ms\tremaining: 1.87s\n",
            "28:\tlearn: 0.4183272\ttotal: 731ms\tremaining: 1.79s\n",
            "29:\tlearn: 0.4115548\ttotal: 750ms\tremaining: 1.75s\n",
            "30:\tlearn: 0.4051441\ttotal: 776ms\tremaining: 1.73s\n",
            "31:\tlearn: 0.4003581\ttotal: 816ms\tremaining: 1.73s\n",
            "32:\tlearn: 0.3941713\ttotal: 854ms\tremaining: 1.73s\n",
            "33:\tlearn: 0.3885056\ttotal: 870ms\tremaining: 1.69s\n",
            "34:\tlearn: 0.3840441\ttotal: 886ms\tremaining: 1.65s\n",
            "35:\tlearn: 0.3797245\ttotal: 914ms\tremaining: 1.62s\n",
            "36:\tlearn: 0.3750371\ttotal: 932ms\tremaining: 1.59s\n",
            "37:\tlearn: 0.3717678\ttotal: 954ms\tremaining: 1.55s\n",
            "38:\tlearn: 0.3680942\ttotal: 973ms\tremaining: 1.52s\n",
            "39:\tlearn: 0.3653413\ttotal: 996ms\tremaining: 1.49s\n",
            "40:\tlearn: 0.3620750\ttotal: 1.01s\tremaining: 1.46s\n",
            "41:\tlearn: 0.3591384\ttotal: 1.04s\tremaining: 1.43s\n",
            "42:\tlearn: 0.3559487\ttotal: 1.07s\tremaining: 1.42s\n",
            "43:\tlearn: 0.3528250\ttotal: 1.11s\tremaining: 1.41s\n",
            "44:\tlearn: 0.3518905\ttotal: 1.11s\tremaining: 1.36s\n",
            "45:\tlearn: 0.3482961\ttotal: 1.15s\tremaining: 1.35s\n",
            "46:\tlearn: 0.3455074\ttotal: 1.2s\tremaining: 1.35s\n",
            "47:\tlearn: 0.3419876\ttotal: 1.24s\tremaining: 1.34s\n",
            "48:\tlearn: 0.3398087\ttotal: 1.27s\tremaining: 1.32s\n",
            "49:\tlearn: 0.3362310\ttotal: 1.29s\tremaining: 1.29s\n",
            "50:\tlearn: 0.3336715\ttotal: 1.32s\tremaining: 1.27s\n",
            "51:\tlearn: 0.3309935\ttotal: 1.35s\tremaining: 1.24s\n",
            "52:\tlearn: 0.3288818\ttotal: 1.39s\tremaining: 1.23s\n",
            "53:\tlearn: 0.3273064\ttotal: 1.42s\tremaining: 1.21s\n",
            "54:\tlearn: 0.3241522\ttotal: 1.48s\tremaining: 1.21s\n",
            "55:\tlearn: 0.3218771\ttotal: 1.49s\tremaining: 1.17s\n",
            "56:\tlearn: 0.3186256\ttotal: 1.51s\tremaining: 1.14s\n",
            "57:\tlearn: 0.3164202\ttotal: 1.52s\tremaining: 1.1s\n",
            "58:\tlearn: 0.3133603\ttotal: 1.54s\tremaining: 1.07s\n",
            "59:\tlearn: 0.3120919\ttotal: 1.56s\tremaining: 1.04s\n",
            "60:\tlearn: 0.3098671\ttotal: 1.59s\tremaining: 1.02s\n",
            "61:\tlearn: 0.3051203\ttotal: 1.61s\tremaining: 990ms\n",
            "62:\tlearn: 0.3022987\ttotal: 1.64s\tremaining: 964ms\n",
            "63:\tlearn: 0.2998076\ttotal: 1.67s\tremaining: 939ms\n",
            "64:\tlearn: 0.2972203\ttotal: 1.7s\tremaining: 917ms\n",
            "65:\tlearn: 0.2952959\ttotal: 1.73s\tremaining: 889ms\n",
            "66:\tlearn: 0.2935443\ttotal: 1.76s\tremaining: 866ms\n",
            "67:\tlearn: 0.2900222\ttotal: 1.79s\tremaining: 841ms\n",
            "68:\tlearn: 0.2875087\ttotal: 1.82s\tremaining: 819ms\n",
            "69:\tlearn: 0.2852262\ttotal: 1.87s\tremaining: 803ms\n",
            "70:\tlearn: 0.2825362\ttotal: 1.92s\tremaining: 784ms\n",
            "71:\tlearn: 0.2801229\ttotal: 1.96s\tremaining: 761ms\n",
            "72:\tlearn: 0.2775588\ttotal: 2s\tremaining: 739ms\n",
            "73:\tlearn: 0.2753553\ttotal: 2.05s\tremaining: 720ms\n",
            "74:\tlearn: 0.2740481\ttotal: 2.09s\tremaining: 695ms\n",
            "75:\tlearn: 0.2720268\ttotal: 2.13s\tremaining: 672ms\n",
            "76:\tlearn: 0.2702311\ttotal: 2.18s\tremaining: 652ms\n",
            "77:\tlearn: 0.2688163\ttotal: 2.22s\tremaining: 626ms\n",
            "78:\tlearn: 0.2672082\ttotal: 2.23s\tremaining: 594ms\n",
            "79:\tlearn: 0.2655814\ttotal: 2.26s\tremaining: 565ms\n",
            "80:\tlearn: 0.2639577\ttotal: 2.28s\tremaining: 536ms\n",
            "81:\tlearn: 0.2622659\ttotal: 2.31s\tremaining: 506ms\n",
            "82:\tlearn: 0.2611364\ttotal: 2.34s\tremaining: 479ms\n",
            "83:\tlearn: 0.2598812\ttotal: 2.36s\tremaining: 450ms\n",
            "84:\tlearn: 0.2587583\ttotal: 2.39s\tremaining: 421ms\n",
            "85:\tlearn: 0.2571492\ttotal: 2.43s\tremaining: 396ms\n",
            "86:\tlearn: 0.2551750\ttotal: 2.46s\tremaining: 367ms\n",
            "87:\tlearn: 0.2536672\ttotal: 2.49s\tremaining: 339ms\n",
            "88:\tlearn: 0.2521213\ttotal: 2.52s\tremaining: 311ms\n",
            "89:\tlearn: 0.2504153\ttotal: 2.54s\tremaining: 283ms\n",
            "90:\tlearn: 0.2474117\ttotal: 2.57s\tremaining: 254ms\n",
            "91:\tlearn: 0.2452915\ttotal: 2.6s\tremaining: 226ms\n",
            "92:\tlearn: 0.2437055\ttotal: 2.61s\tremaining: 197ms\n",
            "93:\tlearn: 0.2422105\ttotal: 2.66s\tremaining: 170ms\n",
            "94:\tlearn: 0.2405535\ttotal: 2.68s\tremaining: 141ms\n",
            "95:\tlearn: 0.2383163\ttotal: 2.7s\tremaining: 112ms\n",
            "96:\tlearn: 0.2365938\ttotal: 2.71s\tremaining: 83.9ms\n",
            "97:\tlearn: 0.2352498\ttotal: 2.74s\tremaining: 55.9ms\n",
            "98:\tlearn: 0.2344544\ttotal: 2.76s\tremaining: 27.8ms\n",
            "99:\tlearn: 0.2331062\ttotal: 2.77s\tremaining: 0us\n",
            "0:\tlearn: 1.1306657\ttotal: 49.8ms\tremaining: 4.93s\n",
            "1:\tlearn: 1.0634231\ttotal: 83.6ms\tremaining: 4.09s\n",
            "2:\tlearn: 1.0011841\ttotal: 116ms\tremaining: 3.75s\n",
            "3:\tlearn: 0.9430721\ttotal: 139ms\tremaining: 3.35s\n",
            "4:\tlearn: 0.8874037\ttotal: 158ms\tremaining: 3s\n",
            "5:\tlearn: 0.8439407\ttotal: 187ms\tremaining: 2.93s\n",
            "6:\tlearn: 0.8015813\ttotal: 215ms\tremaining: 2.86s\n",
            "7:\tlearn: 0.7654209\ttotal: 238ms\tremaining: 2.73s\n",
            "8:\tlearn: 0.7284290\ttotal: 295ms\tremaining: 2.99s\n",
            "9:\tlearn: 0.6966199\ttotal: 299ms\tremaining: 2.69s\n",
            "10:\tlearn: 0.6680427\ttotal: 328ms\tremaining: 2.65s\n",
            "11:\tlearn: 0.6437389\ttotal: 373ms\tremaining: 2.73s\n",
            "12:\tlearn: 0.6164233\ttotal: 413ms\tremaining: 2.77s\n",
            "13:\tlearn: 0.5962139\ttotal: 441ms\tremaining: 2.71s\n",
            "14:\tlearn: 0.5751864\ttotal: 463ms\tremaining: 2.62s\n",
            "15:\tlearn: 0.5559910\ttotal: 488ms\tremaining: 2.56s\n",
            "16:\tlearn: 0.5387270\ttotal: 524ms\tremaining: 2.56s\n",
            "17:\tlearn: 0.5243731\ttotal: 575ms\tremaining: 2.62s\n",
            "18:\tlearn: 0.5101154\ttotal: 616ms\tremaining: 2.63s\n",
            "19:\tlearn: 0.4972322\ttotal: 645ms\tremaining: 2.58s\n",
            "20:\tlearn: 0.4849641\ttotal: 689ms\tremaining: 2.59s\n",
            "21:\tlearn: 0.4741710\ttotal: 719ms\tremaining: 2.55s\n",
            "22:\tlearn: 0.4619723\ttotal: 753ms\tremaining: 2.52s\n",
            "23:\tlearn: 0.4542843\ttotal: 781ms\tremaining: 2.47s\n",
            "24:\tlearn: 0.4450756\ttotal: 806ms\tremaining: 2.42s\n",
            "25:\tlearn: 0.4390553\ttotal: 810ms\tremaining: 2.31s\n",
            "26:\tlearn: 0.4311542\ttotal: 834ms\tremaining: 2.25s\n",
            "27:\tlearn: 0.4241122\ttotal: 874ms\tremaining: 2.25s\n",
            "28:\tlearn: 0.4171327\ttotal: 895ms\tremaining: 2.19s\n",
            "29:\tlearn: 0.4118332\ttotal: 924ms\tremaining: 2.16s\n",
            "30:\tlearn: 0.4051332\ttotal: 961ms\tremaining: 2.14s\n",
            "31:\tlearn: 0.4000486\ttotal: 997ms\tremaining: 2.12s\n",
            "32:\tlearn: 0.3941195\ttotal: 1.04s\tremaining: 2.11s\n",
            "33:\tlearn: 0.3890015\ttotal: 1.08s\tremaining: 2.09s\n",
            "34:\tlearn: 0.3848390\ttotal: 1.1s\tremaining: 2.05s\n",
            "35:\tlearn: 0.3810413\ttotal: 1.14s\tremaining: 2.02s\n",
            "36:\tlearn: 0.3759436\ttotal: 1.17s\tremaining: 1.99s\n",
            "37:\tlearn: 0.3700386\ttotal: 1.19s\tremaining: 1.93s\n",
            "38:\tlearn: 0.3656078\ttotal: 1.2s\tremaining: 1.88s\n",
            "39:\tlearn: 0.3607760\ttotal: 1.23s\tremaining: 1.85s\n",
            "40:\tlearn: 0.3571451\ttotal: 1.26s\tremaining: 1.82s\n",
            "41:\tlearn: 0.3539849\ttotal: 1.3s\tremaining: 1.79s\n",
            "42:\tlearn: 0.3519074\ttotal: 1.3s\tremaining: 1.73s\n",
            "43:\tlearn: 0.3488443\ttotal: 1.33s\tremaining: 1.7s\n",
            "44:\tlearn: 0.3458731\ttotal: 1.39s\tremaining: 1.7s\n",
            "45:\tlearn: 0.3422500\ttotal: 1.42s\tremaining: 1.67s\n",
            "46:\tlearn: 0.3393149\ttotal: 1.45s\tremaining: 1.64s\n",
            "47:\tlearn: 0.3364049\ttotal: 1.48s\tremaining: 1.6s\n",
            "48:\tlearn: 0.3320760\ttotal: 1.49s\tremaining: 1.55s\n",
            "49:\tlearn: 0.3283040\ttotal: 1.5s\tremaining: 1.5s\n",
            "50:\tlearn: 0.3250301\ttotal: 1.55s\tremaining: 1.49s\n",
            "51:\tlearn: 0.3218616\ttotal: 1.58s\tremaining: 1.46s\n",
            "52:\tlearn: 0.3189433\ttotal: 1.6s\tremaining: 1.42s\n",
            "53:\tlearn: 0.3166993\ttotal: 1.63s\tremaining: 1.39s\n",
            "54:\tlearn: 0.3142893\ttotal: 1.65s\tremaining: 1.35s\n",
            "55:\tlearn: 0.3117255\ttotal: 1.67s\tremaining: 1.31s\n",
            "56:\tlearn: 0.3101431\ttotal: 1.7s\tremaining: 1.28s\n",
            "57:\tlearn: 0.3073565\ttotal: 1.73s\tremaining: 1.25s\n",
            "58:\tlearn: 0.3054563\ttotal: 1.78s\tremaining: 1.24s\n",
            "59:\tlearn: 0.3036461\ttotal: 1.81s\tremaining: 1.21s\n",
            "60:\tlearn: 0.3013114\ttotal: 1.85s\tremaining: 1.19s\n",
            "61:\tlearn: 0.2992499\ttotal: 1.89s\tremaining: 1.16s\n",
            "62:\tlearn: 0.2971916\ttotal: 1.91s\tremaining: 1.12s\n",
            "63:\tlearn: 0.2957546\ttotal: 1.94s\tremaining: 1.09s\n",
            "64:\tlearn: 0.2931480\ttotal: 1.97s\tremaining: 1.06s\n",
            "65:\tlearn: 0.2908397\ttotal: 2.01s\tremaining: 1.03s\n",
            "66:\tlearn: 0.2890090\ttotal: 2.04s\tremaining: 1s\n",
            "67:\tlearn: 0.2868014\ttotal: 2.06s\tremaining: 971ms\n",
            "68:\tlearn: 0.2843846\ttotal: 2.09s\tremaining: 940ms\n",
            "69:\tlearn: 0.2825208\ttotal: 2.12s\tremaining: 908ms\n",
            "70:\tlearn: 0.2806714\ttotal: 2.15s\tremaining: 879ms\n",
            "71:\tlearn: 0.2786727\ttotal: 2.18s\tremaining: 848ms\n",
            "72:\tlearn: 0.2769130\ttotal: 2.21s\tremaining: 816ms\n",
            "73:\tlearn: 0.2753891\ttotal: 2.23s\tremaining: 785ms\n",
            "74:\tlearn: 0.2737684\ttotal: 2.26s\tremaining: 754ms\n",
            "75:\tlearn: 0.2719830\ttotal: 2.29s\tremaining: 722ms\n",
            "76:\tlearn: 0.2701687\ttotal: 2.32s\tremaining: 693ms\n",
            "77:\tlearn: 0.2685531\ttotal: 2.36s\tremaining: 665ms\n",
            "78:\tlearn: 0.2667199\ttotal: 2.37s\tremaining: 631ms\n",
            "79:\tlearn: 0.2647118\ttotal: 2.39s\tremaining: 598ms\n",
            "80:\tlearn: 0.2625946\ttotal: 2.43s\tremaining: 570ms\n",
            "81:\tlearn: 0.2614318\ttotal: 2.46s\tremaining: 541ms\n",
            "82:\tlearn: 0.2597841\ttotal: 2.49s\tremaining: 511ms\n",
            "83:\tlearn: 0.2584541\ttotal: 2.52s\tremaining: 479ms\n",
            "84:\tlearn: 0.2562926\ttotal: 2.54s\tremaining: 449ms\n",
            "85:\tlearn: 0.2543035\ttotal: 2.57s\tremaining: 419ms\n",
            "86:\tlearn: 0.2525861\ttotal: 2.6s\tremaining: 389ms\n",
            "87:\tlearn: 0.2509605\ttotal: 2.65s\tremaining: 361ms\n",
            "88:\tlearn: 0.2495910\ttotal: 2.67s\tremaining: 330ms\n",
            "89:\tlearn: 0.2476139\ttotal: 2.7s\tremaining: 300ms\n",
            "90:\tlearn: 0.2460091\ttotal: 2.73s\tremaining: 270ms\n",
            "91:\tlearn: 0.2444240\ttotal: 2.75s\tremaining: 240ms\n",
            "92:\tlearn: 0.2426959\ttotal: 2.78s\tremaining: 209ms\n",
            "93:\tlearn: 0.2409099\ttotal: 2.8s\tremaining: 179ms\n",
            "94:\tlearn: 0.2395079\ttotal: 2.83s\tremaining: 149ms\n",
            "95:\tlearn: 0.2383683\ttotal: 2.87s\tremaining: 119ms\n",
            "96:\tlearn: 0.2366305\ttotal: 2.89s\tremaining: 89.5ms\n",
            "97:\tlearn: 0.2350624\ttotal: 2.93s\tremaining: 59.7ms\n",
            "98:\tlearn: 0.2338090\ttotal: 2.95s\tremaining: 29.8ms\n",
            "99:\tlearn: 0.2326497\ttotal: 2.98s\tremaining: 0us\n",
            "0:\tlearn: 1.1369578\ttotal: 23.4ms\tremaining: 2.32s\n",
            "1:\tlearn: 1.0666705\ttotal: 62.5ms\tremaining: 3.06s\n",
            "2:\tlearn: 1.0014770\ttotal: 88.8ms\tremaining: 2.87s\n",
            "3:\tlearn: 0.9433036\ttotal: 116ms\tremaining: 2.78s\n",
            "4:\tlearn: 0.8895453\ttotal: 123ms\tremaining: 2.33s\n",
            "5:\tlearn: 0.8394172\ttotal: 127ms\tremaining: 1.99s\n",
            "6:\tlearn: 0.7982341\ttotal: 158ms\tremaining: 2.1s\n",
            "7:\tlearn: 0.7576997\ttotal: 182ms\tremaining: 2.1s\n",
            "8:\tlearn: 0.7211154\ttotal: 210ms\tremaining: 2.13s\n",
            "9:\tlearn: 0.6915006\ttotal: 237ms\tremaining: 2.13s\n",
            "10:\tlearn: 0.6625632\ttotal: 275ms\tremaining: 2.22s\n",
            "11:\tlearn: 0.6362412\ttotal: 309ms\tremaining: 2.26s\n",
            "12:\tlearn: 0.6102676\ttotal: 336ms\tremaining: 2.25s\n",
            "13:\tlearn: 0.5892198\ttotal: 363ms\tremaining: 2.23s\n",
            "14:\tlearn: 0.5707759\ttotal: 389ms\tremaining: 2.2s\n",
            "15:\tlearn: 0.5521317\ttotal: 418ms\tremaining: 2.2s\n",
            "16:\tlearn: 0.5359905\ttotal: 444ms\tremaining: 2.17s\n",
            "17:\tlearn: 0.5209339\ttotal: 481ms\tremaining: 2.19s\n",
            "18:\tlearn: 0.5073364\ttotal: 506ms\tremaining: 2.16s\n",
            "19:\tlearn: 0.4937301\ttotal: 537ms\tremaining: 2.15s\n",
            "20:\tlearn: 0.4823022\ttotal: 566ms\tremaining: 2.13s\n",
            "21:\tlearn: 0.4712486\ttotal: 593ms\tremaining: 2.1s\n",
            "22:\tlearn: 0.4612824\ttotal: 615ms\tremaining: 2.06s\n",
            "23:\tlearn: 0.4540688\ttotal: 633ms\tremaining: 2s\n",
            "24:\tlearn: 0.4449425\ttotal: 646ms\tremaining: 1.94s\n",
            "25:\tlearn: 0.4397200\ttotal: 647ms\tremaining: 1.84s\n",
            "26:\tlearn: 0.4317844\ttotal: 662ms\tremaining: 1.79s\n",
            "27:\tlearn: 0.4244570\ttotal: 692ms\tremaining: 1.78s\n",
            "28:\tlearn: 0.4178800\ttotal: 726ms\tremaining: 1.78s\n",
            "29:\tlearn: 0.4115021\ttotal: 757ms\tremaining: 1.77s\n",
            "30:\tlearn: 0.4051664\ttotal: 785ms\tremaining: 1.75s\n",
            "31:\tlearn: 0.3999228\ttotal: 811ms\tremaining: 1.72s\n",
            "32:\tlearn: 0.3934611\ttotal: 852ms\tremaining: 1.73s\n",
            "33:\tlearn: 0.3883342\ttotal: 876ms\tremaining: 1.7s\n",
            "34:\tlearn: 0.3830465\ttotal: 914ms\tremaining: 1.7s\n",
            "35:\tlearn: 0.3777380\ttotal: 943ms\tremaining: 1.68s\n",
            "36:\tlearn: 0.3733301\ttotal: 963ms\tremaining: 1.64s\n",
            "37:\tlearn: 0.3691757\ttotal: 996ms\tremaining: 1.63s\n",
            "38:\tlearn: 0.3652478\ttotal: 1.04s\tremaining: 1.62s\n",
            "39:\tlearn: 0.3609088\ttotal: 1.06s\tremaining: 1.59s\n",
            "40:\tlearn: 0.3581290\ttotal: 1.08s\tremaining: 1.55s\n",
            "41:\tlearn: 0.3549071\ttotal: 1.1s\tremaining: 1.52s\n",
            "42:\tlearn: 0.3528788\ttotal: 1.12s\tremaining: 1.49s\n",
            "43:\tlearn: 0.3505263\ttotal: 1.15s\tremaining: 1.46s\n",
            "44:\tlearn: 0.3472258\ttotal: 1.18s\tremaining: 1.44s\n",
            "45:\tlearn: 0.3445261\ttotal: 1.2s\tremaining: 1.41s\n",
            "46:\tlearn: 0.3411920\ttotal: 1.23s\tremaining: 1.39s\n",
            "47:\tlearn: 0.3385516\ttotal: 1.25s\tremaining: 1.36s\n",
            "48:\tlearn: 0.3359401\ttotal: 1.28s\tremaining: 1.33s\n",
            "49:\tlearn: 0.3337312\ttotal: 1.3s\tremaining: 1.3s\n",
            "50:\tlearn: 0.3316862\ttotal: 1.35s\tremaining: 1.3s\n",
            "51:\tlearn: 0.3295584\ttotal: 1.38s\tremaining: 1.27s\n",
            "52:\tlearn: 0.3262542\ttotal: 1.4s\tremaining: 1.25s\n",
            "53:\tlearn: 0.3239648\ttotal: 1.43s\tremaining: 1.22s\n",
            "54:\tlearn: 0.3216600\ttotal: 1.46s\tremaining: 1.19s\n",
            "55:\tlearn: 0.3188583\ttotal: 1.49s\tremaining: 1.17s\n",
            "56:\tlearn: 0.3162258\ttotal: 1.51s\tremaining: 1.14s\n",
            "57:\tlearn: 0.3142405\ttotal: 1.54s\tremaining: 1.12s\n",
            "58:\tlearn: 0.3114344\ttotal: 1.57s\tremaining: 1.09s\n",
            "59:\tlearn: 0.3093799\ttotal: 1.62s\tremaining: 1.08s\n",
            "60:\tlearn: 0.3062187\ttotal: 1.66s\tremaining: 1.06s\n",
            "61:\tlearn: 0.3040488\ttotal: 1.7s\tremaining: 1.04s\n",
            "62:\tlearn: 0.3016770\ttotal: 1.73s\tremaining: 1.01s\n",
            "63:\tlearn: 0.2997047\ttotal: 1.76s\tremaining: 992ms\n",
            "64:\tlearn: 0.2971464\ttotal: 1.8s\tremaining: 967ms\n",
            "65:\tlearn: 0.2955642\ttotal: 1.82s\tremaining: 940ms\n",
            "66:\tlearn: 0.2933982\ttotal: 1.85s\tremaining: 911ms\n",
            "67:\tlearn: 0.2915986\ttotal: 1.87s\tremaining: 882ms\n",
            "68:\tlearn: 0.2886121\ttotal: 1.9s\tremaining: 852ms\n",
            "69:\tlearn: 0.2866480\ttotal: 1.92s\tremaining: 825ms\n",
            "70:\tlearn: 0.2848037\ttotal: 2s\tremaining: 817ms\n",
            "71:\tlearn: 0.2833202\ttotal: 2.04s\tremaining: 795ms\n",
            "72:\tlearn: 0.2816737\ttotal: 2.08s\tremaining: 771ms\n",
            "73:\tlearn: 0.2793259\ttotal: 2.14s\tremaining: 753ms\n",
            "74:\tlearn: 0.2780155\ttotal: 2.17s\tremaining: 725ms\n",
            "75:\tlearn: 0.2758901\ttotal: 2.23s\tremaining: 706ms\n",
            "76:\tlearn: 0.2740949\ttotal: 2.27s\tremaining: 677ms\n",
            "77:\tlearn: 0.2725975\ttotal: 2.29s\tremaining: 647ms\n",
            "78:\tlearn: 0.2710600\ttotal: 2.32s\tremaining: 616ms\n",
            "79:\tlearn: 0.2689105\ttotal: 2.36s\tremaining: 590ms\n",
            "80:\tlearn: 0.2666618\ttotal: 2.39s\tremaining: 560ms\n",
            "81:\tlearn: 0.2656786\ttotal: 2.41s\tremaining: 528ms\n",
            "82:\tlearn: 0.2641820\ttotal: 2.42s\tremaining: 496ms\n",
            "83:\tlearn: 0.2628493\ttotal: 2.47s\tremaining: 471ms\n",
            "84:\tlearn: 0.2612895\ttotal: 2.5s\tremaining: 442ms\n",
            "85:\tlearn: 0.2593823\ttotal: 2.53s\tremaining: 412ms\n",
            "86:\tlearn: 0.2574774\ttotal: 2.56s\tremaining: 383ms\n",
            "87:\tlearn: 0.2561154\ttotal: 2.59s\tremaining: 353ms\n",
            "88:\tlearn: 0.2538844\ttotal: 2.62s\tremaining: 324ms\n",
            "89:\tlearn: 0.2521980\ttotal: 2.65s\tremaining: 294ms\n",
            "90:\tlearn: 0.2503874\ttotal: 2.69s\tremaining: 266ms\n",
            "91:\tlearn: 0.2483294\ttotal: 2.73s\tremaining: 238ms\n",
            "92:\tlearn: 0.2468060\ttotal: 2.75s\tremaining: 207ms\n",
            "93:\tlearn: 0.2452187\ttotal: 2.77s\tremaining: 177ms\n",
            "94:\tlearn: 0.2440691\ttotal: 2.79s\tremaining: 147ms\n",
            "95:\tlearn: 0.2427065\ttotal: 2.82s\tremaining: 118ms\n",
            "96:\tlearn: 0.2417133\ttotal: 2.85s\tremaining: 88.2ms\n",
            "97:\tlearn: 0.2406448\ttotal: 2.88s\tremaining: 58.7ms\n",
            "98:\tlearn: 0.2386226\ttotal: 2.92s\tremaining: 29.5ms\n",
            "99:\tlearn: 0.2370544\ttotal: 2.94s\tremaining: 0us\n",
            "0:\tlearn: 1.0556000\ttotal: 38.3ms\tremaining: 3.79s\n",
            "1:\tlearn: 0.9921731\ttotal: 61.7ms\tremaining: 3.02s\n",
            "2:\tlearn: 0.9318544\ttotal: 99.4ms\tremaining: 3.21s\n",
            "3:\tlearn: 0.8855854\ttotal: 161ms\tremaining: 3.86s\n",
            "4:\tlearn: 0.8344041\ttotal: 175ms\tremaining: 3.33s\n",
            "5:\tlearn: 0.7921200\ttotal: 191ms\tremaining: 2.99s\n",
            "6:\tlearn: 0.7530690\ttotal: 207ms\tremaining: 2.75s\n",
            "7:\tlearn: 0.7215615\ttotal: 231ms\tremaining: 2.65s\n",
            "8:\tlearn: 0.6869308\ttotal: 258ms\tremaining: 2.61s\n",
            "9:\tlearn: 0.6565393\ttotal: 273ms\tremaining: 2.46s\n",
            "10:\tlearn: 0.6296639\ttotal: 308ms\tremaining: 2.49s\n",
            "11:\tlearn: 0.6038882\ttotal: 335ms\tremaining: 2.46s\n",
            "12:\tlearn: 0.5817260\ttotal: 386ms\tremaining: 2.58s\n",
            "13:\tlearn: 0.5623047\ttotal: 450ms\tremaining: 2.76s\n",
            "14:\tlearn: 0.5437806\ttotal: 486ms\tremaining: 2.75s\n",
            "15:\tlearn: 0.5276394\ttotal: 524ms\tremaining: 2.75s\n",
            "16:\tlearn: 0.5137419\ttotal: 561ms\tremaining: 2.74s\n",
            "17:\tlearn: 0.5001549\ttotal: 605ms\tremaining: 2.75s\n",
            "18:\tlearn: 0.4873154\ttotal: 633ms\tremaining: 2.7s\n",
            "19:\tlearn: 0.4744581\ttotal: 662ms\tremaining: 2.65s\n",
            "20:\tlearn: 0.4635919\ttotal: 699ms\tremaining: 2.63s\n",
            "21:\tlearn: 0.4549762\ttotal: 737ms\tremaining: 2.61s\n",
            "22:\tlearn: 0.4457579\ttotal: 763ms\tremaining: 2.55s\n",
            "23:\tlearn: 0.4377799\ttotal: 791ms\tremaining: 2.5s\n",
            "24:\tlearn: 0.4307393\ttotal: 837ms\tremaining: 2.51s\n",
            "25:\tlearn: 0.4237205\ttotal: 865ms\tremaining: 2.46s\n",
            "26:\tlearn: 0.4163492\ttotal: 894ms\tremaining: 2.42s\n",
            "27:\tlearn: 0.4108825\ttotal: 912ms\tremaining: 2.35s\n",
            "28:\tlearn: 0.4035620\ttotal: 927ms\tremaining: 2.27s\n",
            "29:\tlearn: 0.3964455\ttotal: 944ms\tremaining: 2.2s\n",
            "30:\tlearn: 0.3912355\ttotal: 959ms\tremaining: 2.13s\n",
            "31:\tlearn: 0.3867979\ttotal: 981ms\tremaining: 2.08s\n",
            "32:\tlearn: 0.3825171\ttotal: 1.05s\tremaining: 2.13s\n",
            "33:\tlearn: 0.3774194\ttotal: 1.08s\tremaining: 2.1s\n",
            "34:\tlearn: 0.3730849\ttotal: 1.11s\tremaining: 2.06s\n",
            "35:\tlearn: 0.3683747\ttotal: 1.14s\tremaining: 2.02s\n",
            "36:\tlearn: 0.3650103\ttotal: 1.16s\tremaining: 1.98s\n",
            "37:\tlearn: 0.3610940\ttotal: 1.19s\tremaining: 1.94s\n",
            "38:\tlearn: 0.3576293\ttotal: 1.22s\tremaining: 1.91s\n",
            "39:\tlearn: 0.3541074\ttotal: 1.26s\tremaining: 1.89s\n",
            "40:\tlearn: 0.3521306\ttotal: 1.27s\tremaining: 1.83s\n",
            "41:\tlearn: 0.3489038\ttotal: 1.3s\tremaining: 1.79s\n",
            "42:\tlearn: 0.3464321\ttotal: 1.32s\tremaining: 1.75s\n",
            "43:\tlearn: 0.3437260\ttotal: 1.34s\tremaining: 1.71s\n",
            "44:\tlearn: 0.3407128\ttotal: 1.37s\tremaining: 1.68s\n",
            "45:\tlearn: 0.3377969\ttotal: 1.4s\tremaining: 1.65s\n",
            "46:\tlearn: 0.3352531\ttotal: 1.41s\tremaining: 1.59s\n",
            "47:\tlearn: 0.3329171\ttotal: 1.44s\tremaining: 1.56s\n",
            "48:\tlearn: 0.3293497\ttotal: 1.48s\tremaining: 1.54s\n",
            "49:\tlearn: 0.3286543\ttotal: 1.48s\tremaining: 1.48s\n",
            "50:\tlearn: 0.3271319\ttotal: 1.5s\tremaining: 1.45s\n",
            "51:\tlearn: 0.3246214\ttotal: 1.53s\tremaining: 1.41s\n",
            "52:\tlearn: 0.3221460\ttotal: 1.56s\tremaining: 1.39s\n",
            "53:\tlearn: 0.3189025\ttotal: 1.59s\tremaining: 1.36s\n",
            "54:\tlearn: 0.3159807\ttotal: 1.62s\tremaining: 1.33s\n",
            "55:\tlearn: 0.3136330\ttotal: 1.65s\tremaining: 1.29s\n",
            "56:\tlearn: 0.3117829\ttotal: 1.68s\tremaining: 1.27s\n",
            "57:\tlearn: 0.3096616\ttotal: 1.72s\tremaining: 1.25s\n",
            "58:\tlearn: 0.3079396\ttotal: 1.74s\tremaining: 1.21s\n",
            "59:\tlearn: 0.3057188\ttotal: 1.76s\tremaining: 1.17s\n",
            "60:\tlearn: 0.3039936\ttotal: 1.78s\tremaining: 1.14s\n",
            "61:\tlearn: 0.3025700\ttotal: 1.81s\tremaining: 1.11s\n",
            "62:\tlearn: 0.3007763\ttotal: 1.84s\tremaining: 1.08s\n",
            "63:\tlearn: 0.2986755\ttotal: 1.87s\tremaining: 1.05s\n",
            "64:\tlearn: 0.2964188\ttotal: 1.9s\tremaining: 1.02s\n",
            "65:\tlearn: 0.2937503\ttotal: 1.94s\tremaining: 998ms\n",
            "66:\tlearn: 0.2915500\ttotal: 1.96s\tremaining: 966ms\n",
            "67:\tlearn: 0.2897057\ttotal: 1.99s\tremaining: 937ms\n",
            "68:\tlearn: 0.2880020\ttotal: 2.02s\tremaining: 906ms\n",
            "69:\tlearn: 0.2861994\ttotal: 2.03s\tremaining: 870ms\n",
            "70:\tlearn: 0.2835503\ttotal: 2.04s\tremaining: 834ms\n",
            "71:\tlearn: 0.2813111\ttotal: 2.06s\tremaining: 799ms\n",
            "72:\tlearn: 0.2793576\ttotal: 2.07s\tremaining: 766ms\n",
            "73:\tlearn: 0.2773583\ttotal: 2.09s\tremaining: 735ms\n",
            "74:\tlearn: 0.2747125\ttotal: 2.11s\tremaining: 703ms\n",
            "75:\tlearn: 0.2727324\ttotal: 2.12s\tremaining: 671ms\n",
            "76:\tlearn: 0.2704771\ttotal: 2.14s\tremaining: 638ms\n",
            "77:\tlearn: 0.2686507\ttotal: 2.15s\tremaining: 606ms\n",
            "78:\tlearn: 0.2660715\ttotal: 2.16s\tremaining: 574ms\n",
            "79:\tlearn: 0.2642202\ttotal: 2.17s\tremaining: 543ms\n",
            "80:\tlearn: 0.2616831\ttotal: 2.19s\tremaining: 513ms\n",
            "81:\tlearn: 0.2595631\ttotal: 2.2s\tremaining: 482ms\n",
            "82:\tlearn: 0.2577591\ttotal: 2.21s\tremaining: 453ms\n",
            "83:\tlearn: 0.2559678\ttotal: 2.22s\tremaining: 423ms\n",
            "84:\tlearn: 0.2545938\ttotal: 2.23s\tremaining: 394ms\n",
            "85:\tlearn: 0.2527913\ttotal: 2.25s\tremaining: 366ms\n",
            "86:\tlearn: 0.2505378\ttotal: 2.26s\tremaining: 338ms\n",
            "87:\tlearn: 0.2487774\ttotal: 2.28s\tremaining: 311ms\n",
            "88:\tlearn: 0.2473981\ttotal: 2.29s\tremaining: 284ms\n",
            "89:\tlearn: 0.2464027\ttotal: 2.31s\tremaining: 256ms\n",
            "90:\tlearn: 0.2449383\ttotal: 2.32s\tremaining: 229ms\n",
            "91:\tlearn: 0.2435102\ttotal: 2.33s\tremaining: 203ms\n",
            "92:\tlearn: 0.2420361\ttotal: 2.34s\tremaining: 176ms\n",
            "93:\tlearn: 0.2401491\ttotal: 2.36s\tremaining: 150ms\n",
            "94:\tlearn: 0.2390446\ttotal: 2.37s\tremaining: 125ms\n",
            "95:\tlearn: 0.2376484\ttotal: 2.38s\tremaining: 99.2ms\n",
            "96:\tlearn: 0.2360656\ttotal: 2.39s\tremaining: 74ms\n",
            "97:\tlearn: 0.2347267\ttotal: 2.41s\tremaining: 49.1ms\n",
            "98:\tlearn: 0.2328504\ttotal: 2.42s\tremaining: 24.4ms\n",
            "99:\tlearn: 0.2316037\ttotal: 2.43s\tremaining: 0us\n",
            "0:\tlearn: 1.1113653\ttotal: 15.9ms\tremaining: 1.57s\n",
            "1:\tlearn: 1.0447330\ttotal: 32.6ms\tremaining: 1.59s\n",
            "2:\tlearn: 0.9841393\ttotal: 44.4ms\tremaining: 1.43s\n",
            "3:\tlearn: 0.9313239\ttotal: 56.2ms\tremaining: 1.35s\n",
            "4:\tlearn: 0.8765598\ttotal: 58.9ms\tremaining: 1.12s\n",
            "5:\tlearn: 0.8258082\ttotal: 61.1ms\tremaining: 958ms\n",
            "6:\tlearn: 0.7829934\ttotal: 72.8ms\tremaining: 967ms\n",
            "7:\tlearn: 0.7446864\ttotal: 84.8ms\tremaining: 975ms\n",
            "8:\tlearn: 0.7072756\ttotal: 97.1ms\tremaining: 982ms\n",
            "9:\tlearn: 0.6740318\ttotal: 109ms\tremaining: 982ms\n",
            "10:\tlearn: 0.6471142\ttotal: 121ms\tremaining: 980ms\n",
            "11:\tlearn: 0.6177466\ttotal: 133ms\tremaining: 975ms\n",
            "12:\tlearn: 0.5943156\ttotal: 145ms\tremaining: 968ms\n",
            "13:\tlearn: 0.5709257\ttotal: 156ms\tremaining: 961ms\n",
            "14:\tlearn: 0.5519780\ttotal: 168ms\tremaining: 954ms\n",
            "15:\tlearn: 0.5347746\ttotal: 180ms\tremaining: 947ms\n",
            "16:\tlearn: 0.5179129\ttotal: 194ms\tremaining: 945ms\n",
            "17:\tlearn: 0.5044291\ttotal: 210ms\tremaining: 957ms\n",
            "18:\tlearn: 0.4899518\ttotal: 239ms\tremaining: 1.02s\n",
            "19:\tlearn: 0.4761146\ttotal: 251ms\tremaining: 1s\n",
            "20:\tlearn: 0.4653992\ttotal: 263ms\tremaining: 989ms\n",
            "21:\tlearn: 0.4553138\ttotal: 274ms\tremaining: 973ms\n",
            "22:\tlearn: 0.4454417\ttotal: 286ms\tremaining: 959ms\n",
            "23:\tlearn: 0.4373473\ttotal: 299ms\tremaining: 946ms\n",
            "24:\tlearn: 0.4289792\ttotal: 311ms\tremaining: 933ms\n",
            "25:\tlearn: 0.4224543\ttotal: 323ms\tremaining: 920ms\n",
            "26:\tlearn: 0.4145828\ttotal: 335ms\tremaining: 906ms\n",
            "27:\tlearn: 0.4086065\ttotal: 348ms\tremaining: 894ms\n",
            "28:\tlearn: 0.4016781\ttotal: 360ms\tremaining: 881ms\n",
            "29:\tlearn: 0.3946322\ttotal: 372ms\tremaining: 868ms\n",
            "30:\tlearn: 0.3893051\ttotal: 384ms\tremaining: 855ms\n",
            "31:\tlearn: 0.3843540\ttotal: 396ms\tremaining: 842ms\n",
            "32:\tlearn: 0.3808781\ttotal: 398ms\tremaining: 808ms\n",
            "33:\tlearn: 0.3758999\ttotal: 419ms\tremaining: 813ms\n",
            "34:\tlearn: 0.3717535\ttotal: 432ms\tremaining: 802ms\n",
            "35:\tlearn: 0.3678084\ttotal: 444ms\tremaining: 789ms\n",
            "36:\tlearn: 0.3636679\ttotal: 456ms\tremaining: 776ms\n",
            "37:\tlearn: 0.3591175\ttotal: 467ms\tremaining: 762ms\n",
            "38:\tlearn: 0.3553486\ttotal: 479ms\tremaining: 749ms\n",
            "39:\tlearn: 0.3522085\ttotal: 491ms\tremaining: 736ms\n",
            "40:\tlearn: 0.3491318\ttotal: 503ms\tremaining: 723ms\n",
            "41:\tlearn: 0.3462289\ttotal: 515ms\tremaining: 711ms\n",
            "42:\tlearn: 0.3431867\ttotal: 527ms\tremaining: 699ms\n",
            "43:\tlearn: 0.3396766\ttotal: 539ms\tremaining: 686ms\n",
            "44:\tlearn: 0.3381104\ttotal: 543ms\tremaining: 663ms\n",
            "45:\tlearn: 0.3342287\ttotal: 555ms\tremaining: 652ms\n",
            "46:\tlearn: 0.3317038\ttotal: 567ms\tremaining: 640ms\n",
            "47:\tlearn: 0.3286746\ttotal: 579ms\tremaining: 628ms\n",
            "48:\tlearn: 0.3258557\ttotal: 591ms\tremaining: 615ms\n",
            "49:\tlearn: 0.3228513\ttotal: 603ms\tremaining: 603ms\n",
            "50:\tlearn: 0.3200973\ttotal: 624ms\tremaining: 599ms\n",
            "51:\tlearn: 0.3192332\ttotal: 625ms\tremaining: 576ms\n",
            "52:\tlearn: 0.3155881\ttotal: 637ms\tremaining: 565ms\n",
            "53:\tlearn: 0.3129934\ttotal: 648ms\tremaining: 552ms\n",
            "54:\tlearn: 0.3100991\ttotal: 661ms\tremaining: 541ms\n",
            "55:\tlearn: 0.3079072\ttotal: 673ms\tremaining: 529ms\n",
            "56:\tlearn: 0.3060313\ttotal: 685ms\tremaining: 517ms\n",
            "57:\tlearn: 0.3038408\ttotal: 697ms\tremaining: 505ms\n",
            "58:\tlearn: 0.3018243\ttotal: 709ms\tremaining: 493ms\n",
            "59:\tlearn: 0.3003247\ttotal: 721ms\tremaining: 481ms\n",
            "60:\tlearn: 0.2983390\ttotal: 733ms\tremaining: 469ms\n",
            "61:\tlearn: 0.2965874\ttotal: 745ms\tremaining: 457ms\n",
            "62:\tlearn: 0.2947937\ttotal: 757ms\tremaining: 445ms\n",
            "63:\tlearn: 0.2921416\ttotal: 769ms\tremaining: 432ms\n",
            "64:\tlearn: 0.2898539\ttotal: 780ms\tremaining: 420ms\n",
            "65:\tlearn: 0.2877094\ttotal: 792ms\tremaining: 408ms\n",
            "66:\tlearn: 0.2858445\ttotal: 805ms\tremaining: 396ms\n",
            "67:\tlearn: 0.2844596\ttotal: 816ms\tremaining: 384ms\n",
            "68:\tlearn: 0.2824121\ttotal: 839ms\tremaining: 377ms\n",
            "69:\tlearn: 0.2804513\ttotal: 851ms\tremaining: 365ms\n",
            "70:\tlearn: 0.2782663\ttotal: 863ms\tremaining: 352ms\n",
            "71:\tlearn: 0.2767907\ttotal: 874ms\tremaining: 340ms\n",
            "72:\tlearn: 0.2756474\ttotal: 886ms\tremaining: 328ms\n",
            "73:\tlearn: 0.2736919\ttotal: 898ms\tremaining: 315ms\n",
            "74:\tlearn: 0.2724356\ttotal: 910ms\tremaining: 303ms\n",
            "75:\tlearn: 0.2711101\ttotal: 922ms\tremaining: 291ms\n",
            "76:\tlearn: 0.2698382\ttotal: 934ms\tremaining: 279ms\n",
            "77:\tlearn: 0.2683903\ttotal: 946ms\tremaining: 267ms\n",
            "78:\tlearn: 0.2657118\ttotal: 957ms\tremaining: 255ms\n",
            "79:\tlearn: 0.2641183\ttotal: 970ms\tremaining: 242ms\n",
            "80:\tlearn: 0.2617531\ttotal: 982ms\tremaining: 230ms\n",
            "81:\tlearn: 0.2598860\ttotal: 998ms\tremaining: 219ms\n",
            "82:\tlearn: 0.2576547\ttotal: 1.01s\tremaining: 207ms\n",
            "83:\tlearn: 0.2560280\ttotal: 1.02s\tremaining: 195ms\n",
            "84:\tlearn: 0.2541493\ttotal: 1.04s\tremaining: 184ms\n",
            "85:\tlearn: 0.2528613\ttotal: 1.06s\tremaining: 172ms\n",
            "86:\tlearn: 0.2516306\ttotal: 1.07s\tremaining: 160ms\n",
            "87:\tlearn: 0.2503637\ttotal: 1.08s\tremaining: 147ms\n",
            "88:\tlearn: 0.2490437\ttotal: 1.09s\tremaining: 135ms\n",
            "89:\tlearn: 0.2470824\ttotal: 1.11s\tremaining: 123ms\n",
            "90:\tlearn: 0.2455367\ttotal: 1.12s\tremaining: 111ms\n",
            "91:\tlearn: 0.2437668\ttotal: 1.13s\tremaining: 98.3ms\n",
            "92:\tlearn: 0.2424333\ttotal: 1.14s\tremaining: 86ms\n",
            "93:\tlearn: 0.2415654\ttotal: 1.16s\tremaining: 73.8ms\n",
            "94:\tlearn: 0.2407619\ttotal: 1.17s\tremaining: 61.5ms\n",
            "95:\tlearn: 0.2393424\ttotal: 1.18s\tremaining: 49.1ms\n",
            "96:\tlearn: 0.2374375\ttotal: 1.2s\tremaining: 37ms\n",
            "97:\tlearn: 0.2357829\ttotal: 1.21s\tremaining: 24.8ms\n",
            "98:\tlearn: 0.2343222\ttotal: 1.23s\tremaining: 12.4ms\n",
            "99:\tlearn: 0.2329548\ttotal: 1.24s\tremaining: 0us\n",
            "0:\tlearn: 1.1091455\ttotal: 1.64ms\tremaining: 162ms\n",
            "1:\tlearn: 1.0390352\ttotal: 3.6ms\tremaining: 176ms\n",
            "2:\tlearn: 0.9755351\ttotal: 5.44ms\tremaining: 176ms\n",
            "3:\tlearn: 0.9179383\ttotal: 7.26ms\tremaining: 174ms\n",
            "4:\tlearn: 0.8700214\ttotal: 9.04ms\tremaining: 172ms\n",
            "5:\tlearn: 0.8256938\ttotal: 10.8ms\tremaining: 169ms\n",
            "6:\tlearn: 0.7859875\ttotal: 12.5ms\tremaining: 166ms\n",
            "7:\tlearn: 0.7477666\ttotal: 14.2ms\tremaining: 163ms\n",
            "8:\tlearn: 0.7122521\ttotal: 15.9ms\tremaining: 161ms\n",
            "9:\tlearn: 0.6820572\ttotal: 17.6ms\tremaining: 159ms\n",
            "10:\tlearn: 0.6595222\ttotal: 19.4ms\tremaining: 157ms\n",
            "11:\tlearn: 0.6316942\ttotal: 21.2ms\tremaining: 155ms\n",
            "12:\tlearn: 0.6114216\ttotal: 22.9ms\tremaining: 153ms\n",
            "13:\tlearn: 0.5914682\ttotal: 24.5ms\tremaining: 151ms\n",
            "14:\tlearn: 0.5742945\ttotal: 26.2ms\tremaining: 149ms\n",
            "15:\tlearn: 0.5594602\ttotal: 27.9ms\tremaining: 147ms\n",
            "16:\tlearn: 0.5448641\ttotal: 29.6ms\tremaining: 145ms\n",
            "17:\tlearn: 0.5327354\ttotal: 31.4ms\tremaining: 143ms\n",
            "18:\tlearn: 0.5202429\ttotal: 33.1ms\tremaining: 141ms\n",
            "19:\tlearn: 0.5099590\ttotal: 34.8ms\tremaining: 139ms\n",
            "20:\tlearn: 0.5014969\ttotal: 36.5ms\tremaining: 137ms\n",
            "21:\tlearn: 0.4928562\ttotal: 38.2ms\tremaining: 135ms\n",
            "22:\tlearn: 0.4857556\ttotal: 39.9ms\tremaining: 134ms\n",
            "23:\tlearn: 0.4775312\ttotal: 41.6ms\tremaining: 132ms\n",
            "24:\tlearn: 0.4702504\ttotal: 43.3ms\tremaining: 130ms\n",
            "25:\tlearn: 0.4636259\ttotal: 45.1ms\tremaining: 128ms\n",
            "26:\tlearn: 0.4574967\ttotal: 46.8ms\tremaining: 127ms\n",
            "27:\tlearn: 0.4524138\ttotal: 48.7ms\tremaining: 125ms\n",
            "28:\tlearn: 0.4488865\ttotal: 50.1ms\tremaining: 123ms\n",
            "29:\tlearn: 0.4448234\ttotal: 51.9ms\tremaining: 121ms\n",
            "30:\tlearn: 0.4409387\ttotal: 53.7ms\tremaining: 119ms\n",
            "31:\tlearn: 0.4375945\ttotal: 55.4ms\tremaining: 118ms\n",
            "32:\tlearn: 0.4344970\ttotal: 57.1ms\tremaining: 116ms\n",
            "33:\tlearn: 0.4312750\ttotal: 58.8ms\tremaining: 114ms\n",
            "34:\tlearn: 0.4281215\ttotal: 60.6ms\tremaining: 113ms\n",
            "35:\tlearn: 0.4254912\ttotal: 62.3ms\tremaining: 111ms\n",
            "36:\tlearn: 0.4224071\ttotal: 64.1ms\tremaining: 109ms\n",
            "37:\tlearn: 0.4201310\ttotal: 65.8ms\tremaining: 107ms\n",
            "38:\tlearn: 0.4178689\ttotal: 67.5ms\tremaining: 106ms\n",
            "39:\tlearn: 0.4158696\ttotal: 69.1ms\tremaining: 104ms\n",
            "40:\tlearn: 0.4138966\ttotal: 70.7ms\tremaining: 102ms\n",
            "41:\tlearn: 0.4125756\ttotal: 72.5ms\tremaining: 100ms\n",
            "42:\tlearn: 0.4109754\ttotal: 74.2ms\tremaining: 98.3ms\n",
            "43:\tlearn: 0.4090756\ttotal: 75.9ms\tremaining: 96.6ms\n",
            "44:\tlearn: 0.4076602\ttotal: 77.6ms\tremaining: 94.8ms\n",
            "45:\tlearn: 0.4053089\ttotal: 79.2ms\tremaining: 93ms\n",
            "46:\tlearn: 0.4040029\ttotal: 81ms\tremaining: 91.3ms\n",
            "47:\tlearn: 0.4020649\ttotal: 82.7ms\tremaining: 89.6ms\n",
            "48:\tlearn: 0.4004973\ttotal: 84.4ms\tremaining: 87.8ms\n",
            "49:\tlearn: 0.3987729\ttotal: 89ms\tremaining: 89ms\n",
            "50:\tlearn: 0.3966444\ttotal: 90.3ms\tremaining: 86.7ms\n",
            "51:\tlearn: 0.3938759\ttotal: 92ms\tremaining: 84.9ms\n",
            "52:\tlearn: 0.3929352\ttotal: 93.7ms\tremaining: 83.1ms\n",
            "53:\tlearn: 0.3909103\ttotal: 95.4ms\tremaining: 81.3ms\n",
            "54:\tlearn: 0.3899364\ttotal: 97.2ms\tremaining: 79.5ms\n",
            "55:\tlearn: 0.3884561\ttotal: 98.8ms\tremaining: 77.6ms\n",
            "56:\tlearn: 0.3865846\ttotal: 101ms\tremaining: 75.9ms\n",
            "57:\tlearn: 0.3849440\ttotal: 102ms\tremaining: 74ms\n",
            "58:\tlearn: 0.3838611\ttotal: 104ms\tremaining: 72.2ms\n",
            "59:\tlearn: 0.3827643\ttotal: 106ms\tremaining: 70.5ms\n",
            "60:\tlearn: 0.3811538\ttotal: 107ms\tremaining: 68.7ms\n",
            "61:\tlearn: 0.3799786\ttotal: 109ms\tremaining: 66.9ms\n",
            "62:\tlearn: 0.3785395\ttotal: 111ms\tremaining: 65.2ms\n",
            "63:\tlearn: 0.3771448\ttotal: 113ms\tremaining: 63.5ms\n",
            "64:\tlearn: 0.3757010\ttotal: 114ms\tremaining: 61.6ms\n",
            "65:\tlearn: 0.3749356\ttotal: 116ms\tremaining: 59.8ms\n",
            "66:\tlearn: 0.3737646\ttotal: 118ms\tremaining: 58ms\n",
            "67:\tlearn: 0.3724465\ttotal: 120ms\tremaining: 56.2ms\n",
            "68:\tlearn: 0.3707756\ttotal: 121ms\tremaining: 54.5ms\n",
            "69:\tlearn: 0.3698385\ttotal: 123ms\tremaining: 52.9ms\n",
            "70:\tlearn: 0.3686954\ttotal: 125ms\tremaining: 51.1ms\n",
            "71:\tlearn: 0.3675812\ttotal: 127ms\tremaining: 49.4ms\n",
            "72:\tlearn: 0.3668517\ttotal: 129ms\tremaining: 47.6ms\n",
            "73:\tlearn: 0.3655881\ttotal: 130ms\tremaining: 45.8ms\n",
            "74:\tlearn: 0.3645416\ttotal: 132ms\tremaining: 44.1ms\n",
            "75:\tlearn: 0.3630882\ttotal: 134ms\tremaining: 42.4ms\n",
            "76:\tlearn: 0.3623017\ttotal: 136ms\tremaining: 40.6ms\n",
            "77:\tlearn: 0.3615636\ttotal: 138ms\tremaining: 38.8ms\n",
            "78:\tlearn: 0.3606742\ttotal: 139ms\tremaining: 37.1ms\n",
            "79:\tlearn: 0.3600345\ttotal: 141ms\tremaining: 35.3ms\n",
            "80:\tlearn: 0.3588789\ttotal: 143ms\tremaining: 33.5ms\n",
            "81:\tlearn: 0.3568946\ttotal: 145ms\tremaining: 31.7ms\n",
            "82:\tlearn: 0.3559951\ttotal: 160ms\tremaining: 32.7ms\n",
            "83:\tlearn: 0.3550152\ttotal: 162ms\tremaining: 30.8ms\n",
            "84:\tlearn: 0.3544132\ttotal: 164ms\tremaining: 28.9ms\n",
            "85:\tlearn: 0.3536024\ttotal: 165ms\tremaining: 26.9ms\n",
            "86:\tlearn: 0.3522295\ttotal: 167ms\tremaining: 25ms\n",
            "87:\tlearn: 0.3506947\ttotal: 169ms\tremaining: 23ms\n",
            "88:\tlearn: 0.3495832\ttotal: 171ms\tremaining: 21.1ms\n",
            "89:\tlearn: 0.3482104\ttotal: 172ms\tremaining: 19.2ms\n",
            "90:\tlearn: 0.3474850\ttotal: 174ms\tremaining: 17.2ms\n",
            "91:\tlearn: 0.3460047\ttotal: 176ms\tremaining: 15.3ms\n",
            "92:\tlearn: 0.3454571\ttotal: 178ms\tremaining: 13.4ms\n",
            "93:\tlearn: 0.3450285\ttotal: 179ms\tremaining: 11.4ms\n",
            "94:\tlearn: 0.3438249\ttotal: 181ms\tremaining: 9.52ms\n",
            "95:\tlearn: 0.3423699\ttotal: 183ms\tremaining: 7.62ms\n",
            "96:\tlearn: 0.3414707\ttotal: 185ms\tremaining: 5.71ms\n",
            "97:\tlearn: 0.3404421\ttotal: 186ms\tremaining: 3.8ms\n",
            "98:\tlearn: 0.3393319\ttotal: 188ms\tremaining: 1.9ms\n",
            "99:\tlearn: 0.3387057\ttotal: 190ms\tremaining: 0us\n",
            "최적의 하이퍼파라미터 {'depth': 6, 'iterations': 100, 'learning_rate': 0.1}\n",
            "최적 모델의 cv score 0.4574502074875789\n",
            "최적 모델 <catboost.core.CatBoostRegressor object at 0x7f4d3e60a110>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Model  최적 모델의 cv_RMSE\n",
              "0    CB         0.45745"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f9fc16b-0f63-410b-bda3-8e43f9564702\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>최적 모델의 cv_RMSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CB</td>\n",
              "      <td>0.45745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f9fc16b-0f63-410b-bda3-8e43f9564702')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f9fc16b-0f63-410b-bda3-8e43f9564702 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f9fc16b-0f63-410b-bda3-8e43f9564702');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GB"
      ],
      "metadata": {
        "id": "ThQjcBTu0tmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "GBoost = GradientBoostingRegressor()\n",
        "parameters = {\n",
        "    \"n_estimators\": [1, 2, 5, 10, 20, 50, 100, 200, 500],\n",
        "    \"max_leaf_nodes\": [2, 5, 10, 20, 50, 100],\n",
        "    \"learning_rate\": [0.01,0.05, 1]\n",
        "}\n",
        "grid_search = GridSearchCV(GBoost,parameters, cv=5, scoring='neg_root_mean_squared_error')\n",
        "grid_search.fit(train_final_x,train_final_y)\n",
        "print('최적의 하이퍼파라미터',grid_search.best_params_)\n",
        "print('최적 모델의 cv score', -grid_search.best_score_)\n",
        "print('최적 모델',grid_search.best_estimator_ )\n",
        "\n",
        "new_row = {\"Model\": \"GB\",\"최적 모델의 cv_RMSE\": -grid_search.best_score_}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "6Euv3Fa70u3M",
        "outputId": "fed9d525-fae8-4611-d7da-21d52afc8a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 하이퍼파라미터 {'learning_rate': 0.05, 'max_leaf_nodes': 20, 'n_estimators': 200}\n",
            "최적 모델의 cv score 0.45963820919915654\n",
            "최적 모델 GradientBoostingRegressor(learning_rate=0.05, max_leaf_nodes=20,\n",
            "                          n_estimators=200)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Model  최적 모델의 cv_RMSE\n",
              "0    CB        0.465640\n",
              "1    GB        0.459638"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3088388-a46b-417e-ad03-b0da9d379fbb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>최적 모델의 cv_RMSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CB</td>\n",
              "      <td>0.465640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GB</td>\n",
              "      <td>0.459638</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3088388-a46b-417e-ad03-b0da9d379fbb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3088388-a46b-417e-ad03-b0da9d379fbb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3088388-a46b-417e-ad03-b0da9d379fbb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RF"
      ],
      "metadata": {
        "id": "VkzcFva-rKge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf=RandomForestRegressor(random_state=42)\n",
        "parameters ={'max_depth': [10, 50, 100],\n",
        "     'max_features': [2,4,6,10,20],\n",
        "     'n_estimators': [3,10,30,50]}\n",
        "grid_search = GridSearchCV(rf,parameters, cv=5, scoring='neg_root_mean_squared_error')\n",
        "grid_search.fit(train_final_x,train_final_y)\n",
        "print('최적의 하이퍼파라미터',grid_search.best_params_)\n",
        "print('최적 모델의 cv score', -grid_search.best_score_)\n",
        "print('최적 모델',grid_search.best_estimator_ )\n",
        "\n",
        "new_row = {\"Model\": \"Random forest\",\"최적 모델의 cv_RMSE\": -grid_search.best_score_}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uYfyvS7ArMmI",
        "outputId": "fb9491f1-b42d-47f5-a8b7-7b143114edc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 하이퍼파라미터 {'max_depth': 50, 'max_features': 10, 'n_estimators': 50}\n",
            "최적 모델의 cv score 0.48718973316010034\n",
            "최적 모델 RandomForestRegressor(max_depth=50, max_features=10, n_estimators=50,\n",
            "                      random_state=42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "60 fits failed out of a total of 300.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "60 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 467, in fit\n",
            "    for i, t in enumerate(trees)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 1043, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 779, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 263, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 1320, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 308, in fit\n",
            "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
            "ValueError: max_features must be in (0, n_features]\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [-0.67838211 -0.5864147  -0.56239306 -0.56153781 -0.5959689  -0.52946565\n",
            " -0.50335255 -0.50075692 -0.58459913 -0.52559811 -0.49281987 -0.48890739\n",
            " -0.55710576 -0.50689391 -0.48864212 -0.48904897         nan         nan\n",
            "         nan         nan -0.639712   -0.56271803 -0.53997498 -0.53637825\n",
            " -0.60941149 -0.51789126 -0.50160254 -0.49444157 -0.58339828 -0.50948175\n",
            " -0.49371842 -0.48723436 -0.56817989 -0.50192994 -0.48810738 -0.48718973\n",
            "         nan         nan         nan         nan -0.639712   -0.56271803\n",
            " -0.53997498 -0.53637825 -0.60941149 -0.51789126 -0.50160254 -0.49444157\n",
            " -0.58339828 -0.50948175 -0.49371842 -0.48723436 -0.56817989 -0.50192994\n",
            " -0.48810738 -0.48718973         nan         nan         nan         nan]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Model  최적 모델의 cv_RMSE\n",
              "0             CB        0.465640\n",
              "1             GB        0.459638\n",
              "2  Random forest        0.487190"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b92197b3-314f-4027-a8f9-4414367bbcd4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>최적 모델의 cv_RMSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CB</td>\n",
              "      <td>0.465640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GB</td>\n",
              "      <td>0.459638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random forest</td>\n",
              "      <td>0.487190</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b92197b3-314f-4027-a8f9-4414367bbcd4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b92197b3-314f-4027-a8f9-4414367bbcd4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b92197b3-314f-4027-a8f9-4414367bbcd4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGB"
      ],
      "metadata": {
        "id": "8_FU_b1Erk5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XgbBoost=XGBRegressor(random_state=42)\n",
        "parameters ={'nthread':[4],\n",
        "              'objective':['reg:linear'],\n",
        "              'learning_rate': [.03, 0.05, .07],\n",
        "              'max_depth': [5, 6, 7],\n",
        "              'min_child_weight': [4],\n",
        "              'silent': [1],\n",
        "              'subsample': [0.7],\n",
        "              'colsample_bytree': [0.7],\n",
        "              'n_estimators': [500]}\n",
        "grid_search = GridSearchCV(XgbBoost ,parameters, cv=5, scoring='neg_root_mean_squared_error')\n",
        "grid_search.fit(train_final_x,train_final_y)\n",
        "print('최적의 하이퍼파라미터',grid_search.best_params_)\n",
        "print('최적 모델의 cv score', -grid_search.best_score_)\n",
        "print('최적 모델',grid_search.best_estimator_ )\n",
        "\n",
        "new_row = {\"Model\": \"Xgboost\",\"최적 모델의 cv_RMSE\": -grid_search.best_score_}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "SKPE9vD_rj7t",
        "outputId": "ddfa256c-4caa-40b6-d698-62afe773bd7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 하이퍼파라미터 {'colsample_bytree': 0.7, 'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 500, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n",
            "최적 모델의 cv score 0.4565236399580666\n",
            "최적 모델 XGBRegressor(colsample_bytree=0.7, learning_rate=0.03, max_depth=5,\n",
            "             min_child_weight=4, n_estimators=500, nthread=4, random_state=42,\n",
            "             silent=1, subsample=0.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Model  최적 모델의 cv_RMSE\n",
              "0             CB        0.465640\n",
              "1             GB        0.459638\n",
              "2  Random forest        0.487190\n",
              "3        Xgboost        0.456524"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e6fea7d-ecaf-4d74-b17e-5c5897913433\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>최적 모델의 cv_RMSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CB</td>\n",
              "      <td>0.465640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GB</td>\n",
              "      <td>0.459638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random forest</td>\n",
              "      <td>0.487190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>0.456524</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e6fea7d-ecaf-4d74-b17e-5c5897913433')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e6fea7d-ecaf-4d74-b17e-5c5897913433 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e6fea7d-ecaf-4d74-b17e-5c5897913433');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importances_values =grid_search.best_estimator_.feature_importances_\n",
        "importances = pd.Series(importances_values, index=train_final_x.columns)\n",
        "top101 = importances.sort_values(ascending=False)[:30]\n",
        "plt.figure(figsize=(50, 50))\n",
        "plt.title('Feature importances Top 30')\n",
        "sns.barplot(x = top101, y = top101.index)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "GlEsCyw0PxE5",
        "outputId": "1248c96e-e7ca-469c-d9ff-cbb5f9887550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3600x3600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#a=list(importances[importances_values<0.01].index)\n",
        "#train_final_x=train_final_x.drop(a,axis=1)\n",
        "#test_final_x=test_final_x.drop(a,axis=1)"
      ],
      "metadata": {
        "id": "9J9uHs4IQlFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXTRATREE"
      ],
      "metadata": {
        "id": "gwIGXY_6sDrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Extree=ExtraTreesRegressor(random_state=42)\n",
        "parameters={'max_depth': [10, 30, 100, 120],\n",
        "     'max_features': [2,4,7,11,],\n",
        "     'n_estimators': [3,15,30,55,80,100]}\n",
        "grid_search = GridSearchCV(Extree ,parameters, cv=5, scoring='neg_root_mean_squared_error')\n",
        "grid_search.fit(train_final_x,train_final_y)\n",
        "print('최적의 하이퍼파라미터',grid_search.best_params_)\n",
        "print('최적 모델의 cv score', -grid_search.best_score_)\n",
        "print('최적 모델',grid_search.best_estimator_ )\n",
        "\n",
        "new_row = {\"Model\": \"Extratree\",\"최적 모델의 cv_RMSE\": -grid_search.best_score_}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "-V-eDhYlsEyH",
        "outputId": "eea5f59b-3c6c-4d9e-f8cd-ede869b3bd44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 하이퍼파라미터 {'max_depth': 30, 'max_features': 11, 'n_estimators': 55}\n",
            "최적 모델의 cv score 0.4742390729927596\n",
            "최적 모델 ExtraTreesRegressor(max_depth=30, max_features=11, n_estimators=55,\n",
            "                    random_state=42)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Model  최적 모델의 cv_RMSE\n",
              "0             CB        0.465640\n",
              "1             GB        0.459638\n",
              "2  Random forest        0.487190\n",
              "3        Xgboost        0.456524\n",
              "4      Extratree        0.474239"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c70a6ce-1199-49db-a59b-1fda45e334ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>최적 모델의 cv_RMSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CB</td>\n",
              "      <td>0.465640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GB</td>\n",
              "      <td>0.459638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random forest</td>\n",
              "      <td>0.487190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>0.456524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Extratree</td>\n",
              "      <td>0.474239</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c70a6ce-1199-49db-a59b-1fda45e334ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c70a6ce-1199-49db-a59b-1fda45e334ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c70a6ce-1199-49db-a59b-1fda45e334ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LGBM"
      ],
      "metadata": {
        "id": "UynwDI7KscPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Lgbm=LGBMRegressor(random_state=42)\n",
        "parameters = {\n",
        "    'num_leaves': [7, 14, 21, 28, 31, 50],\n",
        "    'learning_rate': [0.1, 0.03, 0.003],\n",
        "    'max_depth': [-1, 3, 5],\n",
        "    'n_estimators': [50, 100, 200, 500],\n",
        "}\n",
        "grid_search = GridSearchCV(Lgbm ,parameters, cv=5, scoring='neg_root_mean_squared_error')\n",
        "grid_search.fit(train_final_x,train_final_y)\n",
        "print('최적의 하이퍼파라미터',grid_search.best_params_)\n",
        "print('최적 모델의 cv score', -grid_search.best_score_)\n",
        "print('최적 모델',grid_search.best_estimator_ )\n",
        "\n",
        "new_row = {\"Model\": \"LGBM\",\"최적 모델의 cv_RMSE\": -grid_search.best_score_}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsForOuAseTU",
        "outputId": "315b5856-13b0-40a6-bd12-5a03bbafae44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 하이퍼파라미터 {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'num_leaves': 7}\n",
            "최적 모델의 cv score 0.464428625287435\n",
            "최적 모델 LGBMRegressor(max_depth=3, num_leaves=7, random_state=42)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Model  최적 모델의 cv_RMSE\n",
              "0             CB        0.465640\n",
              "1             GB        0.459638\n",
              "2  Random forest        0.487190\n",
              "3        Xgboost        0.456524\n",
              "4      Extratree        0.474239\n",
              "5           LGBM        0.464429"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e046c0d-a62a-4f83-b6e8-2b630e058874\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>최적 모델의 cv_RMSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CB</td>\n",
              "      <td>0.465640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GB</td>\n",
              "      <td>0.459638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random forest</td>\n",
              "      <td>0.487190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>0.456524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Extratree</td>\n",
              "      <td>0.474239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LGBM</td>\n",
              "      <td>0.464429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e046c0d-a62a-4f83-b6e8-2b630e058874')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e046c0d-a62a-4f83-b6e8-2b630e058874 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e046c0d-a62a-4f83-b6e8-2b630e058874');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ada"
      ],
      "metadata": {
        "id": "77ivCgDHLrpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AdaBoost=AdaBoostRegressor(random_state=42)\n",
        "parameters ={'n_estimators': [10,50,100,500] , 'learning_rate':[1,0.1,0.01,0.001,0.0001]}\n",
        "grid_search = GridSearchCV(AdaBoost ,parameters, cv=5, scoring='neg_root_mean_squared_error')\n",
        "grid_search.fit(train_final_x,train_final_y)\n",
        "print('최적의 하이퍼파라미터',grid_search.best_params_)\n",
        "print('최적 모델의 cv score', -grid_search.best_score_)\n",
        "print('최적 모델',grid_search.best_estimator_ )\n",
        "\n",
        "new_row = {\"Model\": \"Adaboost\",\"최적 모델의 cv_RMSE\": -grid_search.best_score_}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFHtgB4uLrGo",
        "outputId": "a71a93e6-6c77-48ec-c3fe-f543927ecc0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 하이퍼파라미터 {'learning_rate': 0.001, 'n_estimators': 500}\n",
            "최적 모델의 cv score 0.5861649266121762\n",
            "최적 모델 AdaBoostRegressor(learning_rate=0.001, n_estimators=500, random_state=42)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Model  최적 모델의 cv_RMSE\n",
              "0             CB        0.465640\n",
              "1             GB        0.459638\n",
              "2  Random forest        0.487190\n",
              "3        Xgboost        0.456524\n",
              "4      Extratree        0.474239\n",
              "5           LGBM        0.464429\n",
              "6       Adaboost        0.586165"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34b57617-7300-4db8-b661-63f945920923\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>최적 모델의 cv_RMSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CB</td>\n",
              "      <td>0.465640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GB</td>\n",
              "      <td>0.459638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random forest</td>\n",
              "      <td>0.487190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>0.456524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Extratree</td>\n",
              "      <td>0.474239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LGBM</td>\n",
              "      <td>0.464429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Adaboost</td>\n",
              "      <td>0.586165</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34b57617-7300-4db8-b661-63f945920923')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34b57617-7300-4db8-b661-63f945920923 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34b57617-7300-4db8-b661-63f945920923');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ELA"
      ],
      "metadata": {
        "id": "oF01DagVMM8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Enet= ElasticNet(random_state=42)\n",
        "parametersGrid = {\"max_iter\": [1, 5, 10],\n",
        "                      \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
        "                      \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}\n",
        "\n",
        "grid_search = GridSearchCV(Enet ,parametersGrid, cv=5, scoring='neg_root_mean_squared_error')\n",
        "grid_search.fit(train_final_x,train_final_y)\n",
        "print('최적의 하이퍼파라미터',grid_search.best_params_)\n",
        "print('최적 모델의 cv score', -grid_search.best_score_)\n",
        "print('최적 모델',grid_search.best_estimator_ )\n",
        "\n",
        "new_row = {\"Model\": \"Enet\",\"최적 모델의 cv_RMSE\": -grid_search.best_score_}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpWf54yHMOTT",
        "outputId": "55607d19-fc96-4124-ab82-1963c40064ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.602e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.241e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.359e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.335e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.354e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.602e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.358e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.231e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.350e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.602e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.346e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.318e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.602e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.222e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.245e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.602e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.306e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.241e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.231e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.350e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.349e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.324e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.288e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.231e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.282e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.228e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.608e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.346e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.254e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.194e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.317e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.276e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.610e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.442e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.243e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.361e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.459e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.351e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.318e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.609e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.613e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.335e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.216e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.461e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.610e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.614e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.320e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.162e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.462e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.615e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.276e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.042e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.617e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.289e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.112e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.464e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.613e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.618e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.450e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.243e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.966e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.074e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.923e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.465e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.614e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.619e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.452e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.634e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.776e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.688e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.466e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.615e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.620e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.210e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.179e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.320e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.387e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.463e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.467e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.616e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.621e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.459e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.023e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.022e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.977e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.248e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.647e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.648e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.479e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.310e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.427e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.306e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.399e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.512e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.657e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.659e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.498e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.491e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.060e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.435e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.465e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.159e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.375e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.665e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.669e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.503e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.503e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.676e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.746e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.914e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.895e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.925e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.612e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.790e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.625e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.850e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.184e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.526e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.678e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.506e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.514e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.205e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.395e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.387e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.602e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.244e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.163e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.154e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.118e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.346e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.821e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.532e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.678e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.508e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.057e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.020e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.650e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.547e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.273e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.190e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.069e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.325e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.928e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.683e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.693e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.534e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.121e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.915e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.648e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.474e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.507e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.313e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.632e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.570e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.304e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.688e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.542e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.315e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.987e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.559e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.844e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.775e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.031e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.760e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.241e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.025e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.818e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.541e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.692e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.508e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.550e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.601e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.213e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.386e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.142e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.175e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.690e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.340e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.641e+00, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.610e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.451e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.708e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.508e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.558e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.999e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.576e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.249e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.530e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.662e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.521e+00, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.697e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.712e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.506e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.565e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.485e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.034e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.218e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.700e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.783e+00, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.999e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.936e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.864e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.973e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.951e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.800e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.767e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.723e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.815e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.781e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.675e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.723e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.815e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.781e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.675e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.825e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.949e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.944e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.716e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.792e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.222e+00, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.419e+00, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.698e-01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.337e+00, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.173e-01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.079e-01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.763e-01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.703e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.837e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.511e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.751e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+00, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.217e-01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+00, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.647e+00, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.019e-01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e-01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+02, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.615e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.831e-01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.972e-01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+00, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.641e+00, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.622e-01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e+02, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+02, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.349e+02, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.940e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.192e-01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.666e-01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+00, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.020e-01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.375e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.954e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.292e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.817e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+02, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e-01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.540e-01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.845e-01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.395e-01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.986e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.652e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.297e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.726e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.548e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.646e-01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.652e-01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.712e-01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.811e-01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.646e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.644e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.071e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.927e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.570e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.971e-01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.315e-01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.050e-01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.822e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.235e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.065e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.788e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.369e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.287e-01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.830e-01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.701e-01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.402e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.069e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.751e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.611e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.166e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.986e-01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.369e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.347e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.318e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.056e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.040e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.321e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.281e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.261e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.996e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.953e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.321e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.281e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.261e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.996e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.953e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.126e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.952e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.938e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.848e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.902e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.528e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.534e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.775e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e+01, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.628e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+01, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.647e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.191e+01, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.849e+00, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.831e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.857e+00, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.174e+00, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.313e+00, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.461e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.490e+00, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.940e+00, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.712e+00, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.054e+00, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+01, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.368e+00, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.880e+00, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.551e+00, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.073e+00, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.101e+00, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+00, tolerance: 1.122e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.854e+00, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.702e+00, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e+00, tolerance: 1.002e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.258e+00, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.688e-01, tolerance: 1.149e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+00, tolerance: 1.164e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.588e+00, tolerance: 1.118e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.993e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.990e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.090e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.442e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.783e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.990e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.986e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.087e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.438e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.778e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.990e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.986e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.087e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.438e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.778e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.523e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.629e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.715e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.926e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.471e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.523e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.629e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.715e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.926e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.471e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.523e+02, tolerance: 1.122e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.629e+02, tolerance: 1.149e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.715e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.926e+02, tolerance: 1.002e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.471e+02, tolerance: 1.118e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 하이퍼파라미터 {'alpha': 0.001, 'l1_ratio': 0.1, 'max_iter': 10}\n",
            "최적 모델의 cv score 0.6046927454605436\n",
            "최적 모델 ElasticNet(alpha=0.001, l1_ratio=0.1, max_iter=10, random_state=42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.562e+02, tolerance: 1.393e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Model  최적 모델의 cv_RMSE\n",
              "0             CB        0.465640\n",
              "1             GB        0.459638\n",
              "2  Random forest        0.487190\n",
              "3        Xgboost        0.456524\n",
              "4      Extratree        0.474239\n",
              "5           LGBM        0.464429\n",
              "6       Adaboost        0.586165\n",
              "7           Enet        0.604693"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49011359-16c6-4b6d-8d48-1fdd2f867dbe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>최적 모델의 cv_RMSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CB</td>\n",
              "      <td>0.465640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GB</td>\n",
              "      <td>0.459638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random forest</td>\n",
              "      <td>0.487190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>0.456524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Extratree</td>\n",
              "      <td>0.474239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LGBM</td>\n",
              "      <td>0.464429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Adaboost</td>\n",
              "      <td>0.586165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Enet</td>\n",
              "      <td>0.604693</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49011359-16c6-4b6d-8d48-1fdd2f867dbe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49011359-16c6-4b6d-8d48-1fdd2f867dbe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49011359-16c6-4b6d-8d48-1fdd2f867dbe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacking"
      ],
      "metadata": {
        "id": "c5GOUUtQsL0_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "최종모델"
      ],
      "metadata": {
        "id": "6bpNeyHIubKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
        "    def __init__(self, models):\n",
        "        self.models = models\n",
        "        \n",
        "    # we define clones of the original models to fit the data in\n",
        "    #모델 복제 후 fitting 시킴\n",
        "    def fit(self, X, y):\n",
        "        self.models_ = [clone(x) for x in self.models]\n",
        "        \n",
        "        # Train cloned base models\n",
        "        for model in self.models_:\n",
        "            model.fit(X, y)\n",
        "\n",
        "        return self\n",
        "    \n",
        "    #Now we do the predictions for cloned models and average them\n",
        "    def predict(self, X):\n",
        "        predictions = np.column_stack([\n",
        "            model.predict(X) for model in self.models_\n",
        "        ])\n",
        "        return np.mean(predictions, axis=1) \n",
        "        \n",
        "#Validation function\n",
        "n_folds = 5\n",
        "\n",
        "def rmsle_cv(model):\n",
        "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train_final_x)\n",
        "    rmse= np.sqrt(-cross_val_score(model, train_final_x, train_final_y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
        "    return(rmse)        "
      ],
      "metadata": {
        "id": "ipSQivpQxmFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CB =cb.CatBoostRegressor(depth= 6, iterations=100,learning_rate=0.1)\n",
        "GB=GradientBoostingRegressor(learning_rate=0.05, max_leaf_nodes=50,\n",
        "                          n_estimators=200)\n",
        "XGB= XGBRegressor(colsample_bytree=0.7, learning_rate=0.03, max_depth=5,\n",
        "             min_child_weight=4, n_estimators=500, nthread=4, random_state=42,\n",
        "             silent=1, subsample=0.7)\n",
        "\n",
        "LGB=LGBMRegressor(learning_rate=0.03, max_depth=5, n_estimators=500, num_leaves=7,\n",
        "              random_state=42)"
      ],
      "metadata": {
        "id": "JGTMt-WEOAyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#우영이형 전처리-> 그리드 서치 후 최적 파라미터 이용한 스태킹\n",
        "\n",
        "averaged_models = AveragingModels(models = (XGB,CB))\n",
        "\n",
        "score = rmsle_cv(averaged_models)\n",
        "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
        "\n",
        "averaged_models.fit(train_final_x,train_final_y)\n",
        "test_pred= averaged_models.predict(test_final_x)\n",
        "\n",
        "test_final_y1=np.expm1(test_final_y)\n",
        "test_pred1=np.expm1(test_pred)\n",
        "\n",
        "evaluation(test_final_y1,test_pred1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQfP4Q8EO6dx",
        "outputId": "ffde249f-a84a-4389-e658-2290840d23e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 1.1137859\ttotal: 1.53ms\tremaining: 151ms\n",
            "1:\tlearn: 1.0463552\ttotal: 8.31ms\tremaining: 407ms\n",
            "2:\tlearn: 0.9815046\ttotal: 10ms\tremaining: 324ms\n",
            "3:\tlearn: 0.9304922\ttotal: 11.7ms\tremaining: 281ms\n",
            "4:\tlearn: 0.8785228\ttotal: 13.4ms\tremaining: 254ms\n",
            "5:\tlearn: 0.8317260\ttotal: 14.7ms\tremaining: 231ms\n",
            "6:\tlearn: 0.7917082\ttotal: 16.4ms\tremaining: 219ms\n",
            "7:\tlearn: 0.7523165\ttotal: 18.1ms\tremaining: 208ms\n",
            "8:\tlearn: 0.7202061\ttotal: 19.7ms\tremaining: 200ms\n",
            "9:\tlearn: 0.6923622\ttotal: 21.4ms\tremaining: 192ms\n",
            "10:\tlearn: 0.6651994\ttotal: 23ms\tremaining: 186ms\n",
            "11:\tlearn: 0.6390332\ttotal: 24.8ms\tremaining: 182ms\n",
            "12:\tlearn: 0.6180132\ttotal: 26.5ms\tremaining: 178ms\n",
            "13:\tlearn: 0.5995942\ttotal: 28.4ms\tremaining: 175ms\n",
            "14:\tlearn: 0.5808969\ttotal: 30.1ms\tremaining: 171ms\n",
            "15:\tlearn: 0.5675517\ttotal: 31.7ms\tremaining: 167ms\n",
            "16:\tlearn: 0.5530353\ttotal: 33.4ms\tremaining: 163ms\n",
            "17:\tlearn: 0.5411181\ttotal: 35ms\tremaining: 160ms\n",
            "18:\tlearn: 0.5300813\ttotal: 36.7ms\tremaining: 156ms\n",
            "19:\tlearn: 0.5197716\ttotal: 38.4ms\tremaining: 153ms\n",
            "20:\tlearn: 0.5109046\ttotal: 39.9ms\tremaining: 150ms\n",
            "21:\tlearn: 0.5004387\ttotal: 41.6ms\tremaining: 147ms\n",
            "22:\tlearn: 0.4926233\ttotal: 42.9ms\tremaining: 144ms\n",
            "23:\tlearn: 0.4839557\ttotal: 44.5ms\tremaining: 141ms\n",
            "24:\tlearn: 0.4771158\ttotal: 46.1ms\tremaining: 138ms\n",
            "25:\tlearn: 0.4698838\ttotal: 47.9ms\tremaining: 136ms\n",
            "26:\tlearn: 0.4673857\ttotal: 48.7ms\tremaining: 132ms\n",
            "27:\tlearn: 0.4613549\ttotal: 50.3ms\tremaining: 129ms\n",
            "28:\tlearn: 0.4567325\ttotal: 52ms\tremaining: 127ms\n",
            "29:\tlearn: 0.4527571\ttotal: 53.6ms\tremaining: 125ms\n",
            "30:\tlearn: 0.4490258\ttotal: 55.3ms\tremaining: 123ms\n",
            "31:\tlearn: 0.4452685\ttotal: 57ms\tremaining: 121ms\n",
            "32:\tlearn: 0.4416201\ttotal: 60.1ms\tremaining: 122ms\n",
            "33:\tlearn: 0.4387047\ttotal: 61.8ms\tremaining: 120ms\n",
            "34:\tlearn: 0.4351937\ttotal: 63.5ms\tremaining: 118ms\n",
            "35:\tlearn: 0.4318059\ttotal: 65.1ms\tremaining: 116ms\n",
            "36:\tlearn: 0.4285585\ttotal: 67.1ms\tremaining: 114ms\n",
            "37:\tlearn: 0.4247103\ttotal: 68.7ms\tremaining: 112ms\n",
            "38:\tlearn: 0.4223948\ttotal: 70.4ms\tremaining: 110ms\n",
            "39:\tlearn: 0.4197242\ttotal: 72ms\tremaining: 108ms\n",
            "40:\tlearn: 0.4175940\ttotal: 73.7ms\tremaining: 106ms\n",
            "41:\tlearn: 0.4146079\ttotal: 75.2ms\tremaining: 104ms\n",
            "42:\tlearn: 0.4123812\ttotal: 76.9ms\tremaining: 102ms\n",
            "43:\tlearn: 0.4105126\ttotal: 78.5ms\tremaining: 99.9ms\n",
            "44:\tlearn: 0.4071862\ttotal: 80.2ms\tremaining: 98ms\n",
            "45:\tlearn: 0.4034779\ttotal: 81.9ms\tremaining: 96.2ms\n",
            "46:\tlearn: 0.4019384\ttotal: 86.1ms\tremaining: 97.1ms\n",
            "47:\tlearn: 0.4002458\ttotal: 88.3ms\tremaining: 95.7ms\n",
            "48:\tlearn: 0.3985817\ttotal: 91.6ms\tremaining: 95.3ms\n",
            "49:\tlearn: 0.3968060\ttotal: 93ms\tremaining: 93ms\n",
            "50:\tlearn: 0.3949233\ttotal: 94.6ms\tremaining: 90.9ms\n",
            "51:\tlearn: 0.3929947\ttotal: 105ms\tremaining: 96.9ms\n",
            "52:\tlearn: 0.3915114\ttotal: 107ms\tremaining: 95.3ms\n",
            "53:\tlearn: 0.3897948\ttotal: 112ms\tremaining: 95.5ms\n",
            "54:\tlearn: 0.3886261\ttotal: 117ms\tremaining: 95.6ms\n",
            "55:\tlearn: 0.3871990\ttotal: 123ms\tremaining: 96.5ms\n",
            "56:\tlearn: 0.3858704\ttotal: 127ms\tremaining: 95.5ms\n",
            "57:\tlearn: 0.3845256\ttotal: 128ms\tremaining: 92.9ms\n",
            "58:\tlearn: 0.3820042\ttotal: 130ms\tremaining: 90.3ms\n",
            "59:\tlearn: 0.3797790\ttotal: 132ms\tremaining: 87.7ms\n",
            "60:\tlearn: 0.3777108\ttotal: 133ms\tremaining: 85.1ms\n",
            "61:\tlearn: 0.3756096\ttotal: 135ms\tremaining: 82.6ms\n",
            "62:\tlearn: 0.3746433\ttotal: 136ms\tremaining: 80.1ms\n",
            "63:\tlearn: 0.3734442\ttotal: 138ms\tremaining: 77.7ms\n",
            "64:\tlearn: 0.3714280\ttotal: 140ms\tremaining: 75.2ms\n",
            "65:\tlearn: 0.3697672\ttotal: 141ms\tremaining: 72.8ms\n",
            "66:\tlearn: 0.3686929\ttotal: 143ms\tremaining: 70.4ms\n",
            "67:\tlearn: 0.3665985\ttotal: 144ms\tremaining: 68ms\n",
            "68:\tlearn: 0.3656245\ttotal: 146ms\tremaining: 65.7ms\n",
            "69:\tlearn: 0.3646637\ttotal: 148ms\tremaining: 63.4ms\n",
            "70:\tlearn: 0.3627427\ttotal: 149ms\tremaining: 61ms\n",
            "71:\tlearn: 0.3614950\ttotal: 151ms\tremaining: 58.7ms\n",
            "72:\tlearn: 0.3602021\ttotal: 153ms\tremaining: 56.5ms\n",
            "73:\tlearn: 0.3587658\ttotal: 154ms\tremaining: 54.2ms\n",
            "74:\tlearn: 0.3573175\ttotal: 156ms\tremaining: 52ms\n",
            "75:\tlearn: 0.3559267\ttotal: 158ms\tremaining: 49.8ms\n",
            "76:\tlearn: 0.3542985\ttotal: 159ms\tremaining: 47.6ms\n",
            "77:\tlearn: 0.3528806\ttotal: 161ms\tremaining: 45.4ms\n",
            "78:\tlearn: 0.3517920\ttotal: 163ms\tremaining: 43.3ms\n",
            "79:\tlearn: 0.3504701\ttotal: 164ms\tremaining: 41.1ms\n",
            "80:\tlearn: 0.3485725\ttotal: 166ms\tremaining: 38.9ms\n",
            "81:\tlearn: 0.3471150\ttotal: 168ms\tremaining: 36.8ms\n",
            "82:\tlearn: 0.3457393\ttotal: 169ms\tremaining: 34.7ms\n",
            "83:\tlearn: 0.3441679\ttotal: 171ms\tremaining: 32.6ms\n",
            "84:\tlearn: 0.3436077\ttotal: 173ms\tremaining: 30.5ms\n",
            "85:\tlearn: 0.3421351\ttotal: 174ms\tremaining: 28.4ms\n",
            "86:\tlearn: 0.3417052\ttotal: 176ms\tremaining: 26.3ms\n",
            "87:\tlearn: 0.3411633\ttotal: 178ms\tremaining: 24.2ms\n",
            "88:\tlearn: 0.3399713\ttotal: 179ms\tremaining: 22.1ms\n",
            "89:\tlearn: 0.3384576\ttotal: 181ms\tremaining: 20.1ms\n",
            "90:\tlearn: 0.3380249\ttotal: 182ms\tremaining: 18ms\n",
            "91:\tlearn: 0.3369799\ttotal: 184ms\tremaining: 16ms\n",
            "92:\tlearn: 0.3354067\ttotal: 185ms\tremaining: 14ms\n",
            "93:\tlearn: 0.3331811\ttotal: 188ms\tremaining: 12ms\n",
            "94:\tlearn: 0.3325953\ttotal: 191ms\tremaining: 10ms\n",
            "95:\tlearn: 0.3320933\ttotal: 194ms\tremaining: 8.1ms\n",
            "96:\tlearn: 0.3317559\ttotal: 196ms\tremaining: 6.06ms\n",
            "97:\tlearn: 0.3302374\ttotal: 198ms\tremaining: 4.03ms\n",
            "98:\tlearn: 0.3290983\ttotal: 199ms\tremaining: 2.01ms\n",
            "99:\tlearn: 0.3279073\ttotal: 201ms\tremaining: 0us\n",
            "0:\tlearn: 1.1262692\ttotal: 1.57ms\tremaining: 156ms\n",
            "1:\tlearn: 1.0558039\ttotal: 3.85ms\tremaining: 189ms\n",
            "2:\tlearn: 0.9884005\ttotal: 5.78ms\tremaining: 187ms\n",
            "3:\tlearn: 0.9348341\ttotal: 7.4ms\tremaining: 178ms\n",
            "4:\tlearn: 0.8809363\ttotal: 9.27ms\tremaining: 176ms\n",
            "5:\tlearn: 0.8332530\ttotal: 10.8ms\tremaining: 170ms\n",
            "6:\tlearn: 0.7924684\ttotal: 12.5ms\tremaining: 166ms\n",
            "7:\tlearn: 0.7550590\ttotal: 14.1ms\tremaining: 162ms\n",
            "8:\tlearn: 0.7175878\ttotal: 15.8ms\tremaining: 160ms\n",
            "9:\tlearn: 0.6882319\ttotal: 17.5ms\tremaining: 157ms\n",
            "10:\tlearn: 0.6646721\ttotal: 19.1ms\tremaining: 155ms\n",
            "11:\tlearn: 0.6385665\ttotal: 20.8ms\tremaining: 152ms\n",
            "12:\tlearn: 0.6153457\ttotal: 22.4ms\tremaining: 150ms\n",
            "13:\tlearn: 0.5949373\ttotal: 24.1ms\tremaining: 148ms\n",
            "14:\tlearn: 0.5771930\ttotal: 25.9ms\tremaining: 147ms\n",
            "15:\tlearn: 0.5621712\ttotal: 27.7ms\tremaining: 145ms\n",
            "16:\tlearn: 0.5478140\ttotal: 29.4ms\tremaining: 143ms\n",
            "17:\tlearn: 0.5358533\ttotal: 30.9ms\tremaining: 141ms\n",
            "18:\tlearn: 0.5233888\ttotal: 32.6ms\tremaining: 139ms\n",
            "19:\tlearn: 0.5121181\ttotal: 34.2ms\tremaining: 137ms\n",
            "20:\tlearn: 0.5041494\ttotal: 35.8ms\tremaining: 135ms\n",
            "21:\tlearn: 0.4963415\ttotal: 37.4ms\tremaining: 133ms\n",
            "22:\tlearn: 0.4887928\ttotal: 39.1ms\tremaining: 131ms\n",
            "23:\tlearn: 0.4797535\ttotal: 40.7ms\tremaining: 129ms\n",
            "24:\tlearn: 0.4733969\ttotal: 42.4ms\tremaining: 127ms\n",
            "25:\tlearn: 0.4656227\ttotal: 44.1ms\tremaining: 126ms\n",
            "26:\tlearn: 0.4581352\ttotal: 45.8ms\tremaining: 124ms\n",
            "27:\tlearn: 0.4531590\ttotal: 47.3ms\tremaining: 122ms\n",
            "28:\tlearn: 0.4495432\ttotal: 48.6ms\tremaining: 119ms\n",
            "29:\tlearn: 0.4446914\ttotal: 50.2ms\tremaining: 117ms\n",
            "30:\tlearn: 0.4406257\ttotal: 51.9ms\tremaining: 115ms\n",
            "31:\tlearn: 0.4357050\ttotal: 53.6ms\tremaining: 114ms\n",
            "32:\tlearn: 0.4325411\ttotal: 55.2ms\tremaining: 112ms\n",
            "33:\tlearn: 0.4294287\ttotal: 56.9ms\tremaining: 110ms\n",
            "34:\tlearn: 0.4264903\ttotal: 58.4ms\tremaining: 108ms\n",
            "35:\tlearn: 0.4229379\ttotal: 59.9ms\tremaining: 107ms\n",
            "36:\tlearn: 0.4191845\ttotal: 61.6ms\tremaining: 105ms\n",
            "37:\tlearn: 0.4153639\ttotal: 63.3ms\tremaining: 103ms\n",
            "38:\tlearn: 0.4127446\ttotal: 64.9ms\tremaining: 102ms\n",
            "39:\tlearn: 0.4097157\ttotal: 66.5ms\tremaining: 99.8ms\n",
            "40:\tlearn: 0.4079442\ttotal: 68.2ms\tremaining: 98.2ms\n",
            "41:\tlearn: 0.4065381\ttotal: 69.8ms\tremaining: 96.5ms\n",
            "42:\tlearn: 0.4049265\ttotal: 71.5ms\tremaining: 94.8ms\n",
            "43:\tlearn: 0.4028917\ttotal: 73.4ms\tremaining: 93.4ms\n",
            "44:\tlearn: 0.4010625\ttotal: 75.3ms\tremaining: 92ms\n",
            "45:\tlearn: 0.3987625\ttotal: 77ms\tremaining: 90.4ms\n",
            "46:\tlearn: 0.3967004\ttotal: 78.7ms\tremaining: 88.8ms\n",
            "47:\tlearn: 0.3945776\ttotal: 80.4ms\tremaining: 87.1ms\n",
            "48:\tlearn: 0.3929607\ttotal: 82.2ms\tremaining: 85.6ms\n",
            "49:\tlearn: 0.3910174\ttotal: 83.9ms\tremaining: 83.9ms\n",
            "50:\tlearn: 0.3888641\ttotal: 85.8ms\tremaining: 82.5ms\n",
            "51:\tlearn: 0.3873280\ttotal: 87.6ms\tremaining: 80.8ms\n",
            "52:\tlearn: 0.3856770\ttotal: 89.3ms\tremaining: 79.2ms\n",
            "53:\tlearn: 0.3840172\ttotal: 92.5ms\tremaining: 78.8ms\n",
            "54:\tlearn: 0.3825726\ttotal: 94.2ms\tremaining: 77ms\n",
            "55:\tlearn: 0.3812783\ttotal: 95.9ms\tremaining: 75.3ms\n",
            "56:\tlearn: 0.3793527\ttotal: 97.6ms\tremaining: 73.7ms\n",
            "57:\tlearn: 0.3780514\ttotal: 99.4ms\tremaining: 72ms\n",
            "58:\tlearn: 0.3766650\ttotal: 101ms\tremaining: 70.2ms\n",
            "59:\tlearn: 0.3747612\ttotal: 103ms\tremaining: 68.4ms\n",
            "60:\tlearn: 0.3733499\ttotal: 104ms\tremaining: 66.7ms\n",
            "61:\tlearn: 0.3724523\ttotal: 106ms\tremaining: 64.9ms\n",
            "62:\tlearn: 0.3701372\ttotal: 108ms\tremaining: 63.2ms\n",
            "63:\tlearn: 0.3685586\ttotal: 109ms\tremaining: 61.4ms\n",
            "64:\tlearn: 0.3674637\ttotal: 111ms\tremaining: 59.7ms\n",
            "65:\tlearn: 0.3662162\ttotal: 112ms\tremaining: 57.9ms\n",
            "66:\tlearn: 0.3645373\ttotal: 114ms\tremaining: 56.3ms\n",
            "67:\tlearn: 0.3630141\ttotal: 117ms\tremaining: 55ms\n",
            "68:\tlearn: 0.3612670\ttotal: 119ms\tremaining: 53.6ms\n",
            "69:\tlearn: 0.3596374\ttotal: 121ms\tremaining: 51.9ms\n",
            "70:\tlearn: 0.3580407\ttotal: 124ms\tremaining: 50.8ms\n",
            "71:\tlearn: 0.3561520\ttotal: 126ms\tremaining: 48.9ms\n",
            "72:\tlearn: 0.3551254\ttotal: 127ms\tremaining: 47ms\n",
            "73:\tlearn: 0.3536650\ttotal: 129ms\tremaining: 45.2ms\n",
            "74:\tlearn: 0.3526281\ttotal: 130ms\tremaining: 43.3ms\n",
            "75:\tlearn: 0.3508659\ttotal: 132ms\tremaining: 41.5ms\n",
            "76:\tlearn: 0.3492750\ttotal: 133ms\tremaining: 39.8ms\n",
            "77:\tlearn: 0.3482380\ttotal: 135ms\tremaining: 38ms\n",
            "78:\tlearn: 0.3471563\ttotal: 136ms\tremaining: 36.3ms\n",
            "79:\tlearn: 0.3465734\ttotal: 138ms\tremaining: 34.5ms\n",
            "80:\tlearn: 0.3453692\ttotal: 140ms\tremaining: 32.8ms\n",
            "81:\tlearn: 0.3442503\ttotal: 141ms\tremaining: 31ms\n",
            "82:\tlearn: 0.3431211\ttotal: 143ms\tremaining: 29.3ms\n",
            "83:\tlearn: 0.3420228\ttotal: 145ms\tremaining: 27.5ms\n",
            "84:\tlearn: 0.3413302\ttotal: 146ms\tremaining: 25.8ms\n",
            "85:\tlearn: 0.3403029\ttotal: 148ms\tremaining: 24.1ms\n",
            "86:\tlearn: 0.3392128\ttotal: 150ms\tremaining: 22.3ms\n",
            "87:\tlearn: 0.3381199\ttotal: 151ms\tremaining: 20.6ms\n",
            "88:\tlearn: 0.3369004\ttotal: 153ms\tremaining: 18.9ms\n",
            "89:\tlearn: 0.3356914\ttotal: 155ms\tremaining: 17.2ms\n",
            "90:\tlearn: 0.3348571\ttotal: 156ms\tremaining: 15.4ms\n",
            "91:\tlearn: 0.3337895\ttotal: 158ms\tremaining: 13.7ms\n",
            "92:\tlearn: 0.3324645\ttotal: 160ms\tremaining: 12ms\n",
            "93:\tlearn: 0.3306946\ttotal: 161ms\tremaining: 10.3ms\n",
            "94:\tlearn: 0.3296374\ttotal: 163ms\tremaining: 8.56ms\n",
            "95:\tlearn: 0.3287862\ttotal: 164ms\tremaining: 6.84ms\n",
            "96:\tlearn: 0.3270341\ttotal: 166ms\tremaining: 5.13ms\n",
            "97:\tlearn: 0.3260878\ttotal: 168ms\tremaining: 3.42ms\n",
            "98:\tlearn: 0.3255790\ttotal: 169ms\tremaining: 1.71ms\n",
            "99:\tlearn: 0.3246167\ttotal: 171ms\tremaining: 0us\n",
            "0:\tlearn: 1.1331984\ttotal: 1.41ms\tremaining: 140ms\n",
            "1:\tlearn: 1.0554920\ttotal: 2.85ms\tremaining: 140ms\n",
            "2:\tlearn: 0.9923015\ttotal: 4.16ms\tremaining: 135ms\n",
            "3:\tlearn: 0.9333904\ttotal: 5.82ms\tremaining: 140ms\n",
            "4:\tlearn: 0.8849825\ttotal: 7.53ms\tremaining: 143ms\n",
            "5:\tlearn: 0.8357441\ttotal: 9.28ms\tremaining: 145ms\n",
            "6:\tlearn: 0.7949355\ttotal: 12.6ms\tremaining: 167ms\n",
            "7:\tlearn: 0.7585609\ttotal: 15.1ms\tremaining: 174ms\n",
            "8:\tlearn: 0.7245499\ttotal: 18.6ms\tremaining: 188ms\n",
            "9:\tlearn: 0.6962168\ttotal: 20.8ms\tremaining: 187ms\n",
            "10:\tlearn: 0.6744022\ttotal: 22.6ms\tremaining: 183ms\n",
            "11:\tlearn: 0.6464037\ttotal: 24.3ms\tremaining: 178ms\n",
            "12:\tlearn: 0.6243267\ttotal: 26.1ms\tremaining: 174ms\n",
            "13:\tlearn: 0.6043777\ttotal: 27.8ms\tremaining: 171ms\n",
            "14:\tlearn: 0.5858363\ttotal: 29.6ms\tremaining: 168ms\n",
            "15:\tlearn: 0.5705699\ttotal: 31.3ms\tremaining: 164ms\n",
            "16:\tlearn: 0.5568510\ttotal: 33ms\tremaining: 161ms\n",
            "17:\tlearn: 0.5432545\ttotal: 34.8ms\tremaining: 158ms\n",
            "18:\tlearn: 0.5299184\ttotal: 36.4ms\tremaining: 155ms\n",
            "19:\tlearn: 0.5182452\ttotal: 38.3ms\tremaining: 153ms\n",
            "20:\tlearn: 0.5103727\ttotal: 39.9ms\tremaining: 150ms\n",
            "21:\tlearn: 0.5026392\ttotal: 41.6ms\tremaining: 148ms\n",
            "22:\tlearn: 0.4950401\ttotal: 43.6ms\tremaining: 146ms\n",
            "23:\tlearn: 0.4869034\ttotal: 45.2ms\tremaining: 143ms\n",
            "24:\tlearn: 0.4795878\ttotal: 46.8ms\tremaining: 140ms\n",
            "25:\tlearn: 0.4720586\ttotal: 48.6ms\tremaining: 138ms\n",
            "26:\tlearn: 0.4662539\ttotal: 50.2ms\tremaining: 136ms\n",
            "27:\tlearn: 0.4605510\ttotal: 52ms\tremaining: 134ms\n",
            "28:\tlearn: 0.4567411\ttotal: 53.1ms\tremaining: 130ms\n",
            "29:\tlearn: 0.4523803\ttotal: 54.7ms\tremaining: 128ms\n",
            "30:\tlearn: 0.4479621\ttotal: 56.3ms\tremaining: 125ms\n",
            "31:\tlearn: 0.4430782\ttotal: 58ms\tremaining: 123ms\n",
            "32:\tlearn: 0.4386709\ttotal: 59.6ms\tremaining: 121ms\n",
            "33:\tlearn: 0.4350070\ttotal: 61.4ms\tremaining: 119ms\n",
            "34:\tlearn: 0.4321959\ttotal: 63ms\tremaining: 117ms\n",
            "35:\tlearn: 0.4289211\ttotal: 64.8ms\tremaining: 115ms\n",
            "36:\tlearn: 0.4250366\ttotal: 66.5ms\tremaining: 113ms\n",
            "37:\tlearn: 0.4226504\ttotal: 68.2ms\tremaining: 111ms\n",
            "38:\tlearn: 0.4195422\ttotal: 69.7ms\tremaining: 109ms\n",
            "39:\tlearn: 0.4179693\ttotal: 71.4ms\tremaining: 107ms\n",
            "40:\tlearn: 0.4160516\ttotal: 73.1ms\tremaining: 105ms\n",
            "41:\tlearn: 0.4144673\ttotal: 74.8ms\tremaining: 103ms\n",
            "42:\tlearn: 0.4130042\ttotal: 76.4ms\tremaining: 101ms\n",
            "43:\tlearn: 0.4112160\ttotal: 78.1ms\tremaining: 99.4ms\n",
            "44:\tlearn: 0.4092704\ttotal: 79.6ms\tremaining: 97.3ms\n",
            "45:\tlearn: 0.4072986\ttotal: 81.3ms\tremaining: 95.5ms\n",
            "46:\tlearn: 0.4056220\ttotal: 83ms\tremaining: 93.6ms\n",
            "47:\tlearn: 0.4042646\ttotal: 84.7ms\tremaining: 91.8ms\n",
            "48:\tlearn: 0.4029793\ttotal: 86.4ms\tremaining: 89.9ms\n",
            "49:\tlearn: 0.4005548\ttotal: 88.1ms\tremaining: 88.1ms\n",
            "50:\tlearn: 0.3981721\ttotal: 89.7ms\tremaining: 86.2ms\n",
            "51:\tlearn: 0.3965826\ttotal: 91.4ms\tremaining: 84.4ms\n",
            "52:\tlearn: 0.3951210\ttotal: 93.1ms\tremaining: 82.5ms\n",
            "53:\tlearn: 0.3943104\ttotal: 94.7ms\tremaining: 80.7ms\n",
            "54:\tlearn: 0.3931579\ttotal: 96.4ms\tremaining: 78.8ms\n",
            "55:\tlearn: 0.3905281\ttotal: 98.1ms\tremaining: 77.1ms\n",
            "56:\tlearn: 0.3876223\ttotal: 99.7ms\tremaining: 75.2ms\n",
            "57:\tlearn: 0.3855358\ttotal: 101ms\tremaining: 73.4ms\n",
            "58:\tlearn: 0.3841744\ttotal: 103ms\tremaining: 71.6ms\n",
            "59:\tlearn: 0.3823637\ttotal: 105ms\tremaining: 69.9ms\n",
            "60:\tlearn: 0.3808263\ttotal: 106ms\tremaining: 68.1ms\n",
            "61:\tlearn: 0.3797524\ttotal: 108ms\tremaining: 66.3ms\n",
            "62:\tlearn: 0.3777810\ttotal: 110ms\tremaining: 64.5ms\n",
            "63:\tlearn: 0.3758002\ttotal: 112ms\tremaining: 62.7ms\n",
            "64:\tlearn: 0.3741956\ttotal: 113ms\tremaining: 61ms\n",
            "65:\tlearn: 0.3728386\ttotal: 115ms\tremaining: 59.2ms\n",
            "66:\tlearn: 0.3716590\ttotal: 117ms\tremaining: 57.5ms\n",
            "67:\tlearn: 0.3702350\ttotal: 118ms\tremaining: 55.7ms\n",
            "68:\tlearn: 0.3684888\ttotal: 120ms\tremaining: 53.9ms\n",
            "69:\tlearn: 0.3674169\ttotal: 122ms\tremaining: 52.1ms\n",
            "70:\tlearn: 0.3657582\ttotal: 123ms\tremaining: 50.3ms\n",
            "71:\tlearn: 0.3640143\ttotal: 125ms\tremaining: 48.5ms\n",
            "72:\tlearn: 0.3626657\ttotal: 126ms\tremaining: 46.8ms\n",
            "73:\tlearn: 0.3609112\ttotal: 128ms\tremaining: 45ms\n",
            "74:\tlearn: 0.3592760\ttotal: 130ms\tremaining: 43.3ms\n",
            "75:\tlearn: 0.3574662\ttotal: 132ms\tremaining: 41.6ms\n",
            "76:\tlearn: 0.3560759\ttotal: 133ms\tremaining: 39.8ms\n",
            "77:\tlearn: 0.3545871\ttotal: 135ms\tremaining: 38.1ms\n",
            "78:\tlearn: 0.3529362\ttotal: 137ms\tremaining: 36.4ms\n",
            "79:\tlearn: 0.3512187\ttotal: 138ms\tremaining: 34.6ms\n",
            "80:\tlearn: 0.3501717\ttotal: 140ms\tremaining: 32.9ms\n",
            "81:\tlearn: 0.3493941\ttotal: 142ms\tremaining: 31.1ms\n",
            "82:\tlearn: 0.3482669\ttotal: 143ms\tremaining: 29.3ms\n",
            "83:\tlearn: 0.3471701\ttotal: 145ms\tremaining: 27.6ms\n",
            "84:\tlearn: 0.3463625\ttotal: 147ms\tremaining: 25.9ms\n",
            "85:\tlearn: 0.3456738\ttotal: 149ms\tremaining: 24.2ms\n",
            "86:\tlearn: 0.3444345\ttotal: 150ms\tremaining: 22.5ms\n",
            "87:\tlearn: 0.3434679\ttotal: 152ms\tremaining: 20.7ms\n",
            "88:\tlearn: 0.3424354\ttotal: 154ms\tremaining: 19ms\n",
            "89:\tlearn: 0.3409668\ttotal: 156ms\tremaining: 17.3ms\n",
            "90:\tlearn: 0.3398059\ttotal: 157ms\tremaining: 15.6ms\n",
            "91:\tlearn: 0.3385623\ttotal: 159ms\tremaining: 13.8ms\n",
            "92:\tlearn: 0.3373501\ttotal: 161ms\tremaining: 12.1ms\n",
            "93:\tlearn: 0.3367395\ttotal: 162ms\tremaining: 10.3ms\n",
            "94:\tlearn: 0.3350259\ttotal: 164ms\tremaining: 8.62ms\n",
            "95:\tlearn: 0.3338934\ttotal: 166ms\tremaining: 6.9ms\n",
            "96:\tlearn: 0.3322587\ttotal: 167ms\tremaining: 5.18ms\n",
            "97:\tlearn: 0.3314979\ttotal: 169ms\tremaining: 3.45ms\n",
            "98:\tlearn: 0.3308684\ttotal: 172ms\tremaining: 1.74ms\n",
            "99:\tlearn: 0.3290895\ttotal: 173ms\tremaining: 0us\n",
            "0:\tlearn: 1.0527423\ttotal: 1.47ms\tremaining: 146ms\n",
            "1:\tlearn: 0.9905640\ttotal: 3.53ms\tremaining: 173ms\n",
            "2:\tlearn: 0.9294691\ttotal: 5.09ms\tremaining: 165ms\n",
            "3:\tlearn: 0.8813288\ttotal: 6.69ms\tremaining: 161ms\n",
            "4:\tlearn: 0.8333337\ttotal: 8.3ms\tremaining: 158ms\n",
            "5:\tlearn: 0.7928390\ttotal: 10.1ms\tremaining: 158ms\n",
            "6:\tlearn: 0.7556956\ttotal: 11.8ms\tremaining: 156ms\n",
            "7:\tlearn: 0.7204796\ttotal: 13.4ms\tremaining: 154ms\n",
            "8:\tlearn: 0.6882246\ttotal: 14.7ms\tremaining: 148ms\n",
            "9:\tlearn: 0.6610696\ttotal: 16.3ms\tremaining: 146ms\n",
            "10:\tlearn: 0.6375617\ttotal: 17.9ms\tremaining: 145ms\n",
            "11:\tlearn: 0.6151848\ttotal: 19.6ms\tremaining: 144ms\n",
            "12:\tlearn: 0.5945490\ttotal: 21.2ms\tremaining: 142ms\n",
            "13:\tlearn: 0.5769656\ttotal: 22.9ms\tremaining: 140ms\n",
            "14:\tlearn: 0.5612341\ttotal: 24.4ms\tremaining: 138ms\n",
            "15:\tlearn: 0.5504465\ttotal: 25.4ms\tremaining: 133ms\n",
            "16:\tlearn: 0.5374054\ttotal: 27.1ms\tremaining: 132ms\n",
            "17:\tlearn: 0.5241097\ttotal: 28.6ms\tremaining: 131ms\n",
            "18:\tlearn: 0.5158142\ttotal: 30.2ms\tremaining: 129ms\n",
            "19:\tlearn: 0.5089185\ttotal: 31.5ms\tremaining: 126ms\n",
            "20:\tlearn: 0.5003009\ttotal: 32.8ms\tremaining: 123ms\n",
            "21:\tlearn: 0.4923465\ttotal: 34.4ms\tremaining: 122ms\n",
            "22:\tlearn: 0.4862001\ttotal: 36.1ms\tremaining: 121ms\n",
            "23:\tlearn: 0.4774836\ttotal: 37.8ms\tremaining: 120ms\n",
            "24:\tlearn: 0.4711934\ttotal: 39.4ms\tremaining: 118ms\n",
            "25:\tlearn: 0.4636275\ttotal: 41ms\tremaining: 117ms\n",
            "26:\tlearn: 0.4583322\ttotal: 42.7ms\tremaining: 115ms\n",
            "27:\tlearn: 0.4535639\ttotal: 44.2ms\tremaining: 114ms\n",
            "28:\tlearn: 0.4476261\ttotal: 45.9ms\tremaining: 112ms\n",
            "29:\tlearn: 0.4435811\ttotal: 47.5ms\tremaining: 111ms\n",
            "30:\tlearn: 0.4387802\ttotal: 49.2ms\tremaining: 109ms\n",
            "31:\tlearn: 0.4348835\ttotal: 50.7ms\tremaining: 108ms\n",
            "32:\tlearn: 0.4312190\ttotal: 52.2ms\tremaining: 106ms\n",
            "33:\tlearn: 0.4282382\ttotal: 53.9ms\tremaining: 105ms\n",
            "34:\tlearn: 0.4249504\ttotal: 55.5ms\tremaining: 103ms\n",
            "35:\tlearn: 0.4221255\ttotal: 57ms\tremaining: 101ms\n",
            "36:\tlearn: 0.4186593\ttotal: 58.7ms\tremaining: 100ms\n",
            "37:\tlearn: 0.4163067\ttotal: 60.3ms\tremaining: 98.4ms\n",
            "38:\tlearn: 0.4139810\ttotal: 61.9ms\tremaining: 96.8ms\n",
            "39:\tlearn: 0.4117577\ttotal: 63.5ms\tremaining: 95.3ms\n",
            "40:\tlearn: 0.4103470\ttotal: 65.2ms\tremaining: 93.9ms\n",
            "41:\tlearn: 0.4086896\ttotal: 66.9ms\tremaining: 92.3ms\n",
            "42:\tlearn: 0.4064608\ttotal: 68.5ms\tremaining: 90.8ms\n",
            "43:\tlearn: 0.4045190\ttotal: 70.2ms\tremaining: 89.4ms\n",
            "44:\tlearn: 0.4021776\ttotal: 71.9ms\tremaining: 87.9ms\n",
            "45:\tlearn: 0.3989918\ttotal: 73.6ms\tremaining: 86.4ms\n",
            "46:\tlearn: 0.3971757\ttotal: 75.3ms\tremaining: 84.9ms\n",
            "47:\tlearn: 0.3956472\ttotal: 76.9ms\tremaining: 83.3ms\n",
            "48:\tlearn: 0.3939618\ttotal: 78.5ms\tremaining: 81.7ms\n",
            "49:\tlearn: 0.3911542\ttotal: 80ms\tremaining: 80ms\n",
            "50:\tlearn: 0.3890100\ttotal: 81.7ms\tremaining: 78.5ms\n",
            "51:\tlearn: 0.3880221\ttotal: 83.3ms\tremaining: 76.9ms\n",
            "52:\tlearn: 0.3866411\ttotal: 85ms\tremaining: 75.4ms\n",
            "53:\tlearn: 0.3850690\ttotal: 86.6ms\tremaining: 73.8ms\n",
            "54:\tlearn: 0.3837245\ttotal: 88.2ms\tremaining: 72.2ms\n",
            "55:\tlearn: 0.3818645\ttotal: 89.8ms\tremaining: 70.5ms\n",
            "56:\tlearn: 0.3799730\ttotal: 91.4ms\tremaining: 69ms\n",
            "57:\tlearn: 0.3782515\ttotal: 93ms\tremaining: 67.4ms\n",
            "58:\tlearn: 0.3770341\ttotal: 94.3ms\tremaining: 65.6ms\n",
            "59:\tlearn: 0.3752948\ttotal: 95.9ms\tremaining: 63.9ms\n",
            "60:\tlearn: 0.3741587\ttotal: 97.5ms\tremaining: 62.3ms\n",
            "61:\tlearn: 0.3732840\ttotal: 99.1ms\tremaining: 60.8ms\n",
            "62:\tlearn: 0.3719693\ttotal: 101ms\tremaining: 59.2ms\n",
            "63:\tlearn: 0.3705141\ttotal: 102ms\tremaining: 57.6ms\n",
            "64:\tlearn: 0.3691938\ttotal: 104ms\tremaining: 56.1ms\n",
            "65:\tlearn: 0.3671389\ttotal: 106ms\tremaining: 54.5ms\n",
            "66:\tlearn: 0.3655199\ttotal: 107ms\tremaining: 52.9ms\n",
            "67:\tlearn: 0.3647111\ttotal: 109ms\tremaining: 51.3ms\n",
            "68:\tlearn: 0.3632625\ttotal: 111ms\tremaining: 49.7ms\n",
            "69:\tlearn: 0.3620260\ttotal: 112ms\tremaining: 48.1ms\n",
            "70:\tlearn: 0.3596703\ttotal: 114ms\tremaining: 46.5ms\n",
            "71:\tlearn: 0.3579362\ttotal: 116ms\tremaining: 44.9ms\n",
            "72:\tlearn: 0.3568732\ttotal: 117ms\tremaining: 43.3ms\n",
            "73:\tlearn: 0.3556847\ttotal: 119ms\tremaining: 41.7ms\n",
            "74:\tlearn: 0.3545881\ttotal: 120ms\tremaining: 40.1ms\n",
            "75:\tlearn: 0.3533550\ttotal: 122ms\tremaining: 38.6ms\n",
            "76:\tlearn: 0.3523871\ttotal: 124ms\tremaining: 37ms\n",
            "77:\tlearn: 0.3516504\ttotal: 125ms\tremaining: 35.4ms\n",
            "78:\tlearn: 0.3504525\ttotal: 127ms\tremaining: 33.8ms\n",
            "79:\tlearn: 0.3498317\ttotal: 129ms\tremaining: 32.2ms\n",
            "80:\tlearn: 0.3484770\ttotal: 130ms\tremaining: 30.6ms\n",
            "81:\tlearn: 0.3473927\ttotal: 132ms\tremaining: 29ms\n",
            "82:\tlearn: 0.3457358\ttotal: 134ms\tremaining: 27.4ms\n",
            "83:\tlearn: 0.3440763\ttotal: 135ms\tremaining: 25.8ms\n",
            "84:\tlearn: 0.3431448\ttotal: 137ms\tremaining: 24.2ms\n",
            "85:\tlearn: 0.3418610\ttotal: 138ms\tremaining: 22.5ms\n",
            "86:\tlearn: 0.3403846\ttotal: 140ms\tremaining: 20.9ms\n",
            "87:\tlearn: 0.3389191\ttotal: 142ms\tremaining: 19.3ms\n",
            "88:\tlearn: 0.3375420\ttotal: 143ms\tremaining: 17.7ms\n",
            "89:\tlearn: 0.3369676\ttotal: 145ms\tremaining: 16.1ms\n",
            "90:\tlearn: 0.3355809\ttotal: 147ms\tremaining: 14.5ms\n",
            "91:\tlearn: 0.3344247\ttotal: 148ms\tremaining: 12.9ms\n",
            "92:\tlearn: 0.3339852\ttotal: 150ms\tremaining: 11.3ms\n",
            "93:\tlearn: 0.3334392\ttotal: 151ms\tremaining: 9.66ms\n",
            "94:\tlearn: 0.3327669\ttotal: 153ms\tremaining: 8.05ms\n",
            "95:\tlearn: 0.3312203\ttotal: 155ms\tremaining: 6.44ms\n",
            "96:\tlearn: 0.3296986\ttotal: 156ms\tremaining: 4.83ms\n",
            "97:\tlearn: 0.3282375\ttotal: 158ms\tremaining: 3.22ms\n",
            "98:\tlearn: 0.3269180\ttotal: 160ms\tremaining: 1.61ms\n",
            "99:\tlearn: 0.3266236\ttotal: 161ms\tremaining: 0us\n",
            "0:\tlearn: 1.1043199\ttotal: 1.44ms\tremaining: 143ms\n",
            "1:\tlearn: 1.0326181\ttotal: 3.85ms\tremaining: 189ms\n",
            "2:\tlearn: 0.9677785\ttotal: 5.57ms\tremaining: 180ms\n",
            "3:\tlearn: 0.9118845\ttotal: 7.29ms\tremaining: 175ms\n",
            "4:\tlearn: 0.8626335\ttotal: 8.92ms\tremaining: 169ms\n",
            "5:\tlearn: 0.8179228\ttotal: 10.6ms\tremaining: 166ms\n",
            "6:\tlearn: 0.7751439\ttotal: 12.2ms\tremaining: 162ms\n",
            "7:\tlearn: 0.7348205\ttotal: 13.9ms\tremaining: 159ms\n",
            "8:\tlearn: 0.6980073\ttotal: 15.5ms\tremaining: 157ms\n",
            "9:\tlearn: 0.6667046\ttotal: 17.2ms\tremaining: 155ms\n",
            "10:\tlearn: 0.6410571\ttotal: 18.7ms\tremaining: 151ms\n",
            "11:\tlearn: 0.6154093\ttotal: 20.4ms\tremaining: 150ms\n",
            "12:\tlearn: 0.5913560\ttotal: 22.1ms\tremaining: 148ms\n",
            "13:\tlearn: 0.5699848\ttotal: 23.8ms\tremaining: 146ms\n",
            "14:\tlearn: 0.5517556\ttotal: 25.4ms\tremaining: 144ms\n",
            "15:\tlearn: 0.5380189\ttotal: 27ms\tremaining: 142ms\n",
            "16:\tlearn: 0.5238225\ttotal: 28.7ms\tremaining: 140ms\n",
            "17:\tlearn: 0.5137540\ttotal: 30.3ms\tremaining: 138ms\n",
            "18:\tlearn: 0.5036481\ttotal: 31.9ms\tremaining: 136ms\n",
            "19:\tlearn: 0.4936477\ttotal: 33.5ms\tremaining: 134ms\n",
            "20:\tlearn: 0.4832316\ttotal: 35.2ms\tremaining: 133ms\n",
            "21:\tlearn: 0.4755385\ttotal: 36.8ms\tremaining: 130ms\n",
            "22:\tlearn: 0.4675075\ttotal: 38.4ms\tremaining: 129ms\n",
            "23:\tlearn: 0.4594720\ttotal: 40ms\tremaining: 127ms\n",
            "24:\tlearn: 0.4529842\ttotal: 41.7ms\tremaining: 125ms\n",
            "25:\tlearn: 0.4465283\ttotal: 43.3ms\tremaining: 123ms\n",
            "26:\tlearn: 0.4436618\ttotal: 44ms\tremaining: 119ms\n",
            "27:\tlearn: 0.4388955\ttotal: 45.7ms\tremaining: 117ms\n",
            "28:\tlearn: 0.4341751\ttotal: 47.4ms\tremaining: 116ms\n",
            "29:\tlearn: 0.4300207\ttotal: 49ms\tremaining: 114ms\n",
            "30:\tlearn: 0.4266792\ttotal: 50.7ms\tremaining: 113ms\n",
            "31:\tlearn: 0.4238114\ttotal: 52.2ms\tremaining: 111ms\n",
            "32:\tlearn: 0.4191928\ttotal: 53.9ms\tremaining: 109ms\n",
            "33:\tlearn: 0.4163628\ttotal: 55.5ms\tremaining: 108ms\n",
            "34:\tlearn: 0.4122057\ttotal: 57.2ms\tremaining: 106ms\n",
            "35:\tlearn: 0.4088113\ttotal: 58.8ms\tremaining: 105ms\n",
            "36:\tlearn: 0.4049203\ttotal: 60.5ms\tremaining: 103ms\n",
            "37:\tlearn: 0.4014653\ttotal: 62.1ms\tremaining: 101ms\n",
            "38:\tlearn: 0.3981387\ttotal: 63.8ms\tremaining: 99.7ms\n",
            "39:\tlearn: 0.3956019\ttotal: 65.4ms\tremaining: 98.1ms\n",
            "40:\tlearn: 0.3933275\ttotal: 66.9ms\tremaining: 96.3ms\n",
            "41:\tlearn: 0.3915558\ttotal: 68.5ms\tremaining: 94.7ms\n",
            "42:\tlearn: 0.3889712\ttotal: 70.1ms\tremaining: 92.9ms\n",
            "43:\tlearn: 0.3878923\ttotal: 71.7ms\tremaining: 91.2ms\n",
            "44:\tlearn: 0.3853156\ttotal: 73.2ms\tremaining: 89.5ms\n",
            "45:\tlearn: 0.3825915\ttotal: 74.9ms\tremaining: 87.9ms\n",
            "46:\tlearn: 0.3818040\ttotal: 76.6ms\tremaining: 86.3ms\n",
            "47:\tlearn: 0.3798138\ttotal: 78.2ms\tremaining: 84.7ms\n",
            "48:\tlearn: 0.3784999\ttotal: 79.8ms\tremaining: 83.1ms\n",
            "49:\tlearn: 0.3770626\ttotal: 81.5ms\tremaining: 81.5ms\n",
            "50:\tlearn: 0.3754084\ttotal: 83.1ms\tremaining: 79.9ms\n",
            "51:\tlearn: 0.3736686\ttotal: 84.9ms\tremaining: 78.3ms\n",
            "52:\tlearn: 0.3718698\ttotal: 86.5ms\tremaining: 76.7ms\n",
            "53:\tlearn: 0.3707026\ttotal: 88ms\tremaining: 75ms\n",
            "54:\tlearn: 0.3685402\ttotal: 89.6ms\tremaining: 73.3ms\n",
            "55:\tlearn: 0.3676355\ttotal: 91.3ms\tremaining: 71.7ms\n",
            "56:\tlearn: 0.3657265\ttotal: 92.9ms\tremaining: 70.1ms\n",
            "57:\tlearn: 0.3642199\ttotal: 94.5ms\tremaining: 68.4ms\n",
            "58:\tlearn: 0.3625900\ttotal: 96.3ms\tremaining: 66.9ms\n",
            "59:\tlearn: 0.3616399\ttotal: 97.9ms\tremaining: 65.3ms\n",
            "60:\tlearn: 0.3602643\ttotal: 99.5ms\tremaining: 63.6ms\n",
            "61:\tlearn: 0.3585379\ttotal: 101ms\tremaining: 62ms\n",
            "62:\tlearn: 0.3571093\ttotal: 103ms\tremaining: 60.4ms\n",
            "63:\tlearn: 0.3563423\ttotal: 104ms\tremaining: 58.8ms\n",
            "64:\tlearn: 0.3544086\ttotal: 106ms\tremaining: 57.2ms\n",
            "65:\tlearn: 0.3532561\ttotal: 108ms\tremaining: 55.5ms\n",
            "66:\tlearn: 0.3517379\ttotal: 109ms\tremaining: 53.9ms\n",
            "67:\tlearn: 0.3506720\ttotal: 111ms\tremaining: 52.2ms\n",
            "68:\tlearn: 0.3490458\ttotal: 113ms\tremaining: 50.6ms\n",
            "69:\tlearn: 0.3477991\ttotal: 114ms\tremaining: 49ms\n",
            "70:\tlearn: 0.3466048\ttotal: 116ms\tremaining: 47.3ms\n",
            "71:\tlearn: 0.3453649\ttotal: 117ms\tremaining: 45.7ms\n",
            "72:\tlearn: 0.3439272\ttotal: 119ms\tremaining: 44.1ms\n",
            "73:\tlearn: 0.3418572\ttotal: 121ms\tremaining: 42.5ms\n",
            "74:\tlearn: 0.3405840\ttotal: 122ms\tremaining: 40.8ms\n",
            "75:\tlearn: 0.3397519\ttotal: 124ms\tremaining: 39.2ms\n",
            "76:\tlearn: 0.3385310\ttotal: 126ms\tremaining: 37.6ms\n",
            "77:\tlearn: 0.3364674\ttotal: 127ms\tremaining: 35.9ms\n",
            "78:\tlearn: 0.3355548\ttotal: 129ms\tremaining: 34.3ms\n",
            "79:\tlearn: 0.3343413\ttotal: 131ms\tremaining: 32.7ms\n",
            "80:\tlearn: 0.3332643\ttotal: 132ms\tremaining: 31ms\n",
            "81:\tlearn: 0.3326256\ttotal: 134ms\tremaining: 29.4ms\n",
            "82:\tlearn: 0.3321414\ttotal: 136ms\tremaining: 27.8ms\n",
            "83:\tlearn: 0.3303317\ttotal: 137ms\tremaining: 26.2ms\n",
            "84:\tlearn: 0.3293489\ttotal: 139ms\tremaining: 24.5ms\n",
            "85:\tlearn: 0.3282413\ttotal: 141ms\tremaining: 22.9ms\n",
            "86:\tlearn: 0.3276190\ttotal: 143ms\tremaining: 21.3ms\n",
            "87:\tlearn: 0.3266852\ttotal: 144ms\tremaining: 19.7ms\n",
            "88:\tlearn: 0.3255527\ttotal: 146ms\tremaining: 18.1ms\n",
            "89:\tlearn: 0.3250136\ttotal: 148ms\tremaining: 16.4ms\n",
            "90:\tlearn: 0.3246150\ttotal: 149ms\tremaining: 14.8ms\n",
            "91:\tlearn: 0.3238185\ttotal: 151ms\tremaining: 13.1ms\n",
            "92:\tlearn: 0.3232103\ttotal: 152ms\tremaining: 11.5ms\n",
            "93:\tlearn: 0.3224643\ttotal: 154ms\tremaining: 9.82ms\n",
            "94:\tlearn: 0.3214212\ttotal: 155ms\tremaining: 8.18ms\n",
            "95:\tlearn: 0.3203668\ttotal: 157ms\tremaining: 6.54ms\n",
            "96:\tlearn: 0.3192095\ttotal: 159ms\tremaining: 4.92ms\n",
            "97:\tlearn: 0.3178703\ttotal: 161ms\tremaining: 3.28ms\n",
            "98:\tlearn: 0.3172177\ttotal: 162ms\tremaining: 1.64ms\n",
            "99:\tlearn: 0.3158633\ttotal: 164ms\tremaining: 0us\n",
            " Averaged base models score: 0.4456 (0.0395)\n",
            "\n",
            "0:\tlearn: 1.1091455\ttotal: 1.61ms\tremaining: 159ms\n",
            "1:\tlearn: 1.0390352\ttotal: 3.14ms\tremaining: 154ms\n",
            "2:\tlearn: 0.9755351\ttotal: 4.63ms\tremaining: 150ms\n",
            "3:\tlearn: 0.9179383\ttotal: 6.07ms\tremaining: 146ms\n",
            "4:\tlearn: 0.8700214\ttotal: 7.49ms\tremaining: 142ms\n",
            "5:\tlearn: 0.8256938\ttotal: 8.89ms\tremaining: 139ms\n",
            "6:\tlearn: 0.7859875\ttotal: 10.6ms\tremaining: 140ms\n",
            "7:\tlearn: 0.7477666\ttotal: 12.3ms\tremaining: 142ms\n",
            "8:\tlearn: 0.7122521\ttotal: 14ms\tremaining: 142ms\n",
            "9:\tlearn: 0.6820572\ttotal: 15.8ms\tremaining: 142ms\n",
            "10:\tlearn: 0.6595222\ttotal: 17.5ms\tremaining: 142ms\n",
            "11:\tlearn: 0.6316942\ttotal: 19.3ms\tremaining: 142ms\n",
            "12:\tlearn: 0.6114216\ttotal: 21ms\tremaining: 141ms\n",
            "13:\tlearn: 0.5914682\ttotal: 22.7ms\tremaining: 140ms\n",
            "14:\tlearn: 0.5742945\ttotal: 24.4ms\tremaining: 138ms\n",
            "15:\tlearn: 0.5594602\ttotal: 26.1ms\tremaining: 137ms\n",
            "16:\tlearn: 0.5448641\ttotal: 27.9ms\tremaining: 136ms\n",
            "17:\tlearn: 0.5327354\ttotal: 29.6ms\tremaining: 135ms\n",
            "18:\tlearn: 0.5202429\ttotal: 31.3ms\tremaining: 134ms\n",
            "19:\tlearn: 0.5099590\ttotal: 33.1ms\tremaining: 132ms\n",
            "20:\tlearn: 0.5014969\ttotal: 34.8ms\tremaining: 131ms\n",
            "21:\tlearn: 0.4928562\ttotal: 36.2ms\tremaining: 128ms\n",
            "22:\tlearn: 0.4857556\ttotal: 38ms\tremaining: 127ms\n",
            "23:\tlearn: 0.4775312\ttotal: 39.7ms\tremaining: 126ms\n",
            "24:\tlearn: 0.4702504\ttotal: 41.4ms\tremaining: 124ms\n",
            "25:\tlearn: 0.4636259\ttotal: 43.2ms\tremaining: 123ms\n",
            "26:\tlearn: 0.4574967\ttotal: 44.9ms\tremaining: 121ms\n",
            "27:\tlearn: 0.4524138\ttotal: 46.5ms\tremaining: 120ms\n",
            "28:\tlearn: 0.4488865\ttotal: 47.8ms\tremaining: 117ms\n",
            "29:\tlearn: 0.4448234\ttotal: 49.5ms\tremaining: 116ms\n",
            "30:\tlearn: 0.4409387\ttotal: 51.2ms\tremaining: 114ms\n",
            "31:\tlearn: 0.4375945\ttotal: 52.8ms\tremaining: 112ms\n",
            "32:\tlearn: 0.4344970\ttotal: 54.6ms\tremaining: 111ms\n",
            "33:\tlearn: 0.4312750\ttotal: 56.4ms\tremaining: 109ms\n",
            "34:\tlearn: 0.4281215\ttotal: 58.1ms\tremaining: 108ms\n",
            "35:\tlearn: 0.4254912\ttotal: 59.7ms\tremaining: 106ms\n",
            "36:\tlearn: 0.4224071\ttotal: 61.5ms\tremaining: 105ms\n",
            "37:\tlearn: 0.4201310\ttotal: 63.1ms\tremaining: 103ms\n",
            "38:\tlearn: 0.4178689\ttotal: 64.9ms\tremaining: 101ms\n",
            "39:\tlearn: 0.4158696\ttotal: 66.6ms\tremaining: 99.9ms\n",
            "40:\tlearn: 0.4138966\ttotal: 68.3ms\tremaining: 98.2ms\n",
            "41:\tlearn: 0.4125756\ttotal: 69.9ms\tremaining: 96.6ms\n",
            "42:\tlearn: 0.4109754\ttotal: 71.7ms\tremaining: 95ms\n",
            "43:\tlearn: 0.4090756\ttotal: 73.3ms\tremaining: 93.3ms\n",
            "44:\tlearn: 0.4076602\ttotal: 75ms\tremaining: 91.7ms\n",
            "45:\tlearn: 0.4053089\ttotal: 77.4ms\tremaining: 90.9ms\n",
            "46:\tlearn: 0.4040029\ttotal: 80ms\tremaining: 90.3ms\n",
            "47:\tlearn: 0.4020649\ttotal: 81.8ms\tremaining: 88.6ms\n",
            "48:\tlearn: 0.4004973\ttotal: 83.5ms\tremaining: 86.9ms\n",
            "49:\tlearn: 0.3987729\ttotal: 85.2ms\tremaining: 85.2ms\n",
            "50:\tlearn: 0.3966444\ttotal: 86.6ms\tremaining: 83.2ms\n",
            "51:\tlearn: 0.3938759\ttotal: 88.2ms\tremaining: 81.4ms\n",
            "52:\tlearn: 0.3929352\ttotal: 89.8ms\tremaining: 79.7ms\n",
            "53:\tlearn: 0.3909103\ttotal: 91.6ms\tremaining: 78ms\n",
            "54:\tlearn: 0.3899364\ttotal: 93.4ms\tremaining: 76.4ms\n",
            "55:\tlearn: 0.3884561\ttotal: 95.1ms\tremaining: 74.7ms\n",
            "56:\tlearn: 0.3865846\ttotal: 96.7ms\tremaining: 73ms\n",
            "57:\tlearn: 0.3849440\ttotal: 98.4ms\tremaining: 71.3ms\n",
            "58:\tlearn: 0.3838611\ttotal: 100ms\tremaining: 69.5ms\n",
            "59:\tlearn: 0.3827643\ttotal: 102ms\tremaining: 67.9ms\n",
            "60:\tlearn: 0.3811538\ttotal: 104ms\tremaining: 66.3ms\n",
            "61:\tlearn: 0.3799786\ttotal: 105ms\tremaining: 64.5ms\n",
            "62:\tlearn: 0.3785395\ttotal: 107ms\tremaining: 62.8ms\n",
            "63:\tlearn: 0.3771448\ttotal: 109ms\tremaining: 61.1ms\n",
            "64:\tlearn: 0.3757010\ttotal: 110ms\tremaining: 59.4ms\n",
            "65:\tlearn: 0.3749356\ttotal: 112ms\tremaining: 57.7ms\n",
            "66:\tlearn: 0.3737646\ttotal: 114ms\tremaining: 56.1ms\n",
            "67:\tlearn: 0.3724465\ttotal: 116ms\tremaining: 54.4ms\n",
            "68:\tlearn: 0.3707756\ttotal: 118ms\tremaining: 53.2ms\n",
            "69:\tlearn: 0.3698385\ttotal: 121ms\tremaining: 51.7ms\n",
            "70:\tlearn: 0.3686954\ttotal: 122ms\tremaining: 49.9ms\n",
            "71:\tlearn: 0.3675812\ttotal: 124ms\tremaining: 48.2ms\n",
            "72:\tlearn: 0.3668517\ttotal: 126ms\tremaining: 46.5ms\n",
            "73:\tlearn: 0.3655881\ttotal: 127ms\tremaining: 44.8ms\n",
            "74:\tlearn: 0.3645416\ttotal: 129ms\tremaining: 43.1ms\n",
            "75:\tlearn: 0.3630882\ttotal: 131ms\tremaining: 41.4ms\n",
            "76:\tlearn: 0.3623017\ttotal: 133ms\tremaining: 39.6ms\n",
            "77:\tlearn: 0.3615636\ttotal: 134ms\tremaining: 37.9ms\n",
            "78:\tlearn: 0.3606742\ttotal: 136ms\tremaining: 36.2ms\n",
            "79:\tlearn: 0.3600345\ttotal: 138ms\tremaining: 34.4ms\n",
            "80:\tlearn: 0.3588789\ttotal: 139ms\tremaining: 32.7ms\n",
            "81:\tlearn: 0.3568946\ttotal: 141ms\tremaining: 31ms\n",
            "82:\tlearn: 0.3559951\ttotal: 143ms\tremaining: 29.3ms\n",
            "83:\tlearn: 0.3550152\ttotal: 145ms\tremaining: 27.5ms\n",
            "84:\tlearn: 0.3544132\ttotal: 146ms\tremaining: 25.8ms\n",
            "85:\tlearn: 0.3536024\ttotal: 148ms\tremaining: 24.1ms\n",
            "86:\tlearn: 0.3522295\ttotal: 150ms\tremaining: 22.4ms\n",
            "87:\tlearn: 0.3506947\ttotal: 151ms\tremaining: 20.6ms\n",
            "88:\tlearn: 0.3495832\ttotal: 153ms\tremaining: 18.9ms\n",
            "89:\tlearn: 0.3482104\ttotal: 155ms\tremaining: 17.2ms\n",
            "90:\tlearn: 0.3474850\ttotal: 157ms\tremaining: 15.5ms\n",
            "91:\tlearn: 0.3460047\ttotal: 158ms\tremaining: 13.8ms\n",
            "92:\tlearn: 0.3454571\ttotal: 160ms\tremaining: 12ms\n",
            "93:\tlearn: 0.3450285\ttotal: 161ms\tremaining: 10.3ms\n",
            "94:\tlearn: 0.3438249\ttotal: 163ms\tremaining: 8.59ms\n",
            "95:\tlearn: 0.3423699\ttotal: 165ms\tremaining: 6.89ms\n",
            "96:\tlearn: 0.3414707\ttotal: 167ms\tremaining: 5.17ms\n",
            "97:\tlearn: 0.3404421\ttotal: 169ms\tremaining: 3.44ms\n",
            "98:\tlearn: 0.3393319\ttotal: 170ms\tremaining: 1.72ms\n",
            "99:\tlearn: 0.3387057\ttotal: 172ms\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2778.0743058412013"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제값 vs 예측값 시각화"
      ],
      "metadata": {
        "id": "6E0qz81UijVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(test_final_y1,test_pred1)\n",
        "xpoints = ypoints = plt.xlim()\n",
        "plt.plot(xpoints, ypoints, linestyle='--', color='r', lw=3, scalex=False, scaley=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "klRoKUBdiiuY",
        "outputId": "3b7d565d-1540-46cc-91bf-c003a501087d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4d3e660510>]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 성능 개선 모델링"
      ],
      "metadata": {
        "id": "azpuWAqaXFoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "!pip install catboost\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import ElasticNet,  BayesianRidge, LassoLarsIC\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
        "import catboost as cb\n",
        "import optuna\n",
        "from optuna import Trial, visualization\n",
        "from optuna.samplers import TPESampler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "from sklearn import ensemble\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "def rmse_cv(model):\n",
        "    rmse = -cross_val_score(model, train_final_x,train_final_y, scoring=\"neg_root_mean_squared_error\", cv=5).mean()\n",
        "    return rmse\n",
        "def evaluation(y, predictions):\n",
        "    rmse = np.sqrt(mean_squared_error(y, predictions))\n",
        "    return rmse    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_159FH3XRkm",
        "outputId": "33473fce-d3b7-4dc4-9679-34597e578ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.1-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 52.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.37)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.1-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 77.8 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.1.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=5398d25c3f125721304c11e5823aea9c18ed47017e7ca57ab25b18d3627f8d00\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.1 alembic-1.8.0 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.1 pbr-5.9.0 pyperclip-1.8.2 stevedore-3.5.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.0.6-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 94 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPTUNA_EARLY_STOPING = 30\n",
        "\n",
        "class EarlyStoppingExceeded(optuna.exceptions.OptunaError):\n",
        "    early_stop = OPTUNA_EARLY_STOPING\n",
        "    early_stop_count = 0\n",
        "    best_score = None\n",
        "\n",
        "def early_stopping_opt(study, trial):\n",
        "    if EarlyStoppingExceeded.best_score == None:\n",
        "      EarlyStoppingExceeded.best_score = study.best_value\n",
        "\n",
        "    if study.best_value < EarlyStoppingExceeded.best_score:\n",
        "        EarlyStoppingExceeded.best_score = study.best_value\n",
        "        EarlyStoppingExceeded.early_stop_count = 0\n",
        "    else:\n",
        "      if EarlyStoppingExceeded.early_stop_count > EarlyStoppingExceeded.early_stop:\n",
        "            EarlyStoppingExceeded.early_stop_count = 0\n",
        "            best_score = None\n",
        "            raise EarlyStoppingExceeded()\n",
        "      else:\n",
        "            EarlyStoppingExceeded.early_stop_count=EarlyStoppingExceeded.early_stop_count+1\n",
        "    #print(f'EarlyStop counter: {EarlyStoppingExceeded.early_stop_count}, Best score: {study.best_value} and {EarlyStoppingExceeded.best_score}')\n",
        "    return"
      ],
      "metadata": {
        "id": "OEWrQouxXYVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GradientBoosting regressor"
      ],
      "metadata": {
        "id": "ugglaLL2Xa45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    max_depth = trial.suggest_int('max_depth', 1, 1000)\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1e-2)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 1000)\n",
        "    n_estimators =  trial.suggest_int('n_estimators', 30, 1000)\n",
        "    loss = trial.suggest_categorical('loss', ['ls'])\n",
        "\n",
        "    \n",
        "    regr = ensemble.GradientBoostingRegressor(max_depth = max_depth, learning_rate = learning_rate,\n",
        "                                 min_samples_leaf = min_samples_leaf,n_estimators = n_estimators,loss=loss)\n",
        "    score = cross_val_score(regr,train_final_x,train_final_y, cv=KFold(n_splits=10,shuffle=True,random_state=42), scoring=\"neg_mean_squared_error\")\n",
        "    neg_mean_squared_error_mean = score.mean()\n",
        "\n",
        "    return neg_mean_squared_error_mean"
      ],
      "metadata": {
        "id": "GQ2jZUSKXaP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Execute optuna and set hyperparameters\n",
        "study = optuna.create_study(direction='maximize')\n",
        "try:\n",
        "    study.optimize(objective, n_trials=500, callbacks=[early_stopping_opt])\n",
        "except EarlyStoppingExceeded:\n",
        "    print(f'EarlyStopping Exceeded: No new best scores on iters {OPTUNA_EARLY_STOPING}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwNPG04xXg22",
        "outputId": "1b6b7736-8bd3-482b-8dc6-d136c43d7f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-07 06:34:35,908]\u001b[0m A new study created in memory with name: no-name-d39a1bab-16a9-49aa-b4e0-b1828bbd81af\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:34:38,242]\u001b[0m Trial 0 finished with value: -1.4041052547383992 and parameters: {'max_depth': 19, 'learning_rate': 1.595545481531233e-05, 'min_samples_leaf': 498, 'n_estimators': 565, 'loss': 'ls'}. Best is trial 0 with value: -1.4041052547383992.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:34:42,468]\u001b[0m Trial 1 finished with value: -1.3802937327339229 and parameters: {'max_depth': 251, 'learning_rate': 4.708307960501536e-05, 'min_samples_leaf': 157, 'n_estimators': 257, 'loss': 'ls'}. Best is trial 1 with value: -1.3802937327339229.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:34:43,930]\u001b[0m Trial 2 finished with value: -1.4041052547383992 and parameters: {'max_depth': 112, 'learning_rate': 0.0010583524610318668, 'min_samples_leaf': 514, 'n_estimators': 677, 'loss': 'ls'}. Best is trial 1 with value: -1.3802937327339229.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:34:53,191]\u001b[0m Trial 3 finished with value: -0.5450864765205582 and parameters: {'max_depth': 340, 'learning_rate': 0.0010409214086163343, 'min_samples_leaf': 208, 'n_estimators': 969, 'loss': 'ls'}. Best is trial 3 with value: -0.5450864765205582.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:34:54,570]\u001b[0m Trial 4 finished with value: -1.4041052547383992 and parameters: {'max_depth': 877, 'learning_rate': 0.0012484063982129464, 'min_samples_leaf': 538, 'n_estimators': 731, 'loss': 'ls'}. Best is trial 3 with value: -0.5450864765205582.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:34:55,822]\u001b[0m Trial 5 finished with value: -1.4041052547383992 and parameters: {'max_depth': 471, 'learning_rate': 1.4721410869934494e-05, 'min_samples_leaf': 674, 'n_estimators': 674, 'loss': 'ls'}. Best is trial 3 with value: -0.5450864765205582.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:34:56,818]\u001b[0m Trial 6 finished with value: -1.4041052547383992 and parameters: {'max_depth': 538, 'learning_rate': 0.0018093911308331237, 'min_samples_leaf': 970, 'n_estimators': 530, 'loss': 'ls'}. Best is trial 3 with value: -0.5450864765205582.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:35:04,557]\u001b[0m Trial 7 finished with value: -0.2755247482716693 and parameters: {'max_depth': 323, 'learning_rate': 0.007228692156039215, 'min_samples_leaf': 131, 'n_estimators': 637, 'loss': 'ls'}. Best is trial 7 with value: -0.2755247482716693.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:35:05,440]\u001b[0m Trial 8 finished with value: -1.4038312581201255 and parameters: {'max_depth': 573, 'learning_rate': 3.6599080329372303e-06, 'min_samples_leaf': 10, 'n_estimators': 32, 'loss': 'ls'}. Best is trial 7 with value: -0.2755247482716693.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:35:07,002]\u001b[0m Trial 9 finished with value: -1.4041052547383992 and parameters: {'max_depth': 284, 'learning_rate': 6.549159824839162e-05, 'min_samples_leaf': 486, 'n_estimators': 829, 'loss': 'ls'}. Best is trial 7 with value: -0.2755247482716693.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:35:09,302]\u001b[0m Trial 10 finished with value: -1.4040874602844116 and parameters: {'max_depth': 781, 'learning_rate': 3.611337151099192e-08, 'min_samples_leaf': 271, 'n_estimators': 280, 'loss': 'ls'}. Best is trial 7 with value: -0.2755247482716693.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:35:17,591]\u001b[0m Trial 11 finished with value: -0.3634017172819781 and parameters: {'max_depth': 353, 'learning_rate': 0.009497713674844503, 'min_samples_leaf': 255, 'n_estimators': 997, 'loss': 'ls'}. Best is trial 7 with value: -0.2755247482716693.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:35:50,265]\u001b[0m Trial 12 finished with value: -0.21160521133159013 and parameters: {'max_depth': 408, 'learning_rate': 0.005361406049178215, 'min_samples_leaf': 14, 'n_estimators': 993, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:36:30,888]\u001b[0m Trial 13 finished with value: -0.2551917983530956 and parameters: {'max_depth': 671, 'learning_rate': 0.007507958591393988, 'min_samples_leaf': 4, 'n_estimators': 848, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:37:13,503]\u001b[0m Trial 14 finished with value: -1.4027465217221864 and parameters: {'max_depth': 702, 'learning_rate': 6.737613599747263e-07, 'min_samples_leaf': 1, 'n_estimators': 847, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:37:18,708]\u001b[0m Trial 15 finished with value: -1.144935156507985 and parameters: {'max_depth': 983, 'learning_rate': 0.00022252353935633525, 'min_samples_leaf': 340, 'n_estimators': 879, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:37:19,437]\u001b[0m Trial 16 finished with value: -1.4041052547383992 and parameters: {'max_depth': 646, 'learning_rate': 0.00023401914508883458, 'min_samples_leaf': 858, 'n_estimators': 374, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:37:31,058]\u001b[0m Trial 17 finished with value: -1.40408590026292 and parameters: {'max_depth': 460, 'learning_rate': 1.025492680937569e-08, 'min_samples_leaf': 94, 'n_estimators': 895, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:37:35,895]\u001b[0m Trial 18 finished with value: -1.4025512079969074 and parameters: {'max_depth': 767, 'learning_rate': 1.2167282694926976e-06, 'min_samples_leaf': 373, 'n_estimators': 809, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:37:36,682]\u001b[0m Trial 19 finished with value: -1.4041052547383992 and parameters: {'max_depth': 164, 'learning_rate': 0.0039841297266245196, 'min_samples_leaf': 681, 'n_estimators': 423, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:37:47,563]\u001b[0m Trial 20 finished with value: -1.116400769939738 and parameters: {'max_depth': 450, 'learning_rate': 0.000208608333611785, 'min_samples_leaf': 74, 'n_estimators': 749, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:37:55,466]\u001b[0m Trial 21 finished with value: -0.2642682414467278 and parameters: {'max_depth': 394, 'learning_rate': 0.006672900662551274, 'min_samples_leaf': 122, 'n_estimators': 608, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:38:12,168]\u001b[0m Trial 22 finished with value: -0.24179970355132635 and parameters: {'max_depth': 612, 'learning_rate': 0.0030759060898158932, 'min_samples_leaf': 50, 'n_estimators': 934, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:38:37,008]\u001b[0m Trial 23 finished with value: -0.8014042127348997 and parameters: {'max_depth': 605, 'learning_rate': 0.0003845077846862734, 'min_samples_leaf': 10, 'n_estimators': 946, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:38:46,272]\u001b[0m Trial 24 finished with value: -0.3350992753991708 and parameters: {'max_depth': 695, 'learning_rate': 0.0028851232897630034, 'min_samples_leaf': 179, 'n_estimators': 923, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:39:01,277]\u001b[0m Trial 25 finished with value: -0.7356969183187932 and parameters: {'max_depth': 897, 'learning_rate': 0.0004786905281507835, 'min_samples_leaf': 68, 'n_estimators': 1000, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:39:06,039]\u001b[0m Trial 26 finished with value: -0.5362450131965077 and parameters: {'max_depth': 521, 'learning_rate': 0.002821354291522892, 'min_samples_leaf': 342, 'n_estimators': 790, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:39:13,532]\u001b[0m Trial 27 finished with value: -1.3007642208336476 and parameters: {'max_depth': 731, 'learning_rate': 6.935154364054143e-05, 'min_samples_leaf': 242, 'n_estimators': 894, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:39:21,384]\u001b[0m Trial 28 finished with value: -0.8671613831100167 and parameters: {'max_depth': 627, 'learning_rate': 0.00074794708180515, 'min_samples_leaf': 42, 'n_estimators': 444, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:39:30,089]\u001b[0m Trial 29 finished with value: -1.4038687540958805 and parameters: {'max_depth': 831, 'learning_rate': 1.5665512889549452e-07, 'min_samples_leaf': 123, 'n_estimators': 750, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:39:35,863]\u001b[0m Trial 30 finished with value: -0.46017600266444864 and parameters: {'max_depth': 6, 'learning_rate': 0.009970801159462538, 'min_samples_leaf': 319, 'n_estimators': 952, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n",
            "\u001b[32m[I 2022-07-07 06:39:43,454]\u001b[0m Trial 31 finished with value: -0.2947706534066176 and parameters: {'max_depth': 402, 'learning_rate': 0.00417244074848413, 'min_samples_leaf': 102, 'n_estimators': 575, 'loss': 'ls'}. Best is trial 12 with value: -0.21160521133159013.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping Exceeded: No new best scores on iters 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Best_trial = study.best_trial.params\n",
        "optimised_GB = ensemble.GradientBoostingRegressor(**Best_trial)\n",
        "optimised_GB.fit(train_final_x,train_final_y)\n",
        "mse = mean_squared_error(train_final_y, optimised_GB.predict(train_final_x))\n",
        "\n",
        "print('최적의 하이퍼파라미터',study.best_trial.params)\n",
        "print('최적 모델의 cv score', np.sqrt(mse))\n",
        "print('최적 모델',study.best_trial )\n",
        "\n",
        "models=pd.DataFrame(columns=[\"Model\",\"최적 모델의 cv_RMSE\"])\n",
        "new_row = {\"Model\": \"GradientBoost\",\"최적 모델의 cv_RMSE\": np.sqrt(mse)}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "J1ppYfD4YtMl",
        "outputId": "a8cc5ef0-66d3-4179-834e-4fe12c3a28ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 하이퍼파라미터 {'max_depth': 408, 'learning_rate': 0.005361406049178215, 'min_samples_leaf': 14, 'n_estimators': 993, 'loss': 'ls'}\n",
            "최적 모델의 cv score 0.2145889538960696\n",
            "최적 모델 FrozenTrial(number=12, values=[-0.21160521133159013], datetime_start=datetime.datetime(2022, 7, 7, 6, 35, 17, 593953), datetime_complete=datetime.datetime(2022, 7, 7, 6, 35, 50, 264756), params={'max_depth': 408, 'learning_rate': 0.005361406049178215, 'min_samples_leaf': 14, 'n_estimators': 993, 'loss': 'ls'}, distributions={'max_depth': IntUniformDistribution(high=1000, low=1, step=1), 'learning_rate': LogUniformDistribution(high=0.01, low=1e-08), 'min_samples_leaf': IntUniformDistribution(high=1000, low=1, step=1), 'n_estimators': IntUniformDistribution(high=1000, low=30, step=1), 'loss': CategoricalDistribution(choices=('ls',))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=12, state=TrialState.COMPLETE, value=None)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Model  최적 모델의 cv_RMSE\n",
              "0  GradientBoost        0.214589"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06413332-eef6-4493-807c-3e60e9fddde9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>최적 모델의 cv_RMSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GradientBoost</td>\n",
              "      <td>0.214589</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06413332-eef6-4493-807c-3e60e9fddde9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06413332-eef6-4493-807c-3e60e9fddde9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06413332-eef6-4493-807c-3e60e9fddde9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CATboost"
      ],
      "metadata": {
        "id": "SCM3qx4UY2am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "    cbrm_param = {\n",
        "        'iterations':trial.suggest_int(\"iterations\", 4000, 25000),\n",
        "        'od_wait':trial.suggest_int('od_wait', 500, 2300),\n",
        "        'learning_rate' : trial.suggest_uniform('learning_rate',0.01, 1),\n",
        "        'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
        "        'subsample': trial.suggest_uniform('subsample',0,1),\n",
        "        'random_strength': trial.suggest_uniform('random_strength',10,50),\n",
        "        'depth': trial.suggest_int('depth',1, 15),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n",
        "        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n",
        "        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
        "        'colsample_bylevel':trial.suggest_float('colsample_bylevel', 0.4, 1.0),\n",
        "    }\n",
        "\n",
        "    # Generate model\n",
        "    regr = cb.CatBoostRegressor(**cbrm_param)\n",
        "    score = cross_val_score(regr,train_final_x,train_final_y, cv=KFold(n_splits=10,shuffle=True,random_state=42), scoring=\"neg_mean_squared_error\")\n",
        "    neg_mean_squared_error_mean = score.mean()\n",
        "\n",
        "    return neg_mean_squared_error_mean"
      ],
      "metadata": {
        "id": "5y3Kn1_0Y10o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Execute optuna and set hyperparameters\n",
        "study = optuna.create_study(direction='maximize')\n",
        "try:\n",
        "    study.optimize(objective, n_trials=5, callbacks=[early_stopping_opt])\n",
        "except EarlyStoppingExceeded:\n",
        "    print(f'EarlyStopping Exceeded: No new best scores on iters {OPTUNA_EARLY_STOPING}')"
      ],
      "metadata": {
        "id": "lY8jzNGsY72w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Best_trial = study.best_trial.params\n",
        "optimised_cb = cb.CatBoostRegressor(**Best_trial)\n",
        "optimised_cb.fit(train_final_x,train_final_y)\n",
        "mse = mean_squared_error(train_final_y, optimised_cb.predict(train_final_x))\n",
        "\n",
        "print('최적의 하이퍼파라미터',study.best_trial.params)\n",
        "print('최적 모델의 cv score', np.sqrt(mse))\n",
        "print('최적 모델',study.best_trial )\n",
        "\n",
        "new_row = {\"Model\": \"CatBoost\",\"최적 모델의 cv_RMSE\": np.sqrt(mse)}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "id": "9kBqWBiTY-DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RF"
      ],
      "metadata": {
        "id": "4KIAoujuY8ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "  rf_param = { 'max_features':trial.suggest_int('max_features', 1, 18),\n",
        "              'max_depth':trial.suggest_int('max_depth', 10, 500),\n",
        "              'n_estimators':trial.suggest_int('n_estimators', 1, 100) }\n",
        "\n",
        "  regr = RandomForestRegressor(**rf_param)\n",
        "  score = cross_val_score(regr,train_final_x,train_final_y, cv=KFold(n_splits=10,shuffle=True,random_state=42), scoring=\"neg_mean_squared_error\")\n",
        "  neg_mean_squared_error_mean = score.mean()\n",
        "\n",
        "  return neg_mean_squared_error_mean"
      ],
      "metadata": {
        "id": "-W9fKbCLZAFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Execute optuna and set hyperparameters\n",
        "study = optuna.create_study(direction='maximize')\n",
        "try:\n",
        "    study.optimize(objective, n_trials=500, callbacks=[early_stopping_opt])\n",
        "except EarlyStoppingExceeded:\n",
        "    print(f'EarlyStopping Exceeded: No new best scores on iters {OPTUNA_EARLY_STOPING}')"
      ],
      "metadata": {
        "id": "Dobgn0lXZBkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Best_trial = study.best_trial.params\n",
        "optimised_rf = RandomForestRegressor(**Best_trial)\n",
        "optimised_rf.fit(train_final_x,train_final_y)\n",
        "mse = mean_squared_error(train_final_y, optimised_rf.predict(train_final_x))\n",
        "\n",
        "print('최적의 하이퍼파라미터',study.best_trial.params)\n",
        "print('최적 모델의 cv score', np.sqrt(mse))\n",
        "print('최적 모델',study.best_trial )\n",
        "\n",
        "new_row = {\"Model\": \"RandomForest\",\"최적 모델의 cv_RMSE\": np.sqrt(mse)}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "id": "ELxwqEjtZFTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGB"
      ],
      "metadata": {
        "id": "4ZCjtGdkZG-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "    xgb_param = {\n",
        "        'objective':'reg:squarederror',\n",
        "        'verbose': -1,\n",
        "        'alpha': trial.suggest_uniform('alpha', 0.0, 1.0),\n",
        "        'lambda': trial.suggest_uniform('lambda', 0.0, 10.0),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.7, 1.0),\n",
        "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-2, 1e-1),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
        "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
        "    }\n",
        "\n",
        "    regr = XGBRegressor(**xgb_param)\n",
        "    score = cross_val_score(regr,train_final_x,train_final_y, cv=KFold(n_splits=10,shuffle=True,random_state=42), scoring=\"neg_mean_squared_error\")\n",
        "    neg_mean_squared_error_mean = score.mean()\n",
        "\n",
        "    return neg_mean_squared_error_mean"
      ],
      "metadata": {
        "id": "6LtGORVBZIvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Execute optuna and set hyperparameters\n",
        "study = optuna.create_study(direction='maximize')\n",
        "try:\n",
        "    study.optimize(objective, n_trials=500, callbacks=[early_stopping_opt])\n",
        "except EarlyStoppingExceeded:\n",
        "    print(f'EarlyStopping Exceeded: No new best scores on iters {OPTUNA_EARLY_STOPING}')"
      ],
      "metadata": {
        "id": "Pjh9LK9WZKOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Best_trial = study.best_trial.params\n",
        "optimised_xgb = XGBRegressor(**Best_trial)\n",
        "optimised_xgb.fit(train_final_x,train_final_y)\n",
        "mse = mean_squared_error(train_final_y, optimised_xgb.predict(train_final_x))\n",
        "\n",
        "print('최적의 하이퍼파라미터',study.best_trial.params)\n",
        "print('최적 모델의 cv score', np.sqrt(mse))\n",
        "print('최적 모델',study.best_trial )\n",
        "\n",
        "new_row = {\"Model\": \"XGB\",\"최적 모델의 cv_RMSE\": np.sqrt(mse)}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "id": "VKge0DHdZLpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "extratree"
      ],
      "metadata": {
        "id": "ZPsC2Q5tZNbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "  ex_param = { 'max_features':trial.suggest_int('max_features', 1, 18),\n",
        "              'max_depth':trial.suggest_int('max_depth', 10, 500),\n",
        "              'n_estimators':trial.suggest_int('n_estimators', 1, 100) }\n",
        "\n",
        "  regr = ExtraTreesRegressor(**ex_param,random_state=42)\n",
        "  score = cross_val_score(regr,train_final_x,train_final_y, cv=KFold(n_splits=10,shuffle=True,random_state=42), scoring=\"neg_mean_squared_error\")\n",
        "  neg_mean_squared_error_mean = score.mean()\n",
        "\n",
        "  return neg_mean_squared_error_mean"
      ],
      "metadata": {
        "id": "yPl1GwHKZO6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Execute optuna and set hyperparameters\n",
        "study = optuna.create_study(direction='maximize')\n",
        "try:\n",
        "    study.optimize(objective, n_trials=1000)\n",
        "except EarlyStoppingExceeded:\n",
        "    print(f'EarlyStopping Exceeded: No new best scores on iters {OPTUNA_EARLY_STOPING}')"
      ],
      "metadata": {
        "id": "A3juZzItZQ2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Best_trial = study.best_trial.params\n",
        "optimised_rf = ExtraTreesRegressor(**Best_trial)\n",
        "optimised_rf.fit(train_final_x,train_final_y)\n",
        "mse = mean_squared_error(train_final_y, optimised_rf.predict(train_final_x))\n",
        "\n",
        "print('최적의 하이퍼파라미터',study.best_trial.params)\n",
        "print('최적 모델의 cv score', np.sqrt(mse))\n",
        "print('최적 모델',study.best_trial )\n",
        "\n",
        "new_row = {\"Model\": \"ExtraTrees\",\"최적 모델의 cv_RMSE\": np.sqrt(mse)}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "id": "AfGmTMDsZS0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lgbm"
      ],
      "metadata": {
        "id": "SvnGJp3XZdik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "    lgbm_param = {\n",
        "        'objective': 'regression',\n",
        "        'verbose': -1,\n",
        "        'metric': 'mse', \n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 1024, step=1, log=True), \n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.7, 1.0),\n",
        "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.0, 1.0),\n",
        "        'reg_lambda': trial.suggest_uniform('reg_lambda', 0.0, 10.0),\n",
        "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
        "    }\n",
        "    regr = LGBMRegressor(**lgbm_param)\n",
        "    score = cross_val_score(regr,train_final_x,train_final_y, cv=KFold(n_splits=10,shuffle=True,random_state=42), scoring=\"neg_mean_squared_error\")\n",
        "    neg_mean_squared_error_mean = score.mean()\n",
        "\n",
        "    return neg_mean_squared_error_mean"
      ],
      "metadata": {
        "id": "1joHmr3pZeiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Execute optuna and set hyperparameters\n",
        "study = optuna.create_study(direction='maximize')\n",
        "try:\n",
        "    study.optimize(objective, n_trials=500, callbacks=[early_stopping_opt])\n",
        "except EarlyStoppingExceeded:\n",
        "    print(f'EarlyStopping Exceeded: No new best scores on iters {OPTUNA_EARLY_STOPING}')"
      ],
      "metadata": {
        "id": "j6yMflpfZhJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Best_trial = study.best_trial.params\n",
        "optimised_lgbm = LGBMRegressor(**Best_trial)\n",
        "optimised_lgbm.fit(train_final_x,train_final_y)\n",
        "mse = mean_squared_error(train_final_y, optimised_lgbm.predict(train_final_x))\n",
        "\n",
        "print('최적의 하이퍼파라미터',study.best_trial.params)\n",
        "print('최적 모델의 cv score', np.sqrt(mse))\n",
        "print('최적 모델',study.best_trial )\n",
        "\n",
        "new_row = {\"Model\": \"lightgbm\",\"최적 모델의 cv_RMSE\": np.sqrt(mse)}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "id": "WXDV1iYlZioQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ada"
      ],
      "metadata": {
        "id": "wv8w-Zm8Zkaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    ada_param = { 'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
        "              'n_estimators':trial.suggest_int('n_estimators', 1, 100) }\n",
        "    regr = AdaBoostRegressor(**ada_param,random_state=42)\n",
        "    score = cross_val_score(regr,train_final_x,train_final_y, cv=KFold(n_splits=10,shuffle=True,random_state=42), scoring=\"neg_mean_squared_error\")\n",
        "    neg_mean_squared_error_mean = score.mean()\n",
        "\n",
        "    return neg_mean_squared_error_mean"
      ],
      "metadata": {
        "id": "uJ-4fDELZl4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Execute optuna and set hyperparameters\n",
        "study = optuna.create_study(direction='maximize')\n",
        "try:\n",
        "    study.optimize(objective,n_trials=500, callbacks=[early_stopping_opt])\n",
        "except EarlyStoppingExceeded:\n",
        "    print(f'EarlyStopping Exceeded: No new best scores on iters {OPTUNA_EARLY_STOPING}')"
      ],
      "metadata": {
        "id": "nDjs_L7EZnLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Best_trial = study.best_trial.params\n",
        "optimised_ada = AdaBoostRegressor(**Best_trial)\n",
        "optimised_ada.fit(train_final_x,train_final_y)\n",
        "mse = mean_squared_error(train_final_y, optimised_ada.predict(train_final_x))\n",
        "\n",
        "print('최적의 하이퍼파라미터',study.best_trial.params)\n",
        "print('최적 모델의 cv score', np.sqrt(mse))\n",
        "print('최적 모델',study.best_trial )\n",
        "\n",
        "new_row = {\"Model\": \"Adaboost\",\"최적 모델의 cv_RMSE\": np.sqrt(mse)}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "id": "5pdmzx5WZogi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ela"
      ],
      "metadata": {
        "id": "2c3XyKzKZqYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    ela_param = { 'max_iter':trial.suggest_int('max_iter', 1, 1000),\n",
        "              'alpha':trial.suggest_uniform('alpha', 0.001, 1),\n",
        "              'l1_ratio':trial.suggest_uniform('alpha', 0.001, 1) }\n",
        "    regr = ElasticNet(**ela_param,random_state=42)\n",
        "    score = cross_val_score(regr,train_final_x,train_final_y, cv=KFold(n_splits=10,shuffle=True,random_state=42), scoring=\"neg_mean_squared_error\")\n",
        "    neg_mean_squared_error_mean = score.mean()\n",
        "\n",
        "    return neg_mean_squared_error_mean"
      ],
      "metadata": {
        "id": "TNqpchMOZrBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Execute optuna and set hyperparameters\n",
        "study = optuna.create_study(direction='maximize')\n",
        "try:\n",
        "    study.optimize(objective, n_trials=500, callbacks=[early_stopping_opt])\n",
        "except EarlyStoppingExceeded:\n",
        "    print(f'EarlyStopping Exceeded: No new best scores on iters {OPTUNA_EARLY_STOPING}')"
      ],
      "metadata": {
        "id": "1MhYJYXbZs68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Best_trial = study.best_trial.params\n",
        "optimised_ela = ElasticNet(**Best_trial)\n",
        "optimised_ela.fit(train_final_x,train_final_y)\n",
        "mse = mean_squared_error(train_final_y, optimised_ela.predict(train_final_x))\n",
        "\n",
        "print('최적의 하이퍼파라미터',study.best_trial.params)\n",
        "print('최적 모델의 cv score', np.sqrt(mse))\n",
        "print('최적 모델',study.best_trial )\n",
        "\n",
        "new_row = {\"Model\": \"\bElasticNet\",\"최적 모델의 cv_RMSE\": np.sqrt(mse)}\n",
        "models = models.append(new_row,ignore_index=True)\n",
        "models"
      ],
      "metadata": {
        "id": "LWzCsuc_ZuNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "stacking"
      ],
      "metadata": {
        "id": "ecZzKWOtZvao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
        "    def __init__(self, models):\n",
        "        self.models = models\n",
        "        \n",
        "    # we define clones of the original models to fit the data in\n",
        "    #모델 복제 후 fitting 시킴\n",
        "    def fit(self, X, y):\n",
        "        self.models_ = [clone(x) for x in self.models]\n",
        "        \n",
        "        # Train cloned base models\n",
        "        for model in self.models_:\n",
        "            model.fit(X, y)\n",
        "\n",
        "        return self\n",
        "    \n",
        "    #Now we do the predictions for cloned models and average them\n",
        "    def predict(self, X):\n",
        "        predictions = np.column_stack([\n",
        "            model.predict(X) for model in self.models_\n",
        "        ])\n",
        "        return np.mean(predictions, axis=1) \n",
        "        \n",
        "#Validation function\n",
        "n_folds = 10\n",
        "\n",
        "def rmsle_cv(model):\n",
        "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train_final_x)\n",
        "    rmse= np.sqrt(-cross_val_score(model, train_final_x, train_final_y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
        "    return(rmse)        "
      ],
      "metadata": {
        "id": "8Xuwx0ZbZxpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_pr = {'max_depth': 11, 'learning_rate': 0.009794933198227902, 'min_samples_leaf': 23, 'n_estimators': 976, 'loss': 'ls'}\n",
        "cb_pr = {'iterations': 10637, 'od_wait': 1789, 'learning_rate': 0.09404895730815328, 'reg_lambda': 51.08340432646926, 'subsample': 0.4808467400433857, 'random_strength': 21.485995983978867, 'depth': 7, 'min_data_in_leaf': 1, 'leaf_estimation_iterations': 2, 'bagging_temperature': 0.7489081189661576, 'colsample_bylevel': 0.4720188004073166}\n",
        "rf_pr = {'max_features': 8, 'max_depth': 334, 'n_estimators': 47}\n",
        "xgb_pr = {'alpha': 0.991686499088561, 'lambda': 9.088601450238277, 'colsample_bytree': 0.7444562628375917, 'subsample': 0.5647794393672237, 'learning_rate': 0.08133217592700553, 'n_estimators': 2994, 'max_depth': 15, 'min_child_weight': 1}\n",
        "extra_pr = {'max_features': 15, 'max_depth': 101, 'n_estimators': 95}\n",
        "extra_pr_best ={'max_features': 13, 'max_depth': 10, 'n_estimators': 77}\n",
        "lgbm_pr = {'num_leaves': 365, 'colsample_bytree': 0.9102835616372518, 'reg_alpha': 0.043089329350601835, 'reg_lambda': 0.8937554642690848, 'max_depth': 12, 'learning_rate': 0.004536994407041464, 'n_estimators': 1035, 'min_child_samples': 10, 'subsample': 0.7982089163890633}\n",
        "ada_pr = {'learning_rate': 0.0009024784370187951, 'n_estimators': 37}\n",
        "ela_pr = {'max_iter': 989, 'alpha': 0.006310455718356221}\n",
        "\n",
        "optimised_gb = ensemble.GradientBoostingRegressor(**gb_pr)\n",
        "optimised_cb = cb.CatBoostRegressor(**cb_pr)\n",
        "optimised_rf = RandomForestRegressor(**rf_pr)\n",
        "optimised_xgb = XGBRegressor(**xgb_pr)\n",
        "optimised_lgbm = LGBMRegressor(**lgbm_pr)\n",
        "optimised_extra = ExtraTreesRegressor(**extra_pr)\n",
        "optimised_extra_bs = ExtraTreesRegressor(**extra_pr_best)\n",
        "optimised_ada = AdaBoostRegressor(**ada_pr)\n",
        "optimised_ela = ElasticNet(**ela_pr)"
      ],
      "metadata": {
        "id": "pGkmwQqnZyGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averaged_models = AveragingModels(models = (optimised_cb,optimised_rf))\n",
        "\n",
        "score = rmsle_cv(averaged_models)\n",
        "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
        "\n",
        "averaged_models.fit(train_final_x,train_final_y)\n",
        "test_pred= averaged_models.predict(test_final_x)\n",
        "\n",
        "test_final_y1=np.exp(test_final_y)-1\n",
        "test_pred1=np.exp(test_pred)-1\n",
        "\n",
        "evaluation(test_final_y1,test_pred1)"
      ],
      "metadata": {
        "id": "GMqBzhAPZ1e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averaged_models = AveragingModels(models = (optimised_cb,optimised_xgb))\n",
        "\n",
        "score = rmsle_cv(averaged_models)\n",
        "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
        "\n",
        "averaged_models.fit(train_final_x,train_final_y)\n",
        "test_pred= averaged_models.predict(test_final_x)\n",
        "\n",
        "test_final_y1=np.exp(test_final_y)-1\n",
        "test_pred1=np.exp(test_pred)-1\n",
        "\n",
        "evaluation(test_final_y1,test_pred1)"
      ],
      "metadata": {
        "id": "9q9JjkgEZ30N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averaged_models = AveragingModels(models = (optimised_extra,optimised_xgb))\n",
        "\n",
        "score = rmsle_cv(averaged_models)\n",
        "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
        "\n",
        "averaged_models.fit(train_final_x,train_final_y)\n",
        "test_pred= averaged_models.predict(test_final_x)\n",
        "\n",
        "test_final_y1=np.exp(test_final_y)-1\n",
        "test_pred1=np.exp(test_pred)-1\n",
        "\n",
        "evaluation(test_final_y1,test_pred1)"
      ],
      "metadata": {
        "id": "opyU6FuEZ9fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averaged_models = AveragingModels(models = (optimised_extra,optimised_xgb,optimised_rf))\n",
        "\n",
        "score = rmsle_cv(averaged_models)\n",
        "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
        "\n",
        "averaged_models.fit(train_final_x,train_final_y)\n",
        "test_pred= averaged_models.predict(test_final_x)\n",
        "\n",
        "test_final_y1=np.exp(test_final_y)-1\n",
        "test_pred1=np.exp(test_pred)-1\n",
        "\n",
        "evaluation(test_final_y1,test_pred1)"
      ],
      "metadata": {
        "id": "CClxLwf4aEew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averaged_models = AveragingModels(models = (optimised_cb,optimised_xgb,optimised_extra))\n",
        "\n",
        "score = rmsle_cv(averaged_models)\n",
        "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
        "\n",
        "averaged_models.fit(train_final_x,train_final_y)\n",
        "test_pred= averaged_models.predict(test_final_x)\n",
        "\n",
        "test_final_y1=np.exp(test_final_y)-1\n",
        "test_pred1=np.exp(test_pred)-1\n",
        "\n",
        "evaluation(test_final_y1,test_pred1)"
      ],
      "metadata": {
        "id": "VnSWzxsiaHQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "단일모델"
      ],
      "metadata": {
        "id": "wZ8LXPBRaK--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimised_extra.fit(train_final_x,train_final_y)\n",
        "test_pred= optimised_extra.predict(test_final_x)\n",
        "\n",
        "test_final_y1=np.exp(test_final_y)-1\n",
        "test_pred1=np.exp(test_pred)-1\n",
        "evaluation(test_final_y1,test_pred1)"
      ],
      "metadata": {
        "id": "LkVxNZslaIgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimised_xgb.fit(train_final_x,train_final_y)\n",
        "test_pred= optimised_xgb.predict(test_final_x)\n",
        "\n",
        "test_final_y1=np.exp(test_final_y)-1\n",
        "test_pred1=np.exp(test_pred)-1\n",
        "evaluation(test_final_y1,test_pred1)"
      ],
      "metadata": {
        "id": "5kvwFJ6yaOFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimised_rf.fit(train_final_x,train_final_y)\n",
        "test_pred= optimised_rf.predict(test_final_x)\n",
        "\n",
        "test_final_y1=np.exp(test_final_y)-1\n",
        "test_pred1=np.exp(test_pred)-1\n",
        "evaluation(test_final_y1,test_pred1)"
      ],
      "metadata": {
        "id": "uDEaAZ5MaPaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimised_ela.fit(train_final_x,train_final_y)\n",
        "test_pred= optimised_ela.predict(test_final_x)\n",
        "\n",
        "test_final_y1=np.exp(test_final_y)-1\n",
        "test_pred1=np.exp(test_pred)-1\n",
        "evaluation(test_final_y1,test_pred1)"
      ],
      "metadata": {
        "id": "SenqvyA0aQkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimised_cb.fit(train_final_x,train_final_y)\n",
        "test_pred= optimised_cb.predict(test_final_x)\n",
        "\n",
        "test_final_y1=np.exp(test_final_y)-1\n",
        "test_pred1=np.exp(test_pred)-1\n",
        "evaluation(test_final_y1,test_pred1)"
      ],
      "metadata": {
        "id": "gr9wumtIaRsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimised_gb.fit(train_final_x,train_final_y)\n",
        "test_pred= optimised_gb.predict(test_final_x)\n",
        "\n",
        "test_final_y1=np.exp(test_final_y)-1\n",
        "test_pred1=np.exp(test_pred)-1\n",
        "evaluation(test_final_y1,test_pred1)"
      ],
      "metadata": {
        "id": "9v4iKX9LaTE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimised_ada.fit(train_final_x,train_final_y)\n",
        "test_pred= optimised_ada.predict(test_final_x)\n",
        "\n",
        "test_final_y1=np.exp(test_final_y)-1\n",
        "test_pred1=np.exp(test_pred)-1\n",
        "evaluation(test_final_y1,test_pred1)"
      ],
      "metadata": {
        "id": "aVaava2baUUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimised_lgbm.fit(train_final_x,train_final_y)\n",
        "test_pred= optimised_lgbm.predict(test_final_x)\n",
        "\n",
        "test_final_y1=np.exp(test_final_y)-1\n",
        "test_pred1=np.exp(test_pred)-1\n",
        "evaluation(test_final_y1,test_pred1)"
      ],
      "metadata": {
        "id": "cKoPMLjoaVdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimised_extra_bs.fit(train_final_x,train_final_y)\n",
        "test_pred= optimised_extra_bs.predict(test_final_x)\n",
        "\n",
        "test_final_y1=np.exp(test_final_y)-1\n",
        "test_pred1=np.exp(test_pred)-1\n",
        "evaluation(test_final_y1,test_pred1)"
      ],
      "metadata": {
        "id": "2jC3ParBaWgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 예측"
      ],
      "metadata": {
        "id": "Tz08RQdVaZcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_final_x.columns"
      ],
      "metadata": {
        "id": "GvkcrklbaXpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "날짜 : 2022-07-09\n",
        "요일 : 토\n",
        "계절 : 여름\n",
        "공휴일여부 : 0\n",
        "쉬는날여부 : 0\n",
        "방학여부 : 1\n",
        "강수여부 : 0\n",
        "평균 습도 : 83.54\n",
        "대공원역 하차자 수 : 4237 (3개년 7월 평균)\n",
        "미세먼지 :  30 (좋음의 최고치)\n",
        "최고기온 : 32"
      ],
      "metadata": {
        "id": "ljZjJIhKab5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tomorrow_data = pd.DataFrame({'Humidity_avg' :[83.54], 'Get_off_subway':[4237], 'Fine_dust_concentration':[30],\n",
        "       'Temperature':[32], 'Pub_holiday':[0], 'Weekend':[0], 'Vacation':[1],\n",
        "       'Precipitation_accum':[0], 'Day_Fri':[0], 'Day_Mon':[0], 'Day_Sat':[1], 'Day_Sun':[0],\n",
        "       'Day_Thu':[0], 'Day_Tue':[0], 'Day_Wed':[0], 'Season_Spring':[0], 'Season_Summer':[1],\n",
        "       'Season_Winter':[0], 'Season_fall':[0]})"
      ],
      "metadata": {
        "id": "_R-Ow9VUadek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pred = optimised_extra_bs.predict(tomorrow_data)\n",
        "np.exp(final_pred)-1"
      ],
      "metadata": {
        "id": "HwPxc_B0af6Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}