{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "최종코드.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfhC1z88rowg"
      },
      "outputs": [],
      "source": [
        "``"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 산업분류 AI 활용대회\n",
        "\n",
        "https://data.kostat.go.kr/sbchome/bbs/boardList.do?boardId=SBCSBBS_000000025000&curMenuNo=OPT_09_02_00_0"
      ],
      "metadata": {
        "id": "FMKz2Kn7ETsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT의 bert-base-multilingual-uncased 모델"
      ],
      "metadata": {
        "id": "EpjJfivw9c-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#기본 전처리"
      ],
      "metadata": {
        "id": "Nf93JXEMtDPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##필요한 리소스 준비"
      ],
      "metadata": {
        "id": "abXjDcGctGh1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk3MLjJ6Gaii",
        "outputId": "3b060a87-5269-4388-bb4d-3c5c5129d1a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone -b master https://github.com/charles9n/bert-sklearn\n",
        "!cd bert-sklearn; pip install .\n",
        "import os\n",
        "os.chdir(\"bert-sklearn\")\n",
        "print(os.listdir())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bert-sklearn'...\n",
            "remote: Enumerating objects: 259, done.\u001b[K\n",
            "remote: Total 259 (delta 0), reused 0 (delta 0), pack-reused 259\u001b[K\n",
            "Receiving objects: 100% (259/259), 516.15 KiB | 13.58 MiB/s, done.\n",
            "Resolving deltas: 100% (131/131), done.\n",
            "Processing /content/bert-sklearn\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from bert-sklearn==0.3.1) (1.10.0+cu111)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from bert-sklearn==0.3.1) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bert-sklearn==0.3.1) (1.21.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from bert-sklearn==0.3.1) (1.3.5)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.35-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 15.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert-sklearn==0.3.1) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bert-sklearn==0.3.1) (4.63.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->bert-sklearn==0.3.1) (3.10.0.2)\n",
            "Collecting botocore<1.25.0,>=1.24.35\n",
            "  Downloading botocore-1.24.35-py3-none-any.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 90.5 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.3 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 99.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.35->boto3->bert-sklearn==0.3.1) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.35->boto3->bert-sklearn==0.3.1) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->bert-sklearn==0.3.1) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bert-sklearn==0.3.1) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 96.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert-sklearn==0.3.1) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert-sklearn==0.3.1) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-sklearn==0.3.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-sklearn==0.3.1) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-sklearn==0.3.1) (1.4.1)\n",
            "Building wheels for collected packages: bert-sklearn\n",
            "  Building wheel for bert-sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-sklearn: filename=bert_sklearn-0.3.1-py3-none-any.whl size=54247 sha256=f24dd08dc7897da244fd3ee81cb30eb1fba5d2c74b8e4c22dc74e9679fdccca3\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/d4/73/12b2219a5cd4cd8c7acfd72204603ce34b6d2e4f620b205a80\n",
            "Successfully built bert-sklearn\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, bert-sklearn\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed bert-sklearn-0.3.1 boto3-1.21.35 botocore-1.24.35 jmespath-1.0.0 s3transfer-0.5.2 urllib3-1.25.11\n",
            "['glue_examples', 'demo.ipynb', 'other_examples', 'bert_sklearn', 'Options.md', 'README.md', 'LICENSE', 'tests', 'setup.py', 'demo_tuning_hyperparams.ipynb', '.git']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers==3.0.2\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu7vfE9ZEQGy",
        "outputId": "c0c12b4e-a18f-46c2-8158-a8b1ad132051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mxnet\n",
            "  Downloading mxnet-1.9.0-py3-none-manylinux2014_x86_64.whl (47.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.3 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.0\n",
            "Collecting gluonnlp\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 13.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.28)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.7)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595742 sha256=dbfaf76ac6b524426bd0ab59745494524e46fb3717ba14b691e744218f0567a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 15.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting transformers==3.0.2\n",
            "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
            "\u001b[K     |████████████████████████████████| 769 kB 14.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.96)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 60.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.21.5)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 59.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.63.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.25.11)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.49 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTcgS9b5Jz05",
        "outputId": "e3a822c6-cf3c-497a-d107-e6466caaf13e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-kj2igzuy\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-kj2igzuy\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.21.35)\n",
            "Requirement already satisfied: gluonnlp>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: mxnet>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.9.0)\n",
            "Collecting onnxruntime==1.8.0\n",
            "  Downloading onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 15.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sentencepiece>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.1.96)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.10.0+cu111)\n",
            "Collecting transformers>=4.8.1\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (2.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (1.21.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (0.29.28)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (21.3)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.3) (2.23.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.3) (0.8.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->kobert==0.2.3) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (3.6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (0.0.49)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.63.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 62.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 76.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.11.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp>=0.6.0->kobert==0.2.3) (3.0.7)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->kobert==0.2.3) (1.0.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->kobert==0.2.3) (0.5.2)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.35 in /usr/local/lib/python3.7/dist-packages (from boto3->kobert==0.2.3) (1.24.35)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.35->boto3->kobert==0.2.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.35->boto3->kobert==0.2.3) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.8.1->kobert==0.2.3) (3.7.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (1.1.0)\n",
            "Building wheels for collected packages: kobert\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15674 sha256=cf030dd553f10367f43b91fe6c11215ccf6e7754922a1f9fca28cfda1e65a018\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xbz7o95q/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n",
            "Successfully built kobert\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, onnxruntime, kobert\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.8.1rc1\n",
            "    Uninstalling tokenizers-0.8.1rc1:\n",
            "      Successfully uninstalled tokenizers-0.8.1rc1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 3.0.2\n",
            "    Uninstalling transformers-3.0.2:\n",
            "      Successfully uninstalled transformers-3.0.2\n",
            "Successfully installed huggingface-hub-0.5.1 kobert-0.2.3 onnxruntime-1.8.0 pyyaml-6.0 tokenizers-0.11.6 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ],
      "metadata": {
        "id": "5TPNTYA8JyhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5yg3Tdqt7oz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from bert_sklearn import BertClassifier\n",
        "from bert_sklearn import BertRegressor\n",
        "from bert_sklearn import BertTokenClassifier\n",
        "from bert_sklearn import load_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/gdrive/')\n",
        "os.chdir('/content/gdrive/MyDrive/통계청/데이터')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjjmJmNYvGx-",
        "outputId": "59f33384-0808-4237-e0be-2f1c7a21cdaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##test, train, val file "
      ],
      "metadata": {
        "id": "STxe58mXtRtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###모델1 bert의 인풋"
      ],
      "metadata": {
        "id": "A0Ifjro2tcCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train= pd.read_csv('workdata.txt',sep='|',encoding='euc-kr')\n",
        "test = pd.read_csv('testdata.txt',sep='|',encoding='euc-kr')"
      ],
      "metadata": {
        "id": "wW5eoPe-tfDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['digit_3']=0"
      ],
      "metadata": {
        "id": "6L8eBgQCVyQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "It8uFyicV5FV",
        "outputId": "e08b7049-473f-45ab-9e9f-16ed93122ebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           AI_id  digit_1  digit_2  digit_3  text_obj   text_mthd text_deal\n",
              "0      id_000001      NaN      NaN        0   치킨전문점에서    고객의주문에의해      치킨판매\n",
              "1      id_000002      NaN      NaN        0      산업공구   다른 소매업자에게    철물 수공구\n",
              "2      id_000003      NaN      NaN        0       절에서    신도을 대상으로    불교단체운영\n",
              "3      id_000004      NaN      NaN        0     영업장에서       고객요구로     자동차튜닝\n",
              "4      id_000005      NaN      NaN        0  실내포장마차에서   접객시설을 갖추고   소주,맥주제공\n",
              "...          ...      ...      ...      ...       ...         ...       ...\n",
              "99995  id_099996      NaN      NaN        0     사업장에서     일반인대상으로      버섯농장\n",
              "99996  id_099997      NaN      NaN        0     한의원에서     외래환자위주고        치료\n",
              "99997  id_099998      NaN      NaN        0    일반점포에서       소비자에게      그림판매\n",
              "99998  id_099999      NaN      NaN        0     사업장에서  일반인.학생대상으로    학습공간제공\n",
              "99999  id_100000      NaN      NaN        0     사업장에서    대리현대아파트를        관리\n",
              "\n",
              "[100000 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b66a5731-b1a0-4446-b286-a57ef225eba0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AI_id</th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "      <th>digit_3</th>\n",
              "      <th>text_obj</th>\n",
              "      <th>text_mthd</th>\n",
              "      <th>text_deal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000001</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>치킨전문점에서</td>\n",
              "      <td>고객의주문에의해</td>\n",
              "      <td>치킨판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>산업공구</td>\n",
              "      <td>다른 소매업자에게</td>\n",
              "      <td>철물 수공구</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000003</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>절에서</td>\n",
              "      <td>신도을 대상으로</td>\n",
              "      <td>불교단체운영</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_000004</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>영업장에서</td>\n",
              "      <td>고객요구로</td>\n",
              "      <td>자동차튜닝</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_000005</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>실내포장마차에서</td>\n",
              "      <td>접객시설을 갖추고</td>\n",
              "      <td>소주,맥주제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>id_099996</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인대상으로</td>\n",
              "      <td>버섯농장</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>id_099997</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>한의원에서</td>\n",
              "      <td>외래환자위주고</td>\n",
              "      <td>치료</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>id_099998</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>일반점포에서</td>\n",
              "      <td>소비자에게</td>\n",
              "      <td>그림판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>id_099999</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인.학생대상으로</td>\n",
              "      <td>학습공간제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>id_100000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>대리현대아파트를</td>\n",
              "      <td>관리</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b66a5731-b1a0-4446-b286-a57ef225eba0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b66a5731-b1a0-4446-b286-a57ef225eba0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b66a5731-b1a0-4446-b286-a57ef225eba0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['text_obj'].fillna(\" \", inplace = True)\n",
        "test['text_mthd'].fillna(\" \", inplace = True)\n",
        "test['text_deal'].fillna(\" \", inplace = True)\n",
        "test['data'] = test['text_obj'] + ' ' + test['text_mthd']\n",
        "test['data'] = test['data'] +  ' ' + test['text_deal']"
      ],
      "metadata": {
        "id": "floetn6KV-IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text_obj'].fillna(\" \", inplace = True)\n",
        "train['text_mthd'].fillna(\" \", inplace = True)\n",
        "train['text_deal'].fillna(\" \", inplace = True)\n",
        "train['data'] = train['text_obj'] + ' ' + train['text_mthd']\n",
        "train['data'] = train['data'] + ' ' +  train['text_deal']"
      ],
      "metadata": {
        "id": "x8oRotDDWd-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train= pd.read_csv('/content/gdrive/MyDrive/통계청/데이터/train.csv')\n",
        "test = pd.read_csv('/content/gdrive/MyDrive/통계청/데이터/test.csv')"
      ],
      "metadata": {
        "id": "5GmqSZe9vriu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###모델2 kobert original data input"
      ],
      "metadata": {
        "id": "EaQ4_GWktjVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_kb,valid_kb=train_test_split(train, test_size=0.2)"
      ],
      "metadata": {
        "id": "4pzYZdIuPtD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_kb.to_csv('/content/gdrive/MyDrive/통계청/데이터/train_kb.tsv', sep='\\t',encoding='utf-8',index=False)\n",
        "valid_kb.to_csv('/content/gdrive/MyDrive/통계청/데이터/valid_kb.tsv', sep='\\t',encoding='utf-8',index=False)"
      ],
      "metadata": {
        "id": "9lPS6yzMImTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = nlp.data.TSVDataset('/content/gdrive/MyDrive/통계청/데이터/train_kb.tsv', field_indices=[7,3], num_discard_samples=1)\n",
        "dataset_test = nlp.data.TSVDataset('/content/gdrive/MyDrive/통계청/데이터/valid_kb.tsv', field_indices=[7,3], num_discard_samples=1)"
      ],
      "metadata": {
        "id": "dIR9i9-WRNoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###모델3 kobert 산업분류 추가(2번) data input"
      ],
      "metadata": {
        "id": "zGv2dyCytrIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ind_class=pd.read_csv('산업분류표.csv')"
      ],
      "metadata": {
        "id": "cpfMRaX3jyar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_class=ind_class.dropna(how='all')"
      ],
      "metadata": {
        "id": "UiEJ3Ug0jyas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_class=ind_class.fillna(method='pad')\n",
        "ind_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "af93f88d-fb6a-4600-e493-6fc6da95327e",
        "id": "zzbEy2zLjyas"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     digit_1  digit_2  digit_3  digit_4  digit_5               type_5\n",
              "0          A      1.0     11.0    111.0   1110.0     곡물 및 기타 식량작물 재배업\n",
              "1          A      1.0     11.0    112.0   1121.0             채소작물 재배업\n",
              "2          A      1.0     11.0    112.0   1122.0             화훼작물 재배업\n",
              "3          A      1.0     11.0    112.0   1123.0          종자 및 묘목 생산업\n",
              "4          A      1.0     11.0    113.0   1131.0             과실작물 재배업\n",
              "...      ...      ...      ...      ...      ...                  ...\n",
              "1192       T     97.0    970.0   9700.0  97000.0            가구 내 고용활동\n",
              "1193       T     98.0    981.0   9810.0  98100.0   자가 소비를 위한 가사 생산 활동\n",
              "1194       T     98.0    982.0   9820.0  98200.0  자가 소비를 위한 가사 서비스 활동\n",
              "1195       U     99.0    990.0   9900.0  99001.0             주한 외국 공관\n",
              "1196       U     99.0    990.0   9900.0  99009.0         기타 국제 및 외국기관\n",
              "\n",
              "[1196 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bfe3cb83-cbc8-4b3d-a4ff-ae2d72097763\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "      <th>digit_3</th>\n",
              "      <th>digit_4</th>\n",
              "      <th>digit_5</th>\n",
              "      <th>type_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>1110.0</td>\n",
              "      <td>곡물 및 기타 식량작물 재배업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>1121.0</td>\n",
              "      <td>채소작물 재배업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>1122.0</td>\n",
              "      <td>화훼작물 재배업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>1123.0</td>\n",
              "      <td>종자 및 묘목 생산업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>1131.0</td>\n",
              "      <td>과실작물 재배업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1192</th>\n",
              "      <td>T</td>\n",
              "      <td>97.0</td>\n",
              "      <td>970.0</td>\n",
              "      <td>9700.0</td>\n",
              "      <td>97000.0</td>\n",
              "      <td>가구 내 고용활동</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1193</th>\n",
              "      <td>T</td>\n",
              "      <td>98.0</td>\n",
              "      <td>981.0</td>\n",
              "      <td>9810.0</td>\n",
              "      <td>98100.0</td>\n",
              "      <td>자가 소비를 위한 가사 생산 활동</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1194</th>\n",
              "      <td>T</td>\n",
              "      <td>98.0</td>\n",
              "      <td>982.0</td>\n",
              "      <td>9820.0</td>\n",
              "      <td>98200.0</td>\n",
              "      <td>자가 소비를 위한 가사 서비스 활동</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>U</td>\n",
              "      <td>99.0</td>\n",
              "      <td>990.0</td>\n",
              "      <td>9900.0</td>\n",
              "      <td>99001.0</td>\n",
              "      <td>주한 외국 공관</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>U</td>\n",
              "      <td>99.0</td>\n",
              "      <td>990.0</td>\n",
              "      <td>9900.0</td>\n",
              "      <td>99009.0</td>\n",
              "      <td>기타 국제 및 외국기관</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1196 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfe3cb83-cbc8-4b3d-a4ff-ae2d72097763')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bfe3cb83-cbc8-4b3d-a4ff-ae2d72097763 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bfe3cb83-cbc8-4b3d-a4ff-ae2d72097763');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train2=train_kb[:0]"
      ],
      "metadata": {
        "id": "1iVbSDlPkY7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train2['digit_3']=ind_class['digit_3']\n",
        "train2['data']=ind_class['type_5']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRS_BA_kku_u",
        "outputId": "d21df854-83f1-49b8-9c23-d10d5ccbb688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train2['digit_3'] = train2['digit_3'].astype('int64')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDZ95U5XlLTZ",
        "outputId": "f191516b-de35-4a00-fe9e-e6298ec6df5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_kb2=train_kb.append(train2)\n",
        "train_kb2=train_kb.append(train2)"
      ],
      "metadata": {
        "id": "TaK6Ineojifr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_kb2=train_kb.drop(['AI_id','digit_1','digit_2','text_obj','text_mthd','text_deal'],axis=1)"
      ],
      "metadata": {
        "id": "ClM_U3jylr-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_kb2=valid_kb.drop(['AI_id','digit_1','digit_2','text_obj','text_mthd','text_deal'],axis=1)"
      ],
      "metadata": {
        "id": "FiP0Gg0dmOWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_kb2.to_csv('/content/gdrive/MyDrive/통계청/데이터/train_kb5.tsv', sep='\\t',encoding='utf-8',index=False)\n",
        "valid_kb2.to_csv('/content/gdrive/MyDrive/통계청/데이터/valid_kb5.tsv', sep='\\t',encoding='utf-8',index=False)"
      ],
      "metadata": {
        "id": "i3XGQorGswWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train2 = nlp.data.TSVDataset('/content/gdrive/MyDrive/통계청/데이터/train_kb5.tsv', field_indices=[1,0], num_discard_samples=1)\n",
        "dataset_test2 = nlp.data.TSVDataset('/content/gdrive/MyDrive/통계청/데이터/valid_kb5.tsv', field_indices=[1,0], num_discard_samples=1)"
      ],
      "metadata": {
        "id": "CAlVV_dUswWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "Vo7jdIpm4NXF",
        "outputId": "1981c2a7-f6e4-42d0-bb33-ffd68410e29d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        AI_id digit_1  digit_2  digit_3    text_obj    text_mthd text_deal  \\\n",
              "0  id_0000001       S       95      952       카센터에서      자동차부분정비   타이어오일교환   \n",
              "1  id_0000002       G       47      472       상점내에서    일반인을 대상으로   채소.과일판매   \n",
              "2  id_0000003       G       46      467  절단하여사업체에도매    공업용고무를가지고    합성고무도매   \n",
              "3  id_0000004       G       47      475       영업점에서      일반소비자에게    열쇠잠금장치   \n",
              "4  id_0000005       Q       87      872        어린이집  보호자의 위탁을 받아   취학전아동보육   \n",
              "\n",
              "                        data  \n",
              "0        카센터에서자동차부분정비타이어오일교환  \n",
              "1      상점내에서일반인을 대상으로채소.과일판매  \n",
              "2  절단하여사업체에도매공업용고무를가지고합성고무도매  \n",
              "3         영업점에서일반소비자에게열쇠잠금장치  \n",
              "4     어린이집보호자의 위탁을 받아취학전아동보육  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f20865e-b1c2-442f-a81c-9fefb11789ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AI_id</th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "      <th>digit_3</th>\n",
              "      <th>text_obj</th>\n",
              "      <th>text_mthd</th>\n",
              "      <th>text_deal</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_0000001</td>\n",
              "      <td>S</td>\n",
              "      <td>95</td>\n",
              "      <td>952</td>\n",
              "      <td>카센터에서</td>\n",
              "      <td>자동차부분정비</td>\n",
              "      <td>타이어오일교환</td>\n",
              "      <td>카센터에서자동차부분정비타이어오일교환</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_0000002</td>\n",
              "      <td>G</td>\n",
              "      <td>47</td>\n",
              "      <td>472</td>\n",
              "      <td>상점내에서</td>\n",
              "      <td>일반인을 대상으로</td>\n",
              "      <td>채소.과일판매</td>\n",
              "      <td>상점내에서일반인을 대상으로채소.과일판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_0000003</td>\n",
              "      <td>G</td>\n",
              "      <td>46</td>\n",
              "      <td>467</td>\n",
              "      <td>절단하여사업체에도매</td>\n",
              "      <td>공업용고무를가지고</td>\n",
              "      <td>합성고무도매</td>\n",
              "      <td>절단하여사업체에도매공업용고무를가지고합성고무도매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0000004</td>\n",
              "      <td>G</td>\n",
              "      <td>47</td>\n",
              "      <td>475</td>\n",
              "      <td>영업점에서</td>\n",
              "      <td>일반소비자에게</td>\n",
              "      <td>열쇠잠금장치</td>\n",
              "      <td>영업점에서일반소비자에게열쇠잠금장치</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_0000005</td>\n",
              "      <td>Q</td>\n",
              "      <td>87</td>\n",
              "      <td>872</td>\n",
              "      <td>어린이집</td>\n",
              "      <td>보호자의 위탁을 받아</td>\n",
              "      <td>취학전아동보육</td>\n",
              "      <td>어린이집보호자의 위탁을 받아취학전아동보육</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f20865e-b1c2-442f-a81c-9fefb11789ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f20865e-b1c2-442f-a81c-9fefb11789ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f20865e-b1c2-442f-a81c-9fefb11789ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###모델4 kobert 산업분류 추가(1번) data input"
      ],
      "metadata": {
        "id": "AsEP3C6Rx6m0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train= pd.read_csv('workdata.txt',sep='|',encoding='euc-kr')\n",
        "test = pd.read_csv('testdata.txt',sep='|',encoding='euc-kr')"
      ],
      "metadata": {
        "id": "TLqVy4P4yZ2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text_obj'].fillna(\" \", inplace = True)\n",
        "train['text_mthd'].fillna(\" \", inplace = True)\n",
        "train['text_deal'].fillna(\" \", inplace = True)\n",
        "train['data'] = train['text_obj'] + ' ' + train['text_mthd']\n",
        "train['data'] = train['data'] + ' ' +  train['text_deal']"
      ],
      "metadata": {
        "id": "XRts8ZXnyZ2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=train.append(train2)"
      ],
      "metadata": {
        "id": "_5OBS_kH8m7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_kb3,valid_kb3=train_test_split(train, test_size=0.2)"
      ],
      "metadata": {
        "id": "5_i-n1sByZ2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_kb3.to_csv('/content/gdrive/MyDrive/통계청/데이터/train_kb3.tsv', sep='\\t',encoding='utf-8',index=False)\n",
        "valid_kb3.to_csv('/content/gdrive/MyDrive/통계청/데이터/valid_kb3.tsv', sep='\\t',encoding='utf-8',index=False)"
      ],
      "metadata": {
        "id": "gYicMibPyZ2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train3 = nlp.data.TSVDataset('/content/gdrive/MyDrive/통계청/데이터/train_kb3.tsv', field_indices=[7,3], num_discard_samples=1)\n",
        "dataset_test3 = nlp.data.TSVDataset('/content/gdrive/MyDrive/통계청/데이터/valid_kb3.tsv', field_indices=[7,3], num_discard_samples=1)"
      ],
      "metadata": {
        "id": "HoXSck9yyZ2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모델 적용"
      ],
      "metadata": {
        "id": "kCfNKuLht5io"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##모델1. bert (with original data)"
      ],
      "metadata": {
        "id": "ZRihVFcLt80l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###모델 학습"
      ],
      "metadata": {
        "id": "BnA47F7wuQD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = train[:]"
      ],
      "metadata": {
        "id": "mtsWal9U8DCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_train[\"data\"]\n",
        "y = df_train[\"digit_3\"].values"
      ],
      "metadata": {
        "id": "hpS6itfx8RLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertClassifier(bert_model=\"bert-base-multilingual-uncased\", epochs=3, learning_rate=4e-05, validation_fraction=0.2) # 한 에포그 당 40분\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762,
          "referenced_widgets": [
            "fe893134b8a84fddb07ef2fc5d1fec9f",
            "27dbd2a79d1c4bf0971d9638d5b46b46",
            "1f6c4aa9b8764bb9bb3eb66d3100d6dd",
            "3f53fac0f7314cd1a71d5c7210b48673",
            "22e0db3505a84b9cafd94a574411fa7e",
            "0e63555f4b3c46458d1dcc654602bf59",
            "dc0dd892bd0d4b508b17fabc7ddd7333",
            "88a949b89ae5487ba6a04d888129d917",
            "6d77b158203147ee9b936b8b474b98a5",
            "6f4d873def6e46f08935e6b4ffa6da05",
            "f70125dcf2e34e7c9bc969708cac2954",
            "decb338555f0401cbe20d9c021d9b8aa",
            "340b66d80c274e04b426b6f9abd41174",
            "da9925d3b1cb48708f7df7810ddcc2f9",
            "fbcaeb55f8194cc593dfa1b931031f70",
            "d6f87931880a429cae0fd45881bb5e4c",
            "27a6be76407f4fe69c52aeab47007ffb",
            "aad7fb503bdf4c7f835a8f2944622fec",
            "461944c087314ee3a1fae2c16b3d153a",
            "32a64f7b961f4f409671303d24f22f7c",
            "2829498cb859451c858f7d60e0d90adb",
            "ba6f43d4bb3c4dd3bcbe336aa68f750e",
            "0586975d768d4fb3b6f68cdb7072a6e7",
            "b6fc16b900d1437f8607a6cd49d6b61a",
            "4734cd1dd82d4835ae4fc8a329bb5b0d",
            "223d6d8342d547ad9f7f58531baf2b04",
            "c74c1fc90740467ea6d84b3f41568fba",
            "607923cc6016441aabf621cfc8a7f6e0",
            "b49657ae26354bdd8c73d82bb7faa0d5",
            "665888de343144649cbdcdb76032da03",
            "e48e93a64d3741f38f1fe3bfcd0678fe",
            "e1b61cfbd7624135991dd981fb0bb937",
            "0938ec4b149e4602be9e11a4e6b41b12",
            "adabd7fed30e41b68baaff5c1d1aefd2",
            "583b0539e9134715998d9033cc5b3e6e",
            "25438854bd7745c4b41c4ee2b57a07bd",
            "976916cb5c7b4c5ea76f20cabba67046",
            "4a575a7b5b58465695ca82700312348a",
            "76eac75279fc4a08970a4f7ca02b13be",
            "1c6bd89cf712471783c0e327984db16b",
            "31cc09d129cf4c8aae65d9166f5746a6",
            "30322afee79b4ffb8d0f8ce870e14e56",
            "4ab93441a79b459f891f6af1c5d55da0",
            "bc2be2238fc34e7280dac2f7848114ad",
            "605ac8307dcc45c79735f7d7b6aa2d83",
            "c56e0965f7674e4a829acb1de3619e32",
            "59d8e7c813354d4f9d2c8f06bf90063f",
            "3b99c6fad7074778b182b635e4fe3955",
            "fce1c70f50d24703a10ae96ff4a3cab1",
            "abf7313a250c4db6abd99b49d2a64136",
            "d3c9c1c128904c2881816561964643b3",
            "347157fb70044fb693d1268011767ac7",
            "3c9adc62806244239a4c4c502eaf5196",
            "a8a8ce8ba7604ce0bd12601041358321",
            "2092100d2afe4505aec7c5585e3a015d",
            "cc795e6ca4fc45dfbbed45a129caa163",
            "c87933840247499fb3b4276c5516dabc",
            "393ef534006c40d8ac81f1c6129cc203",
            "fae9c66a65ef4acbbc85abcbc1b07e27",
            "432b32822de24ee7b19213d7e4ee6d2d",
            "89bca0f56ac34151a5aaee1e90fb5700",
            "e6d33e305d25480ea1f389fa2327b7f1",
            "161512438eda42329f744100bf3c3fa0",
            "874771f85e21426b88268dc2e39db1e7",
            "280644785854437bb47f732dc0ec00cb",
            "b9065297fe9845e6a1c1d6c7d6ba8014"
          ]
        },
        "id": "UMVAmncG78wu",
        "outputId": "b348e906-bf77-4323-ae1a-89c763dd31a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building sklearn text classifier...\n",
            "Loading bert-base-multilingual-uncased model...\n",
            "Defaulting to linear classifier/regressor\n",
            "Loading Pytorch checkpoint\n",
            "\n",
            "train data size: 800000, validation data size: 200000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training  :   0%|          | 0/25000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe893134b8a84fddb07ef2fc5d1fec9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validating:   0%|          | 0/25000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "decb338555f0401cbe20d9c021d9b8aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1, Train loss: 0.7721, Val loss: 0.3654, Val accy: 90.55%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training  :   0%|          | 0/25000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0586975d768d4fb3b6f68cdb7072a6e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validating:   0%|          | 0/25000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adabd7fed30e41b68baaff5c1d1aefd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2, Train loss: 0.3230, Val loss: 0.3041, Val accy: 91.97%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training  :   0%|          | 0/25000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "605ac8307dcc45c79735f7d7b6aa2d83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validating:   0%|          | 0/25000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc795e6ca4fc45dfbbed45a129caa163"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3, Train loss: 0.2427, Val loss: 0.2821, Val accy: 92.50%\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertClassifier(bert_model='bert-base-multilingual-uncased', do_lower_case=True,\n",
              "               label_list=array([ 11,  12,  14,  20,  31,  32,  51,  61,  62,  71,  72,  80, 101,\n",
              "       102, 103, 104, 105, 106, 107, 108, 111, 112, 120, 131, 132, 133,\n",
              "       134, 139, 141, 142, 143, 144, 151, 152, 161, 162, 163, 171, 172,\n",
              "       179, 181, 182, 191, 192, 201, 202, 203, 204, 205, 211, 212, 213,\n",
              "       221, 222, 231, 232, 233, 239, 241, 242, 243, 251, 252, 259, 261,\n",
              "       262, 26...\n",
              "       521, 529, 551, 559, 561, 562, 581, 582, 591, 592, 601, 602, 611,\n",
              "       612, 620, 631, 639, 641, 642, 649, 651, 652, 653, 661, 662, 681,\n",
              "       682, 701, 702, 711, 712, 713, 714, 715, 716, 721, 729, 731, 732,\n",
              "       733, 739, 741, 742, 743, 751, 752, 753, 759, 761, 762, 763, 764,\n",
              "       841, 842, 843, 844, 845, 851, 852, 853, 854, 855, 856, 857, 861,\n",
              "       862, 863, 869, 871, 872, 901, 902, 911, 912, 941, 942, 949, 951,\n",
              "       952, 953, 961, 969]),\n",
              "               learning_rate=4e-05, validation_fraction=0.2)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib\n",
        "\n",
        "joblib.dump(model, '/content/gdrive/MyDrive/통계청/데이터/bert_2.pkl')  # 모델 저장하기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgBk4cep3qLi",
        "outputId": "0e9feefd-1fb2-426c-e38f-50341f8c23ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/MyDrive/통계청/데이터/bert_2.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_from_joblib = joblib.load('/content/gdrive/MyDrive/통계청/데이터/bert_2.pkl') # 모델 불러오기\n",
        "# clf_from_joblib.predict(X)"
      ],
      "metadata": {
        "id": "YJcnSLG75FdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###학습된 모델 적용"
      ],
      "metadata": {
        "id": "hOeXrE8WuYle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 14분 정도 걸림\n",
        "X_test = test[\"data\"]\n",
        "y_pred = model.predict(X_test) \n",
        "\n",
        "X_test[\"disit_3\"] = y_pred\n",
        "X_test.head()"
      ],
      "metadata": {
        "id": "KHTBf4Is9tT2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "f6e8230850d443b49605b9f54ce635f9",
            "d0696c02a84648af806ffad982921b0e",
            "81bb2db6fc2e467497f8ebb976666389",
            "08dba36898ca4a06b8ab62ed86939056",
            "2e0463ce4d5c4b29b2a3b485584cd72d",
            "295b9ef58d2b4997a2b15863166d8902",
            "b199f03f22664be09c72c936d74f3d70",
            "b8c4e424fb984de2bceeca913e8ae2b8",
            "e3876a9d08dc47d4a3db3c59b2991a17",
            "ca5e4d20737946c5ad38e774d8099282",
            "9d052d099ce94b1dbf6bf9dc464b7765"
          ]
        },
        "outputId": "e7fcba20-2bed-424e-d5bd-a42ffb998b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting:   0%|          | 0/12500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6e8230850d443b49605b9f54ce635f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         치킨전문점에서고객의주문에의해치킨판매\n",
              "1         산업공구다른 소매업자에게철물 수공구\n",
              "2           절에서신도을 대상으로불교단체운영\n",
              "3             영업장에서고객요구로자동차튜닝\n",
              "4    실내포장마차에서접객시설을 갖추고소주,맥주제공\n",
              "Name: data, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AREn8QL7dPZ",
        "outputId": "9c9c6754-37ce-481f-bcfc-dc9713f6e41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([561, 466, 949, ..., 478, 902, 682])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test[\"data\"]\n",
        "pred_df = pd.DataFrame(X_test)\n",
        "pred_df[\"digit_3\"] = y_pred\n",
        "pred_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "No4IkOlf9Rdw",
        "outputId": "8108003a-8614-48be-e9dd-7e14c79a6e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           data  digit_3\n",
              "0           치킨전문점에서고객의주문에의해치킨판매      561\n",
              "1           산업공구다른 소매업자에게철물 수공구      466\n",
              "2             절에서신도을 대상으로불교단체운영      949\n",
              "3               영업장에서고객요구로자동차튜닝      952\n",
              "4      실내포장마차에서접객시설을 갖추고소주,맥주제공      562\n",
              "...                         ...      ...\n",
              "99995          사업장에서일반인대상으로버섯농장      472\n",
              "99996            한의원에서외래환자위주고치료      862\n",
              "99997           일반점포에서소비자에게그림판매      478\n",
              "99998     사업장에서일반인.학생대상으로학습공간제공      902\n",
              "99999           사업장에서대리현대아파트를관리      682\n",
              "\n",
              "[100000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b732ce50-9aa1-465f-8a0d-1bac5a60f304\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>digit_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>치킨전문점에서고객의주문에의해치킨판매</td>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>산업공구다른 소매업자에게철물 수공구</td>\n",
              "      <td>466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>절에서신도을 대상으로불교단체운영</td>\n",
              "      <td>949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>영업장에서고객요구로자동차튜닝</td>\n",
              "      <td>952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>실내포장마차에서접객시설을 갖추고소주,맥주제공</td>\n",
              "      <td>562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>사업장에서일반인대상으로버섯농장</td>\n",
              "      <td>472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>한의원에서외래환자위주고치료</td>\n",
              "      <td>862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>일반점포에서소비자에게그림판매</td>\n",
              "      <td>478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>사업장에서일반인.학생대상으로학습공간제공</td>\n",
              "      <td>902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>사업장에서대리현대아파트를관리</td>\n",
              "      <td>682</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b732ce50-9aa1-465f-8a0d-1bac5a60f304')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b732ce50-9aa1-465f-8a0d-1bac5a60f304 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b732ce50-9aa1-465f-8a0d-1bac5a60f304');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df.to_csv(\"/content/gdrive/MyDrive/통계청/데이터/bert_2.csv\", index = False)"
      ],
      "metadata": {
        "id": "CR0pKCNv9v8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 소분류를 중,대분류에 매핑"
      ],
      "metadata": {
        "id": "w8_JHZToBO7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ind_class=pd.read_csv('산업분류표.csv')"
      ],
      "metadata": {
        "id": "P3wM37gl5OUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_class=ind_class.drop(['digit_4','digit_5','type_5'],axis=1)"
      ],
      "metadata": {
        "id": "zOvB6F-hYZmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_class=ind_class.dropna(how='all')"
      ],
      "metadata": {
        "id": "2fe-UHmpZ8Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_class=ind_class.fillna(method='pad')\n",
        "ind_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "SMQXcLFedOYa",
        "outputId": "bf205242-6c49-49bd-b8a5-c3fc4bb785b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     digit_1  digit_2  digit_3\n",
              "0          A      1.0     11.0\n",
              "10         A      1.0     12.0\n",
              "17         A      1.0     13.0\n",
              "18         A      1.0     14.0\n",
              "21         A      1.0     15.0\n",
              "...      ...      ...      ...\n",
              "1181       S     96.0    969.0\n",
              "1192       T     97.0    970.0\n",
              "1193       T     98.0    981.0\n",
              "1194       T     98.0    982.0\n",
              "1195       U     99.0    990.0\n",
              "\n",
              "[232 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4034c39-dc7a-4312-b5e3-4f56ca310f7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "      <th>digit_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1181</th>\n",
              "      <td>S</td>\n",
              "      <td>96.0</td>\n",
              "      <td>969.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1192</th>\n",
              "      <td>T</td>\n",
              "      <td>97.0</td>\n",
              "      <td>970.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1193</th>\n",
              "      <td>T</td>\n",
              "      <td>98.0</td>\n",
              "      <td>981.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1194</th>\n",
              "      <td>T</td>\n",
              "      <td>98.0</td>\n",
              "      <td>982.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>U</td>\n",
              "      <td>99.0</td>\n",
              "      <td>990.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>232 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4034c39-dc7a-4312-b5e3-4f56ca310f7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e4034c39-dc7a-4312-b5e3-4f56ca310f7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e4034c39-dc7a-4312-b5e3-4f56ca310f7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pred_df[:]\n",
        "df_test=df[:]"
      ],
      "metadata": {
        "id": "OKK_KrewUUoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ljxbZtGAhmqg",
        "outputId": "2d159e14-16b1-431b-8d59-a76e6b05b68b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           data  digit_3\n",
              "0           치킨전문점에서고객의주문에의해치킨판매      561\n",
              "1           산업공구다른 소매업자에게철물 수공구      466\n",
              "2             절에서신도을 대상으로불교단체운영      949\n",
              "3               영업장에서고객요구로자동차튜닝      952\n",
              "4      실내포장마차에서접객시설을 갖추고소주,맥주제공      562\n",
              "...                         ...      ...\n",
              "99995          사업장에서일반인대상으로버섯농장      472\n",
              "99996            한의원에서외래환자위주고치료      862\n",
              "99997           일반점포에서소비자에게그림판매      478\n",
              "99998     사업장에서일반인.학생대상으로학습공간제공      902\n",
              "99999           사업장에서대리현대아파트를관리      682\n",
              "\n",
              "[100000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-405e3347-c52b-4756-999e-b524ee8bfca3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>digit_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>치킨전문점에서고객의주문에의해치킨판매</td>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>산업공구다른 소매업자에게철물 수공구</td>\n",
              "      <td>466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>절에서신도을 대상으로불교단체운영</td>\n",
              "      <td>949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>영업장에서고객요구로자동차튜닝</td>\n",
              "      <td>952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>실내포장마차에서접객시설을 갖추고소주,맥주제공</td>\n",
              "      <td>562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>사업장에서일반인대상으로버섯농장</td>\n",
              "      <td>472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>한의원에서외래환자위주고치료</td>\n",
              "      <td>862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>일반점포에서소비자에게그림판매</td>\n",
              "      <td>478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>사업장에서일반인.학생대상으로학습공간제공</td>\n",
              "      <td>902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>사업장에서대리현대아파트를관리</td>\n",
              "      <td>682</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-405e3347-c52b-4756-999e-b524ee8bfca3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-405e3347-c52b-4756-999e-b524ee8bfca3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-405e3347-c52b-4756-999e-b524ee8bfca3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['digit_1']=np.nan\n",
        "df['digit_2']=np.nan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nODnQGKDiJZ5",
        "outputId": "9dbf34da-ced0-4285-96ab-d800bd5ec780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df)):\n",
        "  l=ind_class.index[ind_class['digit_3']==df['digit_3'][i]].tolist()\n",
        "  f=l[0]\n",
        "  df['digit_1'][i]=ind_class['digit_1'][f]\n",
        "  df['digit_2'][i]=ind_class['digit_2'][f]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRC9OF0dg6yR",
        "outputId": "186f4776-82bf-4c2a-88a7-aa5a8b05577a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "yeESVZkkgJxA",
        "outputId": "76f6f042-2fc5-427c-934f-91d15be3453d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           data  digit_3 digit_1  digit_2\n",
              "0           치킨전문점에서고객의주문에의해치킨판매      561       I     56.0\n",
              "1           산업공구다른 소매업자에게철물 수공구      466       G     46.0\n",
              "2             절에서신도을 대상으로불교단체운영      949       S     94.0\n",
              "3               영업장에서고객요구로자동차튜닝      952       S     95.0\n",
              "4      실내포장마차에서접객시설을 갖추고소주,맥주제공      562       I     56.0\n",
              "...                         ...      ...     ...      ...\n",
              "99995          사업장에서일반인대상으로버섯농장      472       G     47.0\n",
              "99996            한의원에서외래환자위주고치료      862       Q     86.0\n",
              "99997           일반점포에서소비자에게그림판매      478       G     47.0\n",
              "99998     사업장에서일반인.학생대상으로학습공간제공      902       R     90.0\n",
              "99999           사업장에서대리현대아파트를관리      682       L     68.0\n",
              "\n",
              "[100000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8d9deb6-197f-4698-aef5-13988e390981\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>digit_3</th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>치킨전문점에서고객의주문에의해치킨판매</td>\n",
              "      <td>561</td>\n",
              "      <td>I</td>\n",
              "      <td>56.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>산업공구다른 소매업자에게철물 수공구</td>\n",
              "      <td>466</td>\n",
              "      <td>G</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>절에서신도을 대상으로불교단체운영</td>\n",
              "      <td>949</td>\n",
              "      <td>S</td>\n",
              "      <td>94.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>영업장에서고객요구로자동차튜닝</td>\n",
              "      <td>952</td>\n",
              "      <td>S</td>\n",
              "      <td>95.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>실내포장마차에서접객시설을 갖추고소주,맥주제공</td>\n",
              "      <td>562</td>\n",
              "      <td>I</td>\n",
              "      <td>56.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>사업장에서일반인대상으로버섯농장</td>\n",
              "      <td>472</td>\n",
              "      <td>G</td>\n",
              "      <td>47.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>한의원에서외래환자위주고치료</td>\n",
              "      <td>862</td>\n",
              "      <td>Q</td>\n",
              "      <td>86.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>일반점포에서소비자에게그림판매</td>\n",
              "      <td>478</td>\n",
              "      <td>G</td>\n",
              "      <td>47.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>사업장에서일반인.학생대상으로학습공간제공</td>\n",
              "      <td>902</td>\n",
              "      <td>R</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>사업장에서대리현대아파트를관리</td>\n",
              "      <td>682</td>\n",
              "      <td>L</td>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8d9deb6-197f-4698-aef5-13988e390981')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8d9deb6-197f-4698-aef5-13988e390981 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8d9deb6-197f-4698-aef5-13988e390981');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/gdrive/MyDrive/통계청/데이터/제출1_bertfull3.csv\", index = False)"
      ],
      "metadata": {
        "id": "LEZFBEnjgSUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans = pd.read_csv('답안 작성용 파일.csv',encoding='euc-kr')"
      ],
      "metadata": {
        "id": "GX3V9kTCj-MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans['digit_1']=df['digit_1']\n",
        "ans['digit_2']=df['digit_2']\n",
        "ans['digit_3']=df['digit_3']"
      ],
      "metadata": {
        "id": "E5R1qdM4kPLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "NZk0hwLGkad9",
        "outputId": "c8c4f3e1-5347-4adc-b60b-525857b7c6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           AI_id digit_1  digit_2  digit_3  text_obj   text_mthd text_deal\n",
              "0      id_000001       I     56.0      561   치킨전문점에서    고객의주문에의해      치킨판매\n",
              "1      id_000002       G     46.0      466      산업공구   다른 소매업자에게    철물 수공구\n",
              "2      id_000003       S     94.0      949       절에서    신도을 대상으로    불교단체운영\n",
              "3      id_000004       S     95.0      952     영업장에서       고객요구로     자동차튜닝\n",
              "4      id_000005       I     56.0      562  실내포장마차에서   접객시설을 갖추고   소주,맥주제공\n",
              "...          ...     ...      ...      ...       ...         ...       ...\n",
              "99995  id_099996       G     47.0      472     사업장에서     일반인대상으로      버섯농장\n",
              "99996  id_099997       Q     86.0      862     한의원에서     외래환자위주고        치료\n",
              "99997  id_099998       G     47.0      478    일반점포에서       소비자에게      그림판매\n",
              "99998  id_099999       R     90.0      902     사업장에서  일반인.학생대상으로    학습공간제공\n",
              "99999  id_100000       L     68.0      682     사업장에서    대리현대아파트를        관리\n",
              "\n",
              "[100000 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d99dcba8-8c32-4c64-89d9-71a6e45eb13c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AI_id</th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "      <th>digit_3</th>\n",
              "      <th>text_obj</th>\n",
              "      <th>text_mthd</th>\n",
              "      <th>text_deal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000001</td>\n",
              "      <td>I</td>\n",
              "      <td>56.0</td>\n",
              "      <td>561</td>\n",
              "      <td>치킨전문점에서</td>\n",
              "      <td>고객의주문에의해</td>\n",
              "      <td>치킨판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000002</td>\n",
              "      <td>G</td>\n",
              "      <td>46.0</td>\n",
              "      <td>466</td>\n",
              "      <td>산업공구</td>\n",
              "      <td>다른 소매업자에게</td>\n",
              "      <td>철물 수공구</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000003</td>\n",
              "      <td>S</td>\n",
              "      <td>94.0</td>\n",
              "      <td>949</td>\n",
              "      <td>절에서</td>\n",
              "      <td>신도을 대상으로</td>\n",
              "      <td>불교단체운영</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_000004</td>\n",
              "      <td>S</td>\n",
              "      <td>95.0</td>\n",
              "      <td>952</td>\n",
              "      <td>영업장에서</td>\n",
              "      <td>고객요구로</td>\n",
              "      <td>자동차튜닝</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_000005</td>\n",
              "      <td>I</td>\n",
              "      <td>56.0</td>\n",
              "      <td>562</td>\n",
              "      <td>실내포장마차에서</td>\n",
              "      <td>접객시설을 갖추고</td>\n",
              "      <td>소주,맥주제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>id_099996</td>\n",
              "      <td>G</td>\n",
              "      <td>47.0</td>\n",
              "      <td>472</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인대상으로</td>\n",
              "      <td>버섯농장</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>id_099997</td>\n",
              "      <td>Q</td>\n",
              "      <td>86.0</td>\n",
              "      <td>862</td>\n",
              "      <td>한의원에서</td>\n",
              "      <td>외래환자위주고</td>\n",
              "      <td>치료</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>id_099998</td>\n",
              "      <td>G</td>\n",
              "      <td>47.0</td>\n",
              "      <td>478</td>\n",
              "      <td>일반점포에서</td>\n",
              "      <td>소비자에게</td>\n",
              "      <td>그림판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>id_099999</td>\n",
              "      <td>R</td>\n",
              "      <td>90.0</td>\n",
              "      <td>902</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인.학생대상으로</td>\n",
              "      <td>학습공간제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>id_100000</td>\n",
              "      <td>L</td>\n",
              "      <td>68.0</td>\n",
              "      <td>682</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>대리현대아파트를</td>\n",
              "      <td>관리</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d99dcba8-8c32-4c64-89d9-71a6e45eb13c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d99dcba8-8c32-4c64-89d9-71a6e45eb13c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d99dcba8-8c32-4c64-89d9-71a6e45eb13c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans.to_csv(\"/content/gdrive/MyDrive/통계청/데이터/제출1_bertfull3.csv\", index = False)"
      ],
      "metadata": {
        "id": "Dr1Sq5r-kg5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델2. KOBERT (with original data) "
      ],
      "metadata": {
        "id": "YY5CV7XDuuMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###모델 학습"
      ],
      "metadata": {
        "id": "spguCSESu6Nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F9BmfmNIvThU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHzLkT5SEKqI",
        "outputId": "752cc5f0-28fa-4c72-82cb-b6b58772c3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/gdrive/MyDrive/통계청/데이터/.cache/kobert_v1.zip\n",
            "using cached model. /content/gdrive/MyDrive/통계청/데이터/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "metadata": {
        "id": "3fSfknWzEASB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#파라미터 튜닝..?\n",
        "max_len = 64\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 5\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ],
      "metadata": {
        "id": "0JWW542rD2yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "#BERTDataset 클래스 이용, TensorDataset으로 만들어주기\n",
        "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzDfvphvMTQI",
        "outputId": "9d440c86-eaa4-4fd4-9ff2-33579ff50304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/gdrive/MyDrive/통계청/데이터/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=4)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=4)"
      ],
      "metadata": {
        "id": "jorpF1cqMQVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=990, \n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "metadata": {
        "id": "nkpe73h3DyHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)"
      ],
      "metadata": {
        "id": "qX2fRHSXvTvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VoxnAt9MDjV",
        "outputId": "bb73e03c-d758-4259-d97c-b622d51b77ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ],
      "metadata": {
        "id": "orsP7UuHR-5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} validation acc {}\".format(e+1, test_acc / (batch_id+1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "38f61a1bf79041f69882a7b2924a6aca",
            "49222ac3a4e94ddd94889523b263c4ef",
            "de964378c9fd4505a97e84bc5cc2d04f",
            "36c3498894654c2ba78f8b53c79696d7",
            "c015c3317684431682ff8b13fb2bd74b",
            "133596b7e5a8491aa7ff32791dacb140",
            "1800cbf0c1f8408796710c16387e4ab9",
            "28fe8917e7ff4f2aa63f30b3d82ccef9",
            "f2530b76482848f294fe3a3febfce181",
            "d04bac5dd6624473b6dc375eab99a701",
            "36fd0f4e540348cb95a74da3dc35c7c1",
            "9151f656d44e45ff820433058fce99bc",
            "c8d156943cf64ac1afa0e873703a3201",
            "374d3e467c884088be7d5849579fbba8",
            "a5c4f073747047aea874353961f9a32b",
            "f4942bb9bdd642d686be82727f89e764",
            "e6973c668a2a4a228f6328aa89e8676c",
            "e5e9e9adaec94e918f4039244676fb1e",
            "f282f25b562b4a5c804dea51afce7ba1",
            "eef56b7ad126418fae1843ef15a173df",
            "05a85389defd488eaacfcb113e201037",
            "715a2f16f3244e70be7e06763dd65fb2",
            "1ddebacdf5d946a38340f29deea704e6",
            "d25a9de2a9794a6ab7b85b51c6614632",
            "0d387ceb2d054b3690e5e2cb3a793f6d",
            "d2ac7ec3d2ac41c4aa856554eadd580e",
            "6df46ea2d92a4eb6a1e073722f9f3855",
            "d2eb686716454fa0b85251ae595d6704",
            "925ba170c41645adae3438102cce9920",
            "b30f34c714f6406daf0d6a677834d464",
            "adb5303a77604011902680f53f8f6996",
            "cd331295dd1e4251865398e114c24b92",
            "aedef929eda4473d9f0588df4ff917b8",
            "0541883712364d7eba21beb42bd57bc0",
            "bea6ed1082b3475faafed9d0a4447086",
            "e384ca42251a4fbd9e686bc7a83fa069",
            "cf8aec20fa154e668a28e8fcfedde095",
            "19b2cd5506544926b8a46f18875e114b",
            "67bbb8ca7209409da831885056c5052f",
            "63f62ae0a9434426aee5f41b8d0e1b00",
            "6a7697a9981d4b2c97dd9b4ab667e016",
            "df6a36920a1b4600819d97cf54322891",
            "fadfdb9996894c38b2ce780b863c9690",
            "dc328bfd975e4285801e82a878886192",
            "6d3a133f12d64268be9dfbc0124cc6ee",
            "12b4ba292d4b433c80c21b581f1f5002",
            "eea413cd2b7345c5850c50f81d6357c5",
            "b4b1fed95e484e54aeb3c24768d7ae17",
            "e3bf0053d3774e92869a5c42b4a09f96",
            "bcd90086024d43d8a51d8cdd505d90f2",
            "7bbefd67580449c38eae9119d53c8113",
            "22260ef196714e99a020e0fab2dbc41b",
            "2ffbe02fb154432d823d2b714b3dca95",
            "3f2110afba784cc199070dfdfcace56c",
            "025d6b78ea5d49a5b686cb06b92e8fd7",
            "4a5f6e8f5ab347918b2c65b3a1193620",
            "5f5cb1fe9de845f3acc9019a9c13f23e",
            "820599705fc045a1991cfe5b91a325f7",
            "9cd89b2593de454286d394335a550641",
            "3569d4795ac54d9283fb7ffc2cfe3541",
            "9914ce852f8e4c139516122b8fd9d7f4",
            "a45fc3ce0ca04f398fd19fc8fc0b767b",
            "4d496961f18c4a03a957899506ef4de6",
            "9548cecbfbe2416ea045d577cf025b46",
            "0871766834844bceb07e2733c00bb40b",
            "116d8b5d57834a788d38e215b9c6c8af",
            "f803166f0bfe48b5a8a11ca8a2e0cb65",
            "c10ae038ebe04773a24858ed3c552178",
            "fc20fe1007a743b4a62169ee7bc68d78",
            "7478d8a1584849a9a72e2418e1862367",
            "8b3e1e499ff041c9b4ede6c723c70d03",
            "32feca3ad65241fd8d892f288fdf4728",
            "795824a88c194277a8fb32886a4e0d34",
            "8b2a4e592b8841ca93e9417263883f42",
            "57f44bdd53c6456282fb226772453ff7",
            "c11569332678478cbea3668a11585a68",
            "c4f61ca15d3944d78529abbd67232e01",
            "920f435c7ee0436abbe688f8bd294144",
            "b4966c96e33541a595c5a9da3b94d41c",
            "88eb0af6545f4195950529440847fedf",
            "add92e6879164234b05ce758f31af13f",
            "c922950d873a4962843d34cb3d62045d",
            "420d9eacba05457c893697f1398b549b",
            "4790a0bff6ae41ddad5b4b36a23767e3",
            "590a75e63f3542cfa6dba6889c2702ec",
            "99ca189ac5c44a928a6ac4fd3771854b",
            "7e4bbcac8da74a37a352c4523b1391f6",
            "82d56dabec3649e89112631878f7d30a",
            "771a22a54ceb418ca2f0c4659a23def2",
            "b9f6ff8687964ac1b37edc15c38650c4",
            "19ff1d562794452287d93cd2bef5c038",
            "6183c7e24b1b4d1d9029ab7601c9d104",
            "133d99dd1fbf4b2f9918949c78731c84",
            "d7ed3488894a49f6bf4ef8e8b728352c",
            "ad9f4a7586e44fb49186d4451399dde2",
            "4477cc5c8a41472cb19849229580c36d",
            "03b4756ff1c6470faa38796c2b4de753",
            "9e69c2acac984d1d993b1086253ab242",
            "de9baf38edd248b1b13f5900220197a8",
            "8b8052cd91974552821d6c8add0f3768",
            "9f940f7f7cf645038159db59f9e12289",
            "acfc240ac7b548c3903958fb03687d4b",
            "67bf533faee44c6aa45dc26769cc5950",
            "7cf12f3ab8d54bb2804e6d7d16c49490",
            "475f394dd4d74cfcb28613135d6d24db",
            "dcb14cb0e26f46d584dd5473fd3754ee",
            "6abe1ee99b344bdda024761073ed4c15",
            "440036dd084f4259a0c5e7ae2a919ab1",
            "a6ad7fcfb3564c0d86c8c0c70a3835bf",
            "c2f1356eb9a84ca8a7f9b9b07fc003d7"
          ]
        },
        "id": "10IJmPaHVUtO",
        "outputId": "75cd3fbb-03a0-4113-b2d6-b29aeae16ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38f61a1bf79041f69882a7b2924a6aca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 batch id 1 loss 6.939396381378174 train acc 0.0\n",
            "epoch 1 batch id 201 loss 6.7622761726379395 train acc 0.0017101990049751244\n",
            "epoch 1 batch id 401 loss 6.095229625701904 train acc 0.050810473815461346\n",
            "epoch 1 batch id 601 loss 5.320389270782471 train acc 0.09299604825291181\n",
            "epoch 1 batch id 801 loss 3.662550926208496 train acc 0.11657303370786516\n",
            "epoch 1 batch id 1001 loss 3.5258686542510986 train acc 0.14327859640359641\n",
            "epoch 1 batch id 1201 loss 2.8083581924438477 train acc 0.17909554537885095\n",
            "epoch 1 batch id 1401 loss 2.6241750717163086 train acc 0.21872769450392576\n",
            "epoch 1 batch id 1601 loss 2.502591371536255 train acc 0.25892996564647097\n",
            "epoch 1 batch id 1801 loss 2.0336897373199463 train acc 0.2978553581343698\n",
            "epoch 1 batch id 2001 loss 1.9714664220809937 train acc 0.3344421539230385\n",
            "epoch 1 batch id 2201 loss 1.9008574485778809 train acc 0.3668573943661972\n",
            "epoch 1 batch id 2401 loss 1.684599757194519 train acc 0.3970220741357768\n",
            "epoch 1 batch id 2601 loss 1.5829514265060425 train acc 0.42428993656286046\n",
            "epoch 1 batch id 2801 loss 1.5806034803390503 train acc 0.4493205551588718\n",
            "epoch 1 batch id 3001 loss 0.995582640171051 train acc 0.4723685854715095\n",
            "epoch 1 batch id 3201 loss 0.8381877541542053 train acc 0.49333704311152765\n",
            "epoch 1 batch id 3401 loss 1.0270088911056519 train acc 0.5123033666568656\n",
            "epoch 1 batch id 3601 loss 0.9127078652381897 train acc 0.5300437378505971\n",
            "epoch 1 batch id 3801 loss 0.8372833728790283 train acc 0.5458308668771376\n",
            "epoch 1 batch id 4001 loss 0.5427141785621643 train acc 0.5609417958010497\n",
            "epoch 1 batch id 4201 loss 0.5272567868232727 train acc 0.5746139312068556\n",
            "epoch 1 batch id 4401 loss 1.1286309957504272 train acc 0.5870043740059078\n",
            "epoch 1 batch id 4601 loss 0.7993531823158264 train acc 0.5985893012388611\n",
            "epoch 1 batch id 4801 loss 0.48664405941963196 train acc 0.609602817121433\n",
            "epoch 1 batch id 5001 loss 0.6114553809165955 train acc 0.6199041441711658\n",
            "epoch 1 batch id 5201 loss 0.41554921865463257 train acc 0.6294402518746395\n",
            "epoch 1 batch id 5401 loss 0.4190477728843689 train acc 0.638377152379189\n",
            "epoch 1 batch id 5601 loss 0.5786423087120056 train acc 0.6467985627566506\n",
            "epoch 1 batch id 5801 loss 0.6304845809936523 train acc 0.6548170574038958\n",
            "epoch 1 batch id 6001 loss 0.4960325062274933 train acc 0.6622828486918847\n",
            "epoch 1 batch id 6201 loss 0.596688985824585 train acc 0.669400600709563\n",
            "epoch 1 batch id 6401 loss 0.7616400718688965 train acc 0.676134588345571\n",
            "epoch 1 batch id 6601 loss 1.1024219989776611 train acc 0.6823989736403575\n",
            "epoch 1 batch id 6801 loss 0.4030207693576813 train acc 0.6884419570651374\n",
            "epoch 1 batch id 7001 loss 0.4714471995830536 train acc 0.6940905763462363\n",
            "epoch 1 batch id 7201 loss 0.28683656454086304 train acc 0.6995100506874046\n",
            "epoch 1 batch id 7401 loss 0.43395328521728516 train acc 0.7046492872584785\n",
            "epoch 1 batch id 7601 loss 0.3382002115249634 train acc 0.7095797427970004\n",
            "epoch 1 batch id 7801 loss 0.46825721859931946 train acc 0.7141492276631202\n",
            "epoch 1 batch id 8001 loss 0.3741653263568878 train acc 0.7185996281714786\n",
            "epoch 1 batch id 8201 loss 0.5758683085441589 train acc 0.7227300786489452\n",
            "epoch 1 batch id 8401 loss 0.377137690782547 train acc 0.7267680186882514\n",
            "epoch 1 batch id 8601 loss 0.5870518684387207 train acc 0.7305164370422044\n",
            "epoch 1 batch id 8801 loss 0.599510133266449 train acc 0.7341140211339621\n",
            "epoch 1 batch id 9001 loss 0.19864611327648163 train acc 0.7377583046328186\n",
            "epoch 1 batch id 9201 loss 0.2547098994255066 train acc 0.7411541544397348\n",
            "epoch 1 batch id 9401 loss 0.506041944026947 train acc 0.7444670114881395\n",
            "epoch 1 batch id 9601 loss 0.4324566721916199 train acc 0.7476076710759296\n",
            "epoch 1 batch id 9801 loss 0.529228925704956 train acc 0.7506105882052851\n",
            "epoch 1 batch id 10001 loss 0.24347537755966187 train acc 0.7535590190980902\n",
            "epoch 1 batch id 10201 loss 0.3372320830821991 train acc 0.7563734560337222\n",
            "epoch 1 batch id 10401 loss 0.4548034071922302 train acc 0.7591517642534372\n",
            "epoch 1 batch id 10601 loss 0.3598918616771698 train acc 0.7618134492029054\n",
            "epoch 1 batch id 10801 loss 0.21720623970031738 train acc 0.7643418433478382\n",
            "epoch 1 batch id 11001 loss 0.6128661632537842 train acc 0.7667868261976184\n",
            "epoch 1 batch id 11201 loss 0.5066854953765869 train acc 0.7691082269440228\n",
            "epoch 1 batch id 11401 loss 0.18454018235206604 train acc 0.7715167529164109\n",
            "epoch 1 batch id 11601 loss 0.47823861241340637 train acc 0.7737789306956296\n",
            "epoch 1 batch id 11801 loss 0.25233542919158936 train acc 0.7759975319888145\n",
            "epoch 1 batch id 12001 loss 0.4378804862499237 train acc 0.77816431964003\n",
            "epoch 1 batch id 12201 loss 0.4544788599014282 train acc 0.7801832329317269\n",
            "epoch 1 batch id 12401 loss 0.4188432991504669 train acc 0.7822542032900572\n",
            "epoch 1 train acc 0.78318875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9151f656d44e45ff820433058fce99bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 validation acc 0.908925\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ddebacdf5d946a38340f29deea704e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 batch id 1 loss 0.31223204731941223 train acc 0.9375\n",
            "epoch 2 batch id 201 loss 0.3815394937992096 train acc 0.9028296019900498\n",
            "epoch 2 batch id 401 loss 0.3825431168079376 train acc 0.9029379675810474\n",
            "epoch 2 batch id 601 loss 0.2429758906364441 train acc 0.9036241680532446\n",
            "epoch 2 batch id 801 loss 0.22197017073631287 train acc 0.9033044631710362\n",
            "epoch 2 batch id 1001 loss 0.3455215096473694 train acc 0.9038461538461539\n",
            "epoch 2 batch id 1201 loss 0.07619673013687134 train acc 0.9046757910074937\n",
            "epoch 2 batch id 1401 loss 0.323715478181839 train acc 0.9050789614561028\n",
            "epoch 2 batch id 1601 loss 0.35604432225227356 train acc 0.9053618831980013\n",
            "epoch 2 batch id 1801 loss 0.2717248797416687 train acc 0.9053130205441421\n",
            "epoch 2 batch id 2001 loss 0.19967208802700043 train acc 0.9058049100449775\n",
            "epoch 2 batch id 2201 loss 0.7231066226959229 train acc 0.9054975011358474\n",
            "epoch 2 batch id 2401 loss 0.6319245100021362 train acc 0.9055406601416076\n",
            "epoch 2 batch id 2601 loss 0.4364548325538635 train acc 0.9056012110726643\n",
            "epoch 2 batch id 2801 loss 0.2650167644023895 train acc 0.9056698500535523\n",
            "epoch 2 batch id 3001 loss 0.2678264081478119 train acc 0.9063280989670109\n",
            "epoch 2 batch id 3201 loss 0.35938021540641785 train acc 0.9068211105904405\n",
            "epoch 2 batch id 3401 loss 0.2427365481853485 train acc 0.9071137165539547\n",
            "epoch 2 batch id 3601 loss 0.3268783986568451 train acc 0.9073694806998056\n",
            "epoch 2 batch id 3801 loss 0.2753159999847412 train acc 0.9075490002630887\n",
            "epoch 2 batch id 4001 loss 0.26830995082855225 train acc 0.9078433516620845\n",
            "epoch 2 batch id 4201 loss 0.26727038621902466 train acc 0.9080390085693882\n",
            "epoch 2 batch id 4401 loss 0.5764253735542297 train acc 0.9083659963644626\n",
            "epoch 2 batch id 4601 loss 0.5489081740379333 train acc 0.9085830525972615\n",
            "epoch 2 batch id 4801 loss 0.25440967082977295 train acc 0.9086908977296396\n",
            "epoch 2 batch id 5001 loss 0.382961243391037 train acc 0.9088900969806039\n",
            "epoch 2 batch id 5201 loss 0.314659059047699 train acc 0.9089718323399346\n",
            "epoch 2 batch id 5401 loss 0.11491933465003967 train acc 0.9091169459359378\n",
            "epoch 2 batch id 5601 loss 0.4095512330532074 train acc 0.9091456882699518\n",
            "epoch 2 batch id 5801 loss 0.3870619833469391 train acc 0.9095199103602827\n",
            "epoch 2 batch id 6001 loss 0.3907971978187561 train acc 0.9098848108648558\n",
            "epoch 2 batch id 6201 loss 0.34528765082359314 train acc 0.9101279027576198\n",
            "epoch 2 batch id 6401 loss 0.42399606108665466 train acc 0.9104387986252148\n",
            "epoch 2 batch id 6601 loss 0.7722869515419006 train acc 0.9107829306165732\n",
            "epoch 2 batch id 6801 loss 0.30389881134033203 train acc 0.9110264115571239\n",
            "epoch 2 batch id 7001 loss 0.21056854724884033 train acc 0.9111778674475075\n",
            "epoch 2 batch id 7201 loss 0.1988367736339569 train acc 0.9113404388279406\n",
            "epoch 2 batch id 7401 loss 0.39692679047584534 train acc 0.9115660045939737\n",
            "epoch 2 batch id 7601 loss 0.28619149327278137 train acc 0.9117406426785949\n",
            "epoch 2 batch id 7801 loss 0.24796821177005768 train acc 0.9119163408537367\n",
            "epoch 2 batch id 8001 loss 0.24950538575649261 train acc 0.9121613704536933\n",
            "epoch 2 batch id 8201 loss 0.5559593439102173 train acc 0.9122782282648457\n",
            "epoch 2 batch id 8401 loss 0.2545200288295746 train acc 0.912478797167004\n",
            "epoch 2 batch id 8601 loss 0.49196088314056396 train acc 0.9126609551214975\n",
            "epoch 2 batch id 8801 loss 0.40209993720054626 train acc 0.9126892540620384\n",
            "epoch 2 batch id 9001 loss 0.204709991812706 train acc 0.9129332851905344\n",
            "epoch 2 batch id 9201 loss 0.06307432800531387 train acc 0.9130546272144332\n",
            "epoch 2 batch id 9401 loss 0.46447110176086426 train acc 0.913258895330284\n",
            "epoch 2 batch id 9601 loss 0.37971267104148865 train acc 0.9133212035204666\n",
            "epoch 2 batch id 9801 loss 0.3951103389263153 train acc 0.9134303897561473\n",
            "epoch 2 batch id 10001 loss 0.22340883314609528 train acc 0.9135789546045395\n",
            "epoch 2 batch id 10201 loss 0.3466580808162689 train acc 0.913733947652191\n",
            "epoch 2 batch id 10401 loss 0.25215551257133484 train acc 0.9139641020094221\n",
            "epoch 2 batch id 10601 loss 0.1849163919687271 train acc 0.9141560937647392\n",
            "epoch 2 batch id 10801 loss 0.1745934933423996 train acc 0.9142454981020276\n",
            "epoch 2 batch id 11001 loss 0.341862291097641 train acc 0.9143330719934551\n",
            "epoch 2 batch id 11201 loss 0.3748445212841034 train acc 0.9144007789483082\n",
            "epoch 2 batch id 11401 loss 0.13810087740421295 train acc 0.9145921958600123\n",
            "epoch 2 batch id 11601 loss 0.3724893629550934 train acc 0.9147164037582967\n",
            "epoch 2 batch id 11801 loss 0.17487414181232452 train acc 0.914874798745869\n",
            "epoch 2 batch id 12001 loss 0.31834548711776733 train acc 0.9150643696358637\n",
            "epoch 2 batch id 12201 loss 0.3979683220386505 train acc 0.9151644844684862\n",
            "epoch 2 batch id 12401 loss 0.3124416172504425 train acc 0.9153369687928393\n",
            "epoch 2 train acc 0.9153975\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0541883712364d7eba21beb42bd57bc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 validation acc 0.92039\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d3a133f12d64268be9dfbc0124cc6ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 batch id 1 loss 0.26819345355033875 train acc 0.96875\n",
            "epoch 3 batch id 201 loss 0.2255706638097763 train acc 0.9242848258706468\n",
            "epoch 3 batch id 401 loss 0.24249714612960815 train acc 0.923589463840399\n",
            "epoch 3 batch id 601 loss 0.20968271791934967 train acc 0.924162853577371\n",
            "epoch 3 batch id 801 loss 0.20582924783229828 train acc 0.9235525905118602\n",
            "epoch 3 batch id 1001 loss 0.24654892086982727 train acc 0.9237012987012987\n",
            "epoch 3 batch id 1201 loss 0.05614900961518288 train acc 0.9236833888426311\n",
            "epoch 3 batch id 1401 loss 0.29954180121421814 train acc 0.9237709671663098\n",
            "epoch 3 batch id 1601 loss 0.21655502915382385 train acc 0.9241684884447221\n",
            "epoch 3 batch id 1801 loss 0.2329806685447693 train acc 0.9242521515824542\n",
            "epoch 3 batch id 2001 loss 0.18201935291290283 train acc 0.9247876061969016\n",
            "epoch 3 batch id 2201 loss 0.5840834975242615 train acc 0.924714618355293\n",
            "epoch 3 batch id 2401 loss 0.4049997925758362 train acc 0.9246602977925864\n",
            "epoch 3 batch id 2601 loss 0.3177422285079956 train acc 0.9245903018069973\n",
            "epoch 3 batch id 2801 loss 0.2403813749551773 train acc 0.9245024098536238\n",
            "epoch 3 batch id 3001 loss 0.18783795833587646 train acc 0.9248896201266245\n",
            "epoch 3 batch id 3201 loss 0.3105723261833191 train acc 0.9252479693845673\n",
            "epoch 3 batch id 3401 loss 0.21397434175014496 train acc 0.9254768817994707\n",
            "epoch 3 batch id 3601 loss 0.14476175606250763 train acc 0.9258192168841989\n",
            "epoch 3 batch id 3801 loss 0.1972666233778 train acc 0.9259857603262299\n",
            "epoch 3 batch id 4001 loss 0.2167825549840927 train acc 0.9263504436390902\n",
            "epoch 3 batch id 4201 loss 0.21115069091320038 train acc 0.9264758390859319\n",
            "epoch 3 batch id 4401 loss 0.5536178946495056 train acc 0.9267034480799818\n",
            "epoch 3 batch id 4601 loss 0.44216182827949524 train acc 0.9267210932405999\n",
            "epoch 3 batch id 4801 loss 0.14979419112205505 train acc 0.9267991043532597\n",
            "epoch 3 batch id 5001 loss 0.39435282349586487 train acc 0.9269333633273346\n",
            "epoch 3 batch id 5201 loss 0.275767982006073 train acc 0.9270753220534512\n",
            "epoch 3 batch id 5401 loss 0.14277714490890503 train acc 0.9272472690242548\n",
            "epoch 3 batch id 5601 loss 0.22021231055259705 train acc 0.927342773611855\n",
            "epoch 3 batch id 5801 loss 0.28938281536102295 train acc 0.9275798353732115\n",
            "epoch 3 batch id 6001 loss 0.3313691020011902 train acc 0.9277490209965006\n",
            "epoch 3 batch id 6201 loss 0.2562646269798279 train acc 0.9279476092565715\n",
            "epoch 3 batch id 6401 loss 0.42699599266052246 train acc 0.9282436338072176\n",
            "epoch 3 batch id 6601 loss 0.7330594062805176 train acc 0.9284459740948341\n",
            "epoch 3 batch id 6801 loss 0.22700130939483643 train acc 0.9285743824437582\n",
            "epoch 3 batch id 7001 loss 0.1284482628107071 train acc 0.9286842951006999\n",
            "epoch 3 batch id 7201 loss 0.09262244403362274 train acc 0.9288119705596445\n",
            "epoch 3 batch id 7401 loss 0.2629024088382721 train acc 0.9289580799891907\n",
            "epoch 3 batch id 7601 loss 0.24380159378051758 train acc 0.929069777003026\n",
            "epoch 3 batch id 7801 loss 0.2641777992248535 train acc 0.9292057909242405\n",
            "epoch 3 batch id 8001 loss 0.1717550903558731 train acc 0.9293467222847144\n",
            "epoch 3 batch id 8201 loss 0.3437892198562622 train acc 0.9294522009511035\n",
            "epoch 3 batch id 8401 loss 0.24476686120033264 train acc 0.9295712563980478\n",
            "epoch 3 batch id 8601 loss 0.37438297271728516 train acc 0.9297083914661086\n",
            "epoch 3 batch id 8801 loss 0.41985148191452026 train acc 0.9297274457448017\n",
            "epoch 3 batch id 9001 loss 0.07415083050727844 train acc 0.9298984140651039\n",
            "epoch 3 batch id 9201 loss 0.04764170944690704 train acc 0.9299940223888707\n",
            "epoch 3 batch id 9401 loss 0.3660876154899597 train acc 0.9301420726518456\n",
            "epoch 3 batch id 9601 loss 0.19847489893436432 train acc 0.9301765441099885\n",
            "epoch 3 batch id 9801 loss 0.2586935758590698 train acc 0.9302813488419549\n",
            "epoch 3 batch id 10001 loss 0.19735583662986755 train acc 0.9303710253974603\n",
            "epoch 3 batch id 10201 loss 0.22437015175819397 train acc 0.9304081707675718\n",
            "epoch 3 batch id 10401 loss 0.24381591379642487 train acc 0.9305700773964042\n",
            "epoch 3 batch id 10601 loss 0.09028318524360657 train acc 0.9307096618243562\n",
            "epoch 3 batch id 10801 loss 0.11225613951683044 train acc 0.9307919984260716\n",
            "epoch 3 batch id 11001 loss 0.33426758646965027 train acc 0.9308429347332061\n",
            "epoch 3 batch id 11201 loss 0.3944765329360962 train acc 0.9309046067315419\n",
            "epoch 3 batch id 11401 loss 0.13228163123130798 train acc 0.9310545675817911\n",
            "epoch 3 batch id 11601 loss 0.29370206594467163 train acc 0.9311374019481079\n",
            "epoch 3 batch id 11801 loss 0.06859288364648819 train acc 0.9312862787051944\n",
            "epoch 3 batch id 12001 loss 0.29610785841941833 train acc 0.9314184755437047\n",
            "epoch 3 batch id 12201 loss 0.24657993018627167 train acc 0.9315143225965085\n",
            "epoch 3 batch id 12401 loss 0.27496567368507385 train acc 0.9316662970728167\n",
            "epoch 3 train acc 0.9316925\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a5f6e8f5ab347918b2c65b3a1193620"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 validation acc 0.92501\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f803166f0bfe48b5a8a11ca8a2e0cb65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 batch id 1 loss 0.18261852860450745 train acc 0.96875\n",
            "epoch 4 batch id 201 loss 0.21272484958171844 train acc 0.9395988805970149\n",
            "epoch 4 batch id 401 loss 0.22813348472118378 train acc 0.9383572319201995\n",
            "epoch 4 batch id 601 loss 0.16142146289348602 train acc 0.9390079034941764\n",
            "epoch 4 batch id 801 loss 0.1528264731168747 train acc 0.9384753433208489\n",
            "epoch 4 batch id 1001 loss 0.12132153660058975 train acc 0.9386707042957043\n",
            "epoch 4 batch id 1201 loss 0.02985803596675396 train acc 0.9387489592006661\n",
            "epoch 4 batch id 1401 loss 0.33433353900909424 train acc 0.9390725374732334\n",
            "epoch 4 batch id 1601 loss 0.15966694056987762 train acc 0.9395299812617114\n",
            "epoch 4 batch id 1801 loss 0.17925260961055756 train acc 0.9397209883398112\n",
            "epoch 4 batch id 2001 loss 0.11754059046506882 train acc 0.9402173913043478\n",
            "epoch 4 batch id 2201 loss 0.5682380795478821 train acc 0.940034359382099\n",
            "epoch 4 batch id 2401 loss 0.3280080258846283 train acc 0.9398102353186173\n",
            "epoch 4 batch id 2601 loss 0.2413567155599594 train acc 0.939788783160323\n",
            "epoch 4 batch id 2801 loss 0.16472724080085754 train acc 0.9396588272045698\n",
            "epoch 4 batch id 3001 loss 0.14647176861763 train acc 0.9400668527157614\n",
            "epoch 4 batch id 3201 loss 0.20092150568962097 train acc 0.940296977507029\n",
            "epoch 4 batch id 3401 loss 0.20129607617855072 train acc 0.9405000367538959\n",
            "epoch 4 batch id 3601 loss 0.0629880279302597 train acc 0.9407890169397389\n",
            "epoch 4 batch id 3801 loss 0.20096030831336975 train acc 0.9410147000789266\n",
            "epoch 4 batch id 4001 loss 0.2163139283657074 train acc 0.9412685891027244\n",
            "epoch 4 batch id 4201 loss 0.17007532715797424 train acc 0.9413420911687693\n",
            "epoch 4 batch id 4401 loss 0.5327339172363281 train acc 0.9415083219722791\n",
            "epoch 4 batch id 4601 loss 0.3902439773082733 train acc 0.9415174690284721\n",
            "epoch 4 batch id 4801 loss 0.08804740011692047 train acc 0.9416267444282441\n",
            "epoch 4 batch id 5001 loss 0.28473973274230957 train acc 0.941752274545091\n",
            "epoch 4 batch id 5201 loss 0.22639018297195435 train acc 0.9419282349548164\n",
            "epoch 4 batch id 5401 loss 0.08360673487186432 train acc 0.9420651268283651\n",
            "epoch 4 batch id 5601 loss 0.14119596779346466 train acc 0.942058337796822\n",
            "epoch 4 batch id 5801 loss 0.21106217801570892 train acc 0.9423105930012067\n",
            "epoch 4 batch id 6001 loss 0.30875110626220703 train acc 0.9425147892017997\n",
            "epoch 4 batch id 6201 loss 0.1349855363368988 train acc 0.9426755765199162\n",
            "epoch 4 batch id 6401 loss 0.3638601005077362 train acc 0.9428824597719107\n",
            "epoch 4 batch id 6601 loss 0.5943788886070251 train acc 0.9430697053476746\n",
            "epoch 4 batch id 6801 loss 0.27405351400375366 train acc 0.9431356601970299\n",
            "epoch 4 batch id 7001 loss 0.11507219821214676 train acc 0.9431933830881303\n",
            "epoch 4 batch id 7201 loss 0.05833655595779419 train acc 0.9432240313845299\n",
            "epoch 4 batch id 7401 loss 0.19336172938346863 train acc 0.9433543608971761\n",
            "epoch 4 batch id 7601 loss 0.1823350489139557 train acc 0.9434367188527826\n",
            "epoch 4 batch id 7801 loss 0.17016816139221191 train acc 0.9435829541084476\n",
            "epoch 4 batch id 8001 loss 0.12296359241008759 train acc 0.9436964910636171\n",
            "epoch 4 batch id 8201 loss 0.368924081325531 train acc 0.9437492378978174\n",
            "epoch 4 batch id 8401 loss 0.23801231384277344 train acc 0.9438385311272468\n",
            "epoch 4 batch id 8601 loss 0.3687494695186615 train acc 0.9439581880013952\n",
            "epoch 4 batch id 8801 loss 0.3083937168121338 train acc 0.9439871889558005\n",
            "epoch 4 batch id 9001 loss 0.02344702184200287 train acc 0.9441485668259082\n",
            "epoch 4 batch id 9201 loss 0.044581860303878784 train acc 0.9442061324855994\n",
            "epoch 4 batch id 9401 loss 0.36619338393211365 train acc 0.9442928278906499\n",
            "epoch 4 batch id 9601 loss 0.12456580996513367 train acc 0.9442782652848661\n",
            "epoch 4 batch id 9801 loss 0.212969109416008 train acc 0.9443599505152536\n",
            "epoch 4 batch id 10001 loss 0.13800035417079926 train acc 0.9444118088191181\n",
            "epoch 4 batch id 10201 loss 0.15226596593856812 train acc 0.9444692922262523\n",
            "epoch 4 batch id 10401 loss 0.18099592626094818 train acc 0.9445966733967888\n",
            "epoch 4 batch id 10601 loss 0.04182024300098419 train acc 0.9447443047825677\n",
            "epoch 4 batch id 10801 loss 0.03539802506566048 train acc 0.9447823118229793\n",
            "epoch 4 batch id 11001 loss 0.26356109976768494 train acc 0.944816096263976\n",
            "epoch 4 batch id 11201 loss 0.3177049160003662 train acc 0.9448779684849568\n",
            "epoch 4 batch id 11401 loss 0.07776810228824615 train acc 0.9449801552495395\n",
            "epoch 4 batch id 11601 loss 0.172917440533638 train acc 0.9450666968364796\n",
            "epoch 4 batch id 11801 loss 0.04318305477499962 train acc 0.9451608973815778\n",
            "epoch 4 batch id 12001 loss 0.2633165717124939 train acc 0.9452923193900509\n",
            "epoch 4 batch id 12201 loss 0.16987042129039764 train acc 0.9453656462585034\n",
            "epoch 4 batch id 12401 loss 0.18779271841049194 train acc 0.9454857471171679\n",
            "epoch 4 train acc 0.94553\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "920f435c7ee0436abbe688f8bd294144"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 validation acc 0.92861\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "771a22a54ceb418ca2f0c4659a23def2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 batch id 1 loss 0.18010176718235016 train acc 0.96875\n",
            "epoch 5 batch id 201 loss 0.19482605159282684 train acc 0.9489272388059702\n",
            "epoch 5 batch id 401 loss 0.16796816885471344 train acc 0.9481374688279302\n",
            "epoch 5 batch id 601 loss 0.1444590836763382 train acc 0.9497972129783694\n",
            "epoch 5 batch id 801 loss 0.1673233062028885 train acc 0.9493406679151061\n",
            "epoch 5 batch id 1001 loss 0.11450120806694031 train acc 0.9498626373626373\n",
            "epoch 5 batch id 1201 loss 0.014697805978357792 train acc 0.9500026019983348\n",
            "epoch 5 batch id 1401 loss 0.2495439499616623 train acc 0.9501695217701641\n",
            "epoch 5 batch id 1601 loss 0.10293184965848923 train acc 0.9503728138663335\n",
            "epoch 5 batch id 1801 loss 0.10365220904350281 train acc 0.9503661160466408\n",
            "epoch 5 batch id 2001 loss 0.08854091167449951 train acc 0.9507589955022488\n",
            "epoch 5 batch id 2201 loss 0.506439208984375 train acc 0.9506190368014539\n",
            "epoch 5 batch id 2401 loss 0.2988743185997009 train acc 0.9504308100791337\n",
            "epoch 5 batch id 2601 loss 0.16490982472896576 train acc 0.9504577566320646\n",
            "epoch 5 batch id 2801 loss 0.13064157962799072 train acc 0.9502911906461978\n",
            "epoch 5 batch id 3001 loss 0.0793364867568016 train acc 0.9506987254248583\n",
            "epoch 5 batch id 3201 loss 0.18458841741085052 train acc 0.9509284208059982\n",
            "epoch 5 batch id 3401 loss 0.14660224318504333 train acc 0.9510897530138195\n",
            "epoch 5 batch id 3601 loss 0.05022303760051727 train acc 0.9512548597611774\n",
            "epoch 5 batch id 3801 loss 0.20486272871494293 train acc 0.9513861483820047\n",
            "epoch 5 batch id 4001 loss 0.1657383143901825 train acc 0.9516019432641839\n",
            "epoch 5 batch id 4201 loss 0.1238560900092125 train acc 0.9516261009283504\n",
            "epoch 5 batch id 4401 loss 0.4276767373085022 train acc 0.951747472165417\n",
            "epoch 5 batch id 4601 loss 0.24705511331558228 train acc 0.9517394316452945\n",
            "epoch 5 batch id 4801 loss 0.04602072387933731 train acc 0.9518524786502812\n",
            "epoch 5 batch id 5001 loss 0.19659659266471863 train acc 0.9519064937012598\n",
            "epoch 5 batch id 5201 loss 0.22374430298805237 train acc 0.9520584983656989\n",
            "epoch 5 batch id 5401 loss 0.05267567187547684 train acc 0.9521240279577856\n",
            "epoch 5 batch id 5601 loss 0.1346186250448227 train acc 0.9520956079271559\n",
            "epoch 5 batch id 5801 loss 0.13413871824741364 train acc 0.952316949663851\n",
            "epoch 5 batch id 6001 loss 0.23720689117908478 train acc 0.9524610481586402\n",
            "epoch 5 batch id 6201 loss 0.11705078184604645 train acc 0.952714279954846\n",
            "epoch 5 batch id 6401 loss 0.308273047208786 train acc 0.9529321590376504\n",
            "epoch 5 batch id 6601 loss 0.5580998063087463 train acc 0.9530894940160581\n",
            "epoch 5 batch id 6801 loss 0.2298453152179718 train acc 0.953141082193795\n",
            "epoch 5 batch id 7001 loss 0.1412229984998703 train acc 0.9531495500642765\n",
            "epoch 5 batch id 7201 loss 0.036930058151483536 train acc 0.9531705665879739\n",
            "epoch 5 batch id 7401 loss 0.13316862285137177 train acc 0.9532305600594514\n",
            "epoch 5 batch id 7601 loss 0.12474106252193451 train acc 0.9532812294434942\n",
            "epoch 5 batch id 7801 loss 0.15285876393318176 train acc 0.9533353095756955\n",
            "epoch 5 batch id 8001 loss 0.11980929225683212 train acc 0.9534452724659418\n",
            "epoch 5 batch id 8201 loss 0.24321605265140533 train acc 0.9534050725521278\n",
            "epoch 5 batch id 8401 loss 0.25471556186676025 train acc 0.9534839602428282\n",
            "epoch 5 batch id 8601 loss 0.30533409118652344 train acc 0.9535827956051622\n",
            "epoch 5 batch id 8801 loss 0.3035795986652374 train acc 0.953574167708215\n",
            "epoch 5 batch id 9001 loss 0.03313113749027252 train acc 0.9537134762804133\n",
            "epoch 5 batch id 9201 loss 0.051914747804403305 train acc 0.9537210629279426\n",
            "epoch 5 batch id 9401 loss 0.2727104425430298 train acc 0.9537715402616743\n",
            "epoch 5 batch id 9601 loss 0.09138737618923187 train acc 0.9537287782522654\n",
            "epoch 5 batch id 9801 loss 0.16403967142105103 train acc 0.9537451535557596\n",
            "epoch 5 batch id 10001 loss 0.15102265775203705 train acc 0.9537249400059994\n",
            "epoch 5 batch id 10201 loss 0.1812770515680313 train acc 0.9537361533183021\n",
            "epoch 5 batch id 10401 loss 0.1267419159412384 train acc 0.9538310619171233\n",
            "epoch 5 batch id 10601 loss 0.030924241989850998 train acc 0.9539150198094519\n",
            "epoch 5 batch id 10801 loss 0.02083967626094818 train acc 0.9539249837977966\n",
            "epoch 5 batch id 11001 loss 0.26955994963645935 train acc 0.9539019180074538\n",
            "epoch 5 batch id 11201 loss 0.25846394896507263 train acc 0.9539131550754397\n",
            "epoch 5 batch id 11401 loss 0.0528508685529232 train acc 0.9539541487588808\n",
            "epoch 5 batch id 11601 loss 0.17829696834087372 train acc 0.9540058507887251\n",
            "epoch 5 batch id 11801 loss 0.06858110427856445 train acc 0.9540544763155665\n",
            "epoch 5 batch id 12001 loss 0.2153630256652832 train acc 0.9541131989000916\n",
            "epoch 5 batch id 12201 loss 0.12660962343215942 train acc 0.9541597512498976\n",
            "epoch 5 batch id 12401 loss 0.1748131960630417 train acc 0.9542438613821466\n",
            "epoch 5 train acc 0.95424875\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b8052cd91974552821d6c8add0f3768"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 validation acc 0.928945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###학습된 모델 적용"
      ],
      "metadata": {
        "id": "fEI61yOUu8Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_test = nlp.data.TSVDataset('/content/gdrive/MyDrive/통계청/데이터/test.tsv', field_indices=[7,3], num_discard_samples=1)\n",
        "test_set = BERTDataset(new_test , 0, 1, tok, max_len, True, False)\n",
        "test_input = torch.utils.data.DataLoader(test_set, batch_size=1, num_workers=4)"
      ],
      "metadata": {
        "id": "AljbK7bGeQPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prds=[]\n",
        "for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_input)): \n",
        "  token_ids = token_ids.long().to(device) \n",
        "  segment_ids = segment_ids.long().to(device) \n",
        "  valid_length= valid_length \n",
        "  out = model(token_ids, valid_length, segment_ids)\n",
        "  prediction = out.cpu().detach().numpy().argmax()\n",
        "  prds.append(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "b8f4e0f13994405a89b482da1dcae632",
            "cb301cfd000f4e688e11e1f03f12fe34",
            "cb4a55b5e02e4b58b8f8a3e0e9739752",
            "414f74335bc244a29c49c99b1f1b87e4",
            "3890e2155b2e495bbfb8cb18c3030112",
            "4f25d0b7411941e2bd61df4af6aa00c6",
            "8799f2c976464869959ca04a65d50206",
            "cd1eff6daa544fb18c96aac4c88083a6",
            "1797de30a84f4ab6800ff9f1ffc17a84",
            "b652e5c1e22d45fc8d903d751608ca2c",
            "c19fdcc658fc4742b81605675c843f1e"
          ]
        },
        "id": "TWvXu6QGgNE1",
        "outputId": "15d1b678-e880-4ce6-d970-96dae6e8a9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8f4e0f13994405a89b482da1dcae632"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans = pd.read_csv('답안 작성용 파일.csv',encoding='euc-kr')"
      ],
      "metadata": {
        "id": "IevBR-UenuVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(ans)):\n",
        "  ans['digit_3'][i]=prds[i]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mxhrhHKnhOT",
        "outputId": "f53f6a55-4297-4a60-9c05-62e4b64b9fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###소분류를 중,대분류에 매핑"
      ],
      "metadata": {
        "id": "wBJBcT-Uu-EC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=ans[:]"
      ],
      "metadata": {
        "id": "mPZAObmsooGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df)):\n",
        "  l=ind_class.index[ind_class['digit_3']==df['digit_3'][i]].tolist()\n",
        "  f=l[0]\n",
        "  df['digit_1'][i]=ind_class['digit_1'][f]\n",
        "  df['digit_2'][i]=ind_class['digit_2'][f]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e736a69-bb86-4fd7-8ef8-44baaab5b11b",
        "id": "MgVLLVv2vfK3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:1056: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cacher_needs_updating = self._check_is_chained_assignment_possible()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "37c46891-add1-4b44-93e2-b78607191237",
        "id": "ZdOkrrxkvfK3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           AI_id digit_1  digit_2  digit_3  text_obj   text_mthd text_deal\n",
              "0      id_000001       I     56.0    561.0   치킨전문점에서    고객의주문에의해      치킨판매\n",
              "1      id_000002       G     46.0    466.0      산업공구   다른 소매업자에게    철물 수공구\n",
              "2      id_000003       S     94.0    949.0       절에서    신도을 대상으로    불교단체운영\n",
              "3      id_000004       S     95.0    952.0     영업장에서       고객요구로     자동차튜닝\n",
              "4      id_000005       I     56.0    562.0  실내포장마차에서   접객시설을 갖추고   소주,맥주제공\n",
              "...          ...     ...      ...      ...       ...         ...       ...\n",
              "99995  id_099996       A      1.0     11.0     사업장에서     일반인대상으로      버섯농장\n",
              "99996  id_099997       Q     86.0    862.0     한의원에서     외래환자위주고        치료\n",
              "99997  id_099998       G     47.0    478.0    일반점포에서       소비자에게      그림판매\n",
              "99998  id_099999       R     90.0    902.0     사업장에서  일반인.학생대상으로    학습공간제공\n",
              "99999  id_100000       L     68.0    682.0     사업장에서    대리현대아파트를        관리\n",
              "\n",
              "[100000 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bec3c76b-5083-4d0e-a251-998d41903400\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AI_id</th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "      <th>digit_3</th>\n",
              "      <th>text_obj</th>\n",
              "      <th>text_mthd</th>\n",
              "      <th>text_deal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000001</td>\n",
              "      <td>I</td>\n",
              "      <td>56.0</td>\n",
              "      <td>561.0</td>\n",
              "      <td>치킨전문점에서</td>\n",
              "      <td>고객의주문에의해</td>\n",
              "      <td>치킨판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000002</td>\n",
              "      <td>G</td>\n",
              "      <td>46.0</td>\n",
              "      <td>466.0</td>\n",
              "      <td>산업공구</td>\n",
              "      <td>다른 소매업자에게</td>\n",
              "      <td>철물 수공구</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000003</td>\n",
              "      <td>S</td>\n",
              "      <td>94.0</td>\n",
              "      <td>949.0</td>\n",
              "      <td>절에서</td>\n",
              "      <td>신도을 대상으로</td>\n",
              "      <td>불교단체운영</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_000004</td>\n",
              "      <td>S</td>\n",
              "      <td>95.0</td>\n",
              "      <td>952.0</td>\n",
              "      <td>영업장에서</td>\n",
              "      <td>고객요구로</td>\n",
              "      <td>자동차튜닝</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_000005</td>\n",
              "      <td>I</td>\n",
              "      <td>56.0</td>\n",
              "      <td>562.0</td>\n",
              "      <td>실내포장마차에서</td>\n",
              "      <td>접객시설을 갖추고</td>\n",
              "      <td>소주,맥주제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>id_099996</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인대상으로</td>\n",
              "      <td>버섯농장</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>id_099997</td>\n",
              "      <td>Q</td>\n",
              "      <td>86.0</td>\n",
              "      <td>862.0</td>\n",
              "      <td>한의원에서</td>\n",
              "      <td>외래환자위주고</td>\n",
              "      <td>치료</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>id_099998</td>\n",
              "      <td>G</td>\n",
              "      <td>47.0</td>\n",
              "      <td>478.0</td>\n",
              "      <td>일반점포에서</td>\n",
              "      <td>소비자에게</td>\n",
              "      <td>그림판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>id_099999</td>\n",
              "      <td>R</td>\n",
              "      <td>90.0</td>\n",
              "      <td>902.0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인.학생대상으로</td>\n",
              "      <td>학습공간제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>id_100000</td>\n",
              "      <td>L</td>\n",
              "      <td>68.0</td>\n",
              "      <td>682.0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>대리현대아파트를</td>\n",
              "      <td>관리</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bec3c76b-5083-4d0e-a251-998d41903400')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bec3c76b-5083-4d0e-a251-998d41903400 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bec3c76b-5083-4d0e-a251-998d41903400');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/gdrive/MyDrive/통계청/데이터/제출2_kobertfull5.csv\", index = False)"
      ],
      "metadata": {
        "id": "2x9djAGRvfK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델3. KOBERT (with added data twice) "
      ],
      "metadata": {
        "id": "HSUYpQiJu1sj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###모델 학습"
      ],
      "metadata": {
        "id": "GpuLArAlvJRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7cb8b5f-4973-4940-ad38-a40d8ec3efe1",
        "id": "57mPKNl8vq74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/gdrive/MyDrive/통계청/데이터/.cache/kobert_v1.zip\n",
            "using cached model. /content/gdrive/MyDrive/통계청/데이터/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "metadata": {
        "id": "mySUMvm9vq74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#파라미터 튜닝..?\n",
        "max_len = 64\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 7\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ],
      "metadata": {
        "id": "FRaYgZonvq74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "#BERTDataset 클래스 이용, TensorDataset으로 만들어주기\n",
        "data_train = BERTDataset(dataset_train2, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test2, 0, 1, tok, max_len, True, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ef7bb0-2a62-49a8-fd77-ca77149d1da3",
        "id": "LmigkqHOvq74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/gdrive/MyDrive/통계청/데이터/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=4)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=4)"
      ],
      "metadata": {
        "id": "MbsJSFoivq74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=991, \n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "metadata": {
        "id": "7QdNTS9Ovq75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)"
      ],
      "metadata": {
        "id": "Ic8yhksnvq75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b9e9d8d-0653-426a-f017-acd0f76330fa",
        "id": "2ISj3I7Pvq75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ],
      "metadata": {
        "id": "14jvniz-vq75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} validation acc {}\".format(e+1, test_acc / (batch_id+1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d007e354c796446bac54794b004ca042",
            "a61c1a8634db41acbd1ce492b0ea9458",
            "4892f53a127e4e5ba4be3a457cdc1174",
            "0a790decfd46464da3f99312b04653c7",
            "d2b1c68f2225483190b93aa2d9d446ef",
            "28b75723efee43a6899b7d6cfe478e9a",
            "f2d06511102943d6aab95e6f1a04db09",
            "e05910a2c79f495fb6194f772dec5fe6",
            "97c47392392e4306bed77ec224dab8fc",
            "b4f970416ecd467f8b51e0def1dcbad0",
            "0f4f3faadcd340f8aef234d99b37131a",
            "c79a500a9cb5433db93e8af0b2364951",
            "c5e65bd4aa2346afa115f0280f98c94b",
            "eeefd3db28424b599b6402722a378e6a",
            "2b5f64d6de244e228a757136e515d775",
            "8fd0f86c753947b79690032307b05f1e",
            "1e43fadc12e14419827f562577bec64f",
            "5b021f0d6c5b4765a7399879d71e6421",
            "95a514a61f3445a594cd28f3e3d9c19d",
            "9554aced06d548adad3fec4a48b91fc3",
            "208a360ea94849fc9f4785bf49d7a679",
            "7057bc7880214c25b911a572baec1c90",
            "aa5b480502564f63b39c8c264849b8b7",
            "a1889e2ac624465cb2c0d7c98c719d92",
            "6ba02502452e4f60879de1eea1c88d75",
            "0cbcb5807b4a45d083053ac910d90549",
            "7b555f6b2bb5448791e2a6b44f6f61dc",
            "09d3b6d2cff24023a65392da8e3d4085",
            "c3dabc61db6e435f9e7ed2b3011a11f5",
            "3fe7232e7631459bbb7c290749d6ed25",
            "edb58b8ed17b42d1921b9e1d8d507c7c",
            "f4e9459259ca490faee2f6b2dc29c3c0",
            "5f9fd2c8a958478ca00ab35c18702703",
            "b9d1e25ba8a84a17bd47506e70ca8a2f",
            "d187f6ea44f8496cbfd9dc6462745e44",
            "2ec0be123ffb4b2b87847b7cb8be4475",
            "e7c21230b3bb4ee79e766f5048d33f82",
            "bfeddaec9b7a4141ada9bc5b27d28432",
            "a7a707d423fe4311b5fc28095e34696f",
            "150e4bd5dd63479bad8945cd03770f9c",
            "53ca0a7c043f46ae976c097b664bbc33",
            "6965b8e926e24a4bae868c4e32634902",
            "e255c8e67f7f4d9796a81284ff751a62",
            "7b39a47ae3b34ca484876a7ca4fd5cd2",
            "b056af9e64a2417eb443cc7195380172",
            "e76bdf56855440b0b50fe97d8f32f02e",
            "75fd7fca1f5649c6b51a736c995c808a",
            "75866872c4de4e9192cff4de3bcb8a19",
            "9c8474f26e954b9bbe39bb4068f09e58",
            "1b4c4cc00ff344daae1b15c4955f1e50",
            "630416b28c7a45109fd3ff16ae302c54",
            "3dbeb629fc374b6dbeed400e21a36cc2",
            "5fa5258dd262479ca4cd15e9ece085dc",
            "af8962a5efd145f8948531e0af3d5d79",
            "07eb70e851454b48a7141181c70ba937",
            "3476112406664112a1537833b5b08bff",
            "51f0ae6ae4474f5cbd0045ec310cf7b3",
            "3d0933767e7b4a8d9e74841b63273f60",
            "e49b3a2376a94fd5a897d52af4f3ee0a",
            "d585c212cdce4f1e8cb1bb4ac7357758",
            "f338c6f8d1634b01926d27cdbc2b845f",
            "ffec709154c24ca59ac064f7f8044015",
            "bf9f9a5e46b74e8da553f9b208f1c3e8",
            "cb5193137eab4da4a5e7638d210c745e",
            "7da61167fc3241eaa102aa5d7859c470",
            "48e28da418334862a88e099207aea445",
            "2bfffee6b4cc49e8805fadb869549d0c",
            "0a65a91e5fa74d448e2dc0d118748fa8",
            "8c963116b4b14578b77231c825409078",
            "ff9e58f6c6074893832c80aaadad8876",
            "c23207afbb654c5db115fb55a2908c10",
            "358caee4c0144f98a769a56c7fb3bb7d",
            "7b2df3d352e140cebdba9829ef93ed2e",
            "d1f0418336f145678269495e0e4cdad2",
            "57f6eb9f5a0c454fb730be39f017f912",
            "ea468d07d01d4dd99d05a349b6a58bfe",
            "1a4d23f2b3aa436fae358d3b61508d5c",
            "c29de701ba4f43bb8ff45dfd8baa4069",
            "69893bc3d26c463c8e252e9f8535b635",
            "75365f1f99ed4dc29db04955a36b5353",
            "cf45789d40b749c9a676174f469a0c78",
            "e6fec3ea0071474cb6018af8a1567cd7",
            "58e28f86ab7d41bf865a9082fb34005e",
            "f3503b3d404d4418b1d81375e0ca15cb",
            "85b089853dc5498e8c73a0ddf9786597",
            "2166f9fbadde4df7b49abfcdb79f7c19",
            "0b65148e77b546cd881f117640cf4a6d",
            "fbc20ae37b7e44b8b9d3142a22ed0bdc",
            "faf522e63caa42d194f3a9f5fb184c47",
            "d383e7b329e14851a47953c8315399c8",
            "f5dc5c7e4e6742f9962c240c5df9f176",
            "8c028e879d0b4fa8ad18947e670b979e",
            "6a01671034af48bc94d563f72904f9f5",
            "cfa67f459dcc49a596e46fb0e4f5387c",
            "ddfd83e4c6464a118063f65879b627a8",
            "3a2300116e2246d1a1ffd8ab95cf362c",
            "8c0502751d07405287f24c74651b45b1",
            "e136166729bc47caac04199d4c207d91",
            "34fe7c57948648578329592d059e2324",
            "11f938c8ffcc46538b0a8ce2516af311",
            "1aab194d2174457fa1d17d43e94ba86b",
            "c731526c28b046c08474f68ccae17110",
            "c9313d500a50488c816835dd6c6aff06",
            "f19f14c04f2b4bdb9db773e3eda8bbc1",
            "d5e58ed7f1e34ae4a5b87f2222768f64",
            "b9d32b778bf3452f9e66b3f39af717ef",
            "f389fb492b6540ca915704bef1405fd0",
            "2335c3b18e2049f58f841044a75fc3dc",
            "bf6cb463faee44f3a27be9f661b66752",
            "191afeeb498e4b44bc3fb9cffaf72730",
            "a34c41e3867342a689313dd0c289b8bb",
            "0bb850b9e5b043378c8cc4c48b600670",
            "bb7138d5ee794ea393ac19bb1fb40ffc",
            "d30dd661fe264241a1b043b1bce44d84",
            "e2adc1c7f96b4f86b280414ca089e550",
            "b216791f966c4b2ca5ffcb3b1bac78e3",
            "833163b890874643a782f861f910643b",
            "4edbf95839974b858b87d684e3319752",
            "8d096b91a1cf4c98b50d8b669cedbd1d",
            "2e7e6ee10ae341538d770fd468975fd6",
            "1b43d7e87efb47e6bb2fd52abca19b40",
            "c03f5121e77a498ebe0983c3b53106cc",
            "c5e7b4867566445eafa5ff26d061c366",
            "0252fe274b1a41aa9e1f550e87a0e318",
            "82a685f1fe144d77a285eb3b31790478",
            "bcc3b601f77747b3a35bb9726dbcf331",
            "91825b652e804f8f928d6a50543c5bae",
            "6be69f91a50b449aa324188bedbc436c",
            "ab675a7429e44c2d893d1c670a317403",
            "5c40d41a6ca446b98eeefca88beca962",
            "8301455a184f4e78b8d87e3394d8e96a",
            "4085790634714a22b2d0f6bbd17d8e56",
            "75ffe0cbec7149fcb863a14f736c2740",
            "cd5474d719a44adcb8ec61c733a895cd",
            "1986466ecb2b4c9187ba69c3c83b2605",
            "1ba0377f317349379892495479de6e3c",
            "3321ccb86b364065b16b8e46f00f6e07",
            "49b708bcaf06476587a5733242d4551e",
            "2c2fc8a10122450aa64961a3fb847698",
            "9e3847bc9a944e46bd7f6210ab1310d3",
            "356ccef799b6418189e9d32bf9c2cf53",
            "6326b974cf6549ffb62b0c0fdb053585",
            "bb082bec24c341d28b3b9d5b59097e7a",
            "24af79a4b1294c1995d4e87ced3fd9c7",
            "a68110bc5683493cbe76b6a3d89adcf0",
            "8f22e46cc8024c1481a1b8f2b0721f9b",
            "05133ef93a934a648d00d0fe7402f85a",
            "7fba76aec658462ea079e2db8537d547",
            "8e3dc0a2831849f4adf3885a57cc532f",
            "c8e8d834bb5b4c8f85e258cf74050b7f",
            "10e6522e53e8437bbabab38143367414",
            "23c54d9587e443e48619ef1ea5fc0f83",
            "401dbbea8bb54af3bcf47d469069f9d7",
            "3be39dd71b8047ee830dc2c78dd9f0a2"
          ]
        },
        "outputId": "1daec531-19f5-4866-eaaa-0867c73aa848",
        "id": "8mDGaPfivq75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12538 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d007e354c796446bac54794b004ca042"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 batch id 1 loss 6.957755088806152 train acc 0.0\n",
            "epoch 1 batch id 201 loss 6.73248815536499 train acc 0.0021766169154228856\n",
            "epoch 1 batch id 401 loss 6.3135528564453125 train acc 0.04547225685785536\n",
            "epoch 1 batch id 601 loss 5.711589813232422 train acc 0.07903494176372712\n",
            "epoch 1 batch id 801 loss 4.857412338256836 train acc 0.10520053058676654\n",
            "epoch 1 batch id 1001 loss 4.296240329742432 train acc 0.1263267982017982\n",
            "epoch 1 batch id 1201 loss 3.662010431289673 train acc 0.1528023522064946\n",
            "epoch 1 batch id 1401 loss 3.1565725803375244 train acc 0.18315042826552463\n",
            "epoch 1 batch id 1601 loss 2.9369664192199707 train acc 0.21608564959400375\n",
            "epoch 1 batch id 1801 loss 2.38822865486145 train acc 0.25142282065519156\n",
            "epoch 1 batch id 2001 loss 2.394650936126709 train acc 0.28612256371814093\n",
            "epoch 1 batch id 2201 loss 1.8532437086105347 train acc 0.31751192639709225\n",
            "epoch 1 batch id 2401 loss 1.3464562892913818 train acc 0.34587151187005416\n",
            "epoch 1 batch id 2601 loss 1.6012732982635498 train acc 0.3727292387543253\n",
            "epoch 1 batch id 2801 loss 1.549882173538208 train acc 0.3973580863977151\n",
            "epoch 1 batch id 3001 loss 1.0535850524902344 train acc 0.4204275658113962\n",
            "epoch 1 batch id 3201 loss 1.2319247722625732 train acc 0.44191756482349265\n",
            "epoch 1 batch id 3401 loss 1.5063652992248535 train acc 0.4619183695971773\n",
            "epoch 1 batch id 3601 loss 1.7000679969787598 train acc 0.47994914607053596\n",
            "epoch 1 batch id 3801 loss 1.0173970460891724 train acc 0.4967113917390161\n",
            "epoch 1 batch id 4001 loss 0.6572638750076294 train acc 0.511844695076231\n",
            "epoch 1 batch id 4201 loss 0.9581687450408936 train acc 0.526072661271126\n",
            "epoch 1 batch id 4401 loss 1.1174618005752563 train acc 0.5397210861167916\n",
            "epoch 1 batch id 4601 loss 0.7164552211761475 train acc 0.5521455933492719\n",
            "epoch 1 batch id 4801 loss 0.5736146569252014 train acc 0.5639743022287024\n",
            "epoch 1 batch id 5001 loss 0.9339997172355652 train acc 0.5750568636272746\n",
            "epoch 1 batch id 5201 loss 0.9237762093544006 train acc 0.5853321476639108\n",
            "epoch 1 batch id 5401 loss 0.901793897151947 train acc 0.5951907054249214\n",
            "epoch 1 batch id 5601 loss 0.5435248017311096 train acc 0.6045070076772004\n",
            "epoch 1 batch id 5801 loss 0.7806783318519592 train acc 0.6131054990518876\n",
            "epoch 1 batch id 6001 loss 0.6776314973831177 train acc 0.6214198675220797\n",
            "epoch 1 batch id 6201 loss 0.24378415942192078 train acc 0.6293037413320433\n",
            "epoch 1 batch id 6401 loss 0.6741447448730469 train acc 0.6367584166536479\n",
            "epoch 1 batch id 6601 loss 0.8926442861557007 train acc 0.6436098697167096\n",
            "epoch 1 batch id 6801 loss 0.2578369379043579 train acc 0.6502651264519923\n",
            "epoch 1 batch id 7001 loss 0.26415446400642395 train acc 0.6565914690758463\n",
            "epoch 1 batch id 7201 loss 0.7012266516685486 train acc 0.662698757117067\n",
            "epoch 1 batch id 7401 loss 0.4876944422721863 train acc 0.6683302932036211\n",
            "epoch 1 batch id 7601 loss 0.5207980871200562 train acc 0.6737230298644915\n",
            "epoch 1 batch id 7801 loss 0.3021089434623718 train acc 0.6788813132931676\n",
            "epoch 1 batch id 8001 loss 0.49132445454597473 train acc 0.6837895263092113\n",
            "epoch 1 batch id 8201 loss 0.5098342895507812 train acc 0.6885840903548348\n",
            "epoch 1 batch id 8401 loss 0.700453519821167 train acc 0.6930908522794905\n",
            "epoch 1 batch id 8601 loss 0.5664463639259338 train acc 0.697377121846297\n",
            "epoch 1 batch id 8801 loss 0.5975717902183533 train acc 0.7016319168276333\n",
            "epoch 1 batch id 9001 loss 0.2727859318256378 train acc 0.7056663842906343\n",
            "epoch 1 batch id 9201 loss 0.3769072890281677 train acc 0.7095288555591783\n",
            "epoch 1 batch id 9401 loss 0.41206657886505127 train acc 0.7132170114881395\n",
            "epoch 1 batch id 9601 loss 0.6322760581970215 train acc 0.7168930970732216\n",
            "epoch 1 batch id 9801 loss 0.4684186577796936 train acc 0.7203585731047852\n",
            "epoch 1 batch id 10001 loss 0.36054089665412903 train acc 0.7236510723927607\n",
            "epoch 1 batch id 10201 loss 0.31626126170158386 train acc 0.7268006813057544\n",
            "epoch 1 batch id 10401 loss 0.6611517071723938 train acc 0.7299147918469377\n",
            "epoch 1 batch id 10601 loss 0.3659657835960388 train acc 0.7329276129610414\n",
            "epoch 1 batch id 10801 loss 0.42924579977989197 train acc 0.7356813026571614\n",
            "epoch 1 batch id 11001 loss 0.7593393921852112 train acc 0.7384470729933642\n",
            "epoch 1 batch id 11201 loss 0.34767407178878784 train acc 0.7411628984019284\n",
            "epoch 1 batch id 11401 loss 0.9060338139533997 train acc 0.7437711056047716\n",
            "epoch 1 batch id 11601 loss 0.3923424482345581 train acc 0.7463526851133523\n",
            "epoch 1 batch id 11801 loss 0.5696022510528564 train acc 0.748844112787052\n",
            "epoch 1 batch id 12001 loss 0.42922306060791016 train acc 0.7512863511374052\n",
            "epoch 1 batch id 12201 loss 0.5459893345832825 train acc 0.7535307044504549\n",
            "epoch 1 batch id 12401 loss 0.25220614671707153 train acc 0.7558135432626402\n",
            "epoch 1 train acc 0.7567876987291965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c79a500a9cb5433db93e8af0b2364951"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 validation acc 0.89674\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12538 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa5b480502564f63b39c8c264849b8b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 batch id 1 loss 0.5143552422523499 train acc 0.890625\n",
            "epoch 2 batch id 201 loss 0.28208959102630615 train acc 0.8938121890547264\n",
            "epoch 2 batch id 401 loss 0.2909695506095886 train acc 0.8962749376558603\n",
            "epoch 2 batch id 601 loss 0.4879952371120453 train acc 0.8959546589018302\n",
            "epoch 2 batch id 801 loss 0.5457431077957153 train acc 0.8948774968789014\n",
            "epoch 2 batch id 1001 loss 0.5125319957733154 train acc 0.8951985514485514\n",
            "epoch 2 batch id 1201 loss 0.4232923984527588 train acc 0.8956468567860116\n",
            "epoch 2 batch id 1401 loss 0.5231121182441711 train acc 0.8962348322626695\n",
            "epoch 2 batch id 1601 loss 0.5894898176193237 train acc 0.8966173485321673\n",
            "epoch 2 batch id 1801 loss 0.3844678997993469 train acc 0.8970016657412548\n",
            "epoch 2 batch id 2001 loss 0.4154459238052368 train acc 0.8973560094952524\n",
            "epoch 2 batch id 2201 loss 0.26368260383605957 train acc 0.8978518287142208\n",
            "epoch 2 batch id 2401 loss 0.3193625509738922 train acc 0.898173937942524\n",
            "epoch 2 batch id 2601 loss 0.5348922610282898 train acc 0.8983203575547867\n",
            "epoch 2 batch id 2801 loss 0.3444277048110962 train acc 0.8984793377365227\n",
            "epoch 2 batch id 3001 loss 0.31161823868751526 train acc 0.898955556481173\n",
            "epoch 2 batch id 3201 loss 0.22070075571537018 train acc 0.8992453530146829\n",
            "epoch 2 batch id 3401 loss 0.3445177972316742 train acc 0.8994964716259923\n",
            "epoch 2 batch id 3601 loss 0.5057240724563599 train acc 0.8997891210774784\n",
            "epoch 2 batch id 3801 loss 0.5763548016548157 train acc 0.8998248816101027\n",
            "epoch 2 batch id 4001 loss 0.317374587059021 train acc 0.8999429830042489\n",
            "epoch 2 batch id 4201 loss 0.374258428812027 train acc 0.9000386812663651\n",
            "epoch 2 batch id 4401 loss 0.4747440218925476 train acc 0.9003493524199045\n",
            "epoch 2 batch id 4601 loss 0.3121289014816284 train acc 0.9004937785264073\n",
            "epoch 2 batch id 4801 loss 0.2254265993833542 train acc 0.9007596073734638\n",
            "epoch 2 batch id 5001 loss 0.33870816230773926 train acc 0.9009073185362927\n",
            "epoch 2 batch id 5201 loss 0.43267011642456055 train acc 0.9008393818496443\n",
            "epoch 2 batch id 5401 loss 0.41481056809425354 train acc 0.9011004906498796\n",
            "epoch 2 batch id 5601 loss 0.3260467052459717 train acc 0.9012229958935905\n",
            "epoch 2 batch id 5801 loss 0.5069959163665771 train acc 0.9014043914842269\n",
            "epoch 2 batch id 6001 loss 0.4913524389266968 train acc 0.9015919221796367\n",
            "epoch 2 batch id 6201 loss 0.1866997927427292 train acc 0.9018429487179487\n",
            "epoch 2 batch id 6401 loss 0.46707862615585327 train acc 0.9021246680206217\n",
            "epoch 2 batch id 6601 loss 0.5089855194091797 train acc 0.9021833813058627\n",
            "epoch 2 batch id 6801 loss 0.16398504376411438 train acc 0.902348919276577\n",
            "epoch 2 batch id 7001 loss 0.23302452266216278 train acc 0.9026210541351235\n",
            "epoch 2 batch id 7201 loss 0.33235660195350647 train acc 0.90289326135259\n",
            "epoch 2 batch id 7401 loss 0.42595863342285156 train acc 0.9030557526009999\n",
            "epoch 2 batch id 7601 loss 0.5022825002670288 train acc 0.9032323049598737\n",
            "epoch 2 batch id 7801 loss 0.20403946936130524 train acc 0.9034538841174209\n",
            "epoch 2 batch id 8001 loss 0.3037549555301666 train acc 0.9035901762279716\n",
            "epoch 2 batch id 8201 loss 0.38372108340263367 train acc 0.9038684306791854\n",
            "epoch 2 batch id 8401 loss 0.5067228674888611 train acc 0.9040330020235686\n",
            "epoch 2 batch id 8601 loss 0.39240941405296326 train acc 0.9041136205092432\n",
            "epoch 2 batch id 8801 loss 0.5404561758041382 train acc 0.9043485825474378\n",
            "epoch 2 batch id 9001 loss 0.29744741320610046 train acc 0.9046043495167204\n",
            "epoch 2 batch id 9201 loss 0.36378392577171326 train acc 0.9048235246168894\n",
            "epoch 2 batch id 9401 loss 0.23201341927051544 train acc 0.9049901606212105\n",
            "epoch 2 batch id 9601 loss 0.37517446279525757 train acc 0.9052116966982606\n",
            "epoch 2 batch id 9801 loss 0.21215315163135529 train acc 0.9054656412610959\n",
            "epoch 2 batch id 10001 loss 0.2523057758808136 train acc 0.9055813168683132\n",
            "epoch 2 batch id 10201 loss 0.2505605220794678 train acc 0.9057721056759142\n",
            "epoch 2 batch id 10401 loss 0.46334683895111084 train acc 0.9059735842707431\n",
            "epoch 2 batch id 10601 loss 0.22562304139137268 train acc 0.9060672342231865\n",
            "epoch 2 batch id 10801 loss 0.3560180962085724 train acc 0.9062123877418757\n",
            "epoch 2 batch id 11001 loss 0.49780043959617615 train acc 0.9063877715662213\n",
            "epoch 2 batch id 11201 loss 0.376286119222641 train acc 0.9065262030175877\n",
            "epoch 2 batch id 11401 loss 0.7329850196838379 train acc 0.9067543417244102\n",
            "epoch 2 batch id 11601 loss 0.4244275391101837 train acc 0.9069503706577019\n",
            "epoch 2 batch id 11801 loss 0.6430091261863708 train acc 0.9071106262181171\n",
            "epoch 2 batch id 12001 loss 0.30194106698036194 train acc 0.907305901591534\n",
            "epoch 2 batch id 12201 loss 0.4149964451789856 train acc 0.9073282927628883\n",
            "epoch 2 batch id 12401 loss 0.18226194381713867 train acc 0.9074671397467946\n",
            "epoch 2 train acc 0.9073761598075184\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9d1e25ba8a84a17bd47506e70ca8a2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 validation acc 0.9146\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12538 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b056af9e64a2417eb443cc7195380172"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 batch id 1 loss 0.46149593591690063 train acc 0.90625\n",
            "epoch 3 batch id 201 loss 0.1914810836315155 train acc 0.9156560945273632\n",
            "epoch 3 batch id 401 loss 0.18065476417541504 train acc 0.9184850374064838\n",
            "epoch 3 batch id 601 loss 0.31545862555503845 train acc 0.9170653078202995\n",
            "epoch 3 batch id 801 loss 0.391408771276474 train acc 0.9169397627965044\n",
            "epoch 3 batch id 1001 loss 0.43303167819976807 train acc 0.9166926823176823\n",
            "epoch 3 batch id 1201 loss 0.2435828447341919 train acc 0.9168011032472939\n",
            "epoch 3 batch id 1401 loss 0.4301188886165619 train acc 0.917268915060671\n",
            "epoch 3 batch id 1601 loss 0.4382041394710541 train acc 0.9173660993129295\n",
            "epoch 3 batch id 1801 loss 0.3752228319644928 train acc 0.917866810105497\n",
            "epoch 3 batch id 2001 loss 0.2903982996940613 train acc 0.9179316591704147\n",
            "epoch 3 batch id 2201 loss 0.239360511302948 train acc 0.918211892321672\n",
            "epoch 3 batch id 2401 loss 0.2537463307380676 train acc 0.9180940233236151\n",
            "epoch 3 batch id 2601 loss 0.42814502120018005 train acc 0.9183607266435986\n",
            "epoch 3 batch id 2801 loss 0.16084811091423035 train acc 0.9184889325240986\n",
            "epoch 3 batch id 3001 loss 0.22877193987369537 train acc 0.918735421526158\n",
            "epoch 3 batch id 3201 loss 0.12257316708564758 train acc 0.9190340909090909\n",
            "epoch 3 batch id 3401 loss 0.24535603821277618 train acc 0.919063326962658\n",
            "epoch 3 batch id 3601 loss 0.5094013810157776 train acc 0.9190849763954457\n",
            "epoch 3 batch id 3801 loss 0.40643560886383057 train acc 0.9192276703499079\n",
            "epoch 3 batch id 4001 loss 0.3755531311035156 train acc 0.9192194138965258\n",
            "epoch 3 batch id 4201 loss 0.4119286835193634 train acc 0.9192565758152821\n",
            "epoch 3 batch id 4401 loss 0.2496076375246048 train acc 0.9194252726653034\n",
            "epoch 3 batch id 4601 loss 0.2866714596748352 train acc 0.9196845794392523\n",
            "epoch 3 batch id 4801 loss 0.1734471172094345 train acc 0.9198246459071027\n",
            "epoch 3 batch id 5001 loss 0.3618367910385132 train acc 0.9198504049190162\n",
            "epoch 3 batch id 5201 loss 0.21544988453388214 train acc 0.9197329840415305\n",
            "epoch 3 batch id 5401 loss 0.2170896828174591 train acc 0.9197660155526755\n",
            "epoch 3 batch id 5601 loss 0.2665179669857025 train acc 0.9197576325656133\n",
            "epoch 3 batch id 5801 loss 0.38021740317344666 train acc 0.9199653077055681\n",
            "epoch 3 batch id 6001 loss 0.34907200932502747 train acc 0.9201070654890852\n",
            "epoch 3 batch id 6201 loss 0.16748125851154327 train acc 0.9202598371230447\n",
            "epoch 3 batch id 6401 loss 0.43204641342163086 train acc 0.9203737697234807\n",
            "epoch 3 batch id 6601 loss 0.534323513507843 train acc 0.9203174708377518\n",
            "epoch 3 batch id 6801 loss 0.1117745190858841 train acc 0.9204436847522424\n",
            "epoch 3 batch id 7001 loss 0.12157150357961655 train acc 0.9205314419368662\n",
            "epoch 3 batch id 7201 loss 0.30410781502723694 train acc 0.920779232051104\n",
            "epoch 3 batch id 7401 loss 0.3935202360153198 train acc 0.9208299554114309\n",
            "epoch 3 batch id 7601 loss 0.33706820011138916 train acc 0.9209869589527694\n",
            "epoch 3 batch id 7801 loss 0.17731286585330963 train acc 0.921049785283938\n",
            "epoch 3 batch id 8001 loss 0.2759542465209961 train acc 0.9211133764529433\n",
            "epoch 3 batch id 8201 loss 0.4443275034427643 train acc 0.9213129496402878\n",
            "epoch 3 batch id 8401 loss 0.2813485264778137 train acc 0.9213412093798358\n",
            "epoch 3 batch id 8601 loss 0.3196146786212921 train acc 0.9214244709917452\n",
            "epoch 3 batch id 8801 loss 0.5552505850791931 train acc 0.9215643108737643\n",
            "epoch 3 batch id 9001 loss 0.22698430716991425 train acc 0.9217152955227197\n",
            "epoch 3 batch id 9201 loss 0.27077439427375793 train acc 0.921842734485382\n",
            "epoch 3 batch id 9401 loss 0.15197457373142242 train acc 0.9219780475481332\n",
            "epoch 3 batch id 9601 loss 0.2790273427963257 train acc 0.9221337621081137\n",
            "epoch 3 batch id 9801 loss 0.11677630245685577 train acc 0.9223357310478523\n",
            "epoch 3 batch id 10001 loss 0.2131524384021759 train acc 0.922368700629937\n",
            "epoch 3 batch id 10201 loss 0.22080837190151215 train acc 0.9225183192824233\n",
            "epoch 3 batch id 10401 loss 0.35543692111968994 train acc 0.9226306364772618\n",
            "epoch 3 batch id 10601 loss 0.19104784727096558 train acc 0.9227107112536553\n",
            "epoch 3 batch id 10801 loss 0.32011860609054565 train acc 0.9228124132024812\n",
            "epoch 3 batch id 11001 loss 0.4279625117778778 train acc 0.9228962139805472\n",
            "epoch 3 batch id 11201 loss 0.24287235736846924 train acc 0.922975627176145\n",
            "epoch 3 batch id 11401 loss 0.6246970891952515 train acc 0.9231125559161477\n",
            "epoch 3 batch id 11601 loss 0.3154294490814209 train acc 0.9232838225153004\n",
            "epoch 3 batch id 11801 loss 0.5100326538085938 train acc 0.9234228031522752\n",
            "epoch 3 batch id 12001 loss 0.20019465684890747 train acc 0.9235740771602367\n",
            "epoch 3 batch id 12201 loss 0.292526513338089 train acc 0.923585925333989\n",
            "epoch 3 batch id 12401 loss 0.0773695632815361 train acc 0.9236477905007661\n",
            "epoch 3 train acc 0.9236342352581485\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3476112406664112a1537833b5b08bff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 validation acc 0.921245\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12538 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bfffee6b4cc49e8805fadb869549d0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 batch id 1 loss 0.3122231364250183 train acc 0.953125\n",
            "epoch 4 batch id 201 loss 0.19300711154937744 train acc 0.9294154228855721\n",
            "epoch 4 batch id 401 loss 0.18455475568771362 train acc 0.9309149002493765\n",
            "epoch 4 batch id 601 loss 0.18808023631572723 train acc 0.9305844425956739\n",
            "epoch 4 batch id 801 loss 0.3377726078033447 train acc 0.9300483770287141\n",
            "epoch 4 batch id 1001 loss 0.3687276840209961 train acc 0.9302260239760239\n",
            "epoch 4 batch id 1201 loss 0.1948414146900177 train acc 0.9298631348875936\n",
            "epoch 4 batch id 1401 loss 0.36714643239974976 train acc 0.9308306566738044\n",
            "epoch 4 batch id 1601 loss 0.355008065700531 train acc 0.9306976108682073\n",
            "epoch 4 batch id 1801 loss 0.3947660028934479 train acc 0.9309671710161022\n",
            "epoch 4 batch id 2001 loss 0.2862226068973541 train acc 0.9311984632683659\n",
            "epoch 4 batch id 2201 loss 0.18617607653141022 train acc 0.9314232167196729\n",
            "epoch 4 batch id 2401 loss 0.17891258001327515 train acc 0.931499895876718\n",
            "epoch 4 batch id 2601 loss 0.32237911224365234 train acc 0.9315948193002691\n",
            "epoch 4 batch id 2801 loss 0.14027780294418335 train acc 0.9318658514816137\n",
            "epoch 4 batch id 3001 loss 0.0920809954404831 train acc 0.9320903448850383\n",
            "epoch 4 batch id 3201 loss 0.1178661361336708 train acc 0.9324527491408935\n",
            "epoch 4 batch id 3401 loss 0.22015871107578278 train acc 0.9323452660982064\n",
            "epoch 4 batch id 3601 loss 0.40252283215522766 train acc 0.932423285198556\n",
            "epoch 4 batch id 3801 loss 0.3440764844417572 train acc 0.9323903249144961\n",
            "epoch 4 batch id 4001 loss 0.36766567826271057 train acc 0.9323684703824044\n",
            "epoch 4 batch id 4201 loss 0.26466935873031616 train acc 0.9323375386812663\n",
            "epoch 4 batch id 4401 loss 0.19371850788593292 train acc 0.9325614917064303\n",
            "epoch 4 batch id 4601 loss 0.20001102983951569 train acc 0.9326573027602695\n",
            "epoch 4 batch id 4801 loss 0.17484255135059357 train acc 0.9328199854197042\n",
            "epoch 4 batch id 5001 loss 0.2863601744174957 train acc 0.9328165616876625\n",
            "epoch 4 batch id 5201 loss 0.13557174801826477 train acc 0.9326842193808883\n",
            "epoch 4 batch id 5401 loss 0.18917450308799744 train acc 0.9327381503425292\n",
            "epoch 4 batch id 5601 loss 0.16446582973003387 train acc 0.9328189162649527\n",
            "epoch 4 batch id 5801 loss 0.4576663672924042 train acc 0.932915661092915\n",
            "epoch 4 batch id 6001 loss 0.2897322177886963 train acc 0.9331048991834694\n",
            "epoch 4 batch id 6201 loss 0.08058077841997147 train acc 0.9332567327850346\n",
            "epoch 4 batch id 6401 loss 0.38335955142974854 train acc 0.9333038783002656\n",
            "epoch 4 batch id 6601 loss 0.31099212169647217 train acc 0.9333150280260567\n",
            "epoch 4 batch id 6801 loss 0.08273769915103912 train acc 0.9334472871636524\n",
            "epoch 4 batch id 7001 loss 0.06918350607156754 train acc 0.9336010034280817\n",
            "epoch 4 batch id 7201 loss 0.23599393665790558 train acc 0.9338004270240244\n",
            "epoch 4 batch id 7401 loss 0.4415503442287445 train acc 0.9338497331441697\n",
            "epoch 4 batch id 7601 loss 0.19974692165851593 train acc 0.9340115609788185\n",
            "epoch 4 batch id 7801 loss 0.2718375325202942 train acc 0.9340689494936547\n",
            "epoch 4 batch id 8001 loss 0.2783960998058319 train acc 0.9341078458942632\n",
            "epoch 4 batch id 8201 loss 0.27059853076934814 train acc 0.934289644555542\n",
            "epoch 4 batch id 8401 loss 0.23184780776500702 train acc 0.9343400339245328\n",
            "epoch 4 batch id 8601 loss 0.2549777626991272 train acc 0.9344334961051041\n",
            "epoch 4 batch id 8801 loss 0.38693755865097046 train acc 0.9346132541756619\n",
            "epoch 4 batch id 9001 loss 0.14898470044136047 train acc 0.9347398900122209\n",
            "epoch 4 batch id 9201 loss 0.23505713045597076 train acc 0.9348559259863058\n",
            "epoch 4 batch id 9401 loss 0.1910688281059265 train acc 0.9349703488990533\n",
            "epoch 4 batch id 9601 loss 0.26014891266822815 train acc 0.9351353374648474\n",
            "epoch 4 batch id 9801 loss 0.0967201218008995 train acc 0.9352919982654831\n",
            "epoch 4 batch id 10001 loss 0.14008541405200958 train acc 0.935297095290471\n",
            "epoch 4 batch id 10201 loss 0.19665277004241943 train acc 0.9354030854818155\n",
            "epoch 4 batch id 10401 loss 0.4213746190071106 train acc 0.9355065017786751\n",
            "epoch 4 batch id 10601 loss 0.19926747679710388 train acc 0.9355323200641449\n",
            "epoch 4 batch id 10801 loss 0.22024615108966827 train acc 0.9356164938431627\n",
            "epoch 4 batch id 11001 loss 0.36055952310562134 train acc 0.9356763021543496\n",
            "epoch 4 batch id 11201 loss 0.20197318494319916 train acc 0.9357381595393268\n",
            "epoch 4 batch id 11401 loss 0.5251593589782715 train acc 0.9358499254451363\n",
            "epoch 4 batch id 11601 loss 0.31238940358161926 train acc 0.9359982436858891\n",
            "epoch 4 batch id 11801 loss 0.4835190773010254 train acc 0.9361203499703415\n",
            "epoch 4 batch id 12001 loss 0.18909583985805511 train acc 0.9362396883593034\n",
            "epoch 4 batch id 12201 loss 0.2038590908050537 train acc 0.9362539443488239\n",
            "epoch 4 batch id 12401 loss 0.0637568011879921 train acc 0.9363219196032578\n",
            "epoch 4 train acc 0.9363555624235657\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c29de701ba4f43bb8ff45dfd8baa4069"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 validation acc 0.92387\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12538 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faf522e63caa42d194f3a9f5fb184c47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 batch id 1 loss 0.3267231285572052 train acc 0.9375\n",
            "epoch 5 batch id 201 loss 0.19319437444210052 train acc 0.9375777363184079\n",
            "epoch 5 batch id 401 loss 0.15183734893798828 train acc 0.9399937655860349\n",
            "epoch 5 batch id 601 loss 0.11599145084619522 train acc 0.9398138519134775\n",
            "epoch 5 batch id 801 loss 0.2785874307155609 train acc 0.9400749063670412\n",
            "epoch 5 batch id 1001 loss 0.35058704018592834 train acc 0.9403877372627373\n",
            "epoch 5 batch id 1201 loss 0.13904251158237457 train acc 0.9403491881765196\n",
            "epoch 5 batch id 1401 loss 0.38736769556999207 train acc 0.9408792826552462\n",
            "epoch 5 batch id 1601 loss 0.3204033076763153 train acc 0.9411988600874454\n",
            "epoch 5 batch id 1801 loss 0.3632161319255829 train acc 0.9416383259300388\n",
            "epoch 5 batch id 2001 loss 0.2583324611186981 train acc 0.9419899425287356\n",
            "epoch 5 batch id 2201 loss 0.1913096159696579 train acc 0.9422989550204453\n",
            "epoch 5 batch id 2401 loss 0.11535445600748062 train acc 0.9425174406497293\n",
            "epoch 5 batch id 2601 loss 0.2895727753639221 train acc 0.9426242310649751\n",
            "epoch 5 batch id 2801 loss 0.09803087264299393 train acc 0.9427771331667262\n",
            "epoch 5 batch id 3001 loss 0.08162719756364822 train acc 0.9430033738753749\n",
            "epoch 5 batch id 3201 loss 0.09316816180944443 train acc 0.9432501562011871\n",
            "epoch 5 batch id 3401 loss 0.13561967015266418 train acc 0.9434862907968244\n",
            "epoch 5 batch id 3601 loss 0.3601684868335724 train acc 0.9435833796167731\n",
            "epoch 5 batch id 3801 loss 0.3130248188972473 train acc 0.9436250328860826\n",
            "epoch 5 batch id 4001 loss 0.28049156069755554 train acc 0.9436273744063984\n",
            "epoch 5 batch id 4201 loss 0.19115681946277618 train acc 0.9435737026898358\n",
            "epoch 5 batch id 4401 loss 0.1378229409456253 train acc 0.9436562713019768\n",
            "epoch 5 batch id 4601 loss 0.1288105994462967 train acc 0.9437588296022604\n",
            "epoch 5 batch id 4801 loss 0.17380519211292267 train acc 0.9439602426577797\n",
            "epoch 5 batch id 5001 loss 0.22870036959648132 train acc 0.9440143221355729\n",
            "epoch 5 batch id 5201 loss 0.05615072697401047 train acc 0.9439831282445683\n",
            "epoch 5 batch id 5401 loss 0.18088209629058838 train acc 0.9440092112571746\n",
            "epoch 5 batch id 5601 loss 0.12556737661361694 train acc 0.9440613283342261\n",
            "epoch 5 batch id 5801 loss 0.3242964744567871 train acc 0.9441529477676263\n",
            "epoch 5 batch id 6001 loss 0.30079585313796997 train acc 0.94425147892018\n",
            "epoch 5 batch id 6201 loss 0.026880741119384766 train acc 0.944368851798097\n",
            "epoch 5 batch id 6401 loss 0.31208673119544983 train acc 0.9444715669426652\n",
            "epoch 5 batch id 6601 loss 0.29451119899749756 train acc 0.9443952620815028\n",
            "epoch 5 batch id 6801 loss 0.07205549627542496 train acc 0.9445026466696074\n",
            "epoch 5 batch id 7001 loss 0.07144071906805038 train acc 0.9446574596486216\n",
            "epoch 5 batch id 7201 loss 0.13048259913921356 train acc 0.9448275413137064\n",
            "epoch 5 batch id 7401 loss 0.38189932703971863 train acc 0.9449272057830023\n",
            "epoch 5 batch id 7601 loss 0.1455792933702469 train acc 0.9450730167083279\n",
            "epoch 5 batch id 7801 loss 0.17783239483833313 train acc 0.9451232213818741\n",
            "epoch 5 batch id 8001 loss 0.25498539209365845 train acc 0.9452216910386202\n",
            "epoch 5 batch id 8201 loss 0.11487489938735962 train acc 0.9454201469333008\n",
            "epoch 5 batch id 8401 loss 0.2821164131164551 train acc 0.9454789608379954\n",
            "epoch 5 batch id 8601 loss 0.2758145034313202 train acc 0.9455750058132776\n",
            "epoch 5 batch id 8801 loss 0.2919357717037201 train acc 0.9457163958641064\n",
            "epoch 5 batch id 9001 loss 0.09307911247015 train acc 0.945856710365515\n",
            "epoch 5 batch id 9201 loss 0.19846227765083313 train acc 0.9459620557548093\n",
            "epoch 5 batch id 9401 loss 0.09848155081272125 train acc 0.9460712291245612\n",
            "epoch 5 batch id 9601 loss 0.13018739223480225 train acc 0.9462132850744714\n",
            "epoch 5 batch id 9801 loss 0.05274353176355362 train acc 0.946363891439649\n",
            "epoch 5 batch id 10001 loss 0.05171576887369156 train acc 0.9464444180581941\n",
            "epoch 5 batch id 10201 loss 0.12027013301849365 train acc 0.9465554847563964\n",
            "epoch 5 batch id 10401 loss 0.1882750689983368 train acc 0.9466742981444092\n",
            "epoch 5 batch id 10601 loss 0.1654856652021408 train acc 0.9466987194604283\n",
            "epoch 5 batch id 10801 loss 0.1838301718235016 train acc 0.9467555087491899\n",
            "epoch 5 batch id 11001 loss 0.2836344838142395 train acc 0.9468116534860467\n",
            "epoch 5 batch id 11201 loss 0.13686111569404602 train acc 0.9468811378448353\n",
            "epoch 5 batch id 11401 loss 0.3304145634174347 train acc 0.9469399614068942\n",
            "epoch 5 batch id 11601 loss 0.2593965530395508 train acc 0.9470923842772175\n",
            "epoch 5 batch id 11801 loss 0.43260592222213745 train acc 0.9472105118210321\n",
            "epoch 5 batch id 12001 loss 0.1567450612783432 train acc 0.9473012665611199\n",
            "epoch 5 batch id 12201 loss 0.15659599006175995 train acc 0.9473224530776166\n",
            "epoch 5 batch id 12401 loss 0.03583492338657379 train acc 0.9473908354164987\n",
            "epoch 5 train acc 0.9474131972138033\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11f938c8ffcc46538b0a8ce2516af311"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 validation acc 0.925715\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12538 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a34c41e3867342a689313dd0c289b8bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 batch id 1 loss 0.24588382244110107 train acc 0.953125\n",
            "epoch 6 batch id 201 loss 0.14045463502407074 train acc 0.9512593283582089\n",
            "epoch 6 batch id 401 loss 0.07924141734838486 train acc 0.9518391521197007\n",
            "epoch 6 batch id 601 loss 0.07836032658815384 train acc 0.9514611064891847\n",
            "epoch 6 batch id 801 loss 0.22417870163917542 train acc 0.95125234082397\n",
            "epoch 6 batch id 1001 loss 0.27945512533187866 train acc 0.9517982017982018\n",
            "epoch 6 batch id 1201 loss 0.14694930613040924 train acc 0.9520191507077436\n",
            "epoch 6 batch id 1401 loss 0.3452753722667694 train acc 0.9526008208422555\n",
            "epoch 6 batch id 1601 loss 0.30152809619903564 train acc 0.9528029356652092\n",
            "epoch 6 batch id 1801 loss 0.2951120436191559 train acc 0.9527519433647973\n",
            "epoch 6 batch id 2001 loss 0.12851005792617798 train acc 0.9530469140429785\n",
            "epoch 6 batch id 2201 loss 0.1666354238986969 train acc 0.9532882780554294\n",
            "epoch 6 batch id 2401 loss 0.08321447670459747 train acc 0.9533722927946688\n",
            "epoch 6 batch id 2601 loss 0.3167762756347656 train acc 0.9535395040369089\n",
            "epoch 6 batch id 2801 loss 0.08856986463069916 train acc 0.9536605230274902\n",
            "epoch 6 batch id 3001 loss 0.03147338330745697 train acc 0.953807064311896\n",
            "epoch 6 batch id 3201 loss 0.016147343441843987 train acc 0.9540914948453608\n",
            "epoch 6 batch id 3401 loss 0.09579533338546753 train acc 0.9542827477212584\n",
            "epoch 6 batch id 3601 loss 0.3273918628692627 train acc 0.9544006873090808\n",
            "epoch 6 batch id 3801 loss 0.2432115077972412 train acc 0.9543294527755853\n",
            "epoch 6 batch id 4001 loss 0.31570881605148315 train acc 0.9542223819045239\n",
            "epoch 6 batch id 4201 loss 0.16267144680023193 train acc 0.9541031897167341\n",
            "epoch 6 batch id 4401 loss 0.09808314591646194 train acc 0.9542256021358783\n",
            "epoch 6 batch id 4601 loss 0.10685215890407562 train acc 0.9542762442947186\n",
            "epoch 6 batch id 4801 loss 0.13548053801059723 train acc 0.9543259216829827\n",
            "epoch 6 batch id 5001 loss 0.19415265321731567 train acc 0.9543966206758648\n",
            "epoch 6 batch id 5201 loss 0.12282485514879227 train acc 0.9543176792924437\n",
            "epoch 6 batch id 5401 loss 0.15263201296329498 train acc 0.9542561562673579\n",
            "epoch 6 batch id 5601 loss 0.11338435113430023 train acc 0.9542743483306553\n",
            "epoch 6 batch id 5801 loss 0.24390971660614014 train acc 0.9543774780210309\n",
            "epoch 6 batch id 6001 loss 0.21197570860385895 train acc 0.9544763372771204\n",
            "epoch 6 batch id 6201 loss 0.00990757904946804 train acc 0.9545486615062087\n",
            "epoch 6 batch id 6401 loss 0.28299158811569214 train acc 0.9545969379784409\n",
            "epoch 6 batch id 6601 loss 0.23190347850322723 train acc 0.95448606271777\n",
            "epoch 6 batch id 6801 loss 0.030463675037026405 train acc 0.9545333406851934\n",
            "epoch 6 batch id 7001 loss 0.04935193806886673 train acc 0.9546493358091701\n",
            "epoch 6 batch id 7201 loss 0.11225057393312454 train acc 0.9548196431051242\n",
            "epoch 6 batch id 7401 loss 0.36482176184654236 train acc 0.9548688521821376\n",
            "epoch 6 batch id 7601 loss 0.05486966297030449 train acc 0.9549216386001842\n",
            "epoch 6 batch id 7801 loss 0.12347530573606491 train acc 0.9549977566978592\n",
            "epoch 6 batch id 8001 loss 0.16421855986118317 train acc 0.9550544463192101\n",
            "epoch 6 batch id 8201 loss 0.19166210293769836 train acc 0.9551960126813803\n",
            "epoch 6 batch id 8401 loss 0.15508008003234863 train acc 0.955275041661707\n",
            "epoch 6 batch id 8601 loss 0.2207166999578476 train acc 0.9553413120567376\n",
            "epoch 6 batch id 8801 loss 0.2535451650619507 train acc 0.9554596068628565\n",
            "epoch 6 batch id 9001 loss 0.04890384152531624 train acc 0.9555552855238307\n",
            "epoch 6 batch id 9201 loss 0.1933407038450241 train acc 0.9556179355504837\n",
            "epoch 6 batch id 9401 loss 0.09592319279909134 train acc 0.9556662855015424\n",
            "epoch 6 batch id 9601 loss 0.0945926159620285 train acc 0.9557549343818352\n",
            "epoch 6 batch id 9801 loss 0.04044226557016373 train acc 0.9558925747372717\n",
            "epoch 6 batch id 10001 loss 0.05350163206458092 train acc 0.9559169083091691\n",
            "epoch 6 batch id 10201 loss 0.11460347473621368 train acc 0.9560046196451328\n",
            "epoch 6 batch id 10401 loss 0.21211716532707214 train acc 0.9560574103451591\n",
            "epoch 6 batch id 10601 loss 0.17275536060333252 train acc 0.9560595698519008\n",
            "epoch 6 batch id 10801 loss 0.14193910360336304 train acc 0.9560804555133784\n",
            "epoch 6 batch id 11001 loss 0.2057231366634369 train acc 0.9561105240432688\n",
            "epoch 6 batch id 11201 loss 0.14918124675750732 train acc 0.956125569145612\n",
            "epoch 6 batch id 11401 loss 0.2573449909687042 train acc 0.9561880536795018\n",
            "epoch 6 batch id 11601 loss 0.18883506953716278 train acc 0.9562860960262046\n",
            "epoch 6 batch id 11801 loss 0.41461271047592163 train acc 0.956376843064147\n",
            "epoch 6 batch id 12001 loss 0.15152126550674438 train acc 0.9564840950754104\n",
            "epoch 6 batch id 12201 loss 0.08183438330888748 train acc 0.9564828190312269\n",
            "epoch 6 batch id 12401 loss 0.037707362323999405 train acc 0.9564878840416096\n",
            "epoch 6 train acc 0.9565292344605731\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c03f5121e77a498ebe0983c3b53106cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 validation acc 0.92756\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12538 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75ffe0cbec7149fcb863a14f736c2740"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 batch id 1 loss 0.2231331318616867 train acc 0.953125\n",
            "epoch 7 batch id 201 loss 0.10579100996255875 train acc 0.9578669154228856\n",
            "epoch 7 batch id 401 loss 0.09960614144802094 train acc 0.9600997506234414\n",
            "epoch 7 batch id 601 loss 0.13018931448459625 train acc 0.9595465890183028\n",
            "epoch 7 batch id 801 loss 0.1456485241651535 train acc 0.9589380461922596\n",
            "epoch 7 batch id 1001 loss 0.24266768991947174 train acc 0.9594468031968032\n",
            "epoch 7 batch id 1201 loss 0.0705498680472374 train acc 0.959421835970025\n",
            "epoch 7 batch id 1401 loss 0.338710755109787 train acc 0.9597051213418987\n",
            "epoch 7 batch id 1601 loss 0.2996182441711426 train acc 0.9595174890693317\n",
            "epoch 7 batch id 1801 loss 0.19872719049453735 train acc 0.9596318017767906\n",
            "epoch 7 batch id 2001 loss 0.11951407790184021 train acc 0.9599809470264867\n",
            "epoch 7 batch id 2201 loss 0.15994364023208618 train acc 0.9600039754656974\n",
            "epoch 7 batch id 2401 loss 0.05803202465176582 train acc 0.9600296751353603\n",
            "epoch 7 batch id 2601 loss 0.23916985094547272 train acc 0.9601415321030373\n",
            "epoch 7 batch id 2801 loss 0.06461163610219955 train acc 0.9600477508032845\n",
            "epoch 7 batch id 3001 loss 0.028155112639069557 train acc 0.9601643202265912\n",
            "epoch 7 batch id 3201 loss 0.0222441628575325 train acc 0.9603834739144017\n",
            "epoch 7 batch id 3401 loss 0.08318359404802322 train acc 0.9604803734195825\n",
            "epoch 7 batch id 3601 loss 0.2625795602798462 train acc 0.9605491530130519\n",
            "epoch 7 batch id 3801 loss 0.23664872348308563 train acc 0.9605531439094975\n",
            "epoch 7 batch id 4001 loss 0.23684757947921753 train acc 0.9604903461634592\n",
            "epoch 7 batch id 4201 loss 0.15885740518569946 train acc 0.9603926148536063\n",
            "epoch 7 batch id 4401 loss 0.08261667937040329 train acc 0.9604315780504431\n",
            "epoch 7 batch id 4601 loss 0.09199658781290054 train acc 0.9604807378830689\n",
            "epoch 7 batch id 4801 loss 0.11080487817525864 train acc 0.9606104197042283\n",
            "epoch 7 batch id 5001 loss 0.16293027997016907 train acc 0.9606110027994401\n",
            "epoch 7 batch id 5201 loss 0.01771361567080021 train acc 0.9605634733705056\n",
            "epoch 7 batch id 5401 loss 0.1698724329471588 train acc 0.9605078920570265\n",
            "epoch 7 batch id 5601 loss 0.10397002100944519 train acc 0.9605120737368327\n",
            "epoch 7 batch id 5801 loss 0.22867637872695923 train acc 0.9604944190656783\n",
            "epoch 7 batch id 6001 loss 0.19474829733371735 train acc 0.9605612606232294\n",
            "epoch 7 batch id 6201 loss 0.008544755168259144 train acc 0.9606439485566844\n",
            "epoch 7 batch id 6401 loss 0.304121732711792 train acc 0.9606897359787533\n",
            "epoch 7 batch id 6601 loss 0.17894196510314941 train acc 0.9606191296773217\n",
            "epoch 7 batch id 6801 loss 0.02386832982301712 train acc 0.9606124099397148\n",
            "epoch 7 batch id 7001 loss 0.02101283334195614 train acc 0.9606752606770461\n",
            "epoch 7 batch id 7201 loss 0.20046573877334595 train acc 0.9607758471045688\n",
            "epoch 7 batch id 7401 loss 0.3461378216743469 train acc 0.9607443250912039\n",
            "epoch 7 batch id 7601 loss 0.04629744216799736 train acc 0.9608295783449546\n",
            "epoch 7 batch id 7801 loss 0.11782876402139664 train acc 0.9608183245737726\n",
            "epoch 7 batch id 8001 loss 0.06960014253854752 train acc 0.9608388795150606\n",
            "epoch 7 batch id 8201 loss 0.16543297469615936 train acc 0.9609003475185953\n",
            "epoch 7 batch id 8401 loss 0.20123247802257538 train acc 0.9608975122009284\n",
            "epoch 7 batch id 8601 loss 0.24154387414455414 train acc 0.9609638414137891\n",
            "epoch 7 batch id 8801 loss 0.1789759397506714 train acc 0.9610449096693557\n",
            "epoch 7 batch id 9001 loss 0.06743663549423218 train acc 0.9611015442728585\n",
            "epoch 7 batch id 9201 loss 0.19430138170719147 train acc 0.9611693022497555\n",
            "epoch 7 batch id 9401 loss 0.07791011035442352 train acc 0.9611859775555792\n",
            "epoch 7 batch id 9601 loss 0.1116691529750824 train acc 0.9612882121653994\n",
            "epoch 7 batch id 9801 loss 0.026796728372573853 train acc 0.9613527956330986\n",
            "epoch 7 batch id 10001 loss 0.062225550413131714 train acc 0.9613179307069293\n",
            "epoch 7 batch id 10201 loss 0.08998007327318192 train acc 0.9613610185275954\n",
            "epoch 7 batch id 10401 loss 0.1532295048236847 train acc 0.9613844221709451\n",
            "epoch 7 batch id 10601 loss 0.14224135875701904 train acc 0.9613641991321573\n",
            "epoch 7 batch id 10801 loss 0.1592794507741928 train acc 0.9613779974076474\n",
            "epoch 7 batch id 11001 loss 0.23553402721881866 train acc 0.961396975274975\n",
            "epoch 7 batch id 11201 loss 0.10045090317726135 train acc 0.9614096955628961\n",
            "epoch 7 batch id 11401 loss 0.23754899203777313 train acc 0.9614192285764407\n",
            "epoch 7 batch id 11601 loss 0.19962355494499207 train acc 0.9614890418929403\n",
            "epoch 7 batch id 11801 loss 0.37042972445487976 train acc 0.9615578128972121\n",
            "epoch 7 batch id 12001 loss 0.16961847245693207 train acc 0.961643821348221\n",
            "epoch 7 batch id 12201 loss 0.11225622147321701 train acc 0.9616117531349889\n",
            "epoch 7 batch id 12401 loss 0.017890477553009987 train acc 0.9616348983952907\n",
            "epoch 7 train acc 0.9616266549688945\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24af79a4b1294c1995d4e87ced3fd9c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 validation acc 0.928145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###학습된 모델 적용"
      ],
      "metadata": {
        "id": "16syUbucvJRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_test = nlp.data.TSVDataset('/content/gdrive/MyDrive/통계청/데이터/test.tsv', field_indices=[7,3], num_discard_samples=1)\n",
        "test_set = BERTDataset(new_test , 0, 1, tok, max_len, True, False)\n",
        "test_input = torch.utils.data.DataLoader(test_set, batch_size=1, num_workers=4)"
      ],
      "metadata": {
        "id": "vVICozNnvxZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prds=[]\n",
        "for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_input)): \n",
        "  token_ids = token_ids.long().to(device) \n",
        "  segment_ids = segment_ids.long().to(device) \n",
        "  valid_length= valid_length \n",
        "  out = model(token_ids, valid_length, segment_ids)\n",
        "  prediction = out.cpu().detach().numpy().argmax()\n",
        "  prds.append(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "e12724beecc0449e9105d18d62255018",
            "f56fff2210d54e059321d166c77fb8c9",
            "85771784ac6f4dc2ae18e8d2a645c2a0",
            "191ae5f4ab4c42289a56102003fd4c55",
            "2aee5ed0873e4f56a0d61e3a0f3602d5",
            "2701a0d0090248bab81c844ea5d9f1a0",
            "aaff8fffa9a6420bbc6518f307233d54",
            "ed1b0e5eb63a401b94ddcc2637b2a2d0",
            "b57853bd49014267896b1e1c7caa32be",
            "905b5d42dc6743ddab38dc2b29733646",
            "0ad4975b571b43a6a66ea819f1dbc198"
          ]
        },
        "outputId": "14e50ee0-0386-4f06-d0b6-998033729c4a",
        "id": "xJMfkuq2vxZi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e12724beecc0449e9105d18d62255018"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans = pd.read_csv('답안 작성용 파일.csv',encoding='euc-kr')"
      ],
      "metadata": {
        "id": "e7haILdDvxZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(ans)):\n",
        "  ans['digit_3'][i]=prds[i]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37082125-25ee-425e-a80b-7a9fd60eafd5",
        "id": "cGMqLCfsvxZi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###소분류를 중,대분류에 매핑"
      ],
      "metadata": {
        "id": "SaR6QracvJRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=ans[:]"
      ],
      "metadata": {
        "id": "5WSqYGDgv4UW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df)):\n",
        "  l=ind_class.index[ind_class['digit_3']==df['digit_3'][i]].tolist()\n",
        "  f=l[0]\n",
        "  df['digit_1'][i]=ind_class['digit_1'][f]\n",
        "  df['digit_2'][i]=ind_class['digit_2'][f]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7310bb74-b3fa-4b9b-c299-f95cd5766bd3",
        "id": "BPVwRFfzv4UW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:1056: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cacher_needs_updating = self._check_is_chained_assignment_possible()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "134786af-c684-431a-acf5-0f3119a97b1b",
        "id": "NNrE2Nciv4UW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           AI_id digit_1  digit_2  digit_3  text_obj   text_mthd text_deal\n",
              "0      id_000001       I     56.0    561.0   치킨전문점에서    고객의주문에의해      치킨판매\n",
              "1      id_000002       G     46.0    466.0      산업공구   다른 소매업자에게    철물 수공구\n",
              "2      id_000003       S     94.0    949.0       절에서    신도을 대상으로    불교단체운영\n",
              "3      id_000004       C     30.0    302.0     영업장에서       고객요구로     자동차튜닝\n",
              "4      id_000005       I     56.0    562.0  실내포장마차에서   접객시설을 갖추고   소주,맥주제공\n",
              "...          ...     ...      ...      ...       ...         ...       ...\n",
              "99995  id_099996       G     46.0    463.0     사업장에서     일반인대상으로      버섯농장\n",
              "99996  id_099997       Q     86.0    862.0     한의원에서     외래환자위주고        치료\n",
              "99997  id_099998       G     47.0    478.0    일반점포에서       소비자에게      그림판매\n",
              "99998  id_099999       R     90.0    902.0     사업장에서  일반인.학생대상으로    학습공간제공\n",
              "99999  id_100000       L     68.0    682.0     사업장에서    대리현대아파트를        관리\n",
              "\n",
              "[100000 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33059df7-ad7e-4737-b502-4cfae55df267\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AI_id</th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "      <th>digit_3</th>\n",
              "      <th>text_obj</th>\n",
              "      <th>text_mthd</th>\n",
              "      <th>text_deal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000001</td>\n",
              "      <td>I</td>\n",
              "      <td>56.0</td>\n",
              "      <td>561.0</td>\n",
              "      <td>치킨전문점에서</td>\n",
              "      <td>고객의주문에의해</td>\n",
              "      <td>치킨판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000002</td>\n",
              "      <td>G</td>\n",
              "      <td>46.0</td>\n",
              "      <td>466.0</td>\n",
              "      <td>산업공구</td>\n",
              "      <td>다른 소매업자에게</td>\n",
              "      <td>철물 수공구</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000003</td>\n",
              "      <td>S</td>\n",
              "      <td>94.0</td>\n",
              "      <td>949.0</td>\n",
              "      <td>절에서</td>\n",
              "      <td>신도을 대상으로</td>\n",
              "      <td>불교단체운영</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_000004</td>\n",
              "      <td>C</td>\n",
              "      <td>30.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>영업장에서</td>\n",
              "      <td>고객요구로</td>\n",
              "      <td>자동차튜닝</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_000005</td>\n",
              "      <td>I</td>\n",
              "      <td>56.0</td>\n",
              "      <td>562.0</td>\n",
              "      <td>실내포장마차에서</td>\n",
              "      <td>접객시설을 갖추고</td>\n",
              "      <td>소주,맥주제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>id_099996</td>\n",
              "      <td>G</td>\n",
              "      <td>46.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인대상으로</td>\n",
              "      <td>버섯농장</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>id_099997</td>\n",
              "      <td>Q</td>\n",
              "      <td>86.0</td>\n",
              "      <td>862.0</td>\n",
              "      <td>한의원에서</td>\n",
              "      <td>외래환자위주고</td>\n",
              "      <td>치료</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>id_099998</td>\n",
              "      <td>G</td>\n",
              "      <td>47.0</td>\n",
              "      <td>478.0</td>\n",
              "      <td>일반점포에서</td>\n",
              "      <td>소비자에게</td>\n",
              "      <td>그림판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>id_099999</td>\n",
              "      <td>R</td>\n",
              "      <td>90.0</td>\n",
              "      <td>902.0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인.학생대상으로</td>\n",
              "      <td>학습공간제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>id_100000</td>\n",
              "      <td>L</td>\n",
              "      <td>68.0</td>\n",
              "      <td>682.0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>대리현대아파트를</td>\n",
              "      <td>관리</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33059df7-ad7e-4737-b502-4cfae55df267')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33059df7-ad7e-4737-b502-4cfae55df267 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33059df7-ad7e-4737-b502-4cfae55df267');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/gdrive/MyDrive/통계청/데이터/제출3_kobertfull7.csv\", index = False)"
      ],
      "metadata": {
        "id": "92RV9dtUv4UW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델4. KOBERT (with added data once) "
      ],
      "metadata": {
        "id": "E6DQ5qUpyucE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###모델 학습"
      ],
      "metadata": {
        "id": "USWvd96nyucE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f09fce16-22cb-48af-a36b-70df4bb6b940",
        "id": "r7UEz-ON1Bpa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/gdrive/MyDrive/통계청/데이터/.cache/kobert_v1.zip\n",
            "using cached model. /content/gdrive/MyDrive/통계청/데이터/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "metadata": {
        "id": "KwMAK1eH1Bpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#파라미터 튜닝..?\n",
        "max_len = 64\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 10\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ],
      "metadata": {
        "id": "Lge0CXpl1Bpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "#BERTDataset 클래스 이용, TensorDataset으로 만들어주기\n",
        "data_train = BERTDataset(dataset_train3, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test3, 0, 1, tok, max_len, True, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca9552c-0878-42a8-8fce-e03a16648147",
        "id": "L2BFRjhp1Bpb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/gdrive/MyDrive/통계청/데이터/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=4)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=4)"
      ],
      "metadata": {
        "id": "lPp8s8ha1Bpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=991, \n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "metadata": {
        "id": "Hwwth7b91Bpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)"
      ],
      "metadata": {
        "id": "lW9pJXs-1Bpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9152633f-17e3-47bd-c38b-f7b5824566f7",
        "id": "lVHefUby1Bpc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ],
      "metadata": {
        "id": "MzaJxEan1Bpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} validation acc {}\".format(e+1, test_acc / (batch_id+1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "97476e1333eb44debde9eb16b75bf74d",
            "965d8ab36c2144b1bb604e1e8826e116",
            "95c5f8eeb9114e318d6b3772e97f7fe9",
            "68b2bca2fe504192bcf3c7d5c0962299",
            "11a05f0d2fc74dc7a93415ef9826151f",
            "aefd05689f7c444e886064c9c4be2f32",
            "2292b17b76134a208b85eb38d0e8987f",
            "b6098b7a958443fd8e6a202b2aaa3f73",
            "865d865e96294a0caddb5d9b5848b01f",
            "cb6f4623c9be49dbbd441cb8674a3d83",
            "ab55a909e12e4e8c853ed88788889cc8",
            "30a5a0b05a864d248434d021711d71a5",
            "18352dbb53514efe8a4b21d0e21a1bd6",
            "0df1a809589444e695c9cf526e3c724e",
            "66cc98322ea7405d9969011736004580",
            "c24737d77cdf40e78bf39e1b9ddfc69f",
            "e26c7dc956e244ffaca8586c79cf0791",
            "1cca806fdae14a898b56c47bdf044adc",
            "204cc03384f648a69367a4781bf9d05f",
            "461f1335b734477fbc293a4cc86e4b53",
            "fee1477c55ae4538acc2960ad492555f",
            "2fd0ee6627ee4c64b6eb4265bafb7a6a",
            "7fe8308cbcd44429be206f590f360e91",
            "0548437988794ca5adfadc5bb40244d2",
            "ba1806f0ef7342d89df13748c059932f",
            "d0b31cd83783412492c9e3d6259671bd",
            "f92eeea906af47f699e07468039b3936",
            "a82e55cb51f7409f9df6961c84927ff8",
            "1bc7a75fe7e847f68ba15efb69788af8",
            "eefb25ee3d734ad18d4e81788847ce47",
            "ae18640fed87461e9c5a8bcb026547ee",
            "b0efa61b135148dd86f5a81237bf630f",
            "d36a218ca45744ff9f2f9924ad1d959e",
            "3f9bf0c954ca4c14bc0bccb38cbcaa8a",
            "ed6d82b888f649cca6a3fbf7f8c70819",
            "7c31c8a402c24e8a93310503e8bef1a9",
            "883e5be3c68e4e5a90c938000069635a",
            "2dd2649a5f904d099bcf7bf0e90091e3",
            "b07a5eb96a0c43ceb8f3ee5566e73344",
            "945d40f5c4c749ee96cbc316fe5e06da",
            "9cbf5ac34ada44198cebf87bad6e442f",
            "25084fb52a8943e0a567fa903ee4ea73",
            "d88014353738459a8ef53fa03d39a774",
            "fe22d7641bd941bcbcbf3f77f95419da",
            "f4353fc0e7c54d5faee4fe02d3ce3212",
            "b22a347d174f4086911dafd611965b85",
            "6946bd4d41f64e53917fff972bc16746",
            "6f0b460e01b349f589d6ac5effb1d020",
            "55a7b3f6f34e42d59ea48295d2d3d439",
            "3420f1706c664f678a16c63ebb578ccc",
            "adbf16f8d1a34f7d98ccb4fb7844e8a8",
            "322d9a6631b44eb4831b6b2633cba330",
            "7a28749d0ce34636a5efa8a3e2364ced",
            "5165569be983439ab4513fd78935e89e",
            "4b1dc3d88a68433091f6487b77caea7b",
            "62a7433b1cee417e8354d98dd0a05184",
            "bff095c1e07f4ab4b36aed77e0517c67",
            "1359ef5b792d484990f9f25563797293",
            "28776c06baa34e0c8e51d1c03e8a4e3c",
            "793c8f98262a46449f0b2057425cf5d5",
            "2ef98ed99ecb4180b340a0b0e3e03efc",
            "8db6250bc81f450c8d4def80de631f4a",
            "ac0037771bbc429183c088ad04874bf3",
            "0d45f1b07ba74ecb80e3f5088a7a45f0",
            "1f0cf74064d24c05b47208d23365d765",
            "cf480e8702f94cd0b900adb5639294e0",
            "6717fa7771f3414f867ffd5954b349f4",
            "543ef66889ff45a0ba8d4656fc108633",
            "1e53afdeb315438c96fb8d49d1d24468",
            "52fba0e553cf47b5a309eeba56c2a0d8",
            "c3833f75c26547deb44f6c082c1d898c",
            "6ac8fa770b7c46e49213b23e5ab0500b",
            "3e6e54c57d8a46bcb41ed8ef629dba98",
            "545ead9091f4485f8fc0613e0a46bdd3",
            "938dff92d6a14d80b94aa521e7b93d27",
            "227a624b9d7c491495d9b7dac3bccb75",
            "6b76cdf00e1741feaaaaa23a601dda00",
            "19eae7b664e24aa392eddc67536cf076",
            "ae32363b70564fa8869b56f6841ffbbf",
            "8f99b6b1e40d497abdb910e10e7e8d19",
            "eb2216470de945c88c1447f63e4002ff",
            "1f230a7d2f694736888cf9c740851423",
            "8d6093711a6f42bd8ccc6ff9c7589234",
            "72af2db6d2954fcd8c6a34047d27e524",
            "fd0c874a6fe74ab4985e8de1c93acd94",
            "67f0b022ea304de7921b083c4ec6e3d9",
            "a7db603943fc45c48e19d89b4b55f2fa",
            "46cf7b8c1b09408db57e0e18d7d87e21",
            "36eea96b4a9244828f2c1c9132a918b8",
            "619d8b00ae0a42b99fa2a999597ec9ff",
            "2946c9f073f344988a8670cf54e0529b",
            "cc4d124ccb954fee9494852c276928e1",
            "8dd6c0ce00b9469f94f33ca79f3f9919",
            "5044298347cb42339c17de7ea46558ba",
            "550c475f5c6945f38db49b49087b0c8d",
            "0af6f5829409447c856bd3fbfec11f6e",
            "47358b1a15854461bcf28f2308348383",
            "fcd24aa2f3714c308542a19e87ff6939",
            "ba99846ce479451ebbf2694a9e2fba47",
            "5f89237dce444da78d63572882421cf2",
            "21587dd325b1445c803dae3af0b75d4b",
            "b0a49603b96f4ff68a44e38b5fc6f7bf",
            "a220ec7b99cf4620b0c8a8b8b2dfdeee",
            "57653f4683ed4bbdb9d7062dfa6b1b50",
            "5b8cdf2bbd8b4447b6741ee91e554c26",
            "02229ae2c4184f9cacb8d187d31425a8",
            "077326d53f67447d80e4253bca77c690",
            "603cb51a05be479ca672d20824d71bad",
            "536dd24345d344748111658d6ad73745",
            "05c3ccb173834a888a017bc8d6e8a7d7",
            "d2b0b925770f40b9bc129577524cff23",
            "d6eb359a8bea43f0ad4b5603eaf5bfad",
            "7845105dfa3b49a9ac63a9b9d48596a0",
            "ae24d0f5a09549769030a26fa148f351",
            "b45074889134431ca86b9546ba63ea54",
            "458c9c0c8580418f8887f712c34ae2eb",
            "2a9d694afd684caeb6239a703256948d",
            "34fa13fb8f424802914948460cd70208",
            "4e0c21a59c8a46c4b3daddc3804e62a3",
            "309b65f396dd4daabacf94966785cadf",
            "005ecbc694ca4baea029a9d3813cd0b8",
            "30804b088a7c4c18a785e37951e0d0d1",
            "893941fc2d5a4150ac27be4b8f4d6b7e",
            "d7ec824cff9f41439e72b30b4795b2ea",
            "dc5f9622bb304e939097a16f88c6e5b0",
            "8d8e0addb537492b80095151fce418f4",
            "cc09dd46d18a4a1592de18a5a53383d2",
            "34dfe9bf43d3419c8d673075c50ef233",
            "0229218cfba841d3b214bb9b5ea94f72",
            "423adf1213e74bd0bab8caf2923f7a3b",
            "1c2b013d717a4681a1700bfb287630b0",
            "d19021b522474809a72c4169201340b9",
            "90bb842c73674c08b780838e5760cc2f",
            "c70aa639e72b450abc19be8701aa6466",
            "360ce8bf8daf454cb1e03c735c4446fe",
            "b69714b7932d4325b17562b6f79ce422",
            "e26827ab255545a8900bec6047d32c6d",
            "c2c75f40f2ac4490a193e6ac190189a7",
            "c7378c25cc7747bbbf78e8f815bea335",
            "940d6e0d238445869b071d8affff3c70",
            "27fe9af214514e7a897e8e0ad72c657a",
            "e1fb212814cc4b7fbdaa58840be18645",
            "18f7c79b223f4ddb9aac5734f5476882",
            "43cc75b9a4c64589b3c263dab44bd849",
            "5ba8379dc0f7437d94d92ac48388f880",
            "cadb32a5431a422d82efe273569a3328",
            "9129996c2f8f4ffea99e0b9f975f36f3",
            "16ad8a2580ea4a7496efa7b0d4009676",
            "fe5061bc481b4c2c85f48f4a54d6b02e",
            "93a820a7b6364cba8d9a6dd51562a31d",
            "1fadbcb345b74e7a929c27881bffc8e8",
            "47d6dafdae674ae581fb1f351535cc20",
            "02afaeb0a5504299bb610f62574c48d7",
            "7471a817301d421aa838c5b95ec55c22",
            "712689531311415b9878e9470a6be50e",
            "69b778d66bc345879620e0b2ec6d2953",
            "3d105dabd4c64fc88e192ed3f3662223",
            "d1b67c1437ff4fe883ca7109cca197f7",
            "825f818bb2074ba291b9d94ac75355f3",
            "1a4f9232624d4a528d6cf1884ad1a7d2",
            "275e712083964000a56976fe39891c93",
            "02e0ed2978a24c0dbabf3933949dc11f",
            "cb16066efdd14ec5ad2c72bf67807d7f",
            "c585275c32bb41f380d06bd41c5b479f",
            "1f286b577c9240d4b7b549b55eef5ed7",
            "452d5056b2d747d8ab374af143d1a187",
            "0a3671f712d54f82b1958ed0a3812fc3",
            "886c711d159045db807e27bad35cfaf0",
            "04430a65a2f3449c9ae78d1a3525dbfa",
            "78798d4390324ada8c07ad07a919917c",
            "44368361b8154327b303c02d2b28218a",
            "6d06a31aea904034b4bb4981f73c270c",
            "aaa1e93ae180431882d867b3db0ffe45",
            "32eb42f141a445ccae8cfe0dfa06e2e3",
            "d4ba6826273644e5a5eb8f0bff4f4b2c",
            "be5f0acb97ff4a3880921cf49cc2b20f",
            "a0afcb2bec1c449cacda9a80c94af13b",
            "909e4e3baa0c4e139ed01c75b0307d11",
            "7a12409687ab4079b2fc9d123c256f9e",
            "8d52b7daab414eeebee84c381ecad20a",
            "b8e53e03fc2e44b18eeb5275a5f12018",
            "ac0966163d474ffd8df47c8d9b842fba",
            "12f3be57dc0a48d49e002105423f0b4b",
            "e59ef18b391644ec8fbe5fe319241578",
            "3b6da79ebfcf4948a3a3aaf566fc3e8d",
            "f1bc394635ae46dd8bbf78e5378710db",
            "42e5de7f56b644988710c00f02887725",
            "4649e26bc7de4362853c75a4150f989d",
            "f419903dcabe4e9185ef20d3cf559b0e",
            "df682e39abc5480cb1f2b44cdbc197eb",
            "67356c4e6739472f8ddc58085912261c",
            "29f027bf06954a84bb6045ded6f7b7d1",
            "a66515892e7e43658526eae90155b69d",
            "12ad0b1a899a414999a8cde921bc4376",
            "b3fe911569c041cf96dd6374ca1810aa",
            "2ee5f4ad1adf480d82a64c64a1fccf83",
            "738bd6843e5143fbb8f765acc55ba2d9",
            "4d4fb4e0f12b4029aaf1aa044508175f",
            "1affdc38a8ac4c76a135002c6dba0916",
            "21ebea525d7441e799ee3dc522b0d773",
            "831260d3ed2e4648a4bb62811174004b",
            "33896820f4074b57912c93e7d4c83ef8",
            "ce7964ac71504b1289db88b257c7461f",
            "82ef8a6a0a8c489e9b5a3648b659b98c",
            "3f3e22cfe1eb4e74963bbd27519f8d49",
            "c4e9493f22d846ca864c061774c09002",
            "ab8f847546b34cb8ab6a9a087ee59191",
            "6ae0549435e648f1ab4736b055c57aa6",
            "2e637903f0ff4fd1854a36ebe2ab2786",
            "7d113c1317db4560938278d7f255995f",
            "b0b685390607427d9ee85ecbf00d5427",
            "0c14e73e1acc4d29a05f0afff0db208b",
            "5751e0dbfecf4a68aa9deff6320a0822",
            "51379531ed514ac287abaa399a061c51",
            "369c2b9ec24c4795ba556c3d63023061",
            "9952b3ca425d4670a862b05423370306",
            "becd8fb2a4e24ad1a9601fc1db731b8f",
            "51de00f0cc7f43599b809fba24e12653",
            "c4401dd1dcd447438c5adc712734f8db",
            "562080facd4b46cdb2c15234aeaf7f8d"
          ]
        },
        "outputId": "b2204803-f623-4d2a-ab0b-a7d34589dbea",
        "id": "D9zmOzmh1Bpc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25038 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97476e1333eb44debde9eb16b75bf74d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 batch id 1 loss 6.916141986846924 train acc 0.0\n",
            "epoch 1 batch id 201 loss 6.915793418884277 train acc 0.0001554726368159204\n",
            "epoch 1 batch id 401 loss 6.823721885681152 train acc 0.0020261845386533666\n",
            "epoch 1 batch id 601 loss 6.501308917999268 train acc 0.01752287853577371\n",
            "epoch 1 batch id 801 loss 6.316479682922363 train acc 0.045177902621722846\n",
            "epoch 1 batch id 1001 loss 5.993305206298828 train acc 0.06993006993006994\n",
            "epoch 1 batch id 1201 loss 5.776043891906738 train acc 0.08976894254787678\n",
            "epoch 1 batch id 1401 loss 4.674968242645264 train acc 0.1065087437544611\n",
            "epoch 1 batch id 1601 loss 5.267349720001221 train acc 0.11972985633978764\n",
            "epoch 1 batch id 1801 loss 4.145011901855469 train acc 0.12996252082176568\n",
            "epoch 1 batch id 2001 loss 4.1780924797058105 train acc 0.13974262868565718\n",
            "epoch 1 batch id 2201 loss 4.486166477203369 train acc 0.14988925488414356\n",
            "epoch 1 batch id 2401 loss 3.9356887340545654 train acc 0.1620158267388588\n",
            "epoch 1 batch id 2601 loss 3.9599597454071045 train acc 0.17613417916186083\n",
            "epoch 1 batch id 2801 loss 3.010390043258667 train acc 0.19220813995001784\n",
            "epoch 1 batch id 3001 loss 3.0593507289886475 train acc 0.2098258913695435\n",
            "epoch 1 batch id 3201 loss 2.6222851276397705 train acc 0.22614026866604187\n",
            "epoch 1 batch id 3401 loss 2.6244890689849854 train acc 0.24316377536018818\n",
            "epoch 1 batch id 3601 loss 2.984581708908081 train acc 0.2591207303526798\n",
            "epoch 1 batch id 3801 loss 2.0518009662628174 train acc 0.27607044198895025\n",
            "epoch 1 batch id 4001 loss 2.1503326892852783 train acc 0.29263777805548613\n",
            "epoch 1 batch id 4201 loss 2.1731863021850586 train acc 0.3086393120685551\n",
            "epoch 1 batch id 4401 loss 1.4889845848083496 train acc 0.32444330833901386\n",
            "epoch 1 batch id 4601 loss 1.2047312259674072 train acc 0.3393487828732884\n",
            "epoch 1 batch id 4801 loss 1.8006153106689453 train acc 0.3541189335555093\n",
            "epoch 1 batch id 5001 loss 1.3915878534317017 train acc 0.3681138772245551\n",
            "epoch 1 batch id 5201 loss 1.7893608808517456 train acc 0.38153720438377237\n",
            "epoch 1 batch id 5401 loss 1.5929007530212402 train acc 0.39477643029068693\n",
            "epoch 1 batch id 5601 loss 1.0111327171325684 train acc 0.40709806284592037\n",
            "epoch 1 batch id 5801 loss 1.3615635633468628 train acc 0.4193458024478538\n",
            "epoch 1 batch id 6001 loss 1.3283445835113525 train acc 0.43052199633394433\n",
            "epoch 1 batch id 6201 loss 1.3922090530395508 train acc 0.4417533462344783\n",
            "epoch 1 batch id 6401 loss 0.6910757422447205 train acc 0.45227796438056556\n",
            "epoch 1 batch id 6601 loss 1.0439436435699463 train acc 0.4623257839721254\n",
            "epoch 1 batch id 6801 loss 0.9098109602928162 train acc 0.47235241141008677\n",
            "epoch 1 batch id 7001 loss 1.2710918188095093 train acc 0.4819043708041708\n",
            "epoch 1 batch id 7201 loss 0.8790476322174072 train acc 0.49102555200666576\n",
            "epoch 1 batch id 7401 loss 0.6565390229225159 train acc 0.49979310228347523\n",
            "epoch 1 batch id 7601 loss 0.6657584309577942 train acc 0.5080293711353769\n",
            "epoch 1 batch id 7801 loss 1.096153736114502 train acc 0.5160235867196513\n",
            "epoch 1 batch id 8001 loss 1.147166132926941 train acc 0.523559555055618\n",
            "epoch 1 batch id 8201 loss 0.6965306401252747 train acc 0.5311737897817339\n",
            "epoch 1 batch id 8401 loss 1.143133521080017 train acc 0.5382915724318533\n",
            "epoch 1 batch id 8601 loss 0.5542429089546204 train acc 0.5450783339146611\n",
            "epoch 1 batch id 8801 loss 0.45948928594589233 train acc 0.552007584365413\n",
            "epoch 1 batch id 9001 loss 1.1458442211151123 train acc 0.5585073880679925\n",
            "epoch 1 batch id 9201 loss 0.6270585060119629 train acc 0.5651287903488751\n",
            "epoch 1 batch id 9401 loss 0.868839681148529 train acc 0.5711559940431868\n",
            "epoch 1 batch id 9601 loss 0.6019459962844849 train acc 0.577111108217894\n",
            "epoch 1 batch id 9801 loss 0.5911135673522949 train acc 0.5827562238547087\n",
            "epoch 1 batch id 10001 loss 0.1749565154314041 train acc 0.5882161783821618\n",
            "epoch 1 batch id 10201 loss 0.8505579233169556 train acc 0.593511052837957\n",
            "epoch 1 batch id 10401 loss 0.5854651927947998 train acc 0.5986263340063456\n",
            "epoch 1 batch id 10601 loss 0.6434996724128723 train acc 0.6036222997830394\n",
            "epoch 1 batch id 10801 loss 0.6112591028213501 train acc 0.6084940051847051\n",
            "epoch 1 batch id 11001 loss 0.6506978273391724 train acc 0.6131459640032725\n",
            "epoch 1 batch id 11201 loss 0.8210403323173523 train acc 0.6176401660566021\n",
            "epoch 1 batch id 11401 loss 0.850338339805603 train acc 0.6219575037277432\n",
            "epoch 1 batch id 11601 loss 1.0171170234680176 train acc 0.6262391173174726\n",
            "epoch 1 batch id 11801 loss 0.24905335903167725 train acc 0.630354419117024\n",
            "epoch 1 batch id 12001 loss 0.8255751132965088 train acc 0.6343898425131239\n",
            "epoch 1 batch id 12201 loss 0.4271647036075592 train acc 0.6382545488074748\n",
            "epoch 1 batch id 12401 loss 0.8479977250099182 train acc 0.6420827957422789\n",
            "epoch 1 batch id 12601 loss 1.1451514959335327 train acc 0.6457572811681612\n",
            "epoch 1 batch id 12801 loss 0.5460301637649536 train acc 0.6494536559643778\n",
            "epoch 1 batch id 13001 loss 0.34727808833122253 train acc 0.6529641950619183\n",
            "epoch 1 batch id 13201 loss 0.7232109904289246 train acc 0.6564204416332096\n",
            "epoch 1 batch id 13401 loss 0.25235000252723694 train acc 0.6597105626445787\n",
            "epoch 1 batch id 13601 loss 0.4498271644115448 train acc 0.6629935298875083\n",
            "epoch 1 batch id 13801 loss 0.5395641922950745 train acc 0.6661337946525614\n",
            "epoch 1 batch id 14001 loss 0.08782597631216049 train acc 0.6691218484393971\n",
            "epoch 1 batch id 14201 loss 0.14624416828155518 train acc 0.6720873530033096\n",
            "epoch 1 batch id 14401 loss 0.31203535199165344 train acc 0.6750399277827929\n",
            "epoch 1 batch id 14601 loss 0.5993687510490417 train acc 0.6779009143209369\n",
            "epoch 1 batch id 14801 loss 0.2158869057893753 train acc 0.6806233531518141\n",
            "epoch 1 batch id 15001 loss 0.7351366281509399 train acc 0.6832711152589828\n",
            "epoch 1 batch id 15201 loss 0.5052110552787781 train acc 0.6858841523583975\n",
            "epoch 1 batch id 15401 loss 0.2729814946651459 train acc 0.6884820790857736\n",
            "epoch 1 batch id 15601 loss 0.735465943813324 train acc 0.6909693288891737\n",
            "epoch 1 batch id 15801 loss 0.3180079460144043 train acc 0.6934845895829378\n",
            "epoch 1 batch id 16001 loss 0.2869568169116974 train acc 0.6959408786950816\n",
            "epoch 1 batch id 16201 loss 0.8010284304618835 train acc 0.6983384513301648\n",
            "epoch 1 batch id 16401 loss 1.1121803522109985 train acc 0.7006699286628864\n",
            "epoch 1 batch id 16601 loss 0.20171000063419342 train acc 0.7028812270345159\n",
            "epoch 1 batch id 16801 loss 0.6019392609596252 train acc 0.7050956788286411\n",
            "epoch 1 batch id 17001 loss 0.3938433527946472 train acc 0.7072120757602494\n",
            "epoch 1 batch id 17201 loss 0.24733053147792816 train acc 0.709319225626417\n",
            "epoch 1 batch id 17401 loss 0.5683384537696838 train acc 0.7114336101373484\n",
            "epoch 1 batch id 17601 loss 0.426302969455719 train acc 0.7135301261291972\n",
            "epoch 1 batch id 17801 loss 0.35796624422073364 train acc 0.715549688219763\n",
            "epoch 1 batch id 18001 loss 0.5975872278213501 train acc 0.7175278456752403\n",
            "epoch 1 batch id 18201 loss 0.7114042043685913 train acc 0.7194436432064172\n",
            "epoch 1 batch id 18401 loss 0.6437228918075562 train acc 0.7213194935057877\n",
            "epoch 1 batch id 18601 loss 0.1869933158159256 train acc 0.72319868555454\n",
            "epoch 1 batch id 18801 loss 0.16203776001930237 train acc 0.72498803255146\n",
            "epoch 1 batch id 19001 loss 0.19915448129177094 train acc 0.7268104310299458\n",
            "epoch 1 batch id 19201 loss 0.3813193142414093 train acc 0.7285379016717879\n",
            "epoch 1 batch id 19401 loss 0.29467424750328064 train acc 0.7302748569661358\n",
            "epoch 1 batch id 19601 loss 0.4643726944923401 train acc 0.7319715830824958\n",
            "epoch 1 batch id 19801 loss 0.24071063101291656 train acc 0.7336198298065755\n",
            "epoch 1 batch id 20001 loss 0.6444962024688721 train acc 0.7352335508224589\n",
            "epoch 1 batch id 20201 loss 0.2260647565126419 train acc 0.7368230533141924\n",
            "epoch 1 batch id 20401 loss 0.35989972949028015 train acc 0.7383231826871232\n",
            "epoch 1 batch id 20601 loss 0.4104345142841339 train acc 0.7397941847483132\n",
            "epoch 1 batch id 20801 loss 0.2551761567592621 train acc 0.7412924859381761\n",
            "epoch 1 batch id 21001 loss 0.09399033337831497 train acc 0.7427116565877815\n",
            "epoch 1 batch id 21201 loss 0.7578166127204895 train acc 0.7441482713079571\n",
            "epoch 1 batch id 21401 loss 0.19676251709461212 train acc 0.7455405121256016\n",
            "epoch 1 batch id 21601 loss 0.35810521245002747 train acc 0.7468982917457525\n",
            "epoch 1 batch id 21801 loss 0.28554344177246094 train acc 0.7482870625200679\n",
            "epoch 1 batch id 22001 loss 0.4329966902732849 train acc 0.749652004454343\n",
            "epoch 1 batch id 22201 loss 0.4181407392024994 train acc 0.7509276046124048\n",
            "epoch 1 batch id 22401 loss 0.42054614424705505 train acc 0.7522180929422794\n",
            "epoch 1 batch id 22601 loss 0.5993138551712036 train acc 0.75351892615371\n",
            "epoch 1 batch id 22801 loss 0.47900962829589844 train acc 0.754770898206219\n",
            "epoch 1 batch id 23001 loss 0.4111715257167816 train acc 0.7559834355028042\n",
            "epoch 1 batch id 23201 loss 0.4225881099700928 train acc 0.7571413947674669\n",
            "epoch 1 batch id 23401 loss 0.3347519338130951 train acc 0.7583343126362121\n",
            "epoch 1 batch id 23601 loss 0.7386381030082703 train acc 0.7595136328969111\n",
            "epoch 1 batch id 23801 loss 0.5773360729217529 train acc 0.7606652556615269\n",
            "epoch 1 batch id 24001 loss 0.3229226768016815 train acc 0.7617859672513645\n",
            "epoch 1 batch id 24201 loss 0.5216281414031982 train acc 0.7628662038758729\n",
            "epoch 1 batch id 24401 loss 0.2763606309890747 train acc 0.7639351358550879\n",
            "epoch 1 batch id 24601 loss 0.1795480102300644 train acc 0.7650565525791635\n",
            "epoch 1 batch id 24801 loss 0.287346750497818 train acc 0.7661397221886215\n",
            "epoch 1 batch id 25001 loss 4.015957832336426 train acc 0.7671518139274429\n",
            "epoch 1 train acc 0.7670927689911334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30a5a0b05a864d248434d021711d71a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 validation acc 0.90347\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25038 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fe8308cbcd44429be206f590f360e91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 batch id 1 loss 0.8084362745285034 train acc 0.78125\n",
            "epoch 2 batch id 201 loss 0.7907053232192993 train acc 0.9009639303482587\n",
            "epoch 2 batch id 401 loss 0.6685774326324463 train acc 0.9006390274314214\n",
            "epoch 2 batch id 601 loss 0.30850762128829956 train acc 0.899178452579035\n",
            "epoch 2 batch id 801 loss 0.40543079376220703 train acc 0.8981741573033708\n",
            "epoch 2 batch id 1001 loss 0.2602209150791168 train acc 0.8971028971028971\n",
            "epoch 2 batch id 1201 loss 0.22058968245983124 train acc 0.897975645295587\n",
            "epoch 2 batch id 1401 loss 0.4797177016735077 train acc 0.8993799072091363\n",
            "epoch 2 batch id 1601 loss 0.7080065011978149 train acc 0.8987937226733291\n",
            "epoch 2 batch id 1801 loss 0.1655912548303604 train acc 0.89930941143809\n",
            "epoch 2 batch id 2001 loss 0.6730735301971436 train acc 0.8989255372313844\n",
            "epoch 2 batch id 2201 loss 0.723258376121521 train acc 0.8989237846433439\n",
            "epoch 2 batch id 2401 loss 0.4450356066226959 train acc 0.8991566014160767\n",
            "epoch 2 batch id 2601 loss 0.5050094127655029 train acc 0.8987288542868128\n",
            "epoch 2 batch id 2801 loss 0.05670389160513878 train acc 0.898797304534095\n",
            "epoch 2 batch id 3001 loss 0.7375354766845703 train acc 0.8986379540153282\n",
            "epoch 2 batch id 3201 loss 0.3927810788154602 train acc 0.8986937675726335\n",
            "epoch 2 batch id 3401 loss 0.3722218871116638 train acc 0.8988073360776242\n",
            "epoch 2 batch id 3601 loss 0.08953527361154556 train acc 0.8991339211330186\n",
            "epoch 2 batch id 3801 loss 0.3187335729598999 train acc 0.8991137200736649\n",
            "epoch 2 batch id 4001 loss 0.7506110668182373 train acc 0.8993064233941515\n",
            "epoch 2 batch id 4201 loss 0.565254271030426 train acc 0.899027017376815\n",
            "epoch 2 batch id 4401 loss 0.3639998435974121 train acc 0.899326857532379\n",
            "epoch 2 batch id 4601 loss 0.06646153330802917 train acc 0.89944441425777\n",
            "epoch 2 batch id 4801 loss 0.38146480917930603 train acc 0.8992722870235368\n",
            "epoch 2 batch id 5001 loss 0.3358798623085022 train acc 0.8994201159768046\n",
            "epoch 2 batch id 5201 loss 0.3225723206996918 train acc 0.8993763218611805\n",
            "epoch 2 batch id 5401 loss 0.6902149319648743 train acc 0.8997176448805777\n",
            "epoch 2 batch id 5601 loss 0.5307349562644958 train acc 0.8995380289234065\n",
            "epoch 2 batch id 5801 loss 0.2763596177101135 train acc 0.8996778572659886\n",
            "epoch 2 batch id 6001 loss 0.38633090257644653 train acc 0.8995167472087985\n",
            "epoch 2 batch id 6201 loss 0.6960079073905945 train acc 0.8994970569263022\n",
            "epoch 2 batch id 6401 loss 0.12359917163848877 train acc 0.8995078893922824\n",
            "epoch 2 batch id 6601 loss 0.27702954411506653 train acc 0.8995038630510529\n",
            "epoch 2 batch id 6801 loss 0.2825706899166107 train acc 0.8996379208939862\n",
            "epoch 2 batch id 7001 loss 0.5526038408279419 train acc 0.8996705827738894\n",
            "epoch 2 batch id 7201 loss 0.32224586606025696 train acc 0.8997014303568949\n",
            "epoch 2 batch id 7401 loss 0.22730529308319092 train acc 0.8998910620186461\n",
            "epoch 2 batch id 7601 loss 0.17343653738498688 train acc 0.8999062623339035\n",
            "epoch 2 batch id 7801 loss 0.4014856815338135 train acc 0.8998766183822586\n",
            "epoch 2 batch id 8001 loss 0.7083752751350403 train acc 0.8998054930633671\n",
            "epoch 2 batch id 8201 loss 0.547189474105835 train acc 0.8999740885257895\n",
            "epoch 2 batch id 8401 loss 0.24581369757652283 train acc 0.8999747053922152\n",
            "epoch 2 batch id 8601 loss 0.1738208383321762 train acc 0.9000225264504127\n",
            "epoch 2 batch id 8801 loss 0.1493464857339859 train acc 0.9001391887285536\n",
            "epoch 2 batch id 9001 loss 0.3108636438846588 train acc 0.9003825963781802\n",
            "epoch 2 batch id 9201 loss 0.16758908331394196 train acc 0.9005848549070753\n",
            "epoch 2 batch id 9401 loss 0.20048058032989502 train acc 0.9007053770875438\n",
            "epoch 2 batch id 9601 loss 0.1694623976945877 train acc 0.9008501718570983\n",
            "epoch 2 batch id 9801 loss 0.4485616385936737 train acc 0.9010209417406387\n",
            "epoch 2 batch id 10001 loss 0.04289191588759422 train acc 0.9011911308869113\n",
            "epoch 2 batch id 10201 loss 0.6508488059043884 train acc 0.9013362660523478\n",
            "epoch 2 batch id 10401 loss 0.25140902400016785 train acc 0.9014367608883761\n",
            "epoch 2 batch id 10601 loss 0.5184487104415894 train acc 0.9014745071219696\n",
            "epoch 2 batch id 10801 loss 0.19002458453178406 train acc 0.9015571474863439\n",
            "epoch 2 batch id 11001 loss 0.5465248227119446 train acc 0.9016282610671758\n",
            "epoch 2 batch id 11201 loss 0.26889312267303467 train acc 0.9017331041871262\n",
            "epoch 2 batch id 11401 loss 0.4793449938297272 train acc 0.9017355933690027\n",
            "epoch 2 batch id 11601 loss 0.7394774556159973 train acc 0.9018780708559607\n",
            "epoch 2 batch id 11801 loss 0.13107602298259735 train acc 0.9019468689094144\n",
            "epoch 2 batch id 12001 loss 0.5094084739685059 train acc 0.9020706607782685\n",
            "epoch 2 batch id 12201 loss 0.1836419403553009 train acc 0.902067453487419\n",
            "epoch 2 batch id 12401 loss 0.7136636972427368 train acc 0.9021878275945489\n",
            "epoch 2 batch id 12601 loss 0.8032642602920532 train acc 0.9022299817474804\n",
            "epoch 2 batch id 12801 loss 0.3944401443004608 train acc 0.9022879071947504\n",
            "epoch 2 batch id 13001 loss 0.2651417553424835 train acc 0.9023656834089685\n",
            "epoch 2 batch id 13201 loss 0.5202820301055908 train acc 0.9024411029467465\n",
            "epoch 2 batch id 13401 loss 0.3361121416091919 train acc 0.9025072755764495\n",
            "epoch 2 batch id 13601 loss 0.35194578766822815 train acc 0.9026427284758474\n",
            "epoch 2 batch id 13801 loss 0.38733726739883423 train acc 0.9026519817404536\n",
            "epoch 2 batch id 14001 loss 0.05660676956176758 train acc 0.9026498107278051\n",
            "epoch 2 batch id 14201 loss 0.18481533229351044 train acc 0.9027423244841912\n",
            "epoch 2 batch id 14401 loss 0.31111663579940796 train acc 0.9028713283799736\n",
            "epoch 2 batch id 14601 loss 0.3522271513938904 train acc 0.902939011026642\n",
            "epoch 2 batch id 14801 loss 0.12199696898460388 train acc 0.9030006418485238\n",
            "epoch 2 batch id 15001 loss 0.6459641456604004 train acc 0.9030543797080195\n",
            "epoch 2 batch id 15201 loss 0.2717786431312561 train acc 0.9031663212946517\n",
            "epoch 2 batch id 15401 loss 0.07226693630218506 train acc 0.9032997045646387\n",
            "epoch 2 batch id 15601 loss 0.559902548789978 train acc 0.9034236587398243\n",
            "epoch 2 batch id 15801 loss 0.21787889301776886 train acc 0.9034851433453579\n",
            "epoch 2 batch id 16001 loss 0.15382850170135498 train acc 0.9035431379288794\n",
            "epoch 2 batch id 16201 loss 0.9220771193504333 train acc 0.9036035584223197\n",
            "epoch 2 batch id 16401 loss 0.9537370800971985 train acc 0.9036987073958905\n",
            "epoch 2 batch id 16601 loss 0.12927688658237457 train acc 0.9037313264261189\n",
            "epoch 2 batch id 16801 loss 0.3566831350326538 train acc 0.9038022290339861\n",
            "epoch 2 batch id 17001 loss 0.2598489820957184 train acc 0.9038714634433269\n",
            "epoch 2 batch id 17201 loss 0.1542639285326004 train acc 0.90393908784373\n",
            "epoch 2 batch id 17401 loss 0.34884291887283325 train acc 0.9040069536233549\n",
            "epoch 2 batch id 17601 loss 0.3358442783355713 train acc 0.9040928072268621\n",
            "epoch 2 batch id 17801 loss 0.2444501668214798 train acc 0.9041749761249368\n",
            "epoch 2 batch id 18001 loss 0.5401946902275085 train acc 0.9042830953835898\n",
            "epoch 2 batch id 18201 loss 0.4208143353462219 train acc 0.9043905554639855\n",
            "epoch 2 batch id 18401 loss 0.5185009241104126 train acc 0.9044532226509429\n",
            "epoch 2 batch id 18601 loss 0.12297677248716354 train acc 0.9045397424869631\n",
            "epoch 2 batch id 18801 loss 0.09643394500017166 train acc 0.9046244215733206\n",
            "epoch 2 batch id 19001 loss 0.08206295967102051 train acc 0.9047451449923688\n",
            "epoch 2 batch id 19201 loss 0.16272540390491486 train acc 0.9048015077339722\n",
            "epoch 2 batch id 19401 loss 0.398639053106308 train acc 0.9049243595690943\n",
            "epoch 2 batch id 19601 loss 0.3885612189769745 train acc 0.9050207897556247\n",
            "epoch 2 batch id 19801 loss 0.1230425238609314 train acc 0.905090020706025\n",
            "epoch 2 batch id 20001 loss 0.5074869990348816 train acc 0.9052047397630119\n",
            "epoch 2 batch id 20201 loss 0.35035380721092224 train acc 0.9052800603930499\n",
            "epoch 2 batch id 20401 loss 0.20998933911323547 train acc 0.9052834419881378\n",
            "epoch 2 batch id 20601 loss 0.2740919589996338 train acc 0.9053610868404446\n",
            "epoch 2 batch id 20801 loss 0.35159698128700256 train acc 0.9054192106148743\n",
            "epoch 2 batch id 21001 loss 0.03964616730809212 train acc 0.9054702752249892\n",
            "epoch 2 batch id 21201 loss 0.7093037366867065 train acc 0.9055203763973397\n",
            "epoch 2 batch id 21401 loss 0.11933674663305283 train acc 0.9055432573244241\n",
            "epoch 2 batch id 21601 loss 0.35299035906791687 train acc 0.9056380491643905\n",
            "epoch 2 batch id 21801 loss 0.21360933780670166 train acc 0.905736835466263\n",
            "epoch 2 batch id 22001 loss 0.26387014985084534 train acc 0.9058125198854597\n",
            "epoch 2 batch id 22201 loss 0.33807629346847534 train acc 0.9058558736092969\n",
            "epoch 2 batch id 22401 loss 0.2104984074831009 train acc 0.9059500691933395\n",
            "epoch 2 batch id 22601 loss 0.40788733959198 train acc 0.9060121786646609\n",
            "epoch 2 batch id 22801 loss 0.2980318069458008 train acc 0.9060951274066927\n",
            "epoch 2 batch id 23001 loss 0.35654574632644653 train acc 0.9061046258858311\n",
            "epoch 2 batch id 23201 loss 0.2731614112854004 train acc 0.9061072259816387\n",
            "epoch 2 batch id 23401 loss 0.2714398205280304 train acc 0.9061738814580573\n",
            "epoch 2 batch id 23601 loss 0.6526039242744446 train acc 0.9062221939748316\n",
            "epoch 2 batch id 23801 loss 0.5437662601470947 train acc 0.9062854501911685\n",
            "epoch 2 batch id 24001 loss 0.3693019151687622 train acc 0.9063749947918837\n",
            "epoch 2 batch id 24201 loss 0.43779313564300537 train acc 0.9064553117639766\n",
            "epoch 2 batch id 24401 loss 0.26250898838043213 train acc 0.9065253473218311\n",
            "epoch 2 batch id 24601 loss 0.08919814974069595 train acc 0.9066399739847973\n",
            "epoch 2 batch id 24801 loss 0.24340547621250153 train acc 0.9067540119350026\n",
            "epoch 2 batch id 25001 loss 2.6045193672180176 train acc 0.9068012279508819\n",
            "epoch 2 train acc 0.9066872520435605\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f9bf0c954ca4c14bc0bccb38cbcaa8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 validation acc 0.91564\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25038 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4353fc0e7c54d5faee4fe02d3ce3212"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 batch id 1 loss 0.4354904890060425 train acc 0.875\n",
            "epoch 3 batch id 201 loss 0.7014580965042114 train acc 0.9174440298507462\n",
            "epoch 3 batch id 401 loss 0.5602431893348694 train acc 0.9180953865336658\n",
            "epoch 3 batch id 601 loss 0.4235665500164032 train acc 0.9171693011647255\n",
            "epoch 3 batch id 801 loss 0.3158712089061737 train acc 0.9164325842696629\n",
            "epoch 3 batch id 1001 loss 0.37313032150268555 train acc 0.9160214785214785\n",
            "epoch 3 batch id 1201 loss 0.23626631498336792 train acc 0.916996253122398\n",
            "epoch 3 batch id 1401 loss 0.5185459852218628 train acc 0.9183618843683083\n",
            "epoch 3 batch id 1601 loss 0.4805055856704712 train acc 0.9171611492816989\n",
            "epoch 3 batch id 1801 loss 0.10178390890359879 train acc 0.9177193225985564\n",
            "epoch 3 batch id 2001 loss 0.6498680114746094 train acc 0.9169790104947526\n",
            "epoch 3 batch id 2201 loss 0.6831945776939392 train acc 0.9166288050885961\n",
            "epoch 3 batch id 2401 loss 0.4881337285041809 train acc 0.9167664514785506\n",
            "epoch 3 batch id 2601 loss 0.37447884678840637 train acc 0.9165825643983083\n",
            "epoch 3 batch id 2801 loss 0.029070986434817314 train acc 0.9165699750089253\n",
            "epoch 3 batch id 3001 loss 0.6999114155769348 train acc 0.9163091469510163\n",
            "epoch 3 batch id 3201 loss 0.2886106073856354 train acc 0.916256638550453\n",
            "epoch 3 batch id 3401 loss 0.33458226919174194 train acc 0.9164583945898265\n",
            "epoch 3 batch id 3601 loss 0.07804618775844574 train acc 0.916828658705915\n",
            "epoch 3 batch id 3801 loss 0.2659059464931488 train acc 0.9168722046829781\n",
            "epoch 3 batch id 4001 loss 0.5906164050102234 train acc 0.9170754186453387\n",
            "epoch 3 batch id 4201 loss 0.4025045335292816 train acc 0.916835277314925\n",
            "epoch 3 batch id 4401 loss 0.4280814528465271 train acc 0.9168867870938423\n",
            "epoch 3 batch id 4601 loss 0.0325382798910141 train acc 0.9170832427733101\n",
            "epoch 3 batch id 4801 loss 0.4915715157985687 train acc 0.9169704228285773\n",
            "epoch 3 batch id 5001 loss 0.2427493780851364 train acc 0.9170603379324135\n",
            "epoch 3 batch id 5201 loss 0.3730767071247101 train acc 0.9168969909632763\n",
            "epoch 3 batch id 5401 loss 0.38773494958877563 train acc 0.9171391871875578\n",
            "epoch 3 batch id 5601 loss 0.3324509561061859 train acc 0.9170293251205142\n",
            "epoch 3 batch id 5801 loss 0.36885687708854675 train acc 0.9171263575245647\n",
            "epoch 3 batch id 6001 loss 0.23606792092323303 train acc 0.9169305115814032\n",
            "epoch 3 batch id 6201 loss 0.5005670785903931 train acc 0.9167573778422835\n",
            "epoch 3 batch id 6401 loss 0.18764035403728485 train acc 0.9166878222152789\n",
            "epoch 3 batch id 6601 loss 0.09960398077964783 train acc 0.9166982275412816\n",
            "epoch 3 batch id 6801 loss 0.2386031597852707 train acc 0.9167631598294369\n",
            "epoch 3 batch id 7001 loss 0.3040788173675537 train acc 0.9168600914155121\n",
            "epoch 3 batch id 7201 loss 0.19435055553913116 train acc 0.9169429593112067\n",
            "epoch 3 batch id 7401 loss 0.1557684689760208 train acc 0.917063572490204\n",
            "epoch 3 batch id 7601 loss 0.27359890937805176 train acc 0.9169887185896592\n",
            "epoch 3 batch id 7801 loss 0.3065139353275299 train acc 0.9169377323420075\n",
            "epoch 3 batch id 8001 loss 0.6467334628105164 train acc 0.9168307086614174\n",
            "epoch 3 batch id 8201 loss 0.5739762187004089 train acc 0.9168775149372028\n",
            "epoch 3 batch id 8401 loss 0.16114561259746552 train acc 0.9168551362932984\n",
            "epoch 3 batch id 8601 loss 0.15479031205177307 train acc 0.9169028310661551\n",
            "epoch 3 batch id 8801 loss 0.15519632399082184 train acc 0.9169590103397341\n",
            "epoch 3 batch id 9001 loss 0.3869640827178955 train acc 0.9170925452727475\n",
            "epoch 3 batch id 9201 loss 0.07816600799560547 train acc 0.9172882023693076\n",
            "epoch 3 batch id 9401 loss 0.11272083967924118 train acc 0.9172428465056909\n",
            "epoch 3 batch id 9601 loss 0.15588392317295074 train acc 0.9173198104364129\n",
            "epoch 3 batch id 9801 loss 0.4087234139442444 train acc 0.9173553719008265\n",
            "epoch 3 batch id 10001 loss 0.03865610435605049 train acc 0.9175082491750824\n",
            "epoch 3 batch id 10201 loss 0.4548270106315613 train acc 0.917612243897657\n",
            "epoch 3 batch id 10401 loss 0.23795506358146667 train acc 0.9176311172002692\n",
            "epoch 3 batch id 10601 loss 0.26523613929748535 train acc 0.9176139043486463\n",
            "epoch 3 batch id 10801 loss 0.033154070377349854 train acc 0.9176465142116471\n",
            "epoch 3 batch id 11001 loss 0.31909242272377014 train acc 0.9176523725115898\n",
            "epoch 3 batch id 11201 loss 0.1583271622657776 train acc 0.917697080617802\n",
            "epoch 3 batch id 11401 loss 0.30828824639320374 train acc 0.9177128102798\n",
            "epoch 3 batch id 11601 loss 0.5741865634918213 train acc 0.9178411343849668\n",
            "epoch 3 batch id 11801 loss 0.1528133600950241 train acc 0.9178512414202187\n",
            "epoch 3 batch id 12001 loss 0.4892875850200653 train acc 0.9179365261228231\n",
            "epoch 3 batch id 12201 loss 0.17627401649951935 train acc 0.9179140029505778\n",
            "epoch 3 batch id 12401 loss 0.6091599464416504 train acc 0.917957725183453\n",
            "epoch 3 batch id 12601 loss 0.4933641254901886 train acc 0.9179901396714546\n",
            "epoch 3 batch id 12801 loss 0.2778269648551941 train acc 0.918087454105148\n",
            "epoch 3 batch id 13001 loss 0.35805609822273254 train acc 0.9181120683024383\n",
            "epoch 3 batch id 13201 loss 0.342408686876297 train acc 0.9181951177941065\n",
            "epoch 3 batch id 13401 loss 0.182960644364357 train acc 0.9182523692261771\n",
            "epoch 3 batch id 13601 loss 0.2347286343574524 train acc 0.9183401036688479\n",
            "epoch 3 batch id 13801 loss 0.2878791093826294 train acc 0.9183596297369756\n",
            "epoch 3 batch id 14001 loss 0.10710654407739639 train acc 0.9183384222555532\n",
            "epoch 3 batch id 14201 loss 0.047863516956567764 train acc 0.918304608830364\n",
            "epoch 3 batch id 14401 loss 0.2635387182235718 train acc 0.9183824039997223\n",
            "epoch 3 batch id 14601 loss 0.2873370051383972 train acc 0.9184216834463393\n",
            "epoch 3 batch id 14801 loss 0.11896102130413055 train acc 0.9184092291061414\n",
            "epoch 3 batch id 15001 loss 0.5322595834732056 train acc 0.9183971068595427\n",
            "epoch 3 batch id 15201 loss 0.334064245223999 train acc 0.9184531445299652\n",
            "epoch 3 batch id 15401 loss 0.05424835905432701 train acc 0.9185178722160898\n",
            "epoch 3 batch id 15601 loss 0.4723646640777588 train acc 0.9185528972501763\n",
            "epoch 3 batch id 15801 loss 0.14968334138393402 train acc 0.9186345009809506\n",
            "epoch 3 batch id 16001 loss 0.2238478809595108 train acc 0.9186769576901443\n",
            "epoch 3 batch id 16201 loss 0.6625937819480896 train acc 0.9187164372569594\n",
            "epoch 3 batch id 16401 loss 0.9021879434585571 train acc 0.9188235473446741\n",
            "epoch 3 batch id 16601 loss 0.10900269448757172 train acc 0.9188226612854647\n",
            "epoch 3 batch id 16801 loss 0.2946612238883972 train acc 0.9188682965299685\n",
            "epoch 3 batch id 17001 loss 0.18813279271125793 train acc 0.9189477824833834\n",
            "epoch 3 batch id 17201 loss 0.1450321525335312 train acc 0.919003618975641\n",
            "epoch 3 batch id 17401 loss 0.37244632840156555 train acc 0.9190545801965404\n",
            "epoch 3 batch id 17601 loss 0.19432537257671356 train acc 0.9191363416851315\n",
            "epoch 3 batch id 17801 loss 0.18396742641925812 train acc 0.9191846665917645\n",
            "epoch 3 batch id 18001 loss 0.3287844955921173 train acc 0.9192926781845453\n",
            "epoch 3 batch id 18201 loss 0.23169085383415222 train acc 0.919363977253997\n",
            "epoch 3 batch id 18401 loss 0.5070996880531311 train acc 0.9194269333188414\n",
            "epoch 3 batch id 18601 loss 0.1326051503419876 train acc 0.9194633353045535\n",
            "epoch 3 batch id 18801 loss 0.060141194611787796 train acc 0.9195172464230627\n",
            "epoch 3 batch id 19001 loss 0.0704537183046341 train acc 0.9196045602863008\n",
            "epoch 3 batch id 19201 loss 0.07964938133955002 train acc 0.9196249544294568\n",
            "epoch 3 batch id 19401 loss 0.18068012595176697 train acc 0.9196900288644915\n",
            "epoch 3 batch id 19601 loss 0.4877936542034149 train acc 0.9197473980919341\n",
            "epoch 3 batch id 19801 loss 0.033860355615615845 train acc 0.9198272814504318\n",
            "epoch 3 batch id 20001 loss 0.46806472539901733 train acc 0.9198618194090296\n",
            "epoch 3 batch id 20201 loss 0.2428201287984848 train acc 0.9199173308252067\n",
            "epoch 3 batch id 20401 loss 0.14808598160743713 train acc 0.9199028233910103\n",
            "epoch 3 batch id 20601 loss 0.22505612671375275 train acc 0.9199128683073637\n",
            "epoch 3 batch id 20801 loss 0.2773973047733307 train acc 0.9199437527041969\n",
            "epoch 3 batch id 21001 loss 0.03602311760187149 train acc 0.91994875244036\n",
            "epoch 3 batch id 21201 loss 0.38845548033714294 train acc 0.9199846115749257\n",
            "epoch 3 batch id 21401 loss 0.11167286336421967 train acc 0.9200008177187982\n",
            "epoch 3 batch id 21601 loss 0.27701523900032043 train acc 0.9200557844544234\n",
            "epoch 3 batch id 21801 loss 0.14855274558067322 train acc 0.9201140429338104\n",
            "epoch 3 batch id 22001 loss 0.14130358397960663 train acc 0.9201755033862097\n",
            "epoch 3 batch id 22201 loss 0.31079208850860596 train acc 0.9201514008378001\n",
            "epoch 3 batch id 22401 loss 0.22572173178195953 train acc 0.9202198004553368\n",
            "epoch 3 batch id 22601 loss 0.3121102750301361 train acc 0.9202621012344586\n",
            "epoch 3 batch id 22801 loss 0.42274636030197144 train acc 0.9202885838340423\n",
            "epoch 3 batch id 23001 loss 0.30590736865997314 train acc 0.9203050954306334\n",
            "epoch 3 batch id 23201 loss 0.18480074405670166 train acc 0.9203132408085858\n",
            "epoch 3 batch id 23401 loss 0.24781964719295502 train acc 0.9203573031067048\n",
            "epoch 3 batch id 23601 loss 0.351652055978775 train acc 0.9203648680140673\n",
            "epoch 3 batch id 23801 loss 0.3813333809375763 train acc 0.9204025040964665\n",
            "epoch 3 batch id 24001 loss 0.3834262192249298 train acc 0.920460345402275\n",
            "epoch 3 batch id 24201 loss 0.372840017080307 train acc 0.9204797838932276\n",
            "epoch 3 batch id 24401 loss 0.32814621925354004 train acc 0.9205014651038892\n",
            "epoch 3 batch id 24601 loss 0.053830914199352264 train acc 0.920563442542986\n",
            "epoch 3 batch id 24801 loss 0.09714867919683456 train acc 0.9206143401475747\n",
            "epoch 3 batch id 25001 loss 2.3236641883850098 train acc 0.920644424223031\n",
            "epoch 3 train acc 0.9205798852411002\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62a7433b1cee417e8354d98dd0a05184"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 validation acc 0.919325\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25038 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6717fa7771f3414f867ffd5954b349f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 batch id 1 loss 0.6523007750511169 train acc 0.84375\n",
            "epoch 4 batch id 201 loss 0.5902925729751587 train acc 0.9289490049751243\n",
            "epoch 4 batch id 401 loss 0.4157119393348694 train acc 0.9285380299251871\n",
            "epoch 4 batch id 601 loss 0.47229063510894775 train acc 0.9285045757071547\n",
            "epoch 4 batch id 801 loss 0.5709967017173767 train acc 0.9278636079900124\n",
            "epoch 4 batch id 1001 loss 0.1764334887266159 train acc 0.9265734265734266\n",
            "epoch 4 batch id 1201 loss 0.26271432638168335 train acc 0.9276384263114071\n",
            "epoch 4 batch id 1401 loss 0.3770696222782135 train acc 0.9279532476802284\n",
            "epoch 4 batch id 1601 loss 0.42692697048187256 train acc 0.9273110555902561\n",
            "epoch 4 batch id 1801 loss 0.09165339171886444 train acc 0.9276270127706829\n",
            "epoch 4 batch id 2001 loss 0.5916293859481812 train acc 0.9270677161419291\n",
            "epoch 4 batch id 2201 loss 0.6462265849113464 train acc 0.9268514311676511\n",
            "epoch 4 batch id 2401 loss 0.40356722474098206 train acc 0.9271787796751354\n",
            "epoch 4 batch id 2601 loss 0.1670522540807724 train acc 0.9268310265282583\n",
            "epoch 4 batch id 2801 loss 0.015264601446688175 train acc 0.9267895394501964\n",
            "epoch 4 batch id 3001 loss 0.6608361601829529 train acc 0.9265244918360547\n",
            "epoch 4 batch id 3201 loss 0.18573978543281555 train acc 0.9266537800687286\n",
            "epoch 4 batch id 3401 loss 0.3651546239852905 train acc 0.9267586739194354\n",
            "epoch 4 batch id 3601 loss 0.16492795944213867 train acc 0.9269473757289641\n",
            "epoch 4 batch id 3801 loss 0.13894815742969513 train acc 0.9269928966061562\n",
            "epoch 4 batch id 4001 loss 0.7269899845123291 train acc 0.9271275931017245\n",
            "epoch 4 batch id 4201 loss 0.34130293130874634 train acc 0.9268031421090217\n",
            "epoch 4 batch id 4401 loss 0.2437848150730133 train acc 0.9268845148829812\n",
            "epoch 4 batch id 4601 loss 0.04561879113316536 train acc 0.9272508693762226\n",
            "epoch 4 batch id 4801 loss 0.5481863617897034 train acc 0.9269227765048949\n",
            "epoch 4 batch id 5001 loss 0.29361385107040405 train acc 0.9270895820835833\n",
            "epoch 4 batch id 5201 loss 0.285253643989563 train acc 0.926985195154778\n",
            "epoch 4 batch id 5401 loss 0.2381095588207245 train acc 0.9271951953341974\n",
            "epoch 4 batch id 5601 loss 0.1976976990699768 train acc 0.9270721746116765\n",
            "epoch 4 batch id 5801 loss 0.1799367517232895 train acc 0.9272808567488364\n",
            "epoch 4 batch id 6001 loss 0.2103484570980072 train acc 0.9270746542242959\n",
            "epoch 4 batch id 6201 loss 0.4578021168708801 train acc 0.9270984518626028\n",
            "epoch 4 batch id 6401 loss 0.08839186280965805 train acc 0.9270426495860021\n",
            "epoch 4 batch id 6601 loss 0.059007205069065094 train acc 0.9269996970156037\n",
            "epoch 4 batch id 6801 loss 0.12943421304225922 train acc 0.9271890163211293\n",
            "epoch 4 batch id 7001 loss 0.28592783212661743 train acc 0.9272202185402085\n",
            "epoch 4 batch id 7201 loss 0.2901146113872528 train acc 0.9272323288432163\n",
            "epoch 4 batch id 7401 loss 0.09286292642354965 train acc 0.9273282326712606\n",
            "epoch 4 batch id 7601 loss 0.1935701221227646 train acc 0.9272834166557032\n",
            "epoch 4 batch id 7801 loss 0.34010761976242065 train acc 0.9272168632226637\n",
            "epoch 4 batch id 8001 loss 0.5592239499092102 train acc 0.9270833333333334\n",
            "epoch 4 batch id 8201 loss 0.4924722909927368 train acc 0.9272306730886477\n",
            "epoch 4 batch id 8401 loss 0.12069524079561234 train acc 0.9271775681466492\n",
            "epoch 4 batch id 8601 loss 0.13954190909862518 train acc 0.9272468317637484\n",
            "epoch 4 batch id 8801 loss 0.08529962599277496 train acc 0.9272667878650154\n",
            "epoch 4 batch id 9001 loss 0.4103865623474121 train acc 0.9274073714031774\n",
            "epoch 4 batch id 9201 loss 0.05376765504479408 train acc 0.9275622214976633\n",
            "epoch 4 batch id 9401 loss 0.12936124205589294 train acc 0.9275775183491118\n",
            "epoch 4 batch id 9601 loss 0.13144038617610931 train acc 0.9276833142381002\n",
            "epoch 4 batch id 9801 loss 0.35173365473747253 train acc 0.9277369656157535\n",
            "epoch 4 batch id 10001 loss 0.027477335184812546 train acc 0.9277978452154785\n",
            "epoch 4 batch id 10201 loss 0.3948729336261749 train acc 0.927914542691893\n",
            "epoch 4 batch id 10401 loss 0.1432713121175766 train acc 0.9279516392654552\n",
            "epoch 4 batch id 10601 loss 0.29297971725463867 train acc 0.9278959532119612\n",
            "epoch 4 batch id 10801 loss 0.020465657114982605 train acc 0.9278654754189427\n",
            "epoch 4 batch id 11001 loss 0.2678966820240021 train acc 0.927867352967912\n",
            "epoch 4 batch id 11201 loss 0.19859126210212708 train acc 0.9279138023390768\n",
            "epoch 4 batch id 11401 loss 0.307132363319397 train acc 0.9278928383475133\n",
            "epoch 4 batch id 11601 loss 0.5574151277542114 train acc 0.9279857339884493\n",
            "epoch 4 batch id 11801 loss 0.06531412899494171 train acc 0.9280516481654097\n",
            "epoch 4 batch id 12001 loss 0.13541355729103088 train acc 0.9281440088325973\n",
            "epoch 4 batch id 12201 loss 0.120435930788517 train acc 0.9280591754774199\n",
            "epoch 4 batch id 12401 loss 0.7063207626342773 train acc 0.928158515442303\n",
            "epoch 4 batch id 12601 loss 0.5738505125045776 train acc 0.9281703833029125\n",
            "epoch 4 batch id 12801 loss 0.3032377362251282 train acc 0.9282331458479807\n",
            "epoch 4 batch id 13001 loss 0.31372204422950745 train acc 0.9282242712099069\n",
            "epoch 4 batch id 13201 loss 0.27559894323349 train acc 0.9282582758881903\n",
            "epoch 4 batch id 13401 loss 0.1884153038263321 train acc 0.9282749421684949\n",
            "epoch 4 batch id 13601 loss 0.2530325949192047 train acc 0.9283554518050143\n",
            "epoch 4 batch id 13801 loss 0.2876446843147278 train acc 0.9283702267951598\n",
            "epoch 4 batch id 14001 loss 0.13253793120384216 train acc 0.9283354760374259\n",
            "epoch 4 batch id 14201 loss 0.03154488652944565 train acc 0.9283567178367721\n",
            "epoch 4 batch id 14401 loss 0.06003718450665474 train acc 0.9283990695090619\n",
            "epoch 4 batch id 14601 loss 0.17936427891254425 train acc 0.9284188582973769\n",
            "epoch 4 batch id 14801 loss 0.2016122043132782 train acc 0.9284360009458821\n",
            "epoch 4 batch id 15001 loss 0.5130059719085693 train acc 0.9283985234317712\n",
            "epoch 4 batch id 15201 loss 0.20490050315856934 train acc 0.9284751003223473\n",
            "epoch 4 batch id 15401 loss 0.04888899624347687 train acc 0.9285050483734822\n",
            "epoch 4 batch id 15601 loss 0.6476926803588867 train acc 0.9285823024165117\n",
            "epoch 4 batch id 15801 loss 0.1794484555721283 train acc 0.9286378235554712\n",
            "epoch 4 batch id 16001 loss 0.29257121682167053 train acc 0.9286255546528343\n",
            "epoch 4 batch id 16201 loss 0.6920597553253174 train acc 0.9286232331337572\n",
            "epoch 4 batch id 16401 loss 0.8485585451126099 train acc 0.9286666971526126\n",
            "epoch 4 batch id 16601 loss 0.028464891016483307 train acc 0.9286846424914161\n",
            "epoch 4 batch id 16801 loss 0.18652592599391937 train acc 0.9286817004940182\n",
            "epoch 4 batch id 17001 loss 0.14222024381160736 train acc 0.9286677989530028\n",
            "epoch 4 batch id 17201 loss 0.13960523903369904 train acc 0.9287014563106796\n",
            "epoch 4 batch id 17401 loss 0.36629197001457214 train acc 0.9287433193494626\n",
            "epoch 4 batch id 17601 loss 0.12165872752666473 train acc 0.9288144139537526\n",
            "epoch 4 batch id 17801 loss 0.1787131279706955 train acc 0.9288400230324139\n",
            "epoch 4 batch id 18001 loss 0.43083375692367554 train acc 0.9288858952280429\n",
            "epoch 4 batch id 18201 loss 0.20955967903137207 train acc 0.9289496456238668\n",
            "epoch 4 batch id 18401 loss 0.40289878845214844 train acc 0.9289916308896256\n",
            "epoch 4 batch id 18601 loss 0.08402799814939499 train acc 0.9290159131229504\n",
            "epoch 4 batch id 18801 loss 0.05457707867026329 train acc 0.9290662730705813\n",
            "epoch 4 batch id 19001 loss 0.07255005836486816 train acc 0.9291205068154308\n",
            "epoch 4 batch id 19201 loss 0.06353697925806046 train acc 0.9291687281912401\n",
            "epoch 4 batch id 19401 loss 0.25149738788604736 train acc 0.9292368950054121\n",
            "epoch 4 batch id 19601 loss 0.3942778706550598 train acc 0.9292351155553288\n",
            "epoch 4 batch id 19801 loss 0.04353410750627518 train acc 0.9292775617393061\n",
            "epoch 4 batch id 20001 loss 0.49720290303230286 train acc 0.9293160341982901\n",
            "epoch 4 batch id 20201 loss 0.26489514112472534 train acc 0.9293831369734171\n",
            "epoch 4 batch id 20401 loss 0.30076199769973755 train acc 0.9293524214499289\n",
            "epoch 4 batch id 20601 loss 0.30879828333854675 train acc 0.9293556744818213\n",
            "epoch 4 batch id 20801 loss 0.1753999888896942 train acc 0.9293904139224076\n",
            "epoch 4 batch id 21001 loss 0.025602124631404877 train acc 0.9294096114470739\n",
            "epoch 4 batch id 21201 loss 0.39690834283828735 train acc 0.9294196028489222\n",
            "epoch 4 batch id 21401 loss 0.07360101491212845 train acc 0.9294337881407411\n",
            "epoch 4 batch id 21601 loss 0.16860350966453552 train acc 0.9294940049071803\n",
            "epoch 4 batch id 21801 loss 0.13416838645935059 train acc 0.9295101142149442\n",
            "epoch 4 batch id 22001 loss 0.14130786061286926 train acc 0.9295657015590201\n",
            "epoch 4 batch id 22201 loss 0.3120954632759094 train acc 0.9295850975181298\n",
            "epoch 4 batch id 22401 loss 0.16752322018146515 train acc 0.9296473929735279\n",
            "epoch 4 batch id 22601 loss 0.22031830251216888 train acc 0.9296823149418167\n",
            "epoch 4 batch id 22801 loss 0.3812819719314575 train acc 0.9297207359326345\n",
            "epoch 4 batch id 23001 loss 0.3099091053009033 train acc 0.9297163710273466\n",
            "epoch 4 batch id 23201 loss 0.12009455263614655 train acc 0.9297444075686393\n",
            "epoch 4 batch id 23401 loss 0.14328134059906006 train acc 0.9297906606555275\n",
            "epoch 4 batch id 23601 loss 0.3978380858898163 train acc 0.9298043515105292\n",
            "epoch 4 batch id 23801 loss 0.3188760280609131 train acc 0.9298217511869249\n",
            "epoch 4 batch id 24001 loss 0.22990666329860687 train acc 0.9298961501604099\n",
            "epoch 4 batch id 24201 loss 0.3490401804447174 train acc 0.9299189599603322\n",
            "epoch 4 batch id 24401 loss 0.22571203112602234 train acc 0.9299362731035613\n",
            "epoch 4 batch id 24601 loss 0.07940281182527542 train acc 0.9300066562334864\n",
            "epoch 4 batch id 24801 loss 0.16336625814437866 train acc 0.9300544836901737\n",
            "epoch 4 batch id 25001 loss 1.8585211038589478 train acc 0.9300640474381024\n",
            "epoch 4 train acc 0.9300321844130255\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19eae7b664e24aa392eddc67536cf076"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 validation acc 0.92114\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25038 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36eea96b4a9244828f2c1c9132a918b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 batch id 1 loss 0.4355889558792114 train acc 0.875\n",
            "epoch 5 batch id 201 loss 0.7351504564285278 train acc 0.9387437810945274\n",
            "epoch 5 batch id 401 loss 0.45186787843704224 train acc 0.937889650872818\n",
            "epoch 5 batch id 601 loss 0.24800267815589905 train acc 0.937551996672213\n",
            "epoch 5 batch id 801 loss 0.34370219707489014 train acc 0.9375\n",
            "epoch 5 batch id 1001 loss 0.15216118097305298 train acc 0.93622002997003\n",
            "epoch 5 batch id 1201 loss 0.19632075726985931 train acc 0.9360428809325562\n",
            "epoch 5 batch id 1401 loss 0.3467857241630554 train acc 0.9364962526766595\n",
            "epoch 5 batch id 1601 loss 0.4068925380706787 train acc 0.9362898188632105\n",
            "epoch 5 batch id 1801 loss 0.034821245819330215 train acc 0.9367191837867851\n",
            "epoch 5 batch id 2001 loss 0.5270938277244568 train acc 0.936344327836082\n",
            "epoch 5 batch id 2201 loss 0.5366749167442322 train acc 0.936250567923671\n",
            "epoch 5 batch id 2401 loss 0.38005056977272034 train acc 0.9364717825905873\n",
            "epoch 5 batch id 2601 loss 0.2717609107494354 train acc 0.9360942906574394\n",
            "epoch 5 batch id 2801 loss 0.010001324117183685 train acc 0.9359938414851838\n",
            "epoch 5 batch id 3001 loss 0.6858651638031006 train acc 0.935646451182939\n",
            "epoch 5 batch id 3201 loss 0.14918485283851624 train acc 0.9355670103092784\n",
            "epoch 5 batch id 3401 loss 0.3544079661369324 train acc 0.935597985886504\n",
            "epoch 5 batch id 3601 loss 0.057830411940813065 train acc 0.9359986809219661\n",
            "epoch 5 batch id 3801 loss 0.03826889023184776 train acc 0.9360036832412523\n",
            "epoch 5 batch id 4001 loss 0.6726080179214478 train acc 0.9360706698325418\n",
            "epoch 5 batch id 4201 loss 0.3667251169681549 train acc 0.9358709235896215\n",
            "epoch 5 batch id 4401 loss 0.2457732856273651 train acc 0.9359307543740059\n",
            "epoch 5 batch id 4601 loss 0.03724881261587143 train acc 0.9363113996957183\n",
            "epoch 5 batch id 4801 loss 0.4928320646286011 train acc 0.9361526244532389\n",
            "epoch 5 batch id 5001 loss 0.36892250180244446 train acc 0.9361752649470106\n",
            "epoch 5 batch id 5201 loss 0.26002904772758484 train acc 0.9359558258027303\n",
            "epoch 5 batch id 5401 loss 0.10901093482971191 train acc 0.936117154230698\n",
            "epoch 5 batch id 5601 loss 0.2221626490354538 train acc 0.9360828423495804\n",
            "epoch 5 batch id 5801 loss 0.22091391682624817 train acc 0.9362609894845716\n",
            "epoch 5 batch id 6001 loss 0.11184222251176834 train acc 0.9360367022162973\n",
            "epoch 5 batch id 6201 loss 0.4076160788536072 train acc 0.9360284631511047\n",
            "epoch 5 batch id 6401 loss 0.09996186196804047 train acc 0.9359426261521637\n",
            "epoch 5 batch id 6601 loss 0.041598327457904816 train acc 0.9359424708377518\n",
            "epoch 5 batch id 6801 loss 0.12186787277460098 train acc 0.9361353109836789\n",
            "epoch 5 batch id 7001 loss 0.2237987071275711 train acc 0.9362144693615198\n",
            "epoch 5 batch id 7201 loss 0.20981095731258392 train acc 0.9363586654631301\n",
            "epoch 5 batch id 7401 loss 0.10799915343523026 train acc 0.9364148425888393\n",
            "epoch 5 batch id 7601 loss 0.21175436675548553 train acc 0.9364228391001184\n",
            "epoch 5 batch id 7801 loss 0.44721025228500366 train acc 0.936394372516344\n",
            "epoch 5 batch id 8001 loss 0.47009071707725525 train acc 0.9363321772278466\n",
            "epoch 5 batch id 8201 loss 0.5058750510215759 train acc 0.9364559200097549\n",
            "epoch 5 batch id 8401 loss 0.10417132824659348 train acc 0.9364472979407213\n",
            "epoch 5 batch id 8601 loss 0.09571583569049835 train acc 0.9364717765376119\n",
            "epoch 5 batch id 8801 loss 0.09525935351848602 train acc 0.9364951425974322\n",
            "epoch 5 batch id 9001 loss 0.31146156787872314 train acc 0.9366389845572715\n",
            "epoch 5 batch id 9201 loss 0.22506199777126312 train acc 0.9368512933376807\n",
            "epoch 5 batch id 9401 loss 0.06814325600862503 train acc 0.9367853153919796\n",
            "epoch 5 batch id 9601 loss 0.0609888918697834 train acc 0.9368685553588167\n",
            "epoch 5 batch id 9801 loss 0.3381739556789398 train acc 0.9368878175696358\n",
            "epoch 5 batch id 10001 loss 0.0318533256649971 train acc 0.9369219328067193\n",
            "epoch 5 batch id 10201 loss 0.47386568784713745 train acc 0.9369730908734438\n",
            "epoch 5 batch id 10401 loss 0.039872560650110245 train acc 0.9370252860301894\n",
            "epoch 5 batch id 10601 loss 0.20919552445411682 train acc 0.9370607725686256\n",
            "epoch 5 batch id 10801 loss 0.02444588951766491 train acc 0.9370370799000093\n",
            "epoch 5 batch id 11001 loss 0.20978936553001404 train acc 0.9370824243250614\n",
            "epoch 5 batch id 11201 loss 0.24961496889591217 train acc 0.9371205695920007\n",
            "epoch 5 batch id 11401 loss 0.20346827805042267 train acc 0.9371107797561617\n",
            "epoch 5 batch id 11601 loss 0.4248967170715332 train acc 0.9371983018705284\n",
            "epoch 5 batch id 11801 loss 0.0739448219537735 train acc 0.937192822642149\n",
            "epoch 5 batch id 12001 loss 0.022877193987369537 train acc 0.9373020998250146\n",
            "epoch 5 batch id 12201 loss 0.09600135684013367 train acc 0.9372822924350463\n",
            "epoch 5 batch id 12401 loss 0.5712925791740417 train acc 0.9373412426417225\n",
            "epoch 5 batch id 12601 loss 0.5470556020736694 train acc 0.9373636020950719\n",
            "epoch 5 batch id 12801 loss 0.252116858959198 train acc 0.9374243223185689\n",
            "epoch 5 batch id 13001 loss 0.24614761769771576 train acc 0.9374567340973772\n",
            "epoch 5 batch id 13201 loss 0.31117892265319824 train acc 0.9375023672449057\n",
            "epoch 5 batch id 13401 loss 0.13490717113018036 train acc 0.9375279829863443\n",
            "epoch 5 batch id 13601 loss 0.27785420417785645 train acc 0.9375827145062863\n",
            "epoch 5 batch id 13801 loss 0.3159022033214569 train acc 0.9376064234475763\n",
            "epoch 5 batch id 14001 loss 0.048089660704135895 train acc 0.9375803514034712\n",
            "epoch 5 batch id 14201 loss 0.036316368728876114 train acc 0.9376034258150835\n",
            "epoch 5 batch id 14401 loss 0.06708750873804092 train acc 0.9376323692799111\n",
            "epoch 5 batch id 14601 loss 0.1232404112815857 train acc 0.9376583795630437\n",
            "epoch 5 batch id 14801 loss 0.07338770478963852 train acc 0.9376625734747652\n",
            "epoch 5 batch id 15001 loss 0.4789522588253021 train acc 0.9376937370841943\n",
            "epoch 5 batch id 15201 loss 0.16228030622005463 train acc 0.9377487500822315\n",
            "epoch 5 batch id 15401 loss 0.06240597739815712 train acc 0.9378023342640088\n",
            "epoch 5 batch id 15601 loss 0.5728131532669067 train acc 0.9378265015063137\n",
            "epoch 5 batch id 15801 loss 0.11956407874822617 train acc 0.937885655971141\n",
            "epoch 5 batch id 16001 loss 0.09730318188667297 train acc 0.9379140366227111\n",
            "epoch 5 batch id 16201 loss 0.5603248476982117 train acc 0.9379340009875934\n",
            "epoch 5 batch id 16401 loss 0.532088041305542 train acc 0.938014450338394\n",
            "epoch 5 batch id 16601 loss 0.026613395661115646 train acc 0.9380421360159027\n",
            "epoch 5 batch id 16801 loss 0.1892373412847519 train acc 0.9380487024581871\n",
            "epoch 5 batch id 17001 loss 0.15436775982379913 train acc 0.9380973913299218\n",
            "epoch 5 batch id 17201 loss 0.09487944096326828 train acc 0.9380904453229464\n",
            "epoch 5 batch id 17401 loss 0.3671014606952667 train acc 0.9380962301017183\n",
            "epoch 5 batch id 17601 loss 0.05229974538087845 train acc 0.9381569229021078\n",
            "epoch 5 batch id 17801 loss 0.1688116490840912 train acc 0.938214496376608\n",
            "epoch 5 batch id 18001 loss 0.3611203730106354 train acc 0.9382499583356481\n",
            "epoch 5 batch id 18201 loss 0.10269142687320709 train acc 0.9382966595242019\n",
            "epoch 5 batch id 18401 loss 0.37853074073791504 train acc 0.938374612792783\n",
            "epoch 5 batch id 18601 loss 0.03181032836437225 train acc 0.93841560937584\n",
            "epoch 5 batch id 18801 loss 0.02657138742506504 train acc 0.9384723551938726\n",
            "epoch 5 batch id 19001 loss 0.04690345376729965 train acc 0.9385410636282301\n",
            "epoch 5 batch id 19201 loss 0.014859854243695736 train acc 0.93854486745482\n",
            "epoch 5 batch id 19401 loss 0.20740380883216858 train acc 0.9386114117828978\n",
            "epoch 5 batch id 19601 loss 0.2183903008699417 train acc 0.9386192031018825\n",
            "epoch 5 batch id 19801 loss 0.05575188249349594 train acc 0.9386662921064592\n",
            "epoch 5 batch id 20001 loss 0.43638691306114197 train acc 0.93871400179991\n",
            "epoch 5 batch id 20201 loss 0.19241146743297577 train acc 0.9387886119499035\n",
            "epoch 5 batch id 20401 loss 0.17531882226467133 train acc 0.9387744473310132\n",
            "epoch 5 batch id 20601 loss 0.20606112480163574 train acc 0.9388106159895151\n",
            "epoch 5 batch id 20801 loss 0.13546122610569 train acc 0.9388205494928128\n",
            "epoch 5 batch id 21001 loss 0.021205054596066475 train acc 0.9388496381124708\n",
            "epoch 5 batch id 21201 loss 0.42052945494651794 train acc 0.9388339583038536\n",
            "epoch 5 batch id 21401 loss 0.07404167205095291 train acc 0.9388638381384048\n",
            "epoch 5 batch id 21601 loss 0.0941188633441925 train acc 0.9388989514374334\n",
            "epoch 5 batch id 21801 loss 0.1446557641029358 train acc 0.9389190862804458\n",
            "epoch 5 batch id 22001 loss 0.19591747224330902 train acc 0.9389473773919367\n",
            "epoch 5 batch id 22201 loss 0.348777711391449 train acc 0.9389709359938742\n",
            "epoch 5 batch id 22401 loss 0.1340104639530182 train acc 0.9390261595464489\n",
            "epoch 5 batch id 22601 loss 0.1908438801765442 train acc 0.9390624308658909\n",
            "epoch 5 batch id 22801 loss 0.3149558901786804 train acc 0.9390898425507653\n",
            "epoch 5 batch id 23001 loss 0.3241211473941803 train acc 0.9390529216121039\n",
            "epoch 5 batch id 23201 loss 0.13320745527744293 train acc 0.9390853303736908\n",
            "epoch 5 batch id 23401 loss 0.11956947296857834 train acc 0.93912386222811\n",
            "epoch 5 batch id 23601 loss 0.33234021067619324 train acc 0.9391352590991907\n",
            "epoch 5 batch id 23801 loss 0.32725420594215393 train acc 0.9391766627452628\n",
            "epoch 5 batch id 24001 loss 0.27581068873405457 train acc 0.9392395108537144\n",
            "epoch 5 batch id 24201 loss 0.23610152304172516 train acc 0.9392690384694847\n",
            "epoch 5 batch id 24401 loss 0.17032842338085175 train acc 0.939303204786689\n",
            "epoch 5 batch id 24601 loss 0.022611349821090698 train acc 0.9393647615950571\n",
            "epoch 5 batch id 24801 loss 0.016122162342071533 train acc 0.9394039050844724\n",
            "epoch 5 batch id 25001 loss 1.5858161449432373 train acc 0.9393961741530339\n",
            "epoch 5 train acc 0.9393671619138909\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f89237dce444da78d63572882421cf2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 validation acc 0.923445\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25038 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2b0b925770f40b9bc129577524cff23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 batch id 1 loss 0.4769173264503479 train acc 0.875\n",
            "epoch 6 batch id 201 loss 0.5681055188179016 train acc 0.9457400497512438\n",
            "epoch 6 batch id 401 loss 0.320661336183548 train acc 0.9470074812967582\n",
            "epoch 6 batch id 601 loss 0.18413928151130676 train acc 0.9453514975041597\n",
            "epoch 6 batch id 801 loss 0.31908270716667175 train acc 0.9463171036204744\n",
            "epoch 6 batch id 1001 loss 0.21354278922080994 train acc 0.9451173826173827\n",
            "epoch 6 batch id 1201 loss 0.16074791550636292 train acc 0.9448376353039134\n",
            "epoch 6 batch id 1401 loss 0.25407955050468445 train acc 0.9453292291220556\n",
            "epoch 6 batch id 1601 loss 0.32455629110336304 train acc 0.9448001249219238\n",
            "epoch 6 batch id 1801 loss 0.030278313905000687 train acc 0.9449958356468628\n",
            "epoch 6 batch id 2001 loss 0.41162586212158203 train acc 0.9445277361319341\n",
            "epoch 6 batch id 2201 loss 0.4656482934951782 train acc 0.9444996592457974\n",
            "epoch 6 batch id 2401 loss 0.3189797103404999 train acc 0.9445543523531862\n",
            "epoch 6 batch id 2601 loss 0.09813626110553741 train acc 0.9443242983467897\n",
            "epoch 6 batch id 2801 loss 0.010120547376573086 train acc 0.9443167618707604\n",
            "epoch 6 batch id 3001 loss 0.45802202820777893 train acc 0.9441436187937354\n",
            "epoch 6 batch id 3201 loss 0.05660821869969368 train acc 0.9441580756013745\n",
            "epoch 6 batch id 3401 loss 0.42211270332336426 train acc 0.9440973243163775\n",
            "epoch 6 batch id 3601 loss 0.018502580001950264 train acc 0.9444772285476256\n",
            "epoch 6 batch id 3801 loss 0.030345940962433815 train acc 0.9444636279926335\n",
            "epoch 6 batch id 4001 loss 0.6227110624313354 train acc 0.9446544613846538\n",
            "epoch 6 batch id 4201 loss 0.299775630235672 train acc 0.944656034277553\n",
            "epoch 6 batch id 4401 loss 0.22592243552207947 train acc 0.9446006589411498\n",
            "epoch 6 batch id 4601 loss 0.016682397574186325 train acc 0.9449372419039339\n",
            "epoch 6 batch id 4801 loss 0.5113047361373901 train acc 0.9447641116434077\n",
            "epoch 6 batch id 5001 loss 0.318840354681015 train acc 0.9448860227954409\n",
            "epoch 6 batch id 5201 loss 0.27402010560035706 train acc 0.9446801095943088\n",
            "epoch 6 batch id 5401 loss 0.12484525889158249 train acc 0.9449638955748936\n",
            "epoch 6 batch id 5601 loss 0.15900814533233643 train acc 0.9448982324584896\n",
            "epoch 6 batch id 5801 loss 0.1329340785741806 train acc 0.9450040941217032\n",
            "epoch 6 batch id 6001 loss 0.12234761565923691 train acc 0.9448269038493584\n",
            "epoch 6 batch id 6201 loss 0.45130643248558044 train acc 0.9448022496371553\n",
            "epoch 6 batch id 6401 loss 0.10447115451097488 train acc 0.9447107873769723\n",
            "epoch 6 batch id 6601 loss 0.02476510778069496 train acc 0.9446674746250568\n",
            "epoch 6 batch id 6801 loss 0.08988029509782791 train acc 0.9448196956329952\n",
            "epoch 6 batch id 7001 loss 0.19322086870670319 train acc 0.9448739465790601\n",
            "epoch 6 batch id 7201 loss 0.12221962213516235 train acc 0.9449251840022219\n",
            "epoch 6 batch id 7401 loss 0.0515877828001976 train acc 0.945049655451966\n",
            "epoch 6 batch id 7601 loss 0.24358709156513214 train acc 0.9450935732140507\n",
            "epoch 6 batch id 7801 loss 0.4139921963214874 train acc 0.9450871683117549\n",
            "epoch 6 batch id 8001 loss 0.4025323987007141 train acc 0.9450459317585301\n",
            "epoch 6 batch id 8201 loss 0.343758761882782 train acc 0.9451438848920863\n",
            "epoch 6 batch id 8401 loss 0.062261149287223816 train acc 0.9451218604927984\n",
            "epoch 6 batch id 8601 loss 0.09105715155601501 train acc 0.9451190268573422\n",
            "epoch 6 batch id 8801 loss 0.020587794482707977 train acc 0.945201539597773\n",
            "epoch 6 batch id 9001 loss 0.33289918303489685 train acc 0.9452560826574825\n",
            "epoch 6 batch id 9201 loss 0.0313931368291378 train acc 0.945423731116183\n",
            "epoch 6 batch id 9401 loss 0.044687025249004364 train acc 0.9453881236038719\n",
            "epoch 6 batch id 9601 loss 0.026103023439645767 train acc 0.9454386261847724\n",
            "epoch 6 batch id 9801 loss 0.28353461623191833 train acc 0.9454806907458423\n",
            "epoch 6 batch id 10001 loss 0.020221758633852005 train acc 0.9455773172682732\n",
            "epoch 6 batch id 10201 loss 0.2713238596916199 train acc 0.9456088863836879\n",
            "epoch 6 batch id 10401 loss 0.030601926147937775 train acc 0.9457263724641861\n",
            "epoch 6 batch id 10601 loss 0.1345149725675583 train acc 0.9457391991321573\n",
            "epoch 6 batch id 10801 loss 0.013275847770273685 train acc 0.945751550782335\n",
            "epoch 6 batch id 11001 loss 0.17993666231632233 train acc 0.9457833378783747\n",
            "epoch 6 batch id 11201 loss 0.4371507167816162 train acc 0.9458167797518079\n",
            "epoch 6 batch id 11401 loss 0.14361636340618134 train acc 0.9458243794404\n",
            "epoch 6 batch id 11601 loss 0.48133668303489685 train acc 0.9458721230928369\n",
            "epoch 6 batch id 11801 loss 0.12768754363059998 train acc 0.9459367850182188\n",
            "epoch 6 batch id 12001 loss 0.018242040649056435 train acc 0.9459758561786518\n",
            "epoch 6 batch id 12201 loss 0.04754170775413513 train acc 0.9459649823784936\n",
            "epoch 6 batch id 12401 loss 0.6626411080360413 train acc 0.9459998185630191\n",
            "epoch 6 batch id 12601 loss 0.7530620694160461 train acc 0.9460633084675819\n",
            "epoch 6 batch id 12801 loss 0.28796231746673584 train acc 0.9461052847433794\n",
            "epoch 6 batch id 13001 loss 0.2934461534023285 train acc 0.9461411622182909\n",
            "epoch 6 batch id 13201 loss 0.3116365075111389 train acc 0.9461570146201045\n",
            "epoch 6 batch id 13401 loss 0.10650981962680817 train acc 0.9461490746959182\n",
            "epoch 6 batch id 13601 loss 0.20900210738182068 train acc 0.9462171899125065\n",
            "epoch 6 batch id 13801 loss 0.32639577984809875 train acc 0.9462403086732846\n",
            "epoch 6 batch id 14001 loss 0.08247820287942886 train acc 0.9462382151274908\n",
            "epoch 6 batch id 14201 loss 0.03820212930440903 train acc 0.9462405816491797\n",
            "epoch 6 batch id 14401 loss 0.04048227518796921 train acc 0.9463144920491633\n",
            "epoch 6 batch id 14601 loss 0.11354716867208481 train acc 0.9463307307718649\n",
            "epoch 6 batch id 14801 loss 0.03975890949368477 train acc 0.9463380852645091\n",
            "epoch 6 batch id 15001 loss 0.3247765004634857 train acc 0.9463556596226919\n",
            "epoch 6 batch id 15201 loss 0.1937319040298462 train acc 0.9464200546016709\n",
            "epoch 6 batch id 15401 loss 0.049654651433229446 train acc 0.9464381371339523\n",
            "epoch 6 batch id 15601 loss 0.4378637969493866 train acc 0.9464557560412794\n",
            "epoch 6 batch id 15801 loss 0.14868144690990448 train acc 0.9464867729890514\n",
            "epoch 6 batch id 16001 loss 0.1885431706905365 train acc 0.9464916255234048\n",
            "epoch 6 batch id 16201 loss 0.3930126130580902 train acc 0.9465040738226036\n",
            "epoch 6 batch id 16401 loss 0.5660322308540344 train acc 0.9465276507530028\n",
            "epoch 6 batch id 16601 loss 0.03844596818089485 train acc 0.9465676013493163\n",
            "epoch 6 batch id 16801 loss 0.03815970569849014 train acc 0.9465842806975775\n",
            "epoch 6 batch id 17001 loss 0.1169990673661232 train acc 0.9466079201223457\n",
            "epoch 6 batch id 17201 loss 0.06365597248077393 train acc 0.9466291930701703\n",
            "epoch 6 batch id 17401 loss 0.26328638195991516 train acc 0.9466715274984197\n",
            "epoch 6 batch id 17601 loss 0.06093506142497063 train acc 0.9467413073120845\n",
            "epoch 6 batch id 17801 loss 0.11221334338188171 train acc 0.9468253188023145\n",
            "epoch 6 batch id 18001 loss 0.2588782012462616 train acc 0.9469265596355758\n",
            "epoch 6 batch id 18201 loss 0.08690879493951797 train acc 0.9470084061315313\n",
            "epoch 6 batch id 18401 loss 0.5123522281646729 train acc 0.9470782837889246\n",
            "epoch 6 batch id 18601 loss 0.07521560043096542 train acc 0.9471231385409387\n",
            "epoch 6 batch id 18801 loss 0.017047831788659096 train acc 0.9471720254241796\n",
            "epoch 6 batch id 19001 loss 0.10720560699701309 train acc 0.9472363296668597\n",
            "epoch 6 batch id 19201 loss 0.019887369126081467 train acc 0.9472455861673871\n",
            "epoch 6 batch id 19401 loss 0.24399547278881073 train acc 0.9473271351992165\n",
            "epoch 6 batch id 19601 loss 0.18898050487041473 train acc 0.9473560022447834\n",
            "epoch 6 batch id 19801 loss 0.13495467603206635 train acc 0.9473953335690116\n",
            "epoch 6 batch id 20001 loss 0.4630431830883026 train acc 0.9474338783060847\n",
            "epoch 6 batch id 20201 loss 0.18282289803028107 train acc 0.9475010519281224\n",
            "epoch 6 batch id 20401 loss 0.09091373533010483 train acc 0.9474979780402921\n",
            "epoch 6 batch id 20601 loss 0.19722650945186615 train acc 0.9475116499199068\n",
            "epoch 6 batch id 20801 loss 0.11975003778934479 train acc 0.9475611148502476\n",
            "epoch 6 batch id 21001 loss 0.013559113256633282 train acc 0.9475962454168849\n",
            "epoch 6 batch id 21201 loss 0.3858516216278076 train acc 0.9476056553936135\n",
            "epoch 6 batch id 21401 loss 0.04136218503117561 train acc 0.9476440937339377\n",
            "epoch 6 batch id 21601 loss 0.08700879663228989 train acc 0.9476774802092496\n",
            "epoch 6 batch id 21801 loss 0.09183542430400848 train acc 0.9477059538553277\n",
            "epoch 6 batch id 22001 loss 0.08697725087404251 train acc 0.9477495341120858\n",
            "epoch 6 batch id 22201 loss 0.2613476514816284 train acc 0.9477571393180487\n",
            "epoch 6 batch id 22401 loss 0.07479739189147949 train acc 0.9478064595330565\n",
            "epoch 6 batch id 22601 loss 0.1994977444410324 train acc 0.9478507588159816\n",
            "epoch 6 batch id 22801 loss 0.29387715458869934 train acc 0.9479025042761282\n",
            "epoch 6 batch id 23001 loss 0.34071797132492065 train acc 0.9478908525716273\n",
            "epoch 6 batch id 23201 loss 0.15271642804145813 train acc 0.9479198094909702\n",
            "epoch 6 batch id 23401 loss 0.11316751688718796 train acc 0.9479656318106063\n",
            "epoch 6 batch id 23601 loss 0.18428611755371094 train acc 0.9479656582348206\n",
            "epoch 6 batch id 23801 loss 0.1702459454536438 train acc 0.9480024473761607\n",
            "epoch 6 batch id 24001 loss 0.35377439856529236 train acc 0.9480503416524312\n",
            "epoch 6 batch id 24201 loss 0.13888783752918243 train acc 0.948102609396306\n",
            "epoch 6 batch id 24401 loss 0.11921876668930054 train acc 0.9481463362157289\n",
            "epoch 6 batch id 24601 loss 0.02850252017378807 train acc 0.9482058656152189\n",
            "epoch 6 batch id 24801 loss 0.012385562993586063 train acc 0.948258134752631\n",
            "epoch 6 batch id 25001 loss 1.4341938495635986 train acc 0.9482783188672453\n",
            "epoch 6 train acc 0.9482715439199084\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30804b088a7c4c18a785e37951e0d0d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 validation acc 0.923905\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25038 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90bb842c73674c08b780838e5760cc2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 batch id 1 loss 0.39036497473716736 train acc 0.875\n",
            "epoch 7 batch id 201 loss 0.5754706263542175 train acc 0.9560012437810945\n",
            "epoch 7 batch id 401 loss 0.2690106928348541 train acc 0.9574501246882793\n",
            "epoch 7 batch id 601 loss 0.08381085097789764 train acc 0.9546589018302829\n",
            "epoch 7 batch id 801 loss 0.3710504174232483 train acc 0.9547440699126092\n",
            "epoch 7 batch id 1001 loss 0.20764680206775665 train acc 0.9546703296703297\n",
            "epoch 7 batch id 1201 loss 0.041044507175683975 train acc 0.9544650291423813\n",
            "epoch 7 batch id 1401 loss 0.298974871635437 train acc 0.9548313704496788\n",
            "epoch 7 batch id 1601 loss 0.3189365267753601 train acc 0.9543254216114928\n",
            "epoch 7 batch id 1801 loss 0.024626368656754494 train acc 0.9547473625763465\n",
            "epoch 7 batch id 2001 loss 0.3266352713108063 train acc 0.9541635432283858\n",
            "epoch 7 batch id 2201 loss 0.40614980459213257 train acc 0.9539413902771468\n",
            "epoch 7 batch id 2401 loss 0.44328564405441284 train acc 0.9541467097042898\n",
            "epoch 7 batch id 2601 loss 0.03493122011423111 train acc 0.9538278546712803\n",
            "epoch 7 batch id 2801 loss 0.012120461091399193 train acc 0.9538780792574081\n",
            "epoch 7 batch id 3001 loss 0.3866046071052551 train acc 0.9538591302899033\n",
            "epoch 7 batch id 3201 loss 0.03804752230644226 train acc 0.9538327866291784\n",
            "epoch 7 batch id 3401 loss 0.2160983681678772 train acc 0.9537452219935313\n",
            "epoch 7 batch id 3601 loss 0.009350516833364964 train acc 0.9539450846986948\n",
            "epoch 7 batch id 3801 loss 0.04993215203285217 train acc 0.9539841489081821\n",
            "epoch 7 batch id 4001 loss 0.7473924160003662 train acc 0.9541130342414397\n",
            "epoch 7 batch id 4201 loss 0.3090268671512604 train acc 0.9540585574863127\n",
            "epoch 7 batch id 4401 loss 0.17386873066425323 train acc 0.9541013406044081\n",
            "epoch 7 batch id 4601 loss 0.027939673513174057 train acc 0.9544188763312323\n",
            "epoch 7 batch id 4801 loss 0.5528404116630554 train acc 0.9542803582586961\n",
            "epoch 7 batch id 5001 loss 0.25823044776916504 train acc 0.954377874425115\n",
            "epoch 7 batch id 5201 loss 0.35577964782714844 train acc 0.954245577773505\n",
            "epoch 7 batch id 5401 loss 0.0886024683713913 train acc 0.9545165247176449\n",
            "epoch 7 batch id 5601 loss 0.1784316450357437 train acc 0.954494733083378\n",
            "epoch 7 batch id 5801 loss 0.02639482356607914 train acc 0.9546198931218756\n",
            "epoch 7 batch id 6001 loss 0.07592707127332687 train acc 0.9544919596733877\n",
            "epoch 7 batch id 6201 loss 0.45931148529052734 train acc 0.9544025157232704\n",
            "epoch 7 batch id 6401 loss 0.11820767819881439 train acc 0.9544016559912514\n",
            "epoch 7 batch id 6601 loss 0.013504687696695328 train acc 0.9543771777003485\n",
            "epoch 7 batch id 6801 loss 0.10290157794952393 train acc 0.9545149610351419\n",
            "epoch 7 batch id 7001 loss 0.16907601058483124 train acc 0.9545779174403657\n",
            "epoch 7 batch id 7201 loss 0.13335402309894562 train acc 0.9546243577280933\n",
            "epoch 7 batch id 7401 loss 0.111961729824543 train acc 0.9546387312525334\n",
            "epoch 7 batch id 7601 loss 0.2604341506958008 train acc 0.9546523483752137\n",
            "epoch 7 batch id 7801 loss 0.2876935601234436 train acc 0.9546532495833867\n",
            "epoch 7 batch id 8001 loss 0.3803381025791168 train acc 0.9545330271216098\n",
            "epoch 7 batch id 8201 loss 0.1546572744846344 train acc 0.9546701621753445\n",
            "epoch 7 batch id 8401 loss 0.06560423970222473 train acc 0.9546594155457684\n",
            "epoch 7 batch id 8601 loss 0.032835450023412704 train acc 0.9546419021044065\n",
            "epoch 7 batch id 8801 loss 0.0088595449924469 train acc 0.9546500397682082\n",
            "epoch 7 batch id 9001 loss 0.2125648856163025 train acc 0.9547411398733474\n",
            "epoch 7 batch id 9201 loss 0.011674592271447182 train acc 0.9548045049451147\n",
            "epoch 7 batch id 9401 loss 0.047587405890226364 train acc 0.954768774598447\n",
            "epoch 7 batch id 9601 loss 0.015231756493449211 train acc 0.9548321789396937\n",
            "epoch 7 batch id 9801 loss 0.440778911113739 train acc 0.9548419804101622\n",
            "epoch 7 batch id 10001 loss 0.038770891726017 train acc 0.95489201079892\n",
            "epoch 7 batch id 10201 loss 0.28704601526260376 train acc 0.954909445152436\n",
            "epoch 7 batch id 10401 loss 0.008704261854290962 train acc 0.9549652677627152\n",
            "epoch 7 batch id 10601 loss 0.21451294422149658 train acc 0.9549570795207999\n",
            "epoch 7 batch id 10801 loss 0.002460143528878689 train acc 0.9549839135265253\n",
            "epoch 7 batch id 11001 loss 0.20583601295948029 train acc 0.9549927279338242\n",
            "epoch 7 batch id 11201 loss 0.17113034427165985 train acc 0.9550207570752611\n",
            "epoch 7 batch id 11401 loss 0.16083624958992004 train acc 0.955012169985089\n",
            "epoch 7 batch id 11601 loss 0.43288880586624146 train acc 0.9550362037755366\n",
            "epoch 7 batch id 11801 loss 0.02897598408162594 train acc 0.9550832556563004\n",
            "epoch 7 batch id 12001 loss 0.02726145274937153 train acc 0.9551886301141571\n",
            "epoch 7 batch id 12201 loss 0.01657496765255928 train acc 0.9551983443980001\n",
            "epoch 7 batch id 12401 loss 0.5769214034080505 train acc 0.9553009837916298\n",
            "epoch 7 batch id 12601 loss 0.47318390011787415 train acc 0.9553210062693437\n",
            "epoch 7 batch id 12801 loss 0.2851632833480835 train acc 0.9553574916022186\n",
            "epoch 7 batch id 13001 loss 0.2199549674987793 train acc 0.9553760287670179\n",
            "epoch 7 batch id 13201 loss 0.09519214183092117 train acc 0.9554011059768199\n",
            "epoch 7 batch id 13401 loss 0.1267922967672348 train acc 0.955437094246698\n",
            "epoch 7 batch id 13601 loss 0.2624640166759491 train acc 0.9555248694948901\n",
            "epoch 7 batch id 13801 loss 0.28724586963653564 train acc 0.9555331135424969\n",
            "epoch 7 batch id 14001 loss 0.010790322907269001 train acc 0.9555388900792801\n",
            "epoch 7 batch id 14201 loss 0.01860400103032589 train acc 0.955509295120062\n",
            "epoch 7 batch id 14401 loss 0.0204485971480608 train acc 0.9555716616901604\n",
            "epoch 7 batch id 14601 loss 0.07794880867004395 train acc 0.955623758646668\n",
            "epoch 7 batch id 14801 loss 0.024443186819553375 train acc 0.9556301094520641\n",
            "epoch 7 batch id 15001 loss 0.231765478849411 train acc 0.9556571228584761\n",
            "epoch 7 batch id 15201 loss 0.1682412326335907 train acc 0.9556752022893231\n",
            "epoch 7 batch id 15401 loss 0.04351123049855232 train acc 0.9556928121550549\n",
            "epoch 7 batch id 15601 loss 0.2339974045753479 train acc 0.9557600474328569\n",
            "epoch 7 batch id 15801 loss 0.08689852058887482 train acc 0.9557919593696601\n",
            "epoch 7 batch id 16001 loss 0.16041120886802673 train acc 0.9558015905255921\n",
            "epoch 7 batch id 16201 loss 0.5084652900695801 train acc 0.9558148416764397\n",
            "epoch 7 batch id 16401 loss 0.5689699649810791 train acc 0.9558506341076763\n",
            "epoch 7 batch id 16601 loss 0.019781136885285378 train acc 0.9559006234564182\n",
            "epoch 7 batch id 16801 loss 0.01398574560880661 train acc 0.9559382626034164\n",
            "epoch 7 batch id 17001 loss 0.19636455178260803 train acc 0.9559198723604494\n",
            "epoch 7 batch id 17201 loss 0.010294351726770401 train acc 0.9559509621533632\n",
            "epoch 7 batch id 17401 loss 0.2646941542625427 train acc 0.9559831331532671\n",
            "epoch 7 batch id 17601 loss 0.021685101091861725 train acc 0.9560341031759559\n",
            "epoch 7 batch id 17801 loss 0.05366082862019539 train acc 0.9560804168305151\n",
            "epoch 7 batch id 18001 loss 0.32357990741729736 train acc 0.9561395894672519\n",
            "epoch 7 batch id 18201 loss 0.0405263714492321 train acc 0.9562163480028569\n",
            "epoch 7 batch id 18401 loss 0.40678977966308594 train acc 0.9563101190152709\n",
            "epoch 7 batch id 18601 loss 0.014389091171324253 train acc 0.9563397129186603\n",
            "epoch 7 batch id 18801 loss 0.020230121910572052 train acc 0.9564118929844158\n",
            "epoch 7 batch id 19001 loss 0.03880304843187332 train acc 0.9564759749486869\n",
            "epoch 7 batch id 19201 loss 0.00683983089402318 train acc 0.9564964064371647\n",
            "epoch 7 batch id 19401 loss 0.13389065861701965 train acc 0.9565470207721252\n",
            "epoch 7 batch id 19601 loss 0.09406741708517075 train acc 0.9565535559410234\n",
            "epoch 7 batch id 19801 loss 0.05636464059352875 train acc 0.9565836321397909\n",
            "epoch 7 batch id 20001 loss 0.26069289445877075 train acc 0.9566302934853257\n",
            "epoch 7 batch id 20201 loss 0.1658625602722168 train acc 0.9566791247958022\n",
            "epoch 7 batch id 20401 loss 0.008899160660803318 train acc 0.9566473457183471\n",
            "epoch 7 batch id 20601 loss 0.122347392141819 train acc 0.9566601742633852\n",
            "epoch 7 batch id 20801 loss 0.1730632483959198 train acc 0.9566802677755877\n",
            "epoch 7 batch id 21001 loss 0.010747662745416164 train acc 0.9566940264749297\n",
            "epoch 7 batch id 21201 loss 0.1720687448978424 train acc 0.9567031036271874\n",
            "epoch 7 batch id 21401 loss 0.024698767811059952 train acc 0.9567295336666511\n",
            "epoch 7 batch id 21601 loss 0.18770954012870789 train acc 0.9567627077450118\n",
            "epoch 7 batch id 21801 loss 0.13026176393032074 train acc 0.9567981399935783\n",
            "epoch 7 batch id 22001 loss 0.03886059671640396 train acc 0.9568386096086542\n",
            "epoch 7 batch id 22201 loss 0.24993327260017395 train acc 0.9568558285662808\n",
            "epoch 7 batch id 22401 loss 0.0668196976184845 train acc 0.9569006405964019\n",
            "epoch 7 batch id 22601 loss 0.22579433023929596 train acc 0.9569156232025131\n",
            "epoch 7 batch id 22801 loss 0.24426676332950592 train acc 0.9569769418007982\n",
            "epoch 7 batch id 23001 loss 0.23504599928855896 train acc 0.9569842072083823\n",
            "epoch 7 batch id 23201 loss 0.08398052304983139 train acc 0.95702906124736\n",
            "epoch 7 batch id 23401 loss 0.03940583020448685 train acc 0.95707849023546\n",
            "epoch 7 batch id 23601 loss 0.19232457876205444 train acc 0.9570953031651201\n",
            "epoch 7 batch id 23801 loss 0.08144531399011612 train acc 0.9571485966976178\n",
            "epoch 7 batch id 24001 loss 0.34661316871643066 train acc 0.9571892837798425\n",
            "epoch 7 batch id 24201 loss 0.09504688531160355 train acc 0.9572292983761002\n",
            "epoch 7 batch id 24401 loss 0.1202891543507576 train acc 0.9572673763370354\n",
            "epoch 7 batch id 24601 loss 0.022661328315734863 train acc 0.9573353217348888\n",
            "epoch 7 batch id 24801 loss 0.017387961968779564 train acc 0.9573870509253659\n",
            "epoch 7 batch id 25001 loss 1.0504497289657593 train acc 0.9574004539818407\n",
            "epoch 7 train acc 0.9573972561706207\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43cc75b9a4c64589b3c263dab44bd849"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 validation acc 0.92531\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25038 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "712689531311415b9878e9470a6be50e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 batch id 1 loss 0.3012804090976715 train acc 0.90625\n",
            "epoch 8 batch id 201 loss 0.4981899559497833 train acc 0.9643967661691543\n",
            "epoch 8 batch id 401 loss 0.22691486775875092 train acc 0.9652431421446384\n",
            "epoch 8 batch id 601 loss 0.08897526562213898 train acc 0.9636543261231281\n",
            "epoch 8 batch id 801 loss 0.2811928391456604 train acc 0.9634831460674157\n",
            "epoch 8 batch id 1001 loss 0.14702990651130676 train acc 0.9630057442557443\n",
            "epoch 8 batch id 1201 loss 0.021446481347084045 train acc 0.9632077435470441\n",
            "epoch 8 batch id 1401 loss 0.21287375688552856 train acc 0.9637535688793719\n",
            "epoch 8 batch id 1601 loss 0.3300410211086273 train acc 0.9631480324797002\n",
            "epoch 8 batch id 1801 loss 0.01280923280864954 train acc 0.9630760688506386\n",
            "epoch 8 batch id 2001 loss 0.18065550923347473 train acc 0.9625343578210894\n",
            "epoch 8 batch id 2201 loss 0.36214005947113037 train acc 0.9625312358019082\n",
            "epoch 8 batch id 2401 loss 0.34727030992507935 train acc 0.9625806955435235\n",
            "epoch 8 batch id 2601 loss 0.06618715077638626 train acc 0.9623702422145328\n",
            "epoch 8 batch id 2801 loss 0.004814641550183296 train acc 0.9621786861835059\n",
            "epoch 8 batch id 3001 loss 0.2646888792514801 train acc 0.9621480339886704\n",
            "epoch 8 batch id 3201 loss 0.07340843230485916 train acc 0.96217002499219\n",
            "epoch 8 batch id 3401 loss 0.20574820041656494 train acc 0.9622078065274919\n",
            "epoch 8 batch id 3601 loss 0.008512061089277267 train acc 0.9623889197445155\n",
            "epoch 8 batch id 3801 loss 0.024692125618457794 train acc 0.9625509734280453\n",
            "epoch 8 batch id 4001 loss 0.6752545833587646 train acc 0.9625796675831042\n",
            "epoch 8 batch id 4201 loss 0.2853553593158722 train acc 0.962434539395382\n",
            "epoch 8 batch id 4401 loss 0.07790219783782959 train acc 0.9623523062940241\n",
            "epoch 8 batch id 4601 loss 0.03301914781332016 train acc 0.9626983264507716\n",
            "epoch 8 batch id 4801 loss 0.4755602777004242 train acc 0.9624817746302854\n",
            "epoch 8 batch id 5001 loss 0.2536885738372803 train acc 0.9625449910017997\n",
            "epoch 8 batch id 5201 loss 0.12997230887413025 train acc 0.9624771678523361\n",
            "epoch 8 batch id 5401 loss 0.08342093974351883 train acc 0.9626342344010368\n",
            "epoch 8 batch id 5601 loss 0.0835820734500885 train acc 0.9625736475629352\n",
            "epoch 8 batch id 5801 loss 0.023748574778437614 train acc 0.962614204447509\n",
            "epoch 8 batch id 6001 loss 0.05972526967525482 train acc 0.9625218713547742\n",
            "epoch 8 batch id 6201 loss 0.37000811100006104 train acc 0.9624405337848734\n",
            "epoch 8 batch id 6401 loss 0.09489145129919052 train acc 0.9623349867208248\n",
            "epoch 8 batch id 6601 loss 0.019573969766497612 train acc 0.9622689743978186\n",
            "epoch 8 batch id 6801 loss 0.0516061894595623 train acc 0.9624365902073224\n",
            "epoch 8 batch id 7001 loss 0.1338324099779129 train acc 0.9625098200257106\n",
            "epoch 8 batch id 7201 loss 0.06312690675258636 train acc 0.9624965282599639\n",
            "epoch 8 batch id 7401 loss 0.04890919849276543 train acc 0.9625768477232807\n",
            "epoch 8 batch id 7601 loss 0.18427371978759766 train acc 0.9626036047888435\n",
            "epoch 8 batch id 7801 loss 0.3301035165786743 train acc 0.9626169721830534\n",
            "epoch 8 batch id 8001 loss 0.28004780411720276 train acc 0.962586707911511\n",
            "epoch 8 batch id 8201 loss 0.29887986183166504 train acc 0.9627027191805877\n",
            "epoch 8 batch id 8401 loss 0.018558837473392487 train acc 0.9627239316748006\n",
            "epoch 8 batch id 8601 loss 0.04212527349591255 train acc 0.9627041913730962\n",
            "epoch 8 batch id 8801 loss 0.005516418255865574 train acc 0.9627066526531076\n",
            "epoch 8 batch id 9001 loss 0.2926003336906433 train acc 0.9627958004666148\n",
            "epoch 8 batch id 9201 loss 0.015529794618487358 train acc 0.9629388109988045\n",
            "epoch 8 batch id 9401 loss 0.016535596922039986 train acc 0.962942772045527\n",
            "epoch 8 batch id 9601 loss 0.0254896841943264 train acc 0.9629921362358088\n",
            "epoch 8 batch id 9801 loss 0.19304051995277405 train acc 0.9629980359147026\n",
            "epoch 8 batch id 10001 loss 0.03739968314766884 train acc 0.9630661933806619\n",
            "epoch 8 batch id 10201 loss 0.30246201157569885 train acc 0.9630520292128223\n",
            "epoch 8 batch id 10401 loss 0.005218705628067255 train acc 0.9631045091818095\n",
            "epoch 8 batch id 10601 loss 0.08790349960327148 train acc 0.9631048957645505\n",
            "epoch 8 batch id 10801 loss 0.005747726187109947 train acc 0.9631631330432368\n",
            "epoch 8 batch id 11001 loss 0.1907932460308075 train acc 0.9631510771748023\n",
            "epoch 8 batch id 11201 loss 0.19042213261127472 train acc 0.9632203597893045\n",
            "epoch 8 batch id 11401 loss 0.16969120502471924 train acc 0.9632159459696518\n",
            "epoch 8 batch id 11601 loss 0.4211398661136627 train acc 0.9632547840703387\n",
            "epoch 8 batch id 11801 loss 0.03866971656680107 train acc 0.9632419922040505\n",
            "epoch 8 batch id 12001 loss 0.39134904742240906 train acc 0.9632921214898759\n",
            "epoch 8 batch id 12201 loss 0.021166961640119553 train acc 0.963320117203508\n",
            "epoch 8 batch id 12401 loss 0.45098787546157837 train acc 0.9633799693573099\n",
            "epoch 8 batch id 12601 loss 0.42363399267196655 train acc 0.9634329616697087\n",
            "epoch 8 batch id 12801 loss 0.21989932656288147 train acc 0.9634916217483009\n",
            "epoch 8 batch id 13001 loss 0.14962883293628693 train acc 0.9634955964925775\n",
            "epoch 8 batch id 13201 loss 0.10079067200422287 train acc 0.9635160215135217\n",
            "epoch 8 batch id 13401 loss 0.12859554588794708 train acc 0.9635381687933736\n",
            "epoch 8 batch id 13601 loss 0.32801857590675354 train acc 0.9636079148592015\n",
            "epoch 8 batch id 13801 loss 0.37035608291625977 train acc 0.9636212955582929\n",
            "epoch 8 batch id 14001 loss 0.010007554665207863 train acc 0.9635851903435468\n",
            "epoch 8 batch id 14201 loss 0.00604785792529583 train acc 0.9635567037532569\n",
            "epoch 8 batch id 14401 loss 0.005247631575912237 train acc 0.9635941080480522\n",
            "epoch 8 batch id 14601 loss 0.09824889898300171 train acc 0.9636197863160058\n",
            "epoch 8 batch id 14801 loss 0.01649695262312889 train acc 0.9636088777785284\n",
            "epoch 8 batch id 15001 loss 0.20306789875030518 train acc 0.963621175254983\n",
            "epoch 8 batch id 15201 loss 0.08856149762868881 train acc 0.9636434280639432\n",
            "epoch 8 batch id 15401 loss 0.03798186779022217 train acc 0.963632637491072\n",
            "epoch 8 batch id 15601 loss 0.11926119029521942 train acc 0.9636822158835973\n",
            "epoch 8 batch id 15801 loss 0.03711297735571861 train acc 0.96371076197709\n",
            "epoch 8 batch id 16001 loss 0.16514480113983154 train acc 0.9637151584275983\n",
            "epoch 8 batch id 16201 loss 0.4213128685951233 train acc 0.9637040151842479\n",
            "epoch 8 batch id 16401 loss 0.5048678517341614 train acc 0.9637445887445888\n",
            "epoch 8 batch id 16601 loss 0.008147647604346275 train acc 0.96377477260406\n",
            "epoch 8 batch id 16801 loss 0.007182649336755276 train acc 0.9637930777929885\n",
            "epoch 8 batch id 17001 loss 0.04315713420510292 train acc 0.9637833803893888\n",
            "epoch 8 batch id 17201 loss 0.012101086787879467 train acc 0.9637938927969304\n",
            "epoch 8 batch id 17401 loss 0.21115082502365112 train acc 0.9638149387966208\n",
            "epoch 8 batch id 17601 loss 0.03988441824913025 train acc 0.9638639139821601\n",
            "epoch 8 batch id 17801 loss 0.008159593679010868 train acc 0.9639275883377338\n",
            "epoch 8 batch id 18001 loss 0.2328222393989563 train acc 0.9639724876395755\n",
            "epoch 8 batch id 18201 loss 0.044597748667001724 train acc 0.9640507389703863\n",
            "epoch 8 batch id 18401 loss 0.30756187438964844 train acc 0.9641306858322918\n",
            "epoch 8 batch id 18601 loss 0.015627918764948845 train acc 0.9641585129831729\n",
            "epoch 8 batch id 18801 loss 0.009932349435985088 train acc 0.9641707887878305\n",
            "epoch 8 batch id 19001 loss 0.03065893054008484 train acc 0.9642354349771065\n",
            "epoch 8 batch id 19201 loss 0.005218583159148693 train acc 0.9642466538201135\n",
            "epoch 8 batch id 19401 loss 0.04715963080525398 train acc 0.9642753595175506\n",
            "epoch 8 batch id 19601 loss 0.19504669308662415 train acc 0.9642891306565992\n",
            "epoch 8 batch id 19801 loss 0.035315755754709244 train acc 0.9643215620423211\n",
            "epoch 8 batch id 20001 loss 0.22028489410877228 train acc 0.9643267836608169\n",
            "epoch 8 batch id 20201 loss 0.09187544882297516 train acc 0.9643968739171328\n",
            "epoch 8 batch id 20401 loss 0.0059601375833153725 train acc 0.9643798098132444\n",
            "epoch 8 batch id 20601 loss 0.013036752119660378 train acc 0.9643873477015679\n",
            "epoch 8 batch id 20801 loss 0.17540717124938965 train acc 0.9644082616220374\n",
            "epoch 8 batch id 21001 loss 0.007368901744484901 train acc 0.9644347292986049\n",
            "epoch 8 batch id 21201 loss 0.07747554779052734 train acc 0.9644371138153861\n",
            "epoch 8 batch id 21401 loss 0.012415922246873379 train acc 0.9644511354609597\n",
            "epoch 8 batch id 21601 loss 0.09537012130022049 train acc 0.964489491227258\n",
            "epoch 8 batch id 21801 loss 0.11891315132379532 train acc 0.9645185427273978\n",
            "epoch 8 batch id 22001 loss 0.10023821890354156 train acc 0.9645598495522931\n",
            "epoch 8 batch id 22201 loss 0.20772486925125122 train acc 0.9645764830413045\n",
            "epoch 8 batch id 22401 loss 0.10324624925851822 train acc 0.9646053747600554\n",
            "epoch 8 batch id 22601 loss 0.2047225534915924 train acc 0.9646240763683023\n",
            "epoch 8 batch id 22801 loss 0.25964784622192383 train acc 0.964668490417087\n",
            "epoch 8 batch id 23001 loss 0.2089242786169052 train acc 0.9646605038911351\n",
            "epoch 8 batch id 23201 loss 0.1003713607788086 train acc 0.9646957566484203\n",
            "epoch 8 batch id 23401 loss 0.015050111338496208 train acc 0.9647504380154694\n",
            "epoch 8 batch id 23601 loss 0.14942866563796997 train acc 0.9647631456294224\n",
            "epoch 8 batch id 23801 loss 0.030261311680078506 train acc 0.9647979601697407\n",
            "epoch 8 batch id 24001 loss 0.2013031244277954 train acc 0.9648374026082247\n",
            "epoch 8 batch id 24201 loss 0.05727022886276245 train acc 0.9648645717119128\n",
            "epoch 8 batch id 24401 loss 0.09982988238334656 train acc 0.964895137494365\n",
            "epoch 8 batch id 24601 loss 0.01795855537056923 train acc 0.96493409820739\n",
            "epoch 8 batch id 24801 loss 0.01028332207351923 train acc 0.9649774706665054\n",
            "epoch 8 batch id 25001 loss 0.8499723672866821 train acc 0.9649789008439662\n",
            "epoch 8 train acc 0.9649694963655244\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "452d5056b2d747d8ab374af143d1a187"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 validation acc 0.925645\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25038 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0afcb2bec1c449cacda9a80c94af13b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 batch id 1 loss 0.28223228454589844 train acc 0.9375\n",
            "epoch 9 batch id 201 loss 0.44087910652160645 train acc 0.9706156716417911\n",
            "epoch 9 batch id 401 loss 0.21379229426383972 train acc 0.971399625935162\n",
            "epoch 9 batch id 601 loss 0.014975251629948616 train acc 0.9685420133111481\n",
            "epoch 9 batch id 801 loss 0.26262593269348145 train acc 0.969608302122347\n",
            "epoch 9 batch id 1001 loss 0.12735207378864288 train acc 0.9691870629370629\n",
            "epoch 9 batch id 1201 loss 0.02556728757917881 train acc 0.9690101998334721\n",
            "epoch 9 batch id 1401 loss 0.22551098465919495 train acc 0.9697314418272662\n",
            "epoch 9 batch id 1601 loss 0.2584196925163269 train acc 0.9692770143660212\n",
            "epoch 9 batch id 1801 loss 0.01963559165596962 train acc 0.9691143808995003\n",
            "epoch 9 batch id 2001 loss 0.2293916791677475 train acc 0.9686250624687656\n",
            "epoch 9 batch id 2201 loss 0.28707534074783325 train acc 0.9684092457973649\n",
            "epoch 9 batch id 2401 loss 0.32685157656669617 train acc 0.9685287380258226\n",
            "epoch 9 batch id 2601 loss 0.07946116477251053 train acc 0.9684856785851595\n",
            "epoch 9 batch id 2801 loss 0.018311170861124992 train acc 0.9685268654052124\n",
            "epoch 9 batch id 3001 loss 0.0669318437576294 train acc 0.9685417360879707\n",
            "epoch 9 batch id 3201 loss 0.02174234203994274 train acc 0.968525460793502\n",
            "epoch 9 batch id 3401 loss 0.11286991089582443 train acc 0.9685386650985004\n",
            "epoch 9 batch id 3601 loss 0.004773067310452461 train acc 0.9687847125798389\n",
            "epoch 9 batch id 3801 loss 0.029190080240368843 train acc 0.9688815443304394\n",
            "epoch 9 batch id 4001 loss 0.6659079194068909 train acc 0.968992126968258\n",
            "epoch 9 batch id 4201 loss 0.22916284203529358 train acc 0.9689210902166151\n",
            "epoch 9 batch id 4401 loss 0.04007287696003914 train acc 0.9687855032947057\n",
            "epoch 9 batch id 4601 loss 0.014304287731647491 train acc 0.9689537600521626\n",
            "epoch 9 batch id 4801 loss 0.5234300494194031 train acc 0.968802072484899\n",
            "epoch 9 batch id 5001 loss 0.23059368133544922 train acc 0.9688687262547491\n",
            "epoch 9 batch id 5201 loss 0.09399417042732239 train acc 0.9687800422995578\n",
            "epoch 9 batch id 5401 loss 0.06892810016870499 train acc 0.9689004351046102\n",
            "epoch 9 batch id 5601 loss 0.1001473069190979 train acc 0.9688671665773969\n",
            "epoch 9 batch id 5801 loss 0.009593464434146881 train acc 0.9689600930873987\n",
            "epoch 9 batch id 6001 loss 0.013866860419511795 train acc 0.9689739210131645\n",
            "epoch 9 batch id 6201 loss 0.4294711947441101 train acc 0.9689163038219643\n",
            "epoch 9 batch id 6401 loss 0.05969029292464256 train acc 0.9688964614903921\n",
            "epoch 9 batch id 6601 loss 0.022934572771191597 train acc 0.9688588850174216\n",
            "epoch 9 batch id 6801 loss 0.07419867068529129 train acc 0.9689292015880018\n",
            "epoch 9 batch id 7001 loss 0.10862316936254501 train acc 0.9689776460505642\n",
            "epoch 9 batch id 7201 loss 0.03468494489789009 train acc 0.9690364185529787\n",
            "epoch 9 batch id 7401 loss 0.3690994083881378 train acc 0.9690540129712201\n",
            "epoch 9 batch id 7601 loss 0.1991485357284546 train acc 0.9691282397053019\n",
            "epoch 9 batch id 7801 loss 0.3612726628780365 train acc 0.9691586014613511\n",
            "epoch 9 batch id 8001 loss 0.21694757044315338 train acc 0.9690976127984002\n",
            "epoch 9 batch id 8201 loss 0.03665824607014656 train acc 0.9691158090476771\n",
            "epoch 9 batch id 8401 loss 0.016764827072620392 train acc 0.9690922211641472\n",
            "epoch 9 batch id 8601 loss 0.056045051664114 train acc 0.9690261306824788\n",
            "epoch 9 batch id 8801 loss 0.005516461096704006 train acc 0.9690766674241563\n",
            "epoch 9 batch id 9001 loss 0.2145368903875351 train acc 0.9691527330296633\n",
            "epoch 9 batch id 9201 loss 0.006960096303373575 train acc 0.969276437343767\n",
            "epoch 9 batch id 9401 loss 0.0033227107487618923 train acc 0.9692652377406659\n",
            "epoch 9 batch id 9601 loss 0.011276953853666782 train acc 0.9692968180397875\n",
            "epoch 9 batch id 9801 loss 0.12026386708021164 train acc 0.9693334863789409\n",
            "epoch 9 batch id 10001 loss 0.01639181189239025 train acc 0.9693749375062494\n",
            "epoch 9 batch id 10201 loss 0.0513092502951622 train acc 0.9693810655818057\n",
            "epoch 9 batch id 10401 loss 0.006163210608065128 train acc 0.9694079896163831\n",
            "epoch 9 batch id 10601 loss 0.04306747764348984 train acc 0.9694633760965946\n",
            "epoch 9 batch id 10801 loss 0.003541661659255624 train acc 0.9694385936487362\n",
            "epoch 9 batch id 11001 loss 0.15161031484603882 train acc 0.9693948277429325\n",
            "epoch 9 batch id 11201 loss 0.05912068858742714 train acc 0.9694670118739398\n",
            "epoch 9 batch id 11401 loss 0.05811118707060814 train acc 0.969435246908166\n",
            "epoch 9 batch id 11601 loss 0.41287729144096375 train acc 0.9694773079906904\n",
            "epoch 9 batch id 11801 loss 0.031979914754629135 train acc 0.969486166426574\n",
            "epoch 9 batch id 12001 loss 0.03282025456428528 train acc 0.9695494125489542\n",
            "epoch 9 batch id 12201 loss 0.005971788894385099 train acc 0.9695721662158839\n",
            "epoch 9 batch id 12401 loss 0.476869136095047 train acc 0.9695941859527457\n",
            "epoch 9 batch id 12601 loss 0.5275987386703491 train acc 0.9696130267439093\n",
            "epoch 9 batch id 12801 loss 0.21949438750743866 train acc 0.9696508085305835\n",
            "epoch 9 batch id 13001 loss 0.18659299612045288 train acc 0.9696249326974848\n",
            "epoch 9 batch id 13201 loss 0.09153548628091812 train acc 0.9696306151049163\n",
            "epoch 9 batch id 13401 loss 0.03216477110981941 train acc 0.9696407917319603\n",
            "epoch 9 batch id 13601 loss 0.21910659968852997 train acc 0.9696874310712448\n",
            "epoch 9 batch id 13801 loss 0.24185119569301605 train acc 0.9696625244547497\n",
            "epoch 9 batch id 14001 loss 0.003013353329151869 train acc 0.9696360974216127\n",
            "epoch 9 batch id 14201 loss 0.00681571289896965 train acc 0.969610414759524\n",
            "epoch 9 batch id 14401 loss 0.0060604168102145195 train acc 0.9696114853135199\n",
            "epoch 9 batch id 14601 loss 0.032139118760824203 train acc 0.9696253681254708\n",
            "epoch 9 batch id 14801 loss 0.026047322899103165 train acc 0.9696050942503884\n",
            "epoch 9 batch id 15001 loss 0.23422017693519592 train acc 0.969606192920472\n",
            "epoch 9 batch id 15201 loss 0.15139009058475494 train acc 0.9696052068942833\n",
            "epoch 9 batch id 15401 loss 0.01788443885743618 train acc 0.9696123628335822\n",
            "epoch 9 batch id 15601 loss 0.0920117199420929 train acc 0.9696453752964553\n",
            "epoch 9 batch id 15801 loss 0.05064130574464798 train acc 0.9696538193785204\n",
            "epoch 9 batch id 16001 loss 0.27346453070640564 train acc 0.9696542403599775\n",
            "epoch 9 batch id 16201 loss 0.2651267647743225 train acc 0.9696951577063144\n",
            "epoch 9 batch id 16401 loss 0.3636780381202698 train acc 0.9697103072983355\n",
            "epoch 9 batch id 16601 loss 0.0072979493997991085 train acc 0.9697288566953798\n",
            "epoch 9 batch id 16801 loss 0.007452548947185278 train acc 0.9697339444080709\n",
            "epoch 9 batch id 17001 loss 0.03173653781414032 train acc 0.9697536174342686\n",
            "epoch 9 batch id 17201 loss 0.005638667847961187 train acc 0.9697728329748271\n",
            "epoch 9 batch id 17401 loss 0.14925290644168854 train acc 0.9697772398138038\n",
            "epoch 9 batch id 17601 loss 0.03690366819500923 train acc 0.9698046275779785\n",
            "epoch 9 batch id 17801 loss 0.022768354043364525 train acc 0.9698436885568227\n",
            "epoch 9 batch id 18001 loss 0.25761765241622925 train acc 0.969874937503472\n",
            "epoch 9 batch id 18201 loss 0.011698021553456783 train acc 0.9699140843909675\n",
            "epoch 9 batch id 18401 loss 0.2599788010120392 train acc 0.9699608716917559\n",
            "epoch 9 batch id 18601 loss 0.01075113657861948 train acc 0.9699612924036343\n",
            "epoch 9 batch id 18801 loss 0.011224690824747086 train acc 0.9699750013297165\n",
            "epoch 9 batch id 19001 loss 0.0351010225713253 train acc 0.9700098021156781\n",
            "epoch 9 batch id 19201 loss 0.0031844957266002893 train acc 0.9700048174574241\n",
            "epoch 9 batch id 19401 loss 0.04603388160467148 train acc 0.9700176537291892\n",
            "epoch 9 batch id 19601 loss 0.10790363699197769 train acc 0.9700158792918728\n",
            "epoch 9 batch id 19801 loss 0.004459381103515625 train acc 0.9700220317155699\n",
            "epoch 9 batch id 20001 loss 0.27120882272720337 train acc 0.9700155617219139\n",
            "epoch 9 batch id 20201 loss 0.030067231506109238 train acc 0.9700401589030246\n",
            "epoch 9 batch id 20401 loss 0.004836963955312967 train acc 0.9700198519680407\n",
            "epoch 9 batch id 20601 loss 0.004316443577408791 train acc 0.9699999393233338\n",
            "epoch 9 batch id 20801 loss 0.10346377640962601 train acc 0.9700044469015913\n",
            "epoch 9 batch id 21001 loss 0.011382272467017174 train acc 0.9700133326984429\n",
            "epoch 9 batch id 21201 loss 0.04989778250455856 train acc 0.9700132069242017\n",
            "epoch 9 batch id 21401 loss 0.0043401108123362064 train acc 0.9700233049857483\n",
            "epoch 9 batch id 21601 loss 0.11525274813175201 train acc 0.9700390028239433\n",
            "epoch 9 batch id 21801 loss 0.058405615389347076 train acc 0.9700630131645337\n",
            "epoch 9 batch id 22001 loss 0.03770525008440018 train acc 0.970089427753284\n",
            "epoch 9 batch id 22201 loss 0.19223015010356903 train acc 0.9701083284536732\n",
            "epoch 9 batch id 22401 loss 0.020135479047894478 train acc 0.970129681710638\n",
            "epoch 9 batch id 22601 loss 0.1563376635313034 train acc 0.9701465090040263\n",
            "epoch 9 batch id 22801 loss 0.2367601990699768 train acc 0.9701712644182273\n",
            "epoch 9 batch id 23001 loss 0.11406129598617554 train acc 0.9701493956784487\n",
            "epoch 9 batch id 23201 loss 0.10655051469802856 train acc 0.9701736994095083\n",
            "epoch 9 batch id 23401 loss 0.01787455566227436 train acc 0.9702162834921585\n",
            "epoch 9 batch id 23601 loss 0.18321366608142853 train acc 0.9702276916232363\n",
            "epoch 9 batch id 23801 loss 0.016252024099230766 train acc 0.9702546636695937\n",
            "epoch 9 batch id 24001 loss 0.1422293335199356 train acc 0.9702798841714928\n",
            "epoch 9 batch id 24201 loss 0.08113640546798706 train acc 0.9702724060989215\n",
            "epoch 9 batch id 24401 loss 0.11006253212690353 train acc 0.9702881029466005\n",
            "epoch 9 batch id 24601 loss 0.032676320523023605 train acc 0.9703187878541523\n",
            "epoch 9 batch id 24801 loss 0.008091953583061695 train acc 0.9703489778637958\n",
            "epoch 9 batch id 25001 loss 0.9665741324424744 train acc 0.970336186552538\n",
            "epoch 9 train acc 0.9703263539420082\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4649e26bc7de4362853c75a4150f989d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 validation acc 0.926295\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25038 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1affdc38a8ac4c76a135002c6dba0916"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 batch id 1 loss 0.26175621151924133 train acc 0.9375\n",
            "epoch 10 batch id 201 loss 0.537787675857544 train acc 0.9752798507462687\n",
            "epoch 10 batch id 401 loss 0.2115953117609024 train acc 0.9743609725685786\n",
            "epoch 10 batch id 601 loss 0.005792762152850628 train acc 0.9727017470881864\n",
            "epoch 10 batch id 801 loss 0.3165817856788635 train acc 0.9730024968789014\n",
            "epoch 10 batch id 1001 loss 0.1187845915555954 train acc 0.9723401598401599\n",
            "epoch 10 batch id 1201 loss 0.05797606706619263 train acc 0.9724708576186512\n",
            "epoch 10 batch id 1401 loss 0.18614976108074188 train acc 0.9728988222698073\n",
            "epoch 10 batch id 1601 loss 0.20468424260616302 train acc 0.9724000624609619\n",
            "epoch 10 batch id 1801 loss 0.02793189510703087 train acc 0.9722029428095502\n",
            "epoch 10 batch id 2001 loss 0.1120668351650238 train acc 0.9720608445777111\n",
            "epoch 10 batch id 2201 loss 0.3355885446071625 train acc 0.9720297592003635\n",
            "epoch 10 batch id 2401 loss 0.20434026420116425 train acc 0.9721990837151187\n",
            "epoch 10 batch id 2601 loss 0.025567730888724327 train acc 0.9721861783929258\n",
            "epoch 10 batch id 2801 loss 0.007452511694282293 train acc 0.9723313102463406\n",
            "epoch 10 batch id 3001 loss 0.07232517749071121 train acc 0.9722384205264911\n",
            "epoch 10 batch id 3201 loss 0.020831026136875153 train acc 0.9721864261168385\n",
            "epoch 10 batch id 3401 loss 0.1529199630022049 train acc 0.9720854160541017\n",
            "epoch 10 batch id 3601 loss 0.0036330237053334713 train acc 0.9723167175784504\n",
            "epoch 10 batch id 3801 loss 0.019952580332756042 train acc 0.9724496842936069\n",
            "epoch 10 batch id 4001 loss 0.6021921634674072 train acc 0.9725927893026743\n",
            "epoch 10 batch id 4201 loss 0.1458236426115036 train acc 0.9726106879314449\n",
            "epoch 10 batch id 4401 loss 0.04488131031394005 train acc 0.9724281413315156\n",
            "epoch 10 batch id 4601 loss 0.005240392871201038 train acc 0.9726010649858726\n",
            "epoch 10 batch id 4801 loss 0.36100849509239197 train acc 0.9724276192459904\n",
            "epoch 10 batch id 5001 loss 0.21791964769363403 train acc 0.9724805038992201\n",
            "epoch 10 batch id 5201 loss 0.04879482835531235 train acc 0.9724512113055181\n",
            "epoch 10 batch id 5401 loss 0.03808176517486572 train acc 0.9725803092019997\n",
            "epoch 10 batch id 5601 loss 0.1636812537908554 train acc 0.9725495447241564\n",
            "epoch 10 batch id 5801 loss 0.007464919239282608 train acc 0.972580158593346\n",
            "epoch 10 batch id 6001 loss 0.04688994958996773 train acc 0.972556657223796\n",
            "epoch 10 batch id 6201 loss 0.3221801519393921 train acc 0.9724338816319948\n",
            "epoch 10 batch id 6401 loss 0.08803892880678177 train acc 0.9723529526636463\n",
            "epoch 10 batch id 6601 loss 0.010170286521315575 train acc 0.972286396000606\n",
            "epoch 10 batch id 6801 loss 0.049302838742733 train acc 0.9723386266725481\n",
            "epoch 10 batch id 7001 loss 0.11128833889961243 train acc 0.9723655549207256\n",
            "epoch 10 batch id 7201 loss 0.09972254931926727 train acc 0.972417025413137\n",
            "epoch 10 batch id 7401 loss 0.05311881750822067 train acc 0.9724277124712877\n",
            "epoch 10 batch id 7601 loss 0.24255406856536865 train acc 0.9724337258255493\n",
            "epoch 10 batch id 7801 loss 0.3446856439113617 train acc 0.9724434367388797\n",
            "epoch 10 batch id 8001 loss 0.07018835842609406 train acc 0.9723784526934133\n",
            "epoch 10 batch id 8201 loss 0.07644841820001602 train acc 0.9724004694549445\n",
            "epoch 10 batch id 8401 loss 0.013927580788731575 train acc 0.9723582014045947\n",
            "epoch 10 batch id 8601 loss 0.030412791296839714 train acc 0.9723542320660389\n",
            "epoch 10 batch id 8801 loss 0.005982190370559692 train acc 0.9723930519259175\n",
            "epoch 10 batch id 9001 loss 0.2248029112815857 train acc 0.9724613931785357\n",
            "epoch 10 batch id 9201 loss 0.004045901354402304 train acc 0.9725709162047603\n",
            "epoch 10 batch id 9401 loss 0.006593458820134401 train acc 0.9725428145941921\n",
            "epoch 10 batch id 9601 loss 0.013303104788064957 train acc 0.9725777262785127\n",
            "epoch 10 batch id 9801 loss 0.11456656455993652 train acc 0.9725888939904092\n",
            "epoch 10 batch id 10001 loss 0.05572749301791191 train acc 0.9726027397260274\n",
            "epoch 10 batch id 10201 loss 0.051884714514017105 train acc 0.9725854082933045\n",
            "epoch 10 batch id 10401 loss 0.0037005427293479443 train acc 0.9726408518411691\n",
            "epoch 10 batch id 10601 loss 0.09569216519594193 train acc 0.9725969248184133\n",
            "epoch 10 batch id 10801 loss 0.0032444200478494167 train acc 0.9725661975742986\n",
            "epoch 10 batch id 11001 loss 0.08596041053533554 train acc 0.9725309062812472\n",
            "epoch 10 batch id 11201 loss 0.07401853054761887 train acc 0.9725415141505223\n",
            "epoch 10 batch id 11401 loss 0.055774204432964325 train acc 0.97251611700728\n",
            "epoch 10 batch id 11601 loss 0.35558438301086426 train acc 0.9725454702180847\n",
            "epoch 10 batch id 11801 loss 0.029332518577575684 train acc 0.9725499957630709\n",
            "epoch 10 batch id 12001 loss 0.02414354681968689 train acc 0.9725647862678111\n",
            "epoch 10 batch id 12201 loss 0.0059137288480997086 train acc 0.9725355503647242\n",
            "epoch 10 batch id 12401 loss 0.5122472643852234 train acc 0.9725752963470687\n",
            "epoch 10 batch id 12601 loss 0.3674156367778778 train acc 0.9726137806523292\n",
            "epoch 10 batch id 12801 loss 0.24907153844833374 train acc 0.9726315326927584\n",
            "epoch 10 batch id 13001 loss 0.13486707210540771 train acc 0.9726174909622337\n",
            "epoch 10 batch id 13201 loss 0.038252562284469604 train acc 0.9726251799106128\n",
            "epoch 10 batch id 13401 loss 0.04143198952078819 train acc 0.9726163159465712\n",
            "epoch 10 batch id 13601 loss 0.1834215372800827 train acc 0.972681236673774\n",
            "epoch 10 batch id 13801 loss 0.29983192682266235 train acc 0.9726378523295414\n",
            "epoch 10 batch id 14001 loss 0.0032569593749940395 train acc 0.9726224912506249\n",
            "epoch 10 batch id 14201 loss 0.003842415288090706 train acc 0.9725767551580875\n",
            "epoch 10 batch id 14401 loss 0.003162401495501399 train acc 0.9725843691410319\n",
            "epoch 10 batch id 14601 loss 0.054624274373054504 train acc 0.9725832134785288\n",
            "epoch 10 batch id 14801 loss 0.00863553211092949 train acc 0.9725525302344437\n",
            "epoch 10 batch id 15001 loss 0.1717941164970398 train acc 0.9725726618225452\n",
            "epoch 10 batch id 15201 loss 0.09580346941947937 train acc 0.9725429248075784\n",
            "epoch 10 batch id 15401 loss 0.028988800942897797 train acc 0.9725606291799234\n",
            "epoch 10 batch id 15601 loss 0.22261986136436462 train acc 0.972577879623101\n",
            "epoch 10 batch id 15801 loss 0.013748855330049992 train acc 0.9725828270362635\n",
            "epoch 10 batch id 16001 loss 0.115041583776474 train acc 0.9725915567777014\n",
            "epoch 10 batch id 16201 loss 0.34507256746292114 train acc 0.9726174310227764\n",
            "epoch 10 batch id 16401 loss 0.4489021301269531 train acc 0.9726483903420523\n",
            "epoch 10 batch id 16601 loss 0.005500064697116613 train acc 0.9726390729474128\n",
            "epoch 10 batch id 16801 loss 0.024017352610826492 train acc 0.972626257365633\n",
            "epoch 10 batch id 17001 loss 0.014151948504149914 train acc 0.9726247720722311\n",
            "epoch 10 batch id 17201 loss 0.0032326222863048315 train acc 0.9726142375443289\n",
            "epoch 10 batch id 17401 loss 0.12773635983467102 train acc 0.9726272915349693\n",
            "epoch 10 batch id 17601 loss 0.017275404185056686 train acc 0.9726542525992842\n",
            "epoch 10 batch id 17801 loss 0.004889845382422209 train acc 0.9726911409471378\n",
            "epoch 10 batch id 18001 loss 0.3004175126552582 train acc 0.9727167935114716\n",
            "epoch 10 batch id 18201 loss 0.011515866965055466 train acc 0.9727487500686776\n",
            "epoch 10 batch id 18401 loss 0.3519049882888794 train acc 0.972783408510407\n",
            "epoch 10 batch id 18601 loss 0.007049808278679848 train acc 0.9727921213913231\n",
            "epoch 10 batch id 18801 loss 0.005107223521918058 train acc 0.9728039731929152\n",
            "epoch 10 batch id 19001 loss 0.029132703319191933 train acc 0.9728369559496869\n",
            "epoch 10 batch id 19201 loss 0.007592418696731329 train acc 0.9728497213686788\n",
            "epoch 10 batch id 19401 loss 0.08715173602104187 train acc 0.9728428946961497\n",
            "epoch 10 batch id 19601 loss 0.06390993297100067 train acc 0.9728346130299474\n",
            "epoch 10 batch id 19801 loss 0.004840509500354528 train acc 0.9728264986616838\n",
            "epoch 10 batch id 20001 loss 0.19440466165542603 train acc 0.9728185465726714\n",
            "epoch 10 batch id 20201 loss 0.054633136838674545 train acc 0.9728308623335479\n",
            "epoch 10 batch id 20401 loss 0.007785763591527939 train acc 0.9727831969021127\n",
            "epoch 10 batch id 20601 loss 0.0077298409305512905 train acc 0.972769829134508\n",
            "epoch 10 batch id 20801 loss 0.08263787627220154 train acc 0.9727762487380415\n",
            "epoch 10 batch id 21001 loss 0.009382108226418495 train acc 0.9727929622398933\n",
            "epoch 10 batch id 21201 loss 0.06898924708366394 train acc 0.9727725107306259\n",
            "epoch 10 batch id 21401 loss 0.004892599303275347 train acc 0.9727845661417691\n",
            "epoch 10 batch id 21601 loss 0.09109299629926682 train acc 0.9728108652377204\n",
            "epoch 10 batch id 21801 loss 0.03616584837436676 train acc 0.9728137470758222\n",
            "epoch 10 batch id 22001 loss 0.05514682084321976 train acc 0.9728250988591428\n",
            "epoch 10 batch id 22201 loss 0.2720247805118561 train acc 0.9728348385207873\n",
            "epoch 10 batch id 22401 loss 0.005499792285263538 train acc 0.9728416142136512\n",
            "epoch 10 batch id 22601 loss 0.1582622230052948 train acc 0.9728427392593249\n",
            "epoch 10 batch id 22801 loss 0.22980327904224396 train acc 0.9728644028770668\n",
            "epoch 10 batch id 23001 loss 0.1780797690153122 train acc 0.9728354201991217\n",
            "epoch 10 batch id 23201 loss 0.08061622828245163 train acc 0.9728379164691177\n",
            "epoch 10 batch id 23401 loss 0.012288358062505722 train acc 0.9728871095252339\n",
            "epoch 10 batch id 23601 loss 0.32313305139541626 train acc 0.9728864772679123\n",
            "epoch 10 batch id 23801 loss 0.012512201443314552 train acc 0.9729029242468804\n",
            "epoch 10 batch id 24001 loss 0.1598368138074875 train acc 0.9729099829173784\n",
            "epoch 10 batch id 24201 loss 0.05207893252372742 train acc 0.9729195074583695\n",
            "epoch 10 batch id 24401 loss 0.08276131004095078 train acc 0.9729352792918323\n",
            "epoch 10 batch id 24601 loss 0.02511030063033104 train acc 0.9729812812487297\n",
            "epoch 10 batch id 24801 loss 0.006466877181082964 train acc 0.9730013406717472\n",
            "epoch 10 batch id 25001 loss 1.1027321815490723 train acc 0.9729798308067678\n",
            "epoch 10 train acc 0.9729685877466251\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d113c1317db4560938278d7f255995f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 validation acc 0.92626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###학습된 모델 적용"
      ],
      "metadata": {
        "id": "ilS4B8hGyucG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_test = nlp.data.TSVDataset('/content/gdrive/MyDrive/통계청/데이터/test.tsv', field_indices=[7,3], num_discard_samples=1)\n",
        "test_set = BERTDataset(new_test , 0, 1, tok, max_len, True, False)\n",
        "test_input = torch.utils.data.DataLoader(test_set, batch_size=1, num_workers=4)"
      ],
      "metadata": {
        "id": "-AHsWKQd0vWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prds=[]\n",
        "for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_input)): \n",
        "  token_ids = token_ids.long().to(device) \n",
        "  segment_ids = segment_ids.long().to(device) \n",
        "  valid_length= valid_length \n",
        "  out = model(token_ids, valid_length, segment_ids)\n",
        "  prediction = out.cpu().detach().numpy().argmax()\n",
        "  prds.append(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "4deb364ce0c0416f999458cd16b25401",
            "ac777cc3e4e04c9f8a4d84f02904136d",
            "a266ebc8c56940eb979c16457e350fbc",
            "47db2922b59f45edb28a4a20ddb8bb6f",
            "56ef89e2e7ed4068b782b427497d704e",
            "e7ede203c54c45d2a161907934b58035",
            "6cc3dce2c2494b7bb8434f579e72fe8c",
            "0333c48f2d734a4992739d20e81e3239",
            "fc1feef580254e568e9cc21a2633effd",
            "0ec1479258924373811452e082705acd",
            "f9273a86c3c44d7b9fcb23b0e9a3bd18"
          ]
        },
        "outputId": "cbf910aa-d6a0-4a19-8c9f-33b8fe4a9ffe",
        "id": "dDsXK9a30vWF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4deb364ce0c0416f999458cd16b25401"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans = pd.read_csv('답안 작성용 파일.csv',encoding='euc-kr')"
      ],
      "metadata": {
        "id": "7sqpJf6e0vWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(ans)):\n",
        "  ans['digit_3'][i]=prds[i]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daa6539a-5ea9-41d1-ff5a-f591e48279d8",
        "id": "EI7Nmww50vWF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###소분류를 중,대분류에 매핑"
      ],
      "metadata": {
        "id": "Rj-bDAeRyucG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "znYR4_fZ0kGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=ans[:]"
      ],
      "metadata": {
        "id": "ilEofTIr0kTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df)):\n",
        "  l=ind_class.index[ind_class['digit_3']==df['digit_3'][i]].tolist()\n",
        "  f=l[0]\n",
        "  df['digit_1'][i]=ind_class['digit_1'][f]\n",
        "  df['digit_2'][i]=ind_class['digit_2'][f]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae5aa95-ce7a-4f18-9b61-dbc9a078dfd3",
        "id": "HKrsO7t80kTM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:1056: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cacher_needs_updating = self._check_is_chained_assignment_possible()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1287ade7-faa3-4c73-a076-99d3fde0940c",
        "id": "UHDS0mdC0kTM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           AI_id digit_1  digit_2  digit_3  text_obj   text_mthd text_deal\n",
              "0      id_000001       I     56.0    561.0   치킨전문점에서    고객의주문에의해      치킨판매\n",
              "1      id_000002       G     46.0    466.0      산업공구   다른 소매업자에게    철물 수공구\n",
              "2      id_000003       S     94.0    949.0       절에서    신도을 대상으로    불교단체운영\n",
              "3      id_000004       S     95.0    952.0     영업장에서       고객요구로     자동차튜닝\n",
              "4      id_000005       I     56.0    562.0  실내포장마차에서   접객시설을 갖추고   소주,맥주제공\n",
              "...          ...     ...      ...      ...       ...         ...       ...\n",
              "99995  id_099996       G     46.0    463.0     사업장에서     일반인대상으로      버섯농장\n",
              "99996  id_099997       Q     86.0    862.0     한의원에서     외래환자위주고        치료\n",
              "99997  id_099998       G     47.0    478.0    일반점포에서       소비자에게      그림판매\n",
              "99998  id_099999       R     90.0    902.0     사업장에서  일반인.학생대상으로    학습공간제공\n",
              "99999  id_100000       L     68.0    682.0     사업장에서    대리현대아파트를        관리\n",
              "\n",
              "[100000 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52886cd5-e72d-44f1-b7c3-03e3d768465c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AI_id</th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "      <th>digit_3</th>\n",
              "      <th>text_obj</th>\n",
              "      <th>text_mthd</th>\n",
              "      <th>text_deal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000001</td>\n",
              "      <td>I</td>\n",
              "      <td>56.0</td>\n",
              "      <td>561.0</td>\n",
              "      <td>치킨전문점에서</td>\n",
              "      <td>고객의주문에의해</td>\n",
              "      <td>치킨판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000002</td>\n",
              "      <td>G</td>\n",
              "      <td>46.0</td>\n",
              "      <td>466.0</td>\n",
              "      <td>산업공구</td>\n",
              "      <td>다른 소매업자에게</td>\n",
              "      <td>철물 수공구</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000003</td>\n",
              "      <td>S</td>\n",
              "      <td>94.0</td>\n",
              "      <td>949.0</td>\n",
              "      <td>절에서</td>\n",
              "      <td>신도을 대상으로</td>\n",
              "      <td>불교단체운영</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_000004</td>\n",
              "      <td>S</td>\n",
              "      <td>95.0</td>\n",
              "      <td>952.0</td>\n",
              "      <td>영업장에서</td>\n",
              "      <td>고객요구로</td>\n",
              "      <td>자동차튜닝</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_000005</td>\n",
              "      <td>I</td>\n",
              "      <td>56.0</td>\n",
              "      <td>562.0</td>\n",
              "      <td>실내포장마차에서</td>\n",
              "      <td>접객시설을 갖추고</td>\n",
              "      <td>소주,맥주제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>id_099996</td>\n",
              "      <td>G</td>\n",
              "      <td>46.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인대상으로</td>\n",
              "      <td>버섯농장</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>id_099997</td>\n",
              "      <td>Q</td>\n",
              "      <td>86.0</td>\n",
              "      <td>862.0</td>\n",
              "      <td>한의원에서</td>\n",
              "      <td>외래환자위주고</td>\n",
              "      <td>치료</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>id_099998</td>\n",
              "      <td>G</td>\n",
              "      <td>47.0</td>\n",
              "      <td>478.0</td>\n",
              "      <td>일반점포에서</td>\n",
              "      <td>소비자에게</td>\n",
              "      <td>그림판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>id_099999</td>\n",
              "      <td>R</td>\n",
              "      <td>90.0</td>\n",
              "      <td>902.0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인.학생대상으로</td>\n",
              "      <td>학습공간제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>id_100000</td>\n",
              "      <td>L</td>\n",
              "      <td>68.0</td>\n",
              "      <td>682.0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>대리현대아파트를</td>\n",
              "      <td>관리</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52886cd5-e72d-44f1-b7c3-03e3d768465c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52886cd5-e72d-44f1-b7c3-03e3d768465c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52886cd5-e72d-44f1-b7c3-03e3d768465c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/gdrive/MyDrive/통계청/데이터/제출5_kobertfull10.csv\", index = False)"
      ],
      "metadata": {
        "id": "s6B3kPKI0kTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#앙상블"
      ],
      "metadata": {
        "id": "tZBn1hO1wXVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd "
      ],
      "metadata": {
        "id": "hI-OO66Q10uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans1=pd.read_csv('제출2_kobertfull5.csv') #가장 높은 val acc\n",
        "ans2=pd.read_csv('제출3_kobertfull7.csv')\n",
        "ans3=pd.read_csv('제출1_bertfull3.csv')\n",
        "ans4=pd.read_csv('제출5_kobertfull10.csv')"
      ],
      "metadata": {
        "id": "-hKVZ1OowbH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1=[]\n",
        "for i in ans1['digit_3']:\n",
        "  m1.append(i)"
      ],
      "metadata": {
        "id": "4fY0YYsC3FHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m2=[]\n",
        "for i in ans2['digit_3']:\n",
        "  m2.append(i)"
      ],
      "metadata": {
        "id": "VYJlfkzK3aCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m3=[]\n",
        "for i in ans3['digit_3']:\n",
        "  m3.append(i)"
      ],
      "metadata": {
        "id": "Mx7pf0BJ3cQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m4=[]\n",
        "for i in ans4['digit_3']:\n",
        "  m4.append(i)"
      ],
      "metadata": {
        "id": "7DKTDNxa3gwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble = [] \n",
        "\n",
        "for a, b, c, d in zip(m1, m2, m3, m4): \n",
        "    if b==c==d :\n",
        "      ensemble.append(b)\n",
        "    else:\n",
        "      ensemble.append(a)\n"
      ],
      "metadata": {
        "id": "MBXdvXh-sL0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(ans1)):\n",
        "  ans1['digit_3'][i]=ensemble[i]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w3ot9YM37lf",
        "outputId": "59ce515e-7907-4fbe-b4d6-5683fa87e546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind_class=pd.read_csv('산업분류표.csv')"
      ],
      "metadata": {
        "id": "t28nFE774Wu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_class=ind_class.drop(['digit_4','digit_5','type_5'],axis=1)"
      ],
      "metadata": {
        "id": "7_R4Clkv4Wu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_class=ind_class.dropna(how='all')"
      ],
      "metadata": {
        "id": "lBeEyqtK4Wu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_class=ind_class.fillna(method='pad')\n",
        "ind_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "41983341-f118-48be-c9b6-1a5511c52523",
        "id": "hikLBq844Wu2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     digit_1  digit_2  digit_3\n",
              "0          A      1.0     11.0\n",
              "10         A      1.0     12.0\n",
              "17         A      1.0     13.0\n",
              "18         A      1.0     14.0\n",
              "21         A      1.0     15.0\n",
              "...      ...      ...      ...\n",
              "1181       S     96.0    969.0\n",
              "1192       T     97.0    970.0\n",
              "1193       T     98.0    981.0\n",
              "1194       T     98.0    982.0\n",
              "1195       U     99.0    990.0\n",
              "\n",
              "[232 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85a06935-afac-4185-8719-bcd0d6d77cd1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "      <th>digit_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1181</th>\n",
              "      <td>S</td>\n",
              "      <td>96.0</td>\n",
              "      <td>969.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1192</th>\n",
              "      <td>T</td>\n",
              "      <td>97.0</td>\n",
              "      <td>970.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1193</th>\n",
              "      <td>T</td>\n",
              "      <td>98.0</td>\n",
              "      <td>981.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1194</th>\n",
              "      <td>T</td>\n",
              "      <td>98.0</td>\n",
              "      <td>982.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>U</td>\n",
              "      <td>99.0</td>\n",
              "      <td>990.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>232 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85a06935-afac-4185-8719-bcd0d6d77cd1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85a06935-afac-4185-8719-bcd0d6d77cd1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85a06935-afac-4185-8719-bcd0d6d77cd1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=ans1[:]"
      ],
      "metadata": {
        "id": "W5y0w1ln44iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df)):\n",
        "  l=ind_class.index[ind_class['digit_3']==df['digit_3'][i]].tolist()\n",
        "  f=l[0]\n",
        "  df['digit_1'][i]=ind_class['digit_1'][f]\n",
        "  df['digit_2'][i]=ind_class['digit_2'][f]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40fcb1cc-933a-47ea-dbf8-53ac35fbe1a5",
        "id": "8ANVgXTI4Wu3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans = pd.read_csv('답안 작성용 파일.csv',encoding='euc-kr')"
      ],
      "metadata": {
        "id": "3-sMshsS4Wu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans['digit_1']=df['digit_1']\n",
        "ans['digit_2']=df['digit_2']\n",
        "ans['digit_3']=df['digit_3']"
      ],
      "metadata": {
        "id": "N6izDfLC4Wu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "outputId": "449095c4-911d-418f-f71b-b14261ddb960",
        "id": "NB7USvT04Wu4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           AI_id digit_1  digit_2  digit_3  text_obj   text_mthd text_deal\n",
              "0      id_000001       I     56.0    561.0   치킨전문점에서    고객의주문에의해      치킨판매\n",
              "1      id_000002       G     46.0    466.0      산업공구   다른 소매업자에게    철물 수공구\n",
              "2      id_000003       S     94.0    949.0       절에서    신도을 대상으로    불교단체운영\n",
              "3      id_000004       S     95.0    952.0     영업장에서       고객요구로     자동차튜닝\n",
              "4      id_000005       I     56.0    562.0  실내포장마차에서   접객시설을 갖추고   소주,맥주제공\n",
              "...          ...     ...      ...      ...       ...         ...       ...\n",
              "99995  id_099996       A      1.0     11.0     사업장에서     일반인대상으로      버섯농장\n",
              "99996  id_099997       Q     86.0    862.0     한의원에서     외래환자위주고        치료\n",
              "99997  id_099998       G     47.0    478.0    일반점포에서       소비자에게      그림판매\n",
              "99998  id_099999       R     90.0    902.0     사업장에서  일반인.학생대상으로    학습공간제공\n",
              "99999  id_100000       L     68.0    682.0     사업장에서    대리현대아파트를        관리\n",
              "\n",
              "[100000 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e7797bb-d549-4581-a202-46d3839b1ba7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AI_id</th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "      <th>digit_3</th>\n",
              "      <th>text_obj</th>\n",
              "      <th>text_mthd</th>\n",
              "      <th>text_deal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000001</td>\n",
              "      <td>I</td>\n",
              "      <td>56.0</td>\n",
              "      <td>561.0</td>\n",
              "      <td>치킨전문점에서</td>\n",
              "      <td>고객의주문에의해</td>\n",
              "      <td>치킨판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000002</td>\n",
              "      <td>G</td>\n",
              "      <td>46.0</td>\n",
              "      <td>466.0</td>\n",
              "      <td>산업공구</td>\n",
              "      <td>다른 소매업자에게</td>\n",
              "      <td>철물 수공구</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000003</td>\n",
              "      <td>S</td>\n",
              "      <td>94.0</td>\n",
              "      <td>949.0</td>\n",
              "      <td>절에서</td>\n",
              "      <td>신도을 대상으로</td>\n",
              "      <td>불교단체운영</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_000004</td>\n",
              "      <td>S</td>\n",
              "      <td>95.0</td>\n",
              "      <td>952.0</td>\n",
              "      <td>영업장에서</td>\n",
              "      <td>고객요구로</td>\n",
              "      <td>자동차튜닝</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_000005</td>\n",
              "      <td>I</td>\n",
              "      <td>56.0</td>\n",
              "      <td>562.0</td>\n",
              "      <td>실내포장마차에서</td>\n",
              "      <td>접객시설을 갖추고</td>\n",
              "      <td>소주,맥주제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>id_099996</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인대상으로</td>\n",
              "      <td>버섯농장</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>id_099997</td>\n",
              "      <td>Q</td>\n",
              "      <td>86.0</td>\n",
              "      <td>862.0</td>\n",
              "      <td>한의원에서</td>\n",
              "      <td>외래환자위주고</td>\n",
              "      <td>치료</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>id_099998</td>\n",
              "      <td>G</td>\n",
              "      <td>47.0</td>\n",
              "      <td>478.0</td>\n",
              "      <td>일반점포에서</td>\n",
              "      <td>소비자에게</td>\n",
              "      <td>그림판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>id_099999</td>\n",
              "      <td>R</td>\n",
              "      <td>90.0</td>\n",
              "      <td>902.0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인.학생대상으로</td>\n",
              "      <td>학습공간제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>id_100000</td>\n",
              "      <td>L</td>\n",
              "      <td>68.0</td>\n",
              "      <td>682.0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>대리현대아파트를</td>\n",
              "      <td>관리</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e7797bb-d549-4581-a202-46d3839b1ba7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e7797bb-d549-4581-a202-46d3839b1ba7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e7797bb-d549-4581-a202-46d3839b1ba7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans.to_csv(\"/content/gdrive/MyDrive/통계청/데이터/제출fianl.csv\", index = False)"
      ],
      "metadata": {
        "id": "aUGRC3fK5F7_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}